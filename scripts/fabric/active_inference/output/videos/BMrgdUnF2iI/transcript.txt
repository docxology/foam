hello and welcome everyone this is ACM live stream 56.1 it's November 14th 2023 and we're continuing our discussion series on these four papers by Alexander aoria at all welcome to the active inference Institute everyone we're a participatory online Institute that is communicating learning and practicing applied Act of inference this is a recorded and an archived and a published live stream so please provide us feedback so we can improve our work all backgrounds and perspectives are welcome and we'll follow video etiquette for live streams head over to active inference dorg to learn more about projects and learning groups at The Institute well today in 56.0 we're bringing out all of the four Entre and we'll see where we go with these big topics and with Alex here to discuss so we'll begin with intros and go from there so I'm Daniel I'm a researcher in California and what I would like to explore in this stream beyond the trails that were left in the zero is to get the zoomed in what is the space of these micro motifs and then to compose those zooming ins into the bigger picture what do cognitive architectures look like in 2023 how is that different in theory and in practice than 1983 and then where is this all heading in terms of how we can do useful and important research blue cool thanks yeah I'm interested in the 2043 cognitive architecture also um and maybe exploring the space of uh human cognitive architecture but also like non-human cognitive architecture and what that looks like and where maybe that might take us um yeah that's good Alex um all right uh yeah I'm Alex Suburbia uh and I am the director of the neural adaptive Computing laboratory and uh computer science assistant faculty Professor here at RIT in computer science I'm also affiliate professor in Psychology uh soon to be affiliate professor in cognitive science and affiliate faculty in computational Neuroscience kind of a mouthful of different involvements but I I do a lot um yeah and uh I i' i' I've known about the active INF inference Institute before my some of my students are fans of the channel already um so it's very exciting to be here to talk to you guys and I think that you have uh some really good questions and I I think this uh set of papers that you picked is a nice uh little pathway through some of the thinking that I've done over the years uh what was funny when I was watching the zero is uh and and again I also noted this to uh both and Daniel and email is that uh I thought oh there's these other papers that I've written that would have clarified or could have so very easily this could have become like a why don't you do 25 different papers and you know I I I think that might have become quite a burden but uh uh some of my bonus slides that I I know Daniel told me I didn't have to make any or it's not typical but I have some slides taken from some pieces of those other papers that uh might have might give some clarity uh to some pieces of your guys questions depending on which ones we start with uh and you know this and the dot two of next week so again thank you for having me this is very exciting awesome I guess to begin how did you get into cognitive Sciences or cognitive modeling oh okay the history the origin story right uh yeah it's interesting so when I without going into too much and spending too much of the podcast on uh one's own life story uh when I I I started out in computer engineering or computer science and engineering when I was a young undergraduate um and you know I even came from like a background of Art and Digital Arts which is kind of interesting I had learned a program late in high school um and uh then I'm entering in uh Bucknell University was where I went for my undergraduate education and uh it was really strange I did not do much I actually did not know at all of machine learning let alone uh cognitive models or computational Neuroscience it was more of that strict engineering education however uh I like to think that something that I did which was I'm a philosophy minor philosophy of mind is what I studied I like to think that's what biased me and kind of launched me to where I am today uh so I was always studying things like Consciousness also ethics and other aspects of philosophy in Greek philosophy but uh philosophy of mind and identity was something that sort of motivated me to think well hey maybe this stuff I'm doing in you know hardware and Engineering I could combine the two you know is there a way to sort of emulate this concept of identity or Consciousness um little did I even know what you know the free energy principle um and uh so then towards the end I worked on complex adaptive systems again nothing to do with machine learning uh however it ties so beautifully especially nowadays over the last year I've done thinking uh and working with Carl uh on the free energy principle and aspects of the markup blanket it's funny how all that construct ties back together and it was like oh that stuff I studied uh years ago wow it comes back into Force full uh into play really really strongly and then uh grad school uh I was in uh Dr cely Gil lab who's actually a very well-known information retrieval scientist and a classical deep learning researcher uh and uh and then I was uh and he was more artificial intelligence uh but that's the reason why I got into deep learning he gave me a survey I was exposed to neural Nets uh he actually said to me years later the reason he gave me that survey was to discourage me from going into it but uh uh he he told me he was glad that it didn't work and then uh along the way uh this is the part where I would the cognition comes in I was co-advised by a cognitive psychologist Dr David Ryder at Penn State who uh also worked a lot with another well-known cognitive scientist Dr Frank Ritter who is he himself was advised by Alan Newell and her Herbert Simon so some of the greats of our time in cognitive science and classical uh artificial intelligence so I was in the applied cognitive Sciences lab as well and so between those two worlds uh I think that's what sort of solidified me to saying hey uh there's these big problems in machine learning particularly with credit assignment so I don't know I'm pretty sure you guys are familiar with these Concepts in one form or another uh but credit assignment is just like when we're doing back propagation on a big neural network we want to play the blame game how much does this neuron contribute in a positive or negative way to some cost function and for some some reason uh that always felt at odds with me because along the way I worked with all kinds of really non-mainstream models like hopfield networks and Bolton machines were actually my first loves if you will uh that's what I did in my early PhD thesis so that was at odds with what's going on in deep learning even though bols machines were used at the very beginning and then everyone threw them away um and so I think uh those ideas of like memory consolidation and memory storage and the fact that a hot field Network couldn't remember everything actually had very limited storage was awesome to me and I was like I want to probe that more uh can I build systems with this and uh so I was one of the early days working on boltzman machines but like trying to sell them as the thing we should care about um and then towards the end of my PhD so now I'm going to skip around a bit I did work on recurrent neural Nets with Thomas mikolov he's one of my friends uh and then towards the end of my PhD uh I I had somewhere along the line over the years found predictive coding uh my my joke to my grad students is Rish Rous and Dana Ballard's classical 1990s paper on predictive coding and classical effects of the eye uh was something that I I read so many times that I said I slept with it under my pillow to hope that I would absorb how incredible it really was so that paper probably was the strongest influence on why I decided you know what for the rest of my life I'm gonna do predictive coding I think we need a lot of work here because it's again also not a mainstream area it resonated with some aspects of boltman machines for me because I love iterative processing uh and uh and I also read parallel distributed processing by mlen rumelhart Hinton uh Jeff back in the day um so all all of those things kind of sroll together and so that led me to saying I want to do credit assignment but in a biological way so back props got to go it's clearly not what the brain is doing I mean if it turns out it does I'm I'm okay with being wrong at least we explored some other parts in the space that was beyond backprop and so uh I do like the beian brain Theory and the free energy interpretations of predictive coding this is why I'm a fan of aspects of Carl's work um and so uh you know taking that interpretation that came a little bit later I would say once I so after grad school or my PhD I uh got faculty position at RIT um and that's where the free energy principal sort of biased me an active inference a little bit later on actually most of my students in my lab if at least two of them that promis they would watch the stream they both work on active inference so uh uh so we talk a lot about that or read a lot of these papers um and then of course very recently have I finally gotten in touch and uh and I collaborate now you know I would say rather readily Now with uh Chris Buckley who's well real really well known in active inference Carl uh in and free energy stuff um you know and and and Rish Ral was on the survey so it's really great the if I actually did not give you in blue Daniel that big survey uh that I recently worked with uh Thomas so salvator and Anor mly but uh we have this big review of predictive coding over the last like three plus decades and uh Carl's on there Rish Row's on there Chris Buckley's on there Thomas uh is on there so there's a lot of really nice names and they're really great people and it was crazy when I got to talk to Rish Ral just as I told you earlier I slept with under the pillow with you know his 1990s nature paper so to actually meet him in where meet him in Zoom was rather incredible it was actually it was a fun experience uh to get to ask him even the questions I've always had on the tip of my tongue and so anyway that uh that sort of is what molded me uh and uh the cognitive science cognitive architecture part which we'll talk about in point two um that was heavily biased by David Ryder and uh Frank Ritter and my discussions with them and understanding architectures like actar and sore which are these older ones as you mentioned I believe Daniel but or or blue like in 198 or in the 1980s and what's the future uh and we can have some fun chats about that as well um so yeah I would say that because of that interesting blend uh that sort of led me to say that uh I'm not just the guy that says we got to get rid of back propop and here's how we do it and oh we let's use the beian brain theory of predictive coding or predictive processing to do that um but rather uh let's use that but also let's look to the common model of cognition which is sort of like the grand Theory or the blueprint theory in cognitive science that I've also sold my soul to uh I was just at uh DC a couple of weeks ago at the uh cognitive science Symposium one of the FSS symposiums for triple AI uh and uh I was talking to Andrea staco and John Lair and all the greats from like the old cognitive architectures or uh brain Imaging and brain science and uh we were talking about the directions where these go so actually if we talk about later the future of cognitive architectures might I might bring in bring some of my thoughts from that really really nice Symposium and uh yeah and I could keep blabbing I don't know if that really completely answered your question as to why but I guess too long didn't read tldr uh cognitive science co-advisor and grad school combined with an AI main advisor in grad school philosophy of Mind in my undergrad strongly biased me with complex systems and I guess I'll just blame boltzman machines because honestly those were those were wonderful wonderful and I still think elegant little models that sort of like said we got to look to things that don't do uh don't work with at least gradients uh with the reverse mode uh differentiation algorithm that sort of characterizes back prop all the credit goes to boltzman in the end always oh and we should give Helm Holtz some love too Bon Helotes and the helm Holtz machines and you know those are wonderful too well blue if you want to begin with a question or I'm happy to ask there was a lot there so I I I could follow up a few times but um um I am interested in um what you said about the hopfield network forgetting and like how you thought that that was perfect and like the most exciting thing that it it didn't like recollect perfectly the imperfect memory um and I I think that that's interesting to me also and that that kind of introduces variance which we see like in humans I I'm a very much like it's all in your mind and like I I like to walk the tight rope between like perception and like reality and like what is reality and um how how do you like when you have a variant um in a system like because it forgot X Y or Z somewhere along the line how do you find like the best variant best variant like what would and then like you know do you go on to selectively refine like refining selective memory and and what would that look like okay so let me ask a clarification question what do you mean by like variant model or variant is in like a deviation that that's maybe some ter not quite it's not triggering something so so like in bi in biology you get you get variant right like so you have like a biological variant but I mean just as in humans like you have 25 people at a party and 25 you have 25 different perceptions and 25 different memories of that party right and so so in when you have like a network that forgets what do you then do with that forgetting like what you know you have 25 different networks 25 different memories like how do you select the best one or would you want to and then how do you um like what what do you think could be the outcome of that why is that so exciting that you have selective memory in a a network okay um so I now I I understand now what you're asking um to unpack that a little bit briefly to answer why I thought hopfield networks were so cool or so exciting uh and just to make sure that was clear was the fact that they could only had like linear storage capacity so as obviously you could actually calculate I think it was even there's in a formula with respect to the dimensionality of the patterns you can actually say how many memories I can store Vector patterns especially binary patterns yeah as I see the diagram being pulled up here uh before things start to getting corrupt so I think that that was fascinating to me because uh I guess I had assumed that you could just store lots and lots and lots of information these networks right and the fact that memory can be corrupted uh it is a very humanlike quality right we forget things as you've brought up now blue in your in your comments uh and I think it's a it is a humanlike thing but it also highlights and again it later I would discover catastrophic forgetting in deep neural networks which isn't really quite at least in my view humanlike in the way that it happens in machines where and by the way for the audience that may may or may not know catop forgetting it's like you train on neural network on one task to predict cats and dogs and then I move on to airplanes and trucks and I learned to predict that and then I say hey by the way can you tell me if this is a cat or dog and it it gets like zero percent it just it's abysmal performance that's not quite like a human because the joke I tell also my students is um i' be like oh as I learned to play the piano I forget how to breathe uh that doesn't quite work um so I think now tying that back so that again is like motivation and actually have like a bonus slide to say like future directions this is like one of the things that I've been working to try to resolve uh with biological models the hopfield network was interesting in boltzman machines uh by extension because they are just hop field networks with Laten variables I like the concept of attractors so when you when you build like a hopfield network you know the idea is that because you're learning with contrastive heavy and learning which was also the algorithm that really caught my attention I love that idea of just hey I find equilibrium I run my model for like a certain phase I compare it to some clamped phase and then I just do a big subtraction you get heavy en rules out of it that's like one of the central reasons to I liked heavy uh sorry hopfield networks and boltzman models but these idea of having these attractors and space where if you could figure out your optimization landscape usually it's an energy landscape with a a hot field model uh we are ping the data let's say templates even or representative aspects of data at these little pins that are saying these points in the energy landscape or what I'm going to remember and patterns that look similar so I guess this might kind of slightly address your comment on a variant so variant as in like variations to particular memories if I meet someone or I have certain attributes and a vector this would fall into this dynamical attractor right which again would fall into this energy landscape I really like that interpretation of how memory works because then it's not just me storing things in a heart array right the idea of like let me just store every Vector I've ever seen uh because now you have this problem of capacity uh and then again how do I build the and you know there's some value in modeling things in that way so this isn't a criticism of any neural models in that regard but I like the dynamical attractor kind of point of view which again then you can connect it nicely to free energy and say oh it's your free energy functional and I just walking along my landscape to plot my memories in there um so I think that's what fascinated me was the energy based interpretation uh and then again uh boltzman machines and restricted boltzman machines also known as harmoniums uh they have this beautiful kind of energy- based functional interpretation and they too are recollecting patterns right by this you could say a dynamical reconstruction but it's really just like I'm clamping noise and I'm run running this until I reach equilibrium and that sort of rep retrieves from my memory some particular element of life right some something I've experienced in my Niche uh and I pull out that attractor or I basically am just saying how similar I am to that attractor and then of course later on there's been a lot of more efficient work and then there's criticisms of bols machines but um so I think like that's particularly why I found them specifically fascinating um I'm stop myself there I don't know blue if that was scratching at least that some type of answer to your question that was great thank you earlier you mentioned this Grand cognitive science framework kind of the general cognitive model so how do you pursue that or where do we place or enumerate all these features of diverse intelligences like memory but clearly just in your answer there's multiple implementations that are nonoverlapping of memory almost to the point where it's like what what can you really say memory even is so what are those core pieces and how will we know or assess that we have the relevant even um continents sketched out for for worthwhile pursuit of of anything other than just an abstraction well I mean wonderful question complex question and you know I me I'm not the only person I mean I'm just but one small voice right that you know should speak to that I think all of cogn all the great cognitive scientists I've even just met in uh the short span of my life uh have some interesting differing thoughts so I think just to clarify what you said Daniel the grand kind of blueprint theory that I'm referring to is actually well known there's some nice papers I can try to pass them on to you and blue if you don't already know of them it's called the common model of cognition and uh by the way it is not the only way you can build a mind uh it's just the one that resonates the most with me um and so I just want to point that out it's not again just like anything there's no such thing as a silver bullet I would even venture to say that there's probably a no free lunch theorem that applies to cognitive science just like I teach it in machine learning uh so there's probably no one cognitive architecture because I think I think blue said it but you might have said it Daniel about modeling things that are not necessarily human uh which I think could have generalize to animal cognition but it could also even I was my brain weirdly enough went to alien cognition right things that are not even of uh you know planet Earth maybe there's other types of intelligent organizations and I do believe that that there is probably more than one way to build an an intelligent computational entity but with without getting into that also potential can of worms um the common model of cognition I think to sketch out what you said lays out the continents of the mind to use your word uh the reason I like it is that it sort of is like a synthesis the when you read the paper uh they themselves at the time this was now years ago that the original common model of cognition uh paper view paper came out and they looked at things like actar SAR Sigma I don't know if they looked at like for example they might have looked at versions of Randall O'Reilly's work he does a lot of really nice stuff like Libra the Libra architecture I don't remember if that was in there um and other variants of course I don't think they had uh like Chris Elias Smith's group at waterl who does who did the work on spawn you might have heard of nango which are like spiking nural model toolkits uh spais and Spa Daniel if you want to write that that way because there's like a science paper that he had years ago that came out about spawn um but they looked at maybe not those specifically those would be like the updates uh but they looked at particularly the first three that you have in your uh in your notes there and they they synthesiz these architect said what are commonalities here what are they trying to model um and I I sometimes I misuse the word brain regions but rather it's more like functional uh continents I'm going to borrow your terminology Daniel of the brain and they kind of chop it up into saying well what are the grand pieces of computation that goes on and let's see if I can distill it from my own limited memory uh you know we have our motor functionality our motor cortex we have perception uh and of course now I of course have added my own addendums to that where you could break up perception into modalities like audio visual uh and then of course all Factory and touch and taste and all these other elements elements that maybe we don't model very well but we'll leave that again also as a separate discussion and then the parts of memory so we have for example procedural memory then we have declarative memory and we have working memory and those are kind of like the big big kind of groupings of all the other things inside of there there's different types of memory that you could start partitioning up um and so like declarative memory would be like fact-based knowledge or world-based knowledge could also include episodic memory which is kind of blobbed into there uh and I've done some work on modeling episodic memory because I do things with active inference as apply to reinforcement learning so of course you need you know at least a a type of Replay memory to sort of refresh your you know statistics I'll leave that vague for now and then you have working memory which are again this could be a bias on my end because I have studied things like actar but they're like buffers so I think of working memory as not just this one module but rather many little tiny occurrences of this module and they are the glue that helps transmit information between various continents in the brain and then we have procedural memory and procedural memory is really interesting to me and I think it resonates really strongly with just because again we're you're the active inference Institute and I have done research in active inference so uh because I remember a question you had Daniel on point Zer you said where's the action uh then later you guys answer that question actually but uh just to be clear there's other papers too where I try to show you how to do active inference without even a cognitive architecture with predictive coding if I ever show you these bonus slides we could look at some of that but um anyway and uh procedural memory I think resonates really nicely with active inference in the sense that I put in there it's dumic model so again if we imagine we have perception and we think of that as you know the context of active inference which is usually a PDP partially observable Markoff decision process uh let's assume that marvian assumptions are okay for now I I have criticisms of that but the idea is that we have our input space we have a latent space that's what uh your cores are doing right like the visual cortex is transforming beams of light or pixels in a computer into some distributed neuronal representation ideally very sparse and this is again I know blue is very interested in uh my uh my aspects of sparsity which is something I'm obsessed with uh and I think we all should be obsessed with because that's very biological uh and then uh if we put the motor cortex as like well it's going to take other signals and that's where the action comes in Daniel so like for example motor cortex is GNA take information from probably information processed in the cortices maybe information queried from various pieces of memory uh transferred to the working memory and then they'll do something and then we'll get our our signals whether they come from another part of the brain like the prior preference part of the brain which is kind of like our you know uh goal oriented signals uh and then the part that again to go back to the procedural memory the Dynamics model that lives in there the way that I've been modeling it and I do this in COG engine but also I just do this in my robotics work too uh is that that's kind of living in latent space is trying to guess the next state the sparse distributed state of predictive coding circuitry and with that it's saying oh I'm wrong uh you get the basis of an epistemic signal right and that's how you encourage foraging right because exploration is like to me my view is the Su the real Crux of active inference if you don't have foraging you don't have this uh epistemic kind of signal to drive you to be curious about the world I uh you know I know you guys have talked about curiosity um but also the uh prior preference in obviously plays a role because you could either incode goals and if we're doing RL we sort of do it like oh well we could use the reward function or maybe we train some prior model but uh the other way to look at that is that's where also like homeostatic constraints could be uh you know embodied uh and that's the stuff I'm doing with Carl now I'm G to have a a nice big paper that's about to come out once I finish applying some of his edits and it'll basically address that the the life aspect of this but put that aside uh because it's another can of worms lots of can of worms to avoid um and then the last piece of this puzzle is inside procedural memory uh there's the basil ganglia which is another structure I'm very obsessed with uh that in the prefrontal cortex and these particular constructs in the brain uh they do many things I mean the basil gangle is often you know uh you know cited and studied for like dopamine application and reward injection uh that's where the reward signals come and you know I've often used that interpretation but another thing and this is why uh Andrea staco who's at the Symposium and I really enjoy talking to him has done a lot of study of the basil ganglia he has put in his work and he has found neuroscientific evidence of it being like an information routing system and that to me is a humongous uh tool for tackling catastrophic forgetting because the way I see it is if I have this neural structure that is responsible for deciding what task I'm in the brain or what pieces of information should play a role in the task that I am doing uh it's like suppressing regions of neurons and exciting other regions so it also induces sparsity to tie back to varsity at the the the most extreme level right it's like turning off parts of your brain and saying this is Task dependent and the prefrontal cortex can be argued to do some of this too I haven't modeled that specifically but I've seen other people do that uh but again the basil gangalay was one thing and so I have work on that that you guys aren't also talking about but again I've already thrown too many papers at you but uh focusing on just like oh can I do information routing with some basic predictive coding circuitry um so I think that that sort of big glut of uh of speech that I just threw at you guys sort of gives you an answer Daniel as to like how you would why the common model of cognition uh is so nice is what I just explained was uh I just used their blueprint I mean they didn't say the the the mechanics and the active inference part that's my twist to it right oh can I reinterpret com model of cognition through free energy the answer is well I've bet everything I have on that idea um and then you know and I teamed up with someone Mary Kelly at Carlton University uh and she works on for example uh manura 2 memory and Hyper Vector symbolic structures and holographic memory and Hyper vectors and that's where even though I know uh hot field Nets that's kind of another world that you know they sort of intersect so we we put that in there too but I don't you know that's maybe we should save some stuff for point two um but uh the what I what I just explained is I walked you through the blueprint which was very vague it just said we should have these Grand continents uh and they might do certain things they have like little arrows in their diagram about information that's transferred what modulation is going on uh but then they leave the implementation level kind of vag right the ideaas it could be whatever you want you could implement it even classically like in the 1980s with you know production systems and if then statements yeah this is a good diagram actually um you know yeah you can kind of see all some of the key aspects of memory here uh and again too what's nice I took from common model of cognition and uh I do have a slide here I keep saying I have a slide maybe I'll show you one just so I can prove to the audience I do have them uh you know the idea is that the action element the active aspect of active inference common model cognition also speaks to right it says well we have to have a motor cortex uh it doesn't tell you what to do with that motor cortex except that it's going to you know produce some motor command and then you know it will transmit to the body uh and will leave embodiment as another thing that's another can of worms that I have been trying to address and inactiv ISM which is your Niche and how that relates to this but let's just zoom in on the the the architecture of the mind and it has all these components so the way I Envision the future just to tie this to another question to make sure that I'm not just blabbing but keeping us you know uh you know useful uh is that I think the direction we're gonna head or should head I don't know if everyone else will follow that is that you want to build these biological cognitive architectures um rather than just okay you know let's rely on a production system like we do an act art which is valuable I have it's not really a criticism of that because maybe the level of modeling you want to do is I want to encode this knowledge it's a lot more intuitive sometimes to encode in like if then statements and logical statements as you did in classical architectures you can interpret it easier um but the part I think that uh we really need to push for is how do we get that type of behavior that type of self-organization uh without me hardcoding this knowledge right because again it gets to expert systems and good oldfashioned AI uh we kind of don't want to be doing that we want to say can we do this in a neural way and then uh the answer I try to jump ahead to is I say by the way don't do back propop because while you could do back propop and there's I think work on people trying to build types of cognitive architectures with that at least it's a better step than uh you know chat gbt and claiming that that solves cognition because it doesn't uh and I I am in that camp uh but we again leave that can of worms somewhere else but the idea is that you skip that and go into something that's biological which is predictive coding uh there are other things you can do I actually am working on other things besides predictive coding uh maybe we can chat about that in future directions if that question comes up um but I think predictive coding and predictive processing offer you a lot uh that you know other algorithms right now might or might not give give you they might have drawbacks um and this could even help answer if the question comes up Daniel if you're interested like uh what aspects of neurobiology does that bring to the table but I also think it has uh the best way to convince machine learning individuals is to explain the Practical elements of it uh because you know a lot of times they'll say well who cares about modeling the brain I just want to build an intelligent system um but you can you can use predictive coding and predictive processing as pragmatic uh type of argument and you can say hey well you get this you get this you get this and uh among those arguments is sparsity but there's there's even more powerful pieces that we could go into I think I'm gonna stop now because that's a lot of information I don't know if if I missed any piece of your question no it's great I'll ask a short question from the chat VI writes can we represent declarative memory with neural network-based technique such as hot Field net was it did you say Viet yes that's my I believe that's my one of my students um so uh yeah he's also works on active inference as well so uh I'm not surprised that he would throw a question like that um the answer is yes uh uh you can actually there's a lot of good work already even without the cognitive architecture kind of structure because again think of the common model cognition is like a blueprint that tells you what things you're going to need to have and how they interact but if you zoom in on one of those continents declarative memory as was pointed out in the question uh for example you can use Vector symbolic structures you can use for example Manu manura 2 memory uh there's a lot better I would recommend faster models which are heavan based systems right you can model heavan memory uh associative memory hetero I ative memory with a lot of these like simple kind of heavy andlike constructs the learning is very efficient as well uh they don't come without the drawbacks but um so the answer is yes and you can model them with I think heavy in networks uh heavy in learning which is a correlational local learning rule uh the other part with the hopfield network you can also do that and it's weird because while uh the work I have currently done said we will do h field networks in our cognitive architecture which we'll probably chat more about that in point to Cog engine uh but we do have plans to do like uh what do you call it modern hopfield networks that's a particular uh instantiation of hopfield Nets that is actually very uh efficiently implementable uh as I've discussed with my collaborator Mary and uh and others like Robert West at carlston uh you know talking about these types of things but uh you can use a hot field Network to sort of use uh to create that dynamical attractor interpretation I was telling blue about earlier uh the idea is that you know it'll have a certain capacity but the problem is is we need to make sure that we have enough capacity because again uh I don't think I ever completely properly answered Blue's question about variance or you know differences between what's you know reality versus what you think reality is and there's some interesting connections to predictive coding that also answer that question um but um the idea is that if you have you know one single hot field Network that might not be enough but I imagine chaining a bunch of these together to create what I call an assembly or an assembl to use one of Carl's words AIDS of hot field Nets I think is one way to build uh a completely neural implementation of declarative memory uh another piece of declarative memory that we did model I won't argue it was the most efficient thing you should do uh but it can be done is manura 2 uh and again that you can look it up it's Hinman and all and uh hinman's old work it's a heavy and it's an approximation of a large heavy End Auto associative memory and uh what we did is we modeled the episodic memory with like a big manura 2 the reason I say it's not a good idea is manura 2 is really slow because it's kind of like approximating this heavan associativity with like a weird Echo query style lookup table uh at least the implementation and even when you vectorize it and put it in tensorflow or you know your favorite linear algebra back end uh you can only get so much of a speed up so for very big memories I don't think that's the right place to do it but the value of what we did is we essentially try to emulate what episodic memory does when you do replay and reinforcement learning right so uh you have to do some weird hacks to make uh the uh episodic memory predict the next thing rather than recall this thing from a corrupted input Vector that's called heter associative memory uh and we did some things with like a window and we said hey have this predict the next sensory or sorry Laton Vector since you know I told you we live in Laten space in uh the cognitive architecture uh maybe predict what you thought the original Act you're taking and the reward and we sort of use that to roll out little streams or mini streams of episodes uh and then we use that to train the modules that are inside the cognitive architecture for example if you do replay you can refresh the Dynamics model you can refresh the motor cortex because again you're querying this episodic declarative memory to say hey remember these little tiny mini experiences um the other problem with manura 2 was that all you can only remember so far into the future so it gets a little wonky and hacky when you try to build like these like little lookup windows but there are better memories out there and I actually my cabber and I have talked about using modern hot field networks as one possible uh construct and they're very cleanly implementable they almost look like Auto encoders which is kind of crazy uh at least from like the engineering point of view and so once you understand that you're like oh I could build all of these and build again what I said earlier assembl loids right or Assemblies of uh these hot field Network structures right and maybe see what those do uh when I want to recall particular pieces of experience so that would be the answer to your question uh I would say I only have some experience with the episodic piece of declarative when it comes to like the world fact graph organizational knowledge I don't have much to say yet I know you can use use manura 2 and Vector symbolic and holographic memory and hot field memory to emulate that people have done that on like for example language tasks um another really nice name and he's done work on I don't know if you guys in the active inference Institute know him Ben Gerel he's you know a premier researcher in okay you know Ben I see you shaking you know an AGI right and he has open Cog and I know that he's done some really nice work on graphs knowledge graphs and there's people that have had discussions with him about neural implementations of that because when he and I have talked and I I also work a bit with him too uh I've said to him you know okay what what would be the like purely neural version of this and there are ways to do it whether it's simulatable uh in our you know Computing systems nowadays I don't know it it can be expensive but it can be done so he would be open Cog might provide a nicer cleaner answer than I possibly could today about like the world fact knowledge in graph organization of how we think about Concepts uh and you know and I think open Cog has some of that answer uh but again I'm gonna speak with that as the final statement and boundary of my knowledge and you know let the audience look into that but I do recommend Ben gertel's work in that area too so Robert West Ben gzel these are some really nice names kind of look at how they either use the common model of cognition or they build their own cognitive architecture and they model certain pieces of this structure uh that have nothing to do with let's say predictive coding because Ben the reason he's working with me is because I've said oh we should do it with predictive coding and he was like that's a great idea uh and so you know hence collaborations get born but U so yeah and obviously and as Daniel's writing that statement you'll notice I'm extremely uh biased but I think with rather good reasoning uh even from a neuroscientific point of view there's a lot more evidence for predictive coding than there is for back propop in the brain plus you can approximate back propop with predictive coding if you squint at it and make the right theoretical assumptions in the right way so uh obviously I'm going to say everything should be built with predictive coding um and then also the beautiful thing and I Know Carl will like this if he ever watches this is uh you know then you can also State it's uh it's optimizing or minimizing a variational free energy and we can derive where that comes from and it's a it's a beian model right and so you have this basian graphical model interpretation uh it's a really really elegant framework too so that's another strength I think of predictive coding I guess I am the market man for it now but uh but I I I really do believe in it and uh it's it's served me well over the last I mean I'm coming up on almost almost a if we count grad school almost on a decade of working on on this and uh and I do think predictive coding is at the Forefront of where we need to go uh if we want you know biological humanlike even uh machine intelligence and I'm gonna stop there too because I don't know if there's more questions I can keep going very easily yeah it's awesome very um encouraging certainly you lay it out differently everyone does but you lay it out very differently it's actually very rare to start on a high road it's not exactly the high road laid out by the free energy principle but this kind of approach to cognitive science which is like let's sketch out the functionalities and then drill in that's how a big tent is built because it clarifies that there's all these different implement ment ational techniques none of which can be all things in all settings and then another another piece that that the work holds up is what's biological when after all the neural network is the great great great grandchild already of a cell type and so what what is modern and biological and then it just made me think about how there's the pure biomimicry which is usually like if somebody were actually interested in studying that system to resolve some pathology or just to do natural history and that's one sense that we might be doing biologically inspired computation but whether it's leaving the door open to our alien colleagues or developing new synthetic intelligences we need something that's both biological but also novel and then this leads to consideration of well what are the fundamental constraints other than the histor vity of the life forms today with two wings or six legs or whatever they may be what are the real features and that's where we complement those fundamental attributes identified by the common cognitive model like memory action selection and perception where those come together with like local processing only and then also some more potentially aspirational things like low energy compute and other features so these are just some big topics and it's kind of like come work on it these are the challenges because they're laid out the challenges are not esoteric at all oh we've either known about some of them for a while and just never resolve them or or they're becoming more pressing in today's day and age like you brought up the energy compute part right and Energy Efficiency and you know we global warming regardless of whether or not you want to you know accept it is is upon us uh and uh we have the problems of even even in AI there's this thing called Green AI versus red Ai and I've written a little bit about this in some of my papers as a motivation uh to looking to biology because you know the brain is regardless of its you know own limitations every biological system has you know trade-offs that it has to make but uh it is an extremely energy efficient system and it's an example of beautiful parallelism uh as well as low energy compute and if we could get even just a little bit of that in our systems today that would be huge so I think that's a nice uh motivation of course I also work in well I know you guys talked about one of my papers spiking neuron Nets which gets us into neuromorphics and neuromorphic Computing uh and I think there's a lot of really nice Hardware uh in silico that's out there that we could take advantage of uh but the key is finding the right algorithms that we could Implement there uh and carry over the best of all the worlds right the best principles uh that our software simulations and mathematical arguments make uh but then instantiate them in you know you know let's say a memoris crossbar uh and you know and I've worked and talked with different people uh including Intel's Lo ship you know and I'm not saying that that there's many different ways you can build these constructs and and I know that because I've I've watched some of Carl's chats with you guys and talked with Carl about this is also I do think the biological chimeric implementations is like a really cool area I'm a huge fan of uh organoids and uh and organoid intelligence I I think that that's a humongous Place uh that's like a new frontier almost uh given like smirnov's work and a couple other people and uh I think that's where like these ideas of predictive coding and the computational models we build are valuable to even consider in these biological systems either study them and see do they match back to my mathematical theoretical predictions or can we manipulate or engineer them to you know maybe induce similar kinds of compute uh or maybe we'll just see that it pops out maybe they're just doing predictive coding and we're going to see that the neuronal structures emerge and I think that would be fascinating uh a quick point I want to add and because I see blue raising her hand so I just want to mention that the thing I like about my interpretation of predictive coding and it's not only my own it's just that I carry that forward is predictive coding as I've talked to people is interpreted in a lot of different ways like in Psychology predictive coding kind of has similarities but it's not quite where I work which is the mechanis IC version of predictive coding and it's interesting I think you can borrow those worlds like hey the the idea of predicting error and feeding that back in or matching discrepancies you know in our memories you know that's a beautiful concept and that's you know what psychologists look at cognitive scientists kind of see things in that way um biologists and neurobiologists might sometimes talk about predictive coding but they they might not necessarily mean it like in the concrete ways that uh my work which was inspired you know by Regis Rous and others uh you know to say let me build you the exact mechanics and the Dynamics and I think that's important to get right uh I am even though recently I'm getting a little more philosophical which I love and theoretical uh and in talking to Carl and others and Ben uh there's this engineer in me that cannot divorce away the very specific Dynamics and the not just the mathematical like oh the ordinary differential equations but how does that get implemented efficiently because I think that's what lies in the future is the marriage of these kind of highlevel theoretical mathematical philosophical Concepts their mechanistic description which is what like predictive coding says hey one set of neurons tries to get another set of neurons firing rates or their activities and we can feed that back in and you can repeat this Motif and build very beautiful constructs like what I try to do in cognitive architectures or little PVP systems and then we also have the spikes right how does that compute happen at this very fine grein level and then how does that get put onto a chip and then I think the other piece that then I'll shut up is uh the connection to the niche uh I think it goes back to the body and you can't ignore the body and I have a lot more to say about that that but I'm going to bite my tongue for a little bit because I want you guys to read that paper maybe we'll have another chat in the future about it uh Carl and I have really thought very deeply about this the role of the body and that has nothing to do sometimes with neurons or at least not the neurons that we model and then the niche itself and how does that have a role and then I know you can go into and I know all the cognitive theories like extended cognition embedded cognition how do other agents and cultures and tools play a role uh the extended uh theory of mind because I I I did study that as a philosopher so I think like all those parts are gonna those all need to be reconciled and build this kind of framework and I think Daniel you're right you can use blueprints like the CMC as a stepping stone and I think that that top down way is a nice way but then you also merge it right with all this bottom up it's it's kind of like you're doing predictive coding but in the scientific realm right you have this top down kind of Direction you want to fill but then you have all this mechanical low-level stuff that you really can't ignore if you want like Energy Efficiency and where do they meet in the middle so it's a bottom up top down which is beautiful because it it repeats the the metaphor of biology and I'll stop because I see blue it's time to let someone else speak you did it so you really like stole my thunder there oh sorry about that I have a lot to say sometimes it's okay no no it's perfect so I really wanted to ask about the role of the niche and especially like in when we're talking about like Energy Efficiency and predictive coding and the compute power Etc like I think about um like what makes us efficiently able to do cognition and it really is like cognitive offloading into the niche like the internet the phone like click click click now I know this right and then even like with non-human systems like ants like leaving pherone traces in the environment that convey a ton of information as to where to go and what to do and so how can we then bring the efficiency of cognitive AR Co cognitive offloading into cognitive architectures that we can then leverage for increased compute power with very little um you know effort on in terms of like the actual compute so the answer to your question is extremely hard right it's a Grand Challenge if you will um I would say that the right path and I these things are okay for me to share because thankfully uh they're not all of my invention uh so to think about how other agents and other tools could be efficiently used to allow our own agents right our artificial agents to achieve their tasks you do need to now finally answer the question of the body and the question of the environment and I've been thinking a lot about this and let's just assume that you can simulate it that's another issue and of itself but you pick your world right so let's say I'm going to so okay actually I'll pick I'm gonna start with my body I'm gonna do a quadruped robot right like you know what is it big dog or spot right the little robots that are out there and that's going to be my my actual morphological construct the body in which that I'm going to manipulate it now that body let's assume that I have access to all aspects of its physical mechanics okay and it's artificial hardcoded routines because robotics have a lot of like automated procedures like you're not going to necessarily need to manipulate every piece of the arm you know you're going to use like take advantage of inverse kinematics and other algorithms that allow you to say I just need to move this point and the rest of the arm will kind of coordinate around that and that is an offload of what the neurons need to do or the neural compute let's say organized and I'm a fan of common mod cognition so let's assume you build your little brain from the CMC point of view that's going to again not worry that much about the fine grain mechanics of the pieces of let's say the quadrupeds front right arm right or front left arm it's going to offload because it knows that as long as I tell you I plan to move this piece of my you know I don't know joint in this direction the rest of the arm is going to fall along you've already now done embodiment which is embodied cognition which says the and I'm I'm on the extreme end there's like spectrums I've studied in cognitive science uh there's uh the body kind of influences the mind then there's isolated cognition brain and EV that and then there's really strong embodiment which is the body does a lot and the Brain kind of just says hey let me send you a little control signals to manipulate you so that's the embodiment now we get to the niche and by the way so I've already started to answer your question because I picked a body you're going to need to commit yourself to a construct which by the way means you're not as general as you would want to be but it gets you a chance to answer the question because now you say quadruped now you say what's the niche where is that quadruped going to operate and I don't know I'm gonna pick something really simple uh outside my office there's you know some hills and some grass and some trees uh and I'm going to specify this little world uh maybe I going to design some way of recharging that robot's batteries you know because obviously we need to create some type of Life Giving Force some resources uh for this to look for and I specify other properties of my environment now I've specified my Niche now I've answered concretely the exact world that my quadrip is going to operate so now I know the inactive cognition comes into play right because now I have to interact with the physics of my world it's going to manipulate the robot it's going to damage the robot the robot's going to have to respond to this uh so remember under the hood is like a CMC neural predictive kind of neural construct it's offloading a lot of its cognition to the body the body says oh I'm going to also take advantage of sensors that I can read in my environment I know like I don't want to be maybe in a very hot area that starts to you know interact badly with certain properties of the robotic construct and then to now get at the answer to what you said about other things well in this world I should also and I I think there's some work in I cited it in the one paper that's going to come out uh uh about uh like tools you have to specify what are objects that are manipulable so you need to Define your affordances and by the way this is again defining the niche I think it's really important not to just say oh I'm going to throw it in any environment and we'll just it'll work somehow you need to define the properties of your Niche to some degree because that's how we can also experimentally analyze and and study what's going on and you say what are the affordances what are things that I can do what properties of environment am I able to manipulate that I let's say even want to that could help you model this uh and then you introduce other quadrip heads with the same exact underlying cognitive structure because let's say we're not going to do heterogenous uh multi-agent system so you know I introduced a couple other spots right which are also operating under the same principles they minimize a variational free energy inside the common model of cognition they have the same you know roughly uh you know artificial dynamics that they can offload to their robot bodies and they could work together right they could create herds right they could have herd Behavior or group Behavior because maybe now they're going to find those Port charges or whatever the resources is that I allow them maybe there's maybe they're solar powered I don't know and they have solar panels and they need to collect from the sunlight but obviously if it rains they need to hide and so you can now say those Dynamics those groups now they interact maybe one of the spot Bots found a good area and this is a really good place to exploit their prior preference which is you know to survive hey I Want More Energy I need to just continue living right because I think life is the the place you have to look uh they they don't want to die they don't want to terminate so they're going to work together to do that so that answers the embedded part right because the embedded aspect of it is the cultural and this is an approximation I'm not g to claim that a a a little herd of quadruped spot Bots right are going to have a society I I I don't know that's an emergent property perhaps but they'll have some means of communication and that way allows them to organize themselves as their own little system you know in their Niche and then of course because we specified the affordances and properties in the environment that you can manipulate you have extended cognition right because these tools allow them to better survive better find those areas that for example allow them to charge their batteries or you know collect Sun at the right times and avoid damage from the world you know when it's raining or when there's inclement weather and again I'm kind of like vaguely describing a very Comm complex Niche you could really experimentally control it maybe make it a lab and you know you have artificial blocks and charging ports and maybe you could kind of simplify this a little bit but I think that's where that doesn't like give you the exact answer because you know if I had the exact answer I probably would have implemented it and we would have solved AGI right but I do think that's the pathway to answering your question right it says if you want to even have a chance scratching at the answer of efficient uh uh interactions with the environment using objects and tools to solve problems and offload your cognition to these uh let's say non-neural non-biological entities or these non-living or non uh let's say planning entities I Know Carl talked to you guys long ago about the difference between like well the environment's also its own system uh but it doesn't plan but it's you know subject two thermodynamic constraints and the en and the uh entity itself is also you know that one is different because it can plan so there's like a little bit of like you know its own ability to change it act outcomes with planning his inference um so you could kind of like use that as your starting point to say I need to define the niche I need to define the body then I need to define the organization of the brain structure that goes into that body because you you do need to have the neural part we're gonna if we're interested in modeling let's say very high level cognition and behavior and how does that interact with the hardware and that's another question and of itself that you know I'm I've been thinking about and I think with all of that you get a chance to now simulate do experiments uh and actually see how does that efficient interaction emerge right what can we study aspects of embedded cognition right into this little uh experimental Niche and agent niche and Collective agent Niche setup that I've constructed so I think that's like an interesting place that I would this is where I would go right and I'd love to go if I had resources but uh you know these are that I think that gives you a chance to begin to answer that question and then it will tell you what's wrong with a lot of things too because I think it'll say you're you're GNA quickly especially if you just even pick the body and you're doing ody cognition you say uh hey wait a minute this neural construct let's see back propop right uh it isn't working very well right because why I need to unroll in time I need a time machine to do back propop with time based data um but predictive coding doesn't really need that right oh probably that might be the right neural structure for the brain uh because now it interacts with my robot Hardware which has very limited resources you have very limited memory and compute that you can run with so already there you've now manipulated your software you have now co-designed the hardware and the softare where a little bit to interact in the context of this morphological construct your body and because you've you've also Define where it's going to operate you also understand what properties of the environment you need to be aware of maybe you can build that as an inductive bias into the system because we don't want to play Evolution because that's usually how you emerge these systems but I don't know if I want to wait doing genetic algorithms for you know whatever simulated thousands and thousands of years so maybe we need to build those inductive biases as well and that's another interesting research area and I think now I'm I'm digressing so I'm gonna stop there it's great again again sorry oh just the the pathway is clear and in fact this is even in some ways an anti-reductionist pathway that actually starts from the bigger context you stepped through specification of the niche in the context getting to the embodiment including the extended embodiment phermones and all of this with a niche like each time you step through then to the brain and the body then into the multi-agent and then that is where the evolutionary and the ecological Dynamics kick into play Eco evoo is going to pick up once there's like a population even if it's an in silico population that has resource constraints or it actually is a materialized system um then the ball's rolling and it either persists or doesn't it's like a landing strip for our efforts and and a organizing principle for our research whether we're like just beginning to do cognitive science research and thinking about going to grad school or something or trying to recap on this flurry of development over the last years of being aware for a long time um it's actually a to me a mark of the advancement not just like how fast or performant the systems are but how many index card type agreements or ways of coordinating that we have we have the common model we have of course AC infant free energy principle which we've barely talked upon we have this kind of General agreement of the structuring of cognitive systems and then that organizes otherwise what would be essentially arbitrary unlimited information because the scope of cognitive Sciences is so vast that having a some of these categorizing strategies a as part of our recall system is part of it and then that's an interesting question about jump starting it and what do you bring to zero what do you bring to the table and then were the agents with our tools that are building other agents and tools and all of the like reflexivity and also relevance that comes along with that yeah I like that summary go on and on and on about I even have different names for these things but uh I want to there's a little bit of Thunder I can't steal just yet uh but I will ping you guys I I have a couple of people in mind about sharing a manuscript I've been working on for for a many months at this point and uh it this is related uh especially the relationship between neurons the body the environment and Beyond and how that all ties together so this is stuff I've been thinking a lot about so it's actually timely your questions are great I didn't know we'd get into this part but uh you know that that's it's fun and uh there's more to the story too there there's other but I want to save that Thunder yeah three maybe maybe you could have me on about that paper if you ever read that but uh you know that's a different different thing 56 Never Dies um exactly he doesn't leave leave us alone or like a sequel like a one paper a one paper sequel because I will say like four four papers was was challenging and I don't think we've really like we we've skimmed the surface of of each paper but like not even you know there's there's so so many interesting threads to untangle in just what we've talked about here um and like are you sure you don't want to go into Evolution um are you sure I'm not opposed to it I think the problem is space source is blue yeah no I I don't know that genetic algorithms is necessarily like the the way or the means like that that I mean but I I really am curious about like unraveling maybe alien cognition like what does that look like when I really start to think about like what is the most different kind of cognition that I could imagine what is the most different from my own like I really think about plant cognition and then like act of inference becomes kind of problematic because you know they they like they're really limited they have a really restricted like course of action right um but but I think about like what you know how how plants have evolved and how they've co-evolved with humans like and how they've you know they produce all these lovely things that we like to eat and they produce things that alter our own cognition you know so so like they can totally drastically influence our information transmission Pathways and and I I really think about what does that cognitive system look like or what is it like to to be a plant or to have a memory that looks like a plant memory right all of your memory is essentially chemical like or evolutionary and I think about that in terms of like why like evolutionary memory might be important um and across species and across you know evolutionary time like not necessarily evolving through genetic algorithms but but what does that evolutionary memory start to look like I mean it's a great question uh I I've only I well I don't have any work of my own well I have worked weirdly enough with by the way I will say I have worked with neuro Evolution uh actually you guys had I know you know the the ant colony paper uh optimization with Abdul Ramen and Travis right I was in the audience and I chimed in and talk to about active inference uh uh so I I have hedged my bets a little bit you know to look at other ways of doing things so I while I did say I sold my soul to predictive coding and common model of cognition I guess it's not completely the truth because I do look at other things but uh so but I do think that it's interesting blue that you bring up about things that are not human or even maybe animal like right because there's also animal cognition which is there's some differences um so when you go into something like plant Evolution it's interesting because there are there is work as I have found again I I want to say it in a way that again I don't steal too much thund from this one paper I'm like like it's on the tips of my tongue you know and it's like I got no no hold hold it's almost done I gotta finish the edits put on archive and then we can all chat about it um but there there is a dressle of plant cognition and let's like you said alien cognition or just let's say non-human cognition and uh I can this works existed it's wonderful work to read have you guys heard of the uh life mind continuity the thesis uh by kirchof and others they're also heavily influenced by Carl and free energy I they might have even worked with him I I sometimes because Carl's everywhere uh but uh with with that in mind uh I like the lifem continuity thesis because it IT addresses a lot of things that have emerged from evolutionary psychology biology uh even like work that touches in the world of Michael Levan's World which car also worked a lot with uh and uh these ideas that there is cognition at the plant level or organism level you can even go simpler like by the way that's hard for me blue to imagine I've been studying them uh not physically but you know theoretically uh you know bacterial organisms right or you know even like eoli is a wonderful example of studying Its Behavior it to also andise is very energy uh it opens the story to other things which is also what inspires this work that I've done very recently with Carl that I keep teasing everyone about but it's it is I promise it will come out uh but all of these things have cognition but they are not cognitive in the way that humans are so there's like and I've long thought about this ever since uh I was you know studying philosophy of Mind as a young undergrad uh now of course the the thing in when I was very young was about Consciousness and Consciousness is very big world with a lot of implications that I have to be careful because there's been philosophical theories forever and everyone has their holes that they need to fill and then there's flaws and I don't want to go into like Thomas Sagel or dennit concepts right now but um you know I always thought well animals are conscious and plants are conscious they're just not conscious in the same way there's degrees of Consciousness and the reason I brought up the life mind continuity thesis is that it sort of talks about like gradations or degrees of cognition and cognitive functionality and as you go from because and I like this premise I think it's an important premise and since it's published work from them I it's not like I'm stealing any Thunder now it's already out there and you guys even are nodding so I know you know of it um you have the neurons and nervous systems which evolved a lot later in you know when you look at the picture of life right and so what was below that what are things that are more foundational because other organisms might not even have nervous systems and yet they do beautifully complex things they elicit beautifully complex Behavior Uh even doing photosynthesis in a plant is beautifully complex if you study the details uh and it's you know it's also an alien way of which they get their nutrients right we don't do photosynthesis uh you know and so it's a completely different Evol evolved behavior and so Michael Levan and other researchers not just Michael but like others have this thing called basil cognition which is this really really really low-level cognitive functionality that emerges through the memory of evolution so I agree with you blue you can't completely ignore the role of evolution in fact it's another piece to the puzzle that you sort of have to somehow account for and that's where the life mind continuity thesis goes in the opposite direction it says uh we have highlevel cognition our complex minds and brains we also have simple minds and brains and it's not like all of the sudden there's this hard discreet flip switch where you say all of a sudden there's a brain and then there's not a brain it's like no plants do have a brain just not the brain in which we have a brain right and it's not a nervous system it's you know these evolved biological constructs that you know have emerged from their primordial biochemical soup of Evolution uh to then allow them to for example uh manipulate their structure in response to the weather and rotate and move towards the light right to better conduct photosynthesis you know and their growth mechanisms and so their very simple Behavior obviously the plant's not going to get up and walk and figure out oh I I know I want to attack this other plant right that's more high level Behavior although we can come up with really cool science fictions about it but um you know that level of behavior is cognitive it's just basil cognitive and so that gives you what's called a simple mind or even just a mind in a different part of the spectrum and so how do we account for that um I have some thoughts and I don't want to steal that Thunder but there's also the role of evolution they talk about evolution in a life mind continuity thesis and how you actually can't get even the complex Minds to emerge without a memory that is evolutionary right so that's where you have an Aggregate and so that leads you and uh the engineer in me gets a little uh anxious about this premise uh but not because it's not the right path it's rather my ability to contribute properly to it uh because there's only so much you can do which is well now you do have to think in collectives right you can't just model the individual anymore you do have to have many IND individuals and you need a population to then induce some type of evolutionary process because you need what kof and they say in the Life mind continuity thesis is a selection history you need the selection history it can be through the evolutionary process maybe there's other ways to do it that they didn't say specifically uh it's just what biology does and that's what gives you the submergent behavior right to create for example the plant cognition that we observe uh and of course you know the very long chain that gave rise to the evolution of you know apes and primates and then the humans from that uh and so you have that selection history so that means we need to model populations in you know the processes of which they evolve um I the the reason I said the engineering me gets anxious is it's extremely my world complex to computationally simulate just even one agent so and when I do evolution and I've done neuro Evolution you usually simplify the little agents even the ant colony the the paper that you guys talked about well that was a really beautiful example of emergence and other really neat things uh those anti agents that cans as my colleague talked to them they're very simple they weren't even neurals let alone a common imagine running a thousand common model of cognitions and that's not even enough to do the evolution scale that we want so that's where I I say oh um and again knowing that that might limit what I could do and researchers like me that go on this pathway uh maybe the other solution is okay well uh I'm just going to figure out what the inductive biases would have been that were evolved from the evolution and I'll just skip the evolutionary phase however that means you could be wrong you could have gotten the bias wrong right so you just say well I need something so I'm gonna go from there because I'm not given a supercomputer to do the simulations that I dream of doing I have a GPU you so I'm going to build my little agent and I'll and I'll just say when blue you criticize it and you say well you know that could be the right why is that the right bias I'll say oh it's probably wrong but you know it does give me these behaviors you know so if we had the right Behavior plug in my agent into your simulation framework and I'd love to see what happens so yeah and I'll stop there so is this where sparsity then comes in when it becomes like too computationally intensive in terms of like you know evolving a million little tiny creatures or maybe this is a a a good time to talk about sparsity I mean oh first of all oh I see you put a a link here in the chat I didn't yeah yeah so if you want to see a plant walk around watch the MIT so so the MIT media lab has made the what's it called L Len um anyway yeah if you want to see the plant walk around I've shown this before but they the plant will move there's a little plant robot so wow okay I have to read about this yeah it's cool on the plant topic I I I brought in these papers from 2017 with friston and CVO on predictive processing in plants and then uh paper from ' 89 with silver town and Gordon making essentially the exact same points in a broader behavioral setting it's just like wave after wave of the realization that there are diverse intelligences over different spatial and temporal scales and the same things that people remarked upon looking at a piece of grass cracking up through the concrete now is being instrumentally unified with the most advanced cognitive modeling that we have and and also Mike Levens work certainly is to that point you made a great point also about intelligence accelerating Evolution and on Mike Len's YouTube channel there's actually a series of very good discussions to that point um Evolution trial by error and selection and pruning and then Quantum intelligence basically just teleporting you and getting to the solution without needing to Traverse the entire landscape I'll read a question there's a little bit of Chris Fields there too right his Quantum and I know he and Carl have been doing the quantum version of free energy and marov blankets yeah yeah and the course that Chris provided at The Institute over the previous months has helped put a lot of things more in a Quantum footing but that's a super exciting Direction um I'll read a question from the chat can there be self-regulation of ensembles of noisy oracles without intelligence if so it would be extremely helpful for a robot mind so it can discount components that are malfunctioning okay so maybe repeat the question one more time so I make sure it's a little bit of a loaded question it's so is aren't they all of course yeah I think I need to parse it repeat it one more times make sure I get it right can there be self-regulation of ensembles of noisy oracles without intelligence okay yeah the without intelligence part is a little bit of a curve curve at the end but can there be ensembles engaging in distributed regulation seems like yes that was the sparsely connected hop field system that you described so I think I think the key I I wish the there could be a clarification about Oracle right because that's usually something you ask for an answer right you know but I guess if it's just to say oh it's like a sensory reading or a hey I need to query this part of myself right of my morphology or my body and I need to understand what's going on and I say hey tell me and you give me the answer if I interpret it that way and not maybe some other interpretation uh yeah I would agree I think I think our discussion has lend itself to the implication that you want ensembles I mean I I've said this already are assemblies right I've said even earlier when I was addressing some comments for blue and uh vit's question I believe was part of this piece about how you implement memory um even just even classical work on like autoassociative and heter associative memory back before even like talking about hot field Nets like oh I have a matrix and I can update it with some heavy and learning and outer products of vectors um and what I remember when I was studying that is that they said well you wouldn't use this one little Matrix as the memory you would actually stitch together an assembly of them right and so that's how you get this complex Behavior because you know even in biology all the ranging up to nervous systems to modules and structures in the brain they are these like self-organizing systems of parts and relationships between those parts right and we can interpret them as dynamical systems and there's a lot of nice little Frameworks we can apply um so the answer to that or the general gist to that question is yes you could build robotic systems because I think that was the kind of the application area um and would you get things like fault tolerance or would you get for example if a part of the robots morphology or body is damaged with that I think that that would be the right design Paradigm right that would be an appropriate design Paradigm to construct it where you have like a distributed form of intelligence these uh you might not it might the I think the nature of the assembly might be important for example it would probably be semih hierarchical or heterarchical in nature uh Carl's done some really nice uh theoretical sketches of like uh Markov blankets of Marco blankets which uh I I will just borrow this question in that statement to address a piece of something I forgot to say to Blue in our earlier discussion of the body and the niche and the neurology or the neuron neuronal constructs is the I also think it's going to be important going forward to embrace again there might there are other ways to probably do this but I do like the Markoff blanket formalism because it partitions uh the states of the outer world the internal States and dynamics of the system which is very vague but it leaves that on purpose and then you have sensory and active States as your blanket right your little Marco blankie um and I think you need to specify that uh and that will give you the notion of like okay well there's the theoretical body and then we need to answer the question on how to physically instantiate that so that was just a quick thing I had in my notes I wanted to make sure I didn't forget to say that so I think that's another piece of that puzzle you need to uh Embrace that and then there's other Arguments for it but that just something quickly and now that goes back to the answer to the question is that you would want to construct uh you know a cognitive system to manipulate the robot let's even leave the common model and predictive coding because those are just other tools that you could use to construct your brain uh but rather think of like the nervous system of the robot and think of it as I want a Markov blanket of Markov blankets right uh and markco blank it's a Marco blank and you can keep doing this recursive nature where now you have your little atomic unit and that markof blanket kind of construct right is your Oracle right it has its own internal States and that map to some physical component of the robot I think the part is that now you are no longer just saying I abstractly modeled the robot in the software sense but it actually is grounded in some physical component uh Hardware property maybe a particular piece of the robot and then you model these with these little markof blankets and then you have macroscopic or a gradually increasing macroscopic level markup blankets that allow you to say well now I have this organization but the internal states of the higher level Marco blanket are you know these other Marco blankets that have their relationships and that goes back to my biased background in complex adaptive systems because what do you get out of that you get what Herbert Simon and some of the greats of our time you know in the past you know talk about heterarchical partially decomp posable hierarchies right and you build these beautiful complicated systems of control right you have top- down modulation because the upper level markof blankets are maintaining their internal States and there's dynamics that we should probably figure out how to model that I'm leaving the engineering side of this out uh because that's an interesting question of itself um and then those Dynamics and those relationships and laws between those higher level units well they affect those lower level units right because those lower level units upwardly cause the emergence or the existence of the internal states of the upper level markup blanket but the rules of the upper level Markoff blanket uh downwardly cause this this is directions of causation modulate and shape the behavior and interactions of those lower level modules so I think the answer is yes you could do the uh assembly and the noisy Oracle well noise is always a part of it because you know for example physics we always have a thermodynamic exchange with our world there's always loss of heat entropy must go up even if we are an open system uh and the entropy within us goes down the entropy of the entire system of the niche and the agent uh must go up because you can't violate the second law of Thermodynamics and I think that when you consider that you're GNA have this and you're also going to have in uh what do you call it um imperfect sensors right and you're going to have noisy sensors I guess that's where the noisy Oracle comes into play because you're not always going to have a perfect reading and you're going to have to make decisions based on that that's where the uncertainty part comes into play uh the Precision waiting mechanisms of active inference and free energy come into play um and then how do those Dynamics change when for example a part of my system fails right I do think that that's a a viable pathway or a design Paradigm for constructing I would even not don't even need to worry about the common model part the nervous system right of the robot do we just build you know that complex interaction which is neuronal right uh but we're using sort of that hierarchy or the uh recursive Markov blanket formulation to design this and you can tell I like markof blankets because they are a nice little entity that tells you what's going on so I don't know if that was a useful enough answer to the question but yeah great I I'll just note two key pieces first in terms of what does free energy principle and active inference offer in alternative or in addition to these other Frameworks a very clear principled articulation between the math and the theory and the implementation which is already there in the common framework but then to actually separate out the discussion of how to structure the Markov blankets and generative models from the micro implementational message passing on Factor graphs and these features that can improve the componentry as a capacity building work while Blueprinting can be Blueprinting rather than kind of needing to build the blueprint on the ground which is always going to end up with like an overly bespoke setting and then also like even when we are seemingly talk about a single mind whatever an individual would be we are really always talking about the relationship with the niche the multiple agents similar in different types and the whole life cycle and then you said that kind of like made you nervous or something as an engineer because it's like when you want to think about engineering the car not not a car engineer but one account would be to focus on the car on the freeway driving and everything working but then actually the real systems engineering of the car is the supply chain on through the recycling and all the different ways that it can interface with things that are outside of the control and so to just build a cognitive model that is like in silico or just has this kind of like inward perfect gaze it may be an interesting project but then to engage with the messiness of the worlds that's where we again go back to biology look at how it's done and then try to accelerate or complement it yep I mean we can learn a lot from biology so H I think that's I think you set it well um we could look a little bit to a paper one of the maybe the first blue you focused on the first paper or h how about just what do you see in figure two Alex how would you describe figure two or if there's another figure from this first paper that you want to describe but just if you whichever one you feel like is the best graphical abstract just describe how you see it I like figure two um there's a couple other nice diagrams in the paper I'm not sure uh so I think this one is a nice diagram I saw you guys go through this I think everyone should watch0 zero because I think you guys did a nice job at least dissecting parts of it and some mizing the the main takeaways um this is just showing you this is now very fine grain you know our discussion I don't know if that was the intent or maybe that's good thing I don't know how the the podcast likes to keep things constrained but uh we sort of went really high level and then philosophical mathematically conceptual uh and then like you said we haven't really talked about the papers but I would say this paper in general is sort of like okay given that discussion now you're back to being the engineer and saying okay where do I start what's my Lego blocks if you play with Legos or little toys and put things together to build a tower I call this a Lego block right this is a computational unit now you could still go further as you guys also did look at another paper called spiking predictive coding I guess we'll save that one for next we next session um which is like the same thing it's just really really uh intricate and that would be what you'd put on neuromorphic chips so this is like okay I want to build a little Circuit of neurons and I want them to relate to each other and that's what like figure A1 is trying to tell you it says that would be sort of like your network in what's called prediction mode and uh the idea is that like the little two dots the gray dots actually in general are what are called State nodes or just the neuronal units and the reason I call them State nodes is is very different than deep learning uh or at least most of deep learning where these units always exist that's kind of a this this goes back to maybe the earlier part of our discussion uh this paper is what I would call mechanistic predictive coding right it's saying I'm not just telling you the principles of oh error and I bounc it around and I somehow form Impressions it's like okay how do I build this and what would a neuronal model something actually in your brain maybe a a little group of like six neurons how would they be related to each other or you know maybe you're looking at it a little more abstractly but uh this is supposed to describe cortical structure specifically but I like to think that this Paradigm repeats itself and almost everywhere in the brain there might be other ways of doing things so in figure A1 the little two dots the two cray circles in Z2 those are just like okay I have two neurons so I have little regions and those are Layer Two then there's these other two gray circles in one called Z1 those are another set of State neurons and then we have another set of neurons z0 and that's at the bottom so those are the actual physical neurons and they exist all the time uh and what I mean by that is that we simulate their Dynamics this is why I keep saying neural Dynamics is that they're emulated through like an ordinary differential equation right so you have maybe an initial condition which is just the number that you put inside each one so these this model and this paper still has some biological constraints that oh they are modeling roughly firing rates if you want to say that uh so these are like rate coded neurons uh my spiking implementation and my my generalization of predictive coding uh tries to say well maybe I'm not interested in modeling Spike rats I want to model the spike trains and this is a stepping stone to that you actually understanding this and understanding those ordinary differential equations that govern Z ofl which is like Z2 Z1 z0 um you kind of just modify them a little bit and you outp spike trains which is like really cool and uh and I have slides that mention this a little bit but maybe I'll use them next time since we're we're you know we're going over I'll just play off you guys and the the material you have here and so Z2 and A1 is predicting Z1 and what do I mean by that well Z2 I just told you has numbers inside each of those gray circles right it has at a particular snapshot in time they have a firing rate right and it's just represented by a number a scaler and they emit a prediction using those black diamond arrows that are like kind of connecting to E1 we we'll talk about E1 in a minute but those little black diamond arrows and I have you know like terminology for excitatory and inhibitory neurons just to tell you oh when do you subtract and when do you add but let's just forget about the math because if we get in the math that takes a while and I've found confuses people especially on these uh types of presentations so just imagine those scalar values inside of Z2 are being transmitted along those black diamond arrows down to Zar of one that's what that little bar I think you can kind of see it in your in your Visual and that's the mean of a gausian distribution because what the model that we're sort of constructing is we're saying every local set of neurons they are driving like a car the uh car of a gan multivariate gan distribution and so I embrace uh more of a let's say a a Frisian kind of view which is that we're going to learn in this case somewhat of a hierarchical gausian model and so Z2 makes a prediction of the mean and that's what Zar one is in the paper and you can see it in this diagram but it's not like super clear there's also a Precision Matrix or a covariance matrix because a multivariate gan is defined by a vector mean and then a square symmetric Matrix for covariance you know parameters and it's kind of like it lies off to the side it's like lateral connections really and they are what those weird little Diamond Open Diamond Connections in E1 are that's the Precision weights if you will or the covariance weights um and so between those you multiply the mean by the Precision weights which is like a lateral competition not even competition it's more like a lateral pressure and then you're done you've made a prediction from Z2 to Z1 Z1 right I told you has numbers inside of it right because again these neurodynamics exist at every snapshot in time so E1 is what is known in mechanistic predictive coding as the eror neurons and we we're making other biological simplifications we could discuss them later for there's criticisms but uh Ean says okay I also have two little diamonds these orange diamonds and I need two of them right because Z2 has to predict Z1 which has two nodes so it needs to have a dimensionality of two and I need one era neuron to compare each Dimension so there's a mapping of one to one there's a biological criticism of that but for computational purposes it's good so we're going to go with it and Z1 each Dimension is compared to each dimension in Zar one and we can emulate this very simply as in the paper you can take derivatives of a free energy functional uh but at the end of the day you do all the math and it comes out to be a subtraction Z1 minus Zar one that's it so that's called a mismatch signal and that's sort of emulating in a very very simple way uh you know what what's known as like The Superficial pyramidal cells in your brain which sometimes are argued to do like these mismatch computations uh that's kind of one one interpretation of them and the idea make sure that I actually wrote that down make sure I didn't get that flipped yeah no I'm right yeah yeah the superficial and then the the state neur ODS are what are called Deep excitatory pyramidal cells so these are you could almost argue I'm using a lot of pyramidal cells but they're just neuronal units uh that's just the bio interpretation and that's pretty much it so E1 Compares zbar One to Z1 and now you just repeat right so Z1 would be guessing the activity of z0 which means it emulates z bar R of Zer which is the mean of the gausian of the layer below and you know you'll have a Precision Matrix you'll have a set of eror neurons but the calculation just repeats and that's pretty much it you have now a canonical predictive coding circuit um this the the interesting piece of this is this is very similar to like regish Rous model uh except it's not applied to image patches it's just applied to sort of the vector space directly um that's what parentheses one is it's like the prediction mode and then A2 says okay you made those predictions by the way Z1 sorry Z2 predicting Z1 is made in parallel which is a beautiful property that I want to emphasize right now to Z1 predicting z0 by the way z0 in this case you would clamp those numbers to a data point so for example like I do in this paper and I know you and talked about it last time uh pixels of an image right um and maybe by the way you can change the distribution I will add a quick caveat that the bottom layer is actually a multivariate bermi distribution because I'm modeling binary pixels but it doesn't really matter just pretend everything's gausian because it's easy to visualize for the audience um and so that's prediction mode those things happen in parallel notice that the prediction z0 bar does not depend on any except Z1 so for free you get something that's already brain likee which is a kind of answering a question I know you and bluee head about like what do I get from this right what do I get it's kind of like what do I what does predictive coding bring to the table you get layerwise parallelism for free and that's a really nice property because if you can you know emulate that you have multiple gpus or CPUs you have a a performance cluster uh you know you could now actually do literal parallel ISM whereas deep learning you have to kind of like run a for propagation pass everything is locked into sequence this is parallel now the problem with that is now you have to do message passing which I know you guys are familiar with it so I don't need to maybe go into so much detail but that's what two is it tells you how to take the messages at E1 and EZ which are error messages right they tell you how far off was the prediction made to the thing I wanted to look at and then I backwards transmit that information along a different set of synapses which is sort of what makes neurogenerative coding a little bit unique uh we talk about this in my survey as well uh compared to Rish ral's model and even Carl's older models uh which are essentially you would just take the transpose of the weight Matrix for Ford uh prediction uh but that's not biological because we don't don't reuse synapses there is no evidence of the weight transport problem which is I go back along the weights that I transmitted for it the brain is really recurrent uh and so I embrac that uh and so you have a different set of synapses you can call them feedback if you want but I call them error synapses it doesn't matter and that's what those little diamond or sorry dashed open circle uh lines are doing is they are taking the little diamonds uh the orange diamond values and they are backwards transmitting them to a particular layer and it's usually back to the state neurons that made the original prediction and then the last piece of the puzzle if you just want to understand why are what are those uh dashed solid diamond ones well those aren't actually synapses they could be uh they are just basically oh let me take the era message and let me subtract it and this is how you get top down pressure because you need to have bottom up top down pressures at every layer of neurons and so this is where that message passing happens that one step right now I've only shown you one step Z1S Dynamics are going to be perturbed by the message that was passed from the layer below so in this case for Z1 it's the message from e0 and then the prediction or the reverse of the prediction of layer Z2 which is the minus E1 and that's what I have the equations in the paper and I could show some slides that walk you through these steps if you want maybe next time uh but uh the idea is that that happens at Z1 by the way all the layers of neurons do this as long as they're not clamped to data because if you clamp them that means you fix them to a set of values that you're saying well I know what the data is I don't need to infer it so I'm going to put it here um so that's z0 in this case would always be pixels of an image maybe they change with time but but let's keep it static and then all you do is you repeat step one and step two multiple times right until you reach a a a steady state which is one thing you could do which is how many times do you repeat that well you reach equilibrium or you just bound it and you say I'm gonna run this for like I do in the paper a number K you know 10 steps right and what is this doing is it's changing the values inside of Z1 and Z2 only notice I've said nothing about synapses the synapses are just whatever numbers they are the synaptic strengths are fixed at this point so let's say I reach a steady state or I do this for like K times then you make an update to all the synapses so the four the solid uh do uh solid diamond arrows which were the the generative weights and the dashed open circle synapses those are put inside matrices and you just calculate their updates with heavan learning right it's really easy I have statistics paper shows you those rules it's just a matter of product um what is this doing well you probably are familiar with like Dynamic expectation maximization from none other than Carl right and generalized filtering it's a form of that it's just a biological uh manifestation of dynamic em uh in this specific context um when you do things at the spiking level you don't need to wait so long to do synaptic plasticity updates uh I do those online that means Every Step in Time synapses change and you write out their ordinary differential equation we can save that for I think that is actually supposed to be for next time so we can dive into that fun pile of uh Dynamics later and that's pretty much it I mean the little diagram B is just trying to show you oh what do the cells look like so if I just zoom in on like two uh one single state node and one single eror neuron cell you're looking at scalers right and I'm just saying well this is how they wire together and then the so that's just a zoom in if you want if you will if you don't like matrices because Engineers we love vectors and matrices and vectorizing because you can run them on a GPU uh but uh the oldfashioned way in the 80s was scalers and then on the right uh we have diagram C and that's actually showing you all four models that we investigated in that journal article and it's cool because this paper's long by the way so it's funny um I admire you guys for doing four of my papers and on top of them they weren't short little guys either um this paper has a very long appendix I don't know if you found the supplementary material uh that was the reviewers I they had us do a lot of extra things um the appendix actually tells you a lot uh and among the things that it does is it emphasizes something that I think the message kind of got a little tiny bit muted in the main article but that's just how nature is it wants you to sort of say Give me the main thing show me the results all the beautiful math box it up in this nice little corner and if people really care they'll look at it um and so the diagram to the right emphasizes something that in the appendix talks about a naming convention so neurogenerative coding isn't just predictive coding it's like a computational framework that tries to unify as much of predictive coding as I felt that I could in the paper and so that's why the model has underneath there GN cnt1 in the appendix there's like a section that tells you how to interpret why do I use the word gncn what is T1 it means type one T2 means type two and those were refer to the error synapses because you'll see Ral regish ral's name in the model there at the bottom and that's to pay homage because you know I'm a I'm a big buff for historical research and I like to pay credit whereas a lot of people don't uh to Old work because we stand on the shoulders of giants and so as I told you I read a lot of Rouse's work um that model is named after him because it is effectively like the fully connected version of his patch model in his classical nature paper and that is a neural generative coding Network under specific assumptions and so like any mathematici you just say oh I recover this older model because it's a subset of my theory uh and then uh the middle the second model usually it's a little bit similar to regish ral's it's essentially Carl's model from is either 2008 or 2010 uh the reviewers wanted us to implement that and it's not a model mod that many people I hate to say Implement besides Carl so I had to do that and uh it was fun and basically it's just a large piece of it is making sure you get those Precision matrices right because he introduces that in one of his like graphical model papers and so that's why it's named after him uh that pays homage to his classical work and then the uh two to the right are the new models and that's the ones that like for example have separate feedback synapses which is not something that older models directly addressed Carl has mentioned them but he at least the mathematics or the models that of those papers did not concretely tell you how to implement them let alone how to learn them so all of my models all my synapses are learned with like heavan like plasticity and then the last Model the farthest one to the right the reason I like the reason I'm spending time on these is because those are the core models we looked at in the paper the one to the far right just says oh well because NGC is such a broad framework you are not committed to a hierarchical model you could build a heterarchical model or a weird model that has skip connections right and so that's why you see this like weird Arrow going from the very very top layer all the way down to the bottom and so the math in the paper shows you oh I can turn off with these little gating variables uh these weird kind of skip connections that violate the hierarchy but you can still learn them in heavy and ways so the efficiency is all there it turns out that model actually worked the best and so uh there are you guys actually showed in 0 Z the the data samples and those are what I Ed I use the final model the gncn pdh that's like a little compression because when you use a a naming convention the names get really long to a certain point so you're just like well I'm not going to say gncn T2 L Sigma which refers to the lateral connections and the C and the Precision weights and PD I'll just call it pdh right you can just say that to your friends and it's quick and rolls off the tongue um so that that's a little weird naming thing I did and so the nice thing about these models is they they do show you pretty much all the mechanics uh at least visually and then the other piece to this puzzle is you'll notice those gray circles back in figure a also have synapses that I didn't really address those are lateral synapses at the state node level which is also something that you know you know classical work like Rous and friston's models and others don't really use this is something we introduced which encourages like what I would argue extreme sparsity and the motivation for that because I know blue had a question or just wanted to chat a little bit about sparsity so maybe this is a way I'll sneak it in is that uh raal for example introduced sparsity by imposing a CTIC plasan prior which just is basically a pointy distribution over the neural firing rates that just say I want some of these neurons to go to zero and other ones to be high and I want you know as many of them to be zero as possible and that's a useful way to do sparsity it actually comes from Bruno Howen and sparse coding work and I cite Bruno I've met Bruno Howen too he's a cool guy uh you know you can get these activities to be really really really sparse so most of them are zero because zero why do we care about zero not just from a biological Point of View Hardware loves zero zero means I don't compute it so if I don't have to compute it I don't use any hardware resources for it I can ignore it um it's those numbers that aren't zero that are annoying for a computer and so instead of doing a llan prior which I did investigate in this paper and I think I even have the Dynamics in there as well it's like one of the equations um and to be faithful to Ral uh reesh I had to put that in there um but uh the lateral K synaptic connections the state nodes what they do is you uh what we did in this one is we introduced fixed weights because that's the easiest thing to do you don't have to learn them later on I've learned them that's like some future work um and what these these lateral synapses do is they have a it's like a a matrix and they are shaped to be a square uh and they're like let's say the dimensionality of a layer so in the top layer be 2 cross two along the main diagonal are a set of positive numbers or or maybe negative numbers you have to be you have to make sure that the middle diagonal is excitatory and it's called self excitatory which means if a single neuron Fires at a Step in Time its new firing rate is going to be Amplified by its own firing rate so that's called self excitatory or self exitation and the off Di diagonal so the lower and upper right triangle of this lateral Matrix that I'm talking to you about that has to be the opposite sign so I would believe it would be negative unless you wrote the negative sign in the OD then it changes and those are negative numbers and the idea is that those down put a downward pressure and says this neuron let's say in this one element of the column will laterally inhibit other neurons in that layer and the cool part and again it's in the super long appendix of that paper you can find it um that Matrix even though I fix it because I didn't you could try to learn it with like heavy and learning and I later like investigated that um you what you might say okay I'll put some random numbers in that Matrix but wait a minute do I really want every neuron in the main diagonal to inhibit all the other neurons the answer is probably not you could that is a type of pattern what I did is I initialize a masking Matrix and in that Matrix without going into the details of that because it's there's a little bit of an algorithm it just basically says little groups of neurons inhibit each other and no and no one else and so you basically turn off things in that Matrix you fix it with a mask and now you get group sparcity and so the long story short with all of that cool description is that you get K winner take all type uh lateral competition but it's biologically implemented so I'm not like using an activation function and as you go through the Dynamics of this model this Matrix what it'll do is it'll emphasize neurons that are really important for the object that you're processing and it will shut up all the other neurons that aren't relevant right and so this is uh to answer a question I believe it was blue uh in you Daniel we discussing last last week about the results that we had in this paper uh because it's not shown here in this diagram but the idea is that we also got really good classification performance this model has no label right so we trained like a little probe or whatever on the topmost layer and we also showed some TSN plots and the reason I think that the model works as well as it does for something it wasn't trained to do which is discrete categorization of object category like different numbers like the digit zeros the zero category is because of that sparsity and we did measure the sparsity levels and they were really really really tiny the proportion of neurons that were active as you go through these Dynamics especially as it learned is it said oh I don't need a lot of neurons to represent zero so it sort of like extracted out little sub networks that specialize to these templates right so I don't we didn't we didn't exactly probe that hypothesis but that's what I speculate is going on uh and it's also very easy you can justify it uh from the past you can say sparcity is a really important way to do uh memory retrieval it's a beautiful way to fight catastrophic forgetting which is another piece of my work that tries to look at that and the idea is that you're going to get nonoverlapping representations right so you know if we only have a few neurons and a sparse distributed memory semantically if these units activate they're probably related to roughly the same concept and you'll learn as long as you have big enough layers of course this is the thing where you do need like brain level stuff you need lots of neurons uh you'll find that they don't cross talk with each other they don't fight each other so much so knowledge for zero doesn't fight with the knowledge of Two And so you'll have this nice beautiful separation and I think it makes things like classification a little bit easy here it's really nice for fighting forgetting because you'll remember things a lot more until eventually run out of capacity and then you just need more neurons um and it's also energy efficient so the big big argument is if everything is zero except for like a few neurons firing that's a perfect candidate for neuromorphic computing um and then if we can make them Spike which is what the other paper you guys review tried to do uh then we solve all of those weird things because you should only be communicating with you shouldn't be communicating with uh rate coded continuous values which are clean but they're not good for Hardware like a neuromorphic chip or a Meister so that's kind of the general gist of it and I I think uh that's where you get this beautiful benefit of sparsity and you see this nice interaction and you're learning a generative model and of course that paper actually synthesizes the models we look at what samples are produced um yeah and I could keep going on and on but hopefully that that was useful and made sense I see blue is gone so maybe I I I got boring here that was great and a lot yeah it was a lot what do you did make sense it helped me it helped me even after reading all the papers multiple times hearing this explanation still really did help I hope it's helpful for other people too um there's an enormous amount of condensation but you really are laying it out like an engineer how do we build the three-story building what's the wiring diagram of each floor and then you're clearly um striking a fine balance with how much of the mathematics to visually convey versus Explore her and that's why there's appendices that's why there's sequences of papers um what are you looking forward to in dot two or just as we kind of close out yeah I don't know if we went too long I'm sorry if much uh well I mean I'm looking forward to continuing some of this discussion I think uh we didn't really even touch on the convolutional one which is really you could even argue as more of a a to use Carl's terms you could think of it as the convolutional neural coding is a corollary to the neural generative coding framework because it just says wait a minute how do I do image processing in an efficient way um let's do deconvolution or convolution that could be something we briefly touch on next time I'm looking forward to the spiking stuff because I really really love spiking neuronal cells and I don't think he was able to make it but one of my students works with me on Spike time in and uh synaptic plasticity that's driven through solely spikes um so I you know have a particular soft spot for that and I think the future predictive coding at least where I'm trying to lead the crowd is to do things at the spike level because neuromorphic Computing offers beautiful Energy Efficiency we could do Edge Computing so I'm looking forward to some of that chat I also love we sort of borrowed big chunk of what I think you wanted Daniel us to do with the cognitive architecture because we kind of brought all that today I know blue is very interested in that so we sort of front-loaded with a lot of that um so I was gonna say I'm looking forward to that but I I mean I'm always looking forward to chatting more uh I think we front loaded it so maybe we could address more the predictive coding pieces however I do have slides that I'll probably share if you want me to um that maybe talk about other aspects of the cognitive architecture that aren't just the Cog engine but rather like oh I'll show you something I did in robotics uh in a paper at icra this year I could show you some things about how you can make predictive coding do something a little bit more concretely active inference without obscuring it with the common model because I think the common model is like you get kind of lost not you but the audience in general might say oh all these continents of mind and how do they relate well wait where's the active in and I I talk about there it's in there uh I think sometimes it's good to say Let me throw away all that for just a minute because memory can kind of cloud it let's just look at epistemic foraging and prior preference and maybe do something simple like have a robot arm manipulated uh manipulate an object and we could I could talk about that um and also just chatting more about like the future of this I I think that this is I I think what I am trying to represent and actually with dis a lot of discussion with Carl I think I've narrowed down what I what I bring to the table to the fields of cognitive science computational neuroscience and machine learning which is the three the Triad that my lab represents um is this thing called biomimetic intelligence and I think that we need to understand the neurophysiology the bi ology of things and also understand the physics of things and understand how the niche and the body and the neuronal constructs all interplay together to then build technological artifacts that do things like robotics at in an an energy efficient way um and I think this is that path this is one possible Pathway to AGI uh I think it's the path but uh I'm obviously could be clearly wrong uh you know we all don't know until we get there and we have perfect hindsight but I think that that could be a fun little bit of discussion because I know you guys were interested in knowing about the future work that my team has been trying to do as well as the history of those papers which I didn't get to talk about I know blue had said something she was interested to know what was the order of these papers and I had this in my notes so we can we can save those for the next session if you guys want to talk about them or other questions I'm open to anything really awesome yeah this was huge it really it's a tour to force of cognitive science and engineering so I hope the people enjoyed it looking forward to talking next week if you're watching one now and you want to join next week this may be possible and thanks again see you and thank you thank you for having me we appreciate it see you bye take care