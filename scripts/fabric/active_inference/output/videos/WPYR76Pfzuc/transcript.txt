hello it is September 23rd 2022 and we are in meeting four for a cohort two of the active inference textbook group we're having our first discussion of the chapter two of the textbook so before we jump to the book and assess where things are at with questions does anyone want to provide any overview thoughts or experiences that they had like while reading or rereading chapter two just overall anything about chapter two there's a lot of math okay blue thank you anyone else okay we have this questions table and none have added any questions specifically for chapter two or if someone did and put them somewhere else just let us know these are really important we hope and expect and prefer that people do have questions while they're reading the text and this is a really essential learning practice and it helps improve our epistemic niche it also contributes to Future cohorts and future Learners when we can have again every single kind of question from the directly related what does this word mean here to the tangential every kind of question that people have it's a huge service to actually just add several of them to this table so we don't have any for today and that will free us up to give an overview of chapter two walk through it and uh kind of connect a few dots perhaps and then it'd be awesome in our second discussion of chapter two for people to have noted down a few things that they were curious about including during this discussion people can add directly or like write down somewhere else and add later um but this is like a really important way to structure our learning individually and collectively so um we're going to go into chapter two and walk through it paying attention to the formalisms and also to a lot of the work that has been added through the math learning group and through various people's efforts to improve the um legibility of the math because it'll be like either a first coat of paint or a refresher for truly everyone so everyone's going to be approaching this and trying to learn the math um in different ways let's start with figure 1.2 this is the high road coming from the top and the low road coming from the bottom chapter 2 is going to be leading with the low road chapter 3 is going to be presenting from The High Road so chapter 2 is going to begin with an overview of Bayes theorem Bayesian statistics and then make its way up through some of these terms described here and reach that kind of common meeting point with active inference before we flip to chapter two does anyone have any just general comments on the low road okay the chapter begins with this quote from William James my thinking is first and last and always for the sake of my doing what does anyone think that means or how does it reflect on them why is it here anyone can just unmute an address or raise their hands Sean I suppose it's making the connection between perception and action there with the thinking and the doing which is important in chapter two awesome as the name active inference would have it there are going to be many connections between cognition and inference and action like the embodiment of Maneuvers in the real embodied world as well as even ways of thinking about mental or cognitive behaviors as actions like attention as action so that will be a thread that continues as we continue to build on active inference the introduction paragraph is first providing a historical View that even qualitative and pre-1900 views encompassed perception as an unconscious inference and as something that was being generated subliminally and updated and then kind of presented to awareness and then um the author's place the Bayesian brain hypothesis as a kind of formal realization of some of those models of perception and action and explain how active inference is going to be extending those ideas by doing several things not just considering perception as unconscious inference um but also considering various other cognitive features like action planning learning as Bayesian statistical issues in how we model them and then by finding approximations and heuristics that help us address problems that might other be otherwise be intractable um perception as inference here the Bayesian brain perspective is brought up and does anyone want to like add anything that they've heard or what the Bayesian brain kind of brings up for them foreign key feature of the Bayesian brain that they're going to point to is how it contrasts from a kind of outside in signal processing purely recognition based model so we could think of that model as being descriptive statistics and also being compatible with frequent statistics like we're getting kind of a blurry picture out there and then we're gonna do um descriptive statistics frequentism and get some sort of sharpened realized image like the camera filter is a little blurry and then we're just going to post process the image and that's going to result in the final image so it's outside in um in contrast and this is not novel to active inference this is being described as part of the Bayesian brain hypothesis perceptions not a passive outside in process it is a constructive inside out process in which Sensations are used to confirm or disconfirm hypothesis about how they were generative generative um the way that that plays out in Bayesian inference is with kind of a tale of two densities density being another name for a statistical distribution is like a density and the tale of two densities was a paper Title by ramstead at all it was an early live stream that we did and the two densities are like the forward and the reverse model which are used in Bayesian statistics as well as expectation maximization and other algorithms and here's what those two densities are there are the density of observations that's like the observables in the sensory States and then there's another density which are like latent States or hidden states that generate those observables so um if we were looking at a red ball then there'd be like the visual sense states of the location of the ball and then there'd be like a hidden stay of the location of the ball so thermometer giving us readings of the world and then the temperature in the room which is an unobservable and so we can take thermometer data and we can use that to fit a temperature hidden State and also from a given hidden State we could use a generative model or what is sometimes referred to as a forward model two generate predictions about observations in contrast with descriptive statistics which is taking in observables and kind of distilling them and then saying well the mean was 11 and the variance was 4. if that's the end of the road for that modeler that's the end of the road but the Bayesian approach says okay we've got a mean and a variance and now we're going to be able to generate data with mean 11 variance 4. so that's the tale of two densities is the way that these two um generative processes and a recognition model are licked to operationalize that a little bit more the state of the Hidden variables a priori meaning before is called a prior the prior is then going to be updated by observations and depending on a few factors which we're going to go into you can imagine one extreme case where whatever observation comes in you just instantly update your prior to that so then it becomes a posterior like after the fact but the posterior of that first moment becomes the prior for the next moment so it's kind of this unfolding process and again one extreme case would be whatever comes in from the world you just instantly update your prior to that so that's like a zero memory just instantly updating to that incoming data point like what's the average height in this classroom well this child was four feet tall okay the average is four now there's five feet okay now it's five feet tall The Other Extreme would be like very much denoising the observations by having a really stable maybe even stubborn hidden State estimate this relates also to attention because when we pay attention to observables we update our priors more when we're not paying attention observables coming in don't update our hidden State estimates Bayes rule tells us how to combine different elements the prior and the likelihood such that a prior probability becomes transformed into a posterior probability so you have some a priori estimate of How likely it is to be raining at that moment then you're going to detect wetness on your skin or not and then there's going to be a posterior probability update Bayesian inference is a broad topic and so there's many resources in place to learn but it's also very important thing to know in active inference box 2.1 covers some of the underlying mechanics of Bayes theorem um which is like very simple and taught logical yet very powerful in its application there's an example introduced here that's going to come up several more times in the book and does anyone want to like explain this example with the frogs and the apples like what is happening here so the situation is that there's a person holding something in their hands and there's only two options for what it could be either a frog or an apple they also this is their prior belief there's a 10 chance that it's a frog 0.1 because we scale probability distributions to like a total of one because something must happen but a one for a statistical distribution is like a hundred percent so there's a 10 chance of it being a frog and a 90 chance of what they're holding being an apple a priori that's their prior then they have some sort of likelihood model the likelihood model describes for apples and for frogs how different actions are emitted by them so apples jump one percent of the time that's the probability of action equals jumping vertical line means conditioned upon so the probability of jumping conditioned upon the hidden State being an apple is one percent the probability of no jump conditioned on an Apple being the hidden state is 99 so apples rarely jump in contrast the probability of jumping observing a jump when the hidden state is a frog is 81 percent and 19 for not jumping so a priori there's a 10 percent belief that it's a frog ninety percent that it's an apple that's representing the uncertainty around what the object is then a jump is observed just intuitively even without any equations if we know that frogs are more likely to jump than Apples observing a jump should increase our favor of that being like a jumping object and so that's exactly what happens and that's what the Bayesian statistics describe is a situation where you have a prior belief about hidden States that are not directly observable and you have a likelihood model of how observables which is here why how observables map to different hidden States and then through the observations you update and realize a posterior belief about hidden States does anyone have any thoughts or questions about this we're going to continue on the low road this is a method called exact base so this is kind of like a plug and chug method where you can take what is described in box one and apply it to the values that are presented here and you get the exact calculation of different variables depending on what you're trying to find you're going to be able to calculate basically every variable every unknown you can kind of isolate for and solve um this is called exact base exact base has um a clear intuition for small state spaces so when it's like there's two options there's two for hidden State and two options for Behavior it's quite easy to calculate for large State spaces it becomes or unknown State spaces it can become intractable so that's going to motivate some of the heuristics that are brought in later um okay table two again people can just please raise your hands if you have any thoughts or questions or want to like dwell on it at a part table 2.1 is going to be uh Brock yes I just wanted to if anyone is feeling like um so blue is she said there's a lot of math in this chapter and um she's one of the co-workers so that the prince Institute and I'm um this is my second time through so um if you're feeling like this is a lot of math you're not alone but that's okay um I I just I don't know just wanted to say that like it's it I think the way this is presented here is really helpful for people that have a grasp on some of the other um even simpler Parts like the way that you made this distinction of between the generative model being a thing that's producing predictions and the like that's a really important thing to understand um the Bayesian brain versus this sort of bottom-up um um predictive sort of machine thing um part of what is happening there though that I guess we're gonna get into a little bit more when he's talking about hidden State spaces is that um like what what that all depends on when he's going through this apple and frog example is that there's um a conditional probability here that like um the reason that you believe that the frog is jumping or whatever or not or might jump is because it's a frog and that may seem like well obviously or like so what like that you know but if it's something a little uh less you know I don't know contrived or something like um what is Brock gonna say next or whatever like then it helps maybe to have more priors on what what I'm you know and what uh I generally say you know so I I guess what I'm saying I'm trying to draw some attention to those conditional probability it's um kind of uh like a simple concept but it's kind of what makes that whole thing work at all is that there are probabilities that are kind of like strongly related and it may be part of a hidden state or whatever um but that's kind of what is if there weren't any conditional probabilities none of this would work um and that's kind of the uh the magic simple Secret Sauce there that's that's getting traction on so that's helpful or more confusing but thanks for the comments uh the personal comments Brock and also yes the conditional probability this vertical line does so much what's the probability that the Giants win against the Yankees well in my view it's 50 no conditional upon it raining maybe that doesn't matter in your generative model conditional upon this what if I told you that it was seven nothing in the third inning like all these situations where information comes in and there's information that doesn't update our prior like if you uh give a piece of irrelevant information then it doesn't update our prior so like conditioned upon the irrelevant information then we're not updating our hidden State estimate whereas there's other information that comes in that is relevant and that's going to have to do with the sparsity of how the variables are connected and then those conditional estimates help us reduce our uncertainty what's the overall probability that somebody has this has a medical degree in the world it's just the number of medical degrees in the world divided by the total population of the world conditioned upon being in this situation what is it and so that can be a different number um table two one gives a little bit of a statistical detail on several different forms of distributions now again even for people who have taken several courses or even years of Statistics these are not trivial Concepts the piece though that we'll just highlight is what a support means and what surprise means support is describing where that distribution is even valid or definable so there's some distributions like the gaussian that have support over all real numbers that's what the fancy R means so like a gaussian the kind of archetypal case is it's a bell curve centered at zero and it goes off to Infinity in both directions with vanishingly small numbers but it has support everywhere so that's the gaussian um in contrast there's other distribution families that for example can only exist on the range between like zero and infinity so that would be like waiting time between events it can't be a negative number so the gaussian is like an inappropriate distribution of family to even describe situations that can't be negative surprise is a formula that for any given observation helps you determine how surprising that data point is so we have the children in the classroom and the average height is four feet plus or minus one foot and we observe a new measurement and it's exactly four feet that is like the least surprising observation possible and then as it gets further away from four like the standard deviation increases it's more surprising and so these formula describe for each distribution family how to calculate surprise so that's just the surprise how surprising a new data point coming in is observation given the Observer given the hidden States as they're estimated um okay so that's one notion of surprise that's kind of like new data point comes in how surprising is it there's a second notion of surprise that's called Bayesian surprise Bayesian surprise is how much your prior moves following an observation so you could imagine again we have a four foot estimate for the average classroom and data points are coming in and we're surprised or not that's regular surprise Bayesian surprise is the difference between the prior and the posterior so we could get seven foot measurements again and again and again and again but because we're super stubborn in our prior we're still keeping that four foot estimate so those data points are surprising surprising surprising surprising but the Bayesian surprise is zero because the prior is not being updated into a new or different posterior um that's a little bit on the difference between vanilla surprise naked surprise and Bayesian surprise this is specifically within the Bayesian statistics updating framework how do we how do we quantify surprise well we have these formulas you just plug in like the observation and some of the parameters of the distribution the parameters are like the values that make the distribution the way it is so for a gaussian there's two parameters like mean and variance where's the mean of the bell curve the average and how wide is the bell curve those are parameters surprise can be calculated from the parameters of the distribution and the observation with these equations how do we calculate Bayesian surprise this is going to introduce an operation that may be familiar to some or not but it's it's all good it's called the KL Divergence callback Library Divergence and this is what it looks like again these are topics where one can go very very deep and learn a lot so just treat it like many coats of paint you're going to know it's a KL Divergence because it's dkl just like if it was like f of x is like a function of x d k l brackets means that we're going to be talking about a KL Divergence about what's in the square brackets so at this point I'm going to go over the equations I'm going to find equation 2.3 so we can see it here I'm also going to open up the description so this is really helpful this is a super important and valuable contribution for people who can to create natural language descriptions of equations because it helps get us all on the same page because otherwise this is like inscrutable again even for people who might know the area because the notation can be slightly different with different letters like what is Q and so on um so the KL Divergence is going to be hinging upon these two vertical lines when it's one vertical line it's going to be used in a lot of different statistic situations to mean conditional upon x x line Y X conditioned on y the two vertical lines are going to be what the KL Divergence is being calculated between so this is describing the KL Divergence between the Q and the P distribution here's Q of X this is a function here's P of X that's a function um specifically for Bayesian surprise we're talking about the KL Divergence between the prior and the posterior so the KL Divergence between the prior probability distribution Q of X and the posterior probability distribution P of x and then the second part here what does that mean equal sign with a triangle is by definition that's what the triangle means on top is the expectation that's fancy e means expectation over so it's the average value of Q of x of the natural log of Q minus natural log of P this part's a little bit less important a little bit more detail but this is where we're going to see it mostly written out as with two vertical lines and the kale Divergence is measuring the difference between them if they're the same distribution the difference is zero if they're very different the value is going to be high it's kind of like how much Earth do you have to move to reshape the distributions to look like each other it's not exactly that but that's kind of what a KL Divergence is so here we can think about the Bayesian surprise of that frog Jumping Brook yes um I was just gonna say I guess this those details I think this natural log of Q of x minus July that um another way to say that is that that's information those are uh mats or like a form of bits kind of um so that's the expected difference of information is there zero information or is there some change in other words between the the the P of X being the um prior and the Q of X being uh so that Divergence when he's about to go into his his that's what we're talking about is like how much space is there informationally between those two things great so anat is a unit of measurement for information a bit is a binary bit that's zero one digital computers use bits so people are pretty familiar sometimes with a bit a Nat is a unit that's not based around zero one it's based around the natural log and base e instead of like a base 2 binary system so it's monotonically related to bits which is to say like they're both going to go up and they're both going to go down but they're not exactly comparable it's like inches and feet um here when we were calculating just regular surprise so how surprising the observation is that could be calculated in Nets was it a surprising observation or not did it did it surprise me at all that that can be calculated about surprise here knots are also used to calculate the informational Divergence between the prior and the posterior when we're thinking about Bayesian surprise box 2.2 introduces the fancy e notation fancy e is standing for expectation now sometimes conversationally expectation is talking about the future like what do you expect the weather to be tomorrow in the statistical sense expectation is the average expected value it doesn't necessarily refer to the Future it could be an expectation about a future time point but also alone it is only describing basically the average of a distribution the expectation of a gaussian is the center of the bell curve not like what one believes it's going to be in the future but if someone said what is the expectation for of your in your model for what the average is going to be in 10 time steps that can be addressed so it's compatible with the way that people talk about what do you expect to happen tomorrow but just be aware that expectation alone does not refer necessarily to a future time point it's just referring to a statistical average and um One Note again may be familiar to some maybe the first time hearing for some but it's going to come into play in this book is there are discrete State spaces and continuous State spaces a discrete State space is one where values can only take certain like clickable values like 0 1 2 3 4 or it could be 0.1.2.3.4 but it's like there are discrete values on a grid that can be achieved like the two options for what the thing in the hand was it's a discrete State space whether it's two or two million it's a finite set of definables and there's no in-betweets in contrast continuous State spaces would be like a continuous variable describing the temperature now one could also Describe temperature with a discrete State space in my model I'm describing temperature as either 20 21 22 23 only integer values are allowed for my model there's advantages and there's challenges for both discrete and continuous State spaces and this book is going to be like juxtaposing them and the chapters even later are going to be like kind of alternating between them because there's active inference in discrete situations discrete State spaces discrete time and then there's also active inference in continuous State spaces and continuous time so that was very low down on the low road nothing of the above was like about active inference or even many of the ideas that often bring people to the table that was kind of like an overview on some Bayesian statistical ideas Bronwyn this goes back a little bit though I just wanted to maybe ask these questions before we move on one was um in relation to conditional probability or the the role of conditions I think Brock sort of talked to it a little bit um is it is that with the conditional thing like you know in Melbourne tomorrow there's the Grand Final so you know you've got two teams and you said you know there's a 50 50 chance but it depends on what what conditions uh those conditions are they mostly subjective I mean they can be subjective and they can be factual as well so um yeah I suppose it's the question is um the condition what what states are the conditions are there they can they both be well they mostly subject subjective or can you have the fact that frogs jump as as that's what frog frogs do so that that's what generally happens so that's not really my subjective uh opinion of frogs but does my subjective opinion puts a condition honors does that make sense yeah great question these models in their Construction like what their overall structure is and then in their parameterization like what the values are are subjective they're modeler dependent and so we might have different perspectives on the overall likelihood of one team to win and then somebody might say it's going to rain tomorrow or it is raining now and then in your model you had that that's a gonna update your prior but maybe it doesn't update my prior so it is even when it's like frustratingly obvious it is still also subjective and multi-perspectival okay great that's what I thought and then that leads on to to the Bayesian surprise the two differences between surprise and Bayesian surprise and that how Bayesian surprise actually operates in the world say in relationship to that like I might say geelong's going to win tomorrow and even when they're lost I still think they've won um and you can't you can't um convince me of anything other than that is that where my prior doesn't change um yeah so how does base in Surprise itself well can you give us some examples of how that might operate in in the world in the real world yeah it's an awesome question and to connect really surprised by itself so how surprising a single observation is independent of how it changes your belief um you have a stereotype about some sort of situation something surprising happens but then the Bayesian surprises zero because it's a recalcitrant belief that the person has yeah in contrast there might be a surprising event that induces a Bayesian surprise because someone's like whoa I thought about it this way and then I was surprised by this observation and that brought me over here and then neither of those are the experience of surprise but that's an area of a lot of research and discussion which is like how did these Concepts in statistics like beliefs surprises preferences how do those map onto our psychology and phenomenology is a preference in active inference like I prefer A over B is a expectation related to what people use every day and that's kind of the fun part with the active inference ontology is some of these terms are not used in day-to-day conversation and so it's like a blank campus but in other situations these are terms that are used day-to-day ambiguity yeah attention belief and so are we using them in a technical sense that's compatible or isomorphic with the way that it's used broadly is incompatible and so on that's that's interesting I just had a different perception of Bayesian surprise then when you said surprise is always surprise but Beijing surprise maps on to I think you said something like the psychology or the preferences or or whatever so so it's not it's not really a surprise it's it's how we um manage surprise could it be like that that's how what sort of precisions we have on things so that we so that we recognize something or we don't recognize it is it something like that excellent and the connection to Precision is also technically correct which is that when observations are coming in and we're treating them precisely we do have Bayesian surprise because we are updating our priors when we have imprecision about observations we do not update our distributions of beliefs like oh that's just a bad thermometer I know it says that I believe it's 37 in the room the thermometer is just weird it says 65 but don't worry about it so then that's a surprising observation under the belief that it's 37 plus or minus one but it doesn't induce a Bayesian surprise because we haven't updated our prior prior yeah okay that's interesting yep awesome so just to kind of so let's yeah continue please uh it's also interesting in that um I watched that um the the um the podcasting with uh John for record um the other day and it was interesting out of there that just the language the use of language and then you were just talking about the ontology and different uses and are we actually considering the words that we're hearing as as they actually are I think that's really yeah it's really interesting area with all of this because and it makes it really what I've noticed in my in in what I listen to and and my studies is that it's like you have to keep going over and over and over until someone says something like you just said then okay incredible incredible thank you that's the relevance realization in a way with language just looks interesting oh sorry it is interesting um so we pay attention to it we update our priors we learn and we deal with the surprising observations and we deal with the Bayesian surprise to adjust our regime of attention and action along all these ways and we Meme and connect with the active phonetology rather than spiraling off into um uncertainties that aren't relevant but that's not to banish uncertainty like from the realm it's to have the right core screenings that help us deal with certain features of action and perception um here here's the subjective questions coming up Bayesian inference is optimal and this is also the root of like a million discussions how can it be optimal to to crash a car how could it be optimal to be wrong I mean we were talking about the how could I how could I be wrong if betting is always optimal how could I be wrong inference is subjective the results are not necessarily active accurate in any objective sense Bayesian cognition and optimal Bayesian calculation again doesn't mean Society accepts that neurodiversity it means that given that person's generative model and the observations coming in or their body as an embody generative model and the observations and constraints coming in that is its own local optimality and then there's secondary discussions around like is it adequate is it um best amongst a family of counterfactuals does society accept that and those are discussions to have but that's irrational will not be found here and that's a very interesting angle that kind of reframes a lot of again rationality versus irrational thinking um yeah and this is a second reason for optimality being thought of as subjective okay here we're going to get to figure two two which is a schematic that's going to be very um different remixes of this schematic will be found in many places um here is our model of temperature in the world here's the real temperature in the world hidden state here's our thermometer observations coming in we're updating and then we're taking actions which may over you know in some way influence the state of the temperature in the room so this is like the cybernetic Loop this is the control theoretic Loop this is describing um a kind of generalized again not active inference unique way in which um cognitive entities take in observations juxtapose them with a generative model and then do action selection to influence the hidden States such that the observations are brought into alignment with their preferences among other things um here's a short discussion that the state spaces don't have to be the same between x and x star so temperature in the real world might be like a continuous variable whereas we might just have a binary state is it too hot or not too hot or you might have a three state too cold just right too hot or five states getting too hot actually and then you might want to do model selection across two three four five states internally and none of that hinges on quote how it really is so um there's a lot of degrees of freedom in generating cognitive models and their structure doesn't need to map on to the neural anatomy of the brain it doesn't need to map onto a physical mechanism about the cognitive system which you may or may not even know and it doesn't have to be isomorphic the same structure as the hidden states of the world okay all of this so far has been purely inferential Brock I just wanted to I don't know leave a bookmark here uh stigmatically um that you mentioned something about neurodiversity there in the uh context of the Bayes optimality Rabbit Hole um and um just wanted to remind that like the origins of this come from uh Psychiatry and or the impetus for it of trying to have a causal reasoning tool for addressing certain kinds of mental illnesses so it's it really it doesn't yeah it just like you said it doesn't have to map to a specific you know architecture of brain Arrangement it's this in the world or whatever it's you know it is very much like based on the subjective model that's already in there and um it it could you could seeing the whole thing perhaps like reason about how it might make sense from their perspective for many different kinds of priors or whatever and um and why that would be optimal for that model like or seem like at this yeah so great comments and to kind of just Force age chapter nine this is the metabasian so it's the modeler's subjective model the psychiatrist's subjective model of their partner's subjective model so that is the um Genesis of so many discussions around the map and the territory and the fallacies and the fallacies upon fallacies and the the cause and effect and all these different discussions and this is how this modeling framework wraps that up it's a subjective model of a subjective model and that double subjectivity opens up an unbelievable amount of degrees of freedom in modeling which then refocuses the imperative towards selecting from these models but that's a little bit of a later point um just to in in the last minutes because again next week hopefully um many people will add simple tangential Advanced formal any kind of questions um but let's just in the last three or four minutes just see what else is going to happen all of this up to the point has been inferential Bayesian brain #livestream 43 they're going to extend that inference about temperature so to speak in to include action how that happens is at the heart of active inference in the next sections they're going to clarify the quantity that active inference agents minimize through perception action as variational free energy one note minimization and maximization are like twins of each other because with just a negative sign they can be the same so when you see minimization or maximization you can just think of like finding relatively higher or lower values but like whether you choose to think of um like biologists talk about climbing mounts improbable like a Dawkins book and a physicist might talk about finding the bottom of an energy well but those are like going to be seen as kind of um not even like just sisters or twins of each other but like they're actually kind of the same thing through a negative sign there's two ways to reduce free energy as we will all come to learn and love you can update your model that's learning and perception and you can act in the world that's action action and inference active inference first you can learn this is a variant of figure 2-2 where now we're being able to see how the prediction and the observation are being put together there's some discrepancy in any realistic situation there will eventually be a discrepancy and then here are those two roads to reduce free energy change beliefs which can be perception perception and learning are much more similar in active inference than other Frameworks like when the ball moves across your visual field are you perceiving it or are you learning the position of it as it moves over rapid time skills so they're kind of the same and can you act here's how you can resolve that discrepancy you can change your mind about what you're seeing that's perception or you could act that doesn't mean both of them are equally good or they're going to result in your survival or they're plausible in any given situation so it's always situational what affordances there are for Learning and perception and for action but this is the general framework how does free energy get Quantified and minimized we'll return to this later but equation 2 5 and 2 6 are going to be really key equations thankfully through the work of of many people here we have really excellent natural language descriptions connected to the ontology we also have a lot of like notes and questions people have added and things like derivations for those who want to go that way that Jacob and others have worked on so these lines of symbols can be read this way and with a mouse over we can see what those are so yes it's like words words words but um we we have a staged development around these equations because we're going to be revisiting them and understanding how this F as the free energy that's being minimized I mean free energy principle this is kind of what it's about how can it be decomposed into these different sets of natural language terms and in what sense are these terms being used again we don't have the minutes to describe but variational free energy f is about the past of the presence that's figures I mean equation two five equation um and this is what it looks like a little bit graphically here's variational free energy the same figure that was two before but now there's an equation here when we want to look into the future there are going to be several complexities arising which is that we're talking about the surprise of observations we haven't observed yet and we're talking about the consequences of actions that we aren't sure about what their consequences will be and so variational free energy F equation 2.5 morphs into expected free energy G equation 2.6 similarly excellent work in progress as everything is to unpack what this is in natural language there are some special cases for expected free energy such that when certain terms are ignored or set to zero we get a lot of special cases that are in quite broad use and then that's the end of the low road equation 2 5 variational free energy past and present equation 2 6 expected free energy G future that's the end of the low road chapter so that has been this first discussion on chapter two hope that people have enjoyed and it would be extremely appreciated to write any questions that you have on chapter two so that we can as as people were adding during this conversation so that we can have some specifics to follow up on so good luck with your learning in the next week and see you all soon