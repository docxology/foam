hello everyone and welcome back to active inference insights I'm your host darus parv Wayne and today I'm delighted to be speaking to Vana Visa van is a postdoctoral fellow at Johannes Gutenberg University mines in the department of Ro University B sorry the internet has lied to me the internet has lied to me I don't like this introduction bit already um but I think this is true nonetheless his research centers on Consciousness medal rep presentation philosophy of cognitive science philosophy of mind and of course Act of inference uh we also both share a love of self- modeling attention autopoetic intentionality and much much more and I'm sure these are just some of the topics that we will discuss today V welcome to the show thank you so much for joining me thank you for having me it's a pleasure this is really exciting uh yeah as I said in the intro we share a lot of interests uh that might appear quite Niche to people but actually you know as far as I can tell pertaining to their lived experience every every moment so it's it's worthwhile dissecting funnily enough the first time I think I'd heard of you was actually from jackob Javi um in the conversation I had with him and he said that you know Thomas metzinger's work perhaps better than Thomas and certainly better than anyone else um so so I I I wonder whether we could start by outlining some of these crucial um Concepts that sometimes seem a bit counterintuitive to people so for example when I say we both share a love of self- modeling or phenomenal self modeling what does that mean what ises this sort of acronym PSM the phenomenal self modeling yeah good so um maybe as a um disclaimer of course um Thomas knows more about this than me he's um uh in invented the term self models and has developed the self model theory of subjectivity over many many years and um actually I I I think I can say that there's probably no living philosopher who has read as much relevant literature about topic as as Thomas because he's devoted his entire career to this and works a lot and of of course I would never um even even if I tried be in a position to know as much about this as as he does and I I think it might be a good idea even to invite him to this podcast he's been invited he has said yes that was a while ago I've tried to push it so Thomas if you're listening which I think he might be you know you never know um please do come on because I do yeah so actually it's quite likely that some of the things that I've be saying might not be 100% true so Thomas if you're listening now you may want to correct some of the misrepresentations of your work um but anyway yeah what what is the self model so for me it's I think easiest to First think about bodily self models so um just imagine some creature or a robot that has a body and has to control the body and as we all know in many cases control can be facilitated ated or improved if you have a model of the thing that you're controlling and if you want to control your body and the interaction with the environment it can be highly useful to have a model of your body and the model of your environment and this is actually then already a form of self model which is part of the world model so the world model would be just be representation of the world or the relevant part of the the world the the parts that are relevant to you and the your environment and your body is part of this world so it's the the self model is part of the world model but of course that's just a form of self model and it's quite primitive probably compared to the self models that we human beings have and one thing that distinguishes our self models is that we don't have only unconscious self self models but actually we have uh we also consciously experience the contents of our self models so this brings us on to to the notion of a phenomenal self model where phenomenal refers to phenomenal experience phenomenal Consciousness so if you have not just a um an unconscious self model but a phenomenal self model you actually experience your body as your own body and another form of selfhood that you then might experience is experiencing your own actions as your action so um this is often called a sense of agency um that you have over your action and a sense of ownership that you have over your body and both can also um be uh both can go get lost or be affected in in various ways and so the these are some Concepts that are relevant here there's one thing that I wanted to add or maybe an example that um Thomas also likes to use I think is this robot starfish that um was developed by Josh bongard and colleagues and in order to make it flexible and able it to adapt to changes to the environment and also to its own body so for instance one of its lymphs is um damaged or um is is cut off um you you want the robot to still be able to control its body and control movements and so it can be useful to have a model of the body self model but of course in that robot it's just a it's not a phenomenal self model it's not a conscious robot so that would be an example of an unconscious bodily self model yeah I let's start with the body I think that's a good place to start because as you say it's kind of the low hanging through the lower the lowest level of what people think about in terms of the phenomenal self model and I think a potential point of confusion for people is the fact that the body has what I guess Marlo Ponte call the jewel aspect which is both that it can be it's a lived body but it is also a body that can be observed and can be objectified and so I guess um the question here is why do we is there a difference between saying I am my body I live through my body or at or or versus I have a body and what are those different aspects of selfhood because on one part I feel like you're getting what we what we call perspectival I am my body I live through my body I live yeah I mean literally through it as a vehicle through which I can be in the world versus possession I am some in this case it seems like people would feel like a disembodied ego who has a body that they own is there a way of coalescing these kind of two canonical features of selfhood one being possession and one being perspectival or association with the lived body yeah that's a great question so I I think uh these different perspectives are to some extent compatible was it depends on on what you mean so one could for instance wonder whether a um animal non human animal which maybe does not have um a form of Consciousness that is comparable to to human conscious experience and that doesn't um reflect about its own body nevertheless lives through its body and so there there there's a live body but that doesn't mean that we don't have that we I would say it's just that we can also um have different forms of experience or richer forms of bodily experience and uh reflect about our own experience in different ways and so having a body versus living through a body so it it seems to me that the Liv body is that that's charact more characteristic of experiences or situations in which we're not so much aware of having a body at all so maybe when we're engaging in some physical activity um playing sports and just not not thinking about where our limbs are but just moving and interacting and in the sense living through the body I I don't know of that captures what what is usually meant by that expression yes I wonder whether I mean it's a good question um we wrote this paper not you and I me Carl L and others wrote this paper on Flow States uh and flow states are exactly this you're playing sports and we tried to ground it in a self-modeling architecture and actually the revisions have been really useful for that because I've been able to get a little bit more concrete on what I'm talking about and the kind of dichotomy that we're saying is present there I think I can say this because hopefully it'll be published well the prints out is um the distinction really between a minimal phenomenal self which is like these really basil fundamental aspects of selfhood mindness presentness perspectival versus epistemic agency or strong epistemic agency and by that I mean you know when we let's say plan or when I'm talking to you and I have to think about my next sentence there's a very strong sense of self-guiding that process where I can use let's say former resources former knowledge to apply to to uh deep temporal planning and we're saying that that's attenuated in flow and what we're also saying therefore is that metacognition because I think it's really important here to distinguish between pre-reflective self-awareness and reflective self-awareness and I'm treating reflective self-awareness as a metacognitive act your self is reflecting on itself because um reflective self-consciousness is itself a kind of a form of epistemic foraging that too is attenuated in flow States but I think the interesting question there is if I was in flow would I purely live through my body or could I be perceptually aware of having a body nonetheless could I have both um and these are very difficult questions to tease out because you know they're already done retrospectively and so you only get qualitative reports that's an interesting Dimension I had thought about I think okay so I I emailed you however you know a month ago two months ago and I said so I've been trying to get my I've been trying to think about how metzinger's phenomenal self model can be coales with active inference and this is the active inference inight podcast so I message you I said active inference takes cognition to be fundamentally inferential are the processes within or or the processes that generate the phenomenal self model inferential are the processes that are themselves being modeled by the phenomenal self inferential or both because I think van you you would do a great service everyone if you could explain that what Thomas is talking about is kind of the cognitive system recapitulating its own data structures into phenomenal space and I think that's an interesting idea he talks about this in sort of his 2003 book and 2008 book and some other works that the phenomenal self model is a in in an implicitly reflective way is a as you say a model of itself whether that is a you know a giving relevant uh features into Consciousness or Co grain features into Consciousness whatever it is but it's a reflective process where the data structures in the body and brain are being um transposed into phenomenal space so maybe we can start there I may have butchered it and I'm sure Thomas is pulling his hair out um but maybe we can start there and and then feed in inference and see where it might exist in within those Cycles yeah so I I think there's actually quite complex topic because when we're talking about self models it it it it seems to presuppose that there's already an experienced eye right that I'm I'm I have a body I am moving my hand and so on but I don't think that's necessarily already present in in any in in the most basic forms of phenomenal self models and what it's at least the way I I think about it is that having a at least a bodily self model is mainly about just making a distinction between one between inner and outer as it were so I'm just trying to avoid the word um self and and nonself so a distinction between two types of processes one is the environment and the other is here where I am and and I I think that actually suffices for having a a bodily self model or even a phenomenal self model but of course when we think about or our experience and the way we the different forms of self that we experience there's there's more to it there there's something like an an eye and maybe at this point it's useful to um bring another aspect of the the self model theory on the table which is the phenomenal model of the intentionality relation so quite PM exactly and so the idea is that there's in in a complex self model phenomenal self model in which there's not just a distinction between this belongs to me this does not belong to me this is my body this is not my body and so on well this is my my action or this is an uncon um involuntary movement and so on in more complex self models you also have this this perspectival which um and and subjectivity um in the sense that that you not just make the distinction between what is self and nonself or what is outside and what is inside but also how you are related to the environment how you are related to your your body and how your your thoughts are related to the world and so on so this brings a reflexive component to it and makes it more more complex um I find it a bit difficult to put this into words so Thomas could it is difficult I mean so I can I can hopefully assist I have some sort of quotes here um great so this is the way that I've understood it at least and so we'll start with the quote so Thomas metzinger 2008 so the pap the ego tunnel I think is 2009 so this is a really actually very useful paper um he wrote in 2008 something like empirical approach to phenomenal self modeling it's really it's actually very lucid he says that the subjectively experienced content of the phenomenal self is the representational content of a currently active Dynamic data structure in the system central nervous system and that it's it's a representational entity whose content is determined by the system's very own properties so what I mean by that is it's it's standing in for something that is lower level to it namely these data structures right and we obviously here are taking as axiomatic that there are representational structures and maybe that's problematic and we can get there um and then the way that I've always read the PM is that the cognitive system can pay attention to the fact that it itself is directed at other things and therefore what happens is that it well I'm not going to say it makes the inference but it projects into phenomenal space this notion of itself and something else I guess my question here is that's taking as a presupposition that there is some division that the self model can model it can reflect on the fact that its own attent its own attention can be directed at so-called external worldly objects or things in the world model my question here would be how does the brain know what in the sense is external to it and what is internal to it in the sense that I can introspectively pay attention to parts of my own lived experience but not but have a sense of mindness and not feel that kind of Duality or that distinction but if I pay if in princip I pay attention to the chair next to me that feels you know like a separate object to me so if the brain is recapitulating some distinctions that are in its self model I guess my real question is are we not as you say already invoking an a priori distinction between the thing that's paying attention and the attended object yeah so if I understand understand your question correctly um then the answer would be yes and so what you you um mentioned knowledge so how does the brain know and of course knowledge requires truth so you're assuming that there is effect um to um to the matter whether something is really inside or outside or something is really I or or mine or self or not self and um I don't think we have to make this assumption that there is that these are truth claims and that the brain has knowledge about this but it does have to make some prior assumptions about that and these can be can be um delusions so um in in that sense I I think the question how how does a brain know can be dissolved but of of course then the question is where where do these priers come from and [Music] um why why are they relatively immune to revision and what happens if they do breakdown or the the sense of self dissolves and so on so might it be feasible to say that you know at the very bottom level all we have is attention in some way um recognize that I almost well I did commit this kind of dualistic fallacy when I said there is the attender and the attended object seems to me that actually that that might be a an inference too far rather there just is the attention onto these kinds of objects in these data structures again metzinger puts his far be than I do he says that when he talks about the pmir the phenomenal model of the intentionality relation he says that you mentally simulate yourself as currently being directed at a Target object or goal State um and that's a really interesting notion right this mental simulation of yourself maybe he's committing a linguistic uh you know fallacy there that there's a self there in the first place um so so we can pay attention let's say to the fact that we can be targeted at certain areas of our um Phenom of our data State space but then we can also pay attention to the fact that we're paying attention and that seems to me I don't what you think about this proposal that seems to me to be maybe the heart of reflective self-consciousness that I can pay attention to the fact that there seems to be something that is paying attention to that which I'm that which is that where which is where attention is going to there's a kind of triple hierarchy um one does that sound like a feasible uh you know underlying explanation of metacognitive self-concept ization or reflective self-consciousness and two how deep do those recursive patterns go what I mean by that is like how many times can I reflect on my own attentional processes and I know lar s Smith and others have been doing this in terms of So-Cal meta awareness but I'm thinking more in terms of actually the underlying phenomenal reality of being a self is there a point in which the very notion just becomes uh you know irreconcilable with a certain degree of recursive operations yeah um great question so um regarding this this triple distinction I um I think that's already quite difficult to imagine so maybe we can uh just try to um clarify this and and just re restate this again sure um together but before that there's something that um came to my mind because uh when we think about how how does a brain know um what what's inside um and what's in outside and but when it comes to I mean there there's some to to some extent there there might be truth to to these um to to claims about this and um so when it comes to attention we can just make a this really broad distinction between um attention attentional processes that are driven by external influences so when some Salient object or process process loud noise and the environment suddenly captures my intention and we can contrast that with cases in which I'm uh controlling my my attention and so the changes in attention are generated or caus caused by more caused by internal processes than by external processes and the the brain can make inferences about that and can be more or less accurate about whether some changes in attention have been more caused by external or internal processes and it can make sense to model attention to improve these inferences and improve the control of attention and so on maybe we can use this to just re redescribe this triple distinction that you mentioned because because I'm not sure I I fully got what you okay yeah I I I'm aware that there are lots of layers to this um as is the problem when we talk about hierarchies so I can actually read I was thinking maybe it's best for me to just read what I've so this is this is so if people go and look at that flow paper right now on the pre-print server they won't see this hopefully I'm not spoiling anyone's party uh By the time this comes out hope this is at the very end of a review process so hopefully it's fine um anyway people can shout at me if they want but I wrote so it's my words um I said in planning so we're talking about epistemic agency in planning the organism not only knows that it is intentionally directed at something else yielding a weak form of epistemic agency and perspectival but it is also in the act of knowing about its own knowledge which encodes as M multiple counterfactual representations of what might unfold as a result of my actions in the section of my current Eco Niche that I seem to control in this way planning involves strong epistemic agency since the cognizer can epistemically model itself as epistemically agentive I.E it can come to know its own capacity to control itself and its econiche over protracted period of time through stored knowledge and then I go on to say that that self-modeling process is transparent in the sense that the agent often does not know that it knows its intentional objects rather there just is the sense of epistemic agency which permeates a pre-reflexive of self awareness this is where the triple thing comes in when the agent does enter a state of knowing the fact that it knows its epistemic capacities it evolves into a phenomenologically metacognitive metamodeling or perhaps meta epistemic organism which reflects on its being yeah so that I I think the the issue that I had when writing this was you have to start from the original if you're using the metzinger foundation you have to start with the original basis which is that the self model itself is a simulation it's a recapitulation of a data structure but it's a recapitulation data structure which can itself be uh reflected on and that reflected that can also be reflected on so that's where I'm building in this nature of hierarchical recursion how does that sound to your ears and again what what what does it mean for us to continue to go up these recursive ranks like what happens for example if I like is there a point where I just really concretize my sense of self or is it does it actually almost become dispersive because all I realize that's going on is that I'm paying attention and I'm just paying attention at different levels of the hierarchy so I'm kind of curious about what you think might be the phenomenological consequences of going up this hierarchy of reflective recursion yeah so I don't think I can give a full answer to this question because there might be multiple things going on so when I'm not just planning my my actions or planning how to how to interact with the environment or whatever but also reflecting upon my planning becoming aware that I'm planning I might be evaluating this I'm becoming aware of the fact that I'm uncertain about different options or I might become aware of the fact that I really want to do one thing and so this might then lead to further experience experience of of of certainty or maybe also um or or not uncertainty right or confidence that I'm making a good decision or doubtfulness about the decision and I think we can then repeat this process and reflect upon this already metacognitive process but the resulting experience that we have might not add too much so I don't know if if it makes sense to say I'm I'm confident about the confidence that I have in mind my confidence and my confidence and so yes I mean it sounds you know on one hand one could read that as a genuinely vertical recursion on one hand you can also read it as a kind of like the way people talk about the fact that a triple Bluff is the same as a single Bluff you know we might actually just turn our you know turn our heads onto our Tails so to speak and and end up actually experiencing same it's a it's a curious inquiry um someone needs to model that maybe I need to model that um just um um what what I wanted to say is that I I think it makes a lot of sense for three levels or or um three recursions and then above and beyond that I I really don't have a clear intuition and it's probably an empirical question also to what extent it can improve control and um as I said just from the point point of view of experience we we we can mentally build further models further iterations but they might not have a real functional significance for the for the um lower order processes good okay we will park the self models I had to do it because it's been a bug bear of mind but we'll get Thomas on and we'll we can all chat out together and see where we end up um there's a broader question here about the so-call generative passage um which is this idea that uh is really nicely articulated in Maxwell Ramsey's 2022 Pap with and and colleagues of course um which is this idea that okay we kind of have two things that we are trying to balance one is experiential reality lived experience and the other are the in some sense the tools of science that's one thing the other thing could also be let's say neurological systems and um RAM and colleagues present free forms of what they call De generative passage or there's kind of ways of tying those things together one is ontological and so that's not necessarily a subscription to reductionism it's not necessarily saying that phenomenal reality is neural structures but that's one option whether it's super that's that whole conversation one is epistemological which is that the kind of tools that we use in our science um can be applied fruitfully or can be used to describe and explain phenomenal reality lived experience and the last one is methodological naturalization which I I think I've been using a little bit more in my own writing which doesn't really have a commitment it's quite agnostic about ontological epistemological claims and just says well we can do some good explanatory work by thinking about PP schema or predicted processing or whatever it is um but I'm not going to say anything about whether Consciousness is these uh these you know architectures or neurons I was curious about I think I think Thomas I I don't want to speak on his behalf and you'll be able to say better than I do I feel like he's quite materialist or reductive about this um and at least this is something that came to my attention from Julian Kine when I spoke to Julian on this podcast um who was very keen to reject that reductionism and Forefront uh intentional experience and Forefront lived experience and say that that's irreducible so I was just curious about where you stand on on this generative passage and I guess the the sourest question is the ontological passage yeah um deep question so so first of all I I think different views on this all make sense and are useful and there there's a lot of uncertainty about how different levels of reality relate to each other and so to some extent we just have to follow some some assumptions that we make and and then there will be different views that are compatible with the models and data that we have so I'm not claiming that we can say well we we can obviously we can reduce um conscious experience to brain activity or something like that and it's to some extent also an open question for me what role computational models actually play in explaining conscious experience and what well do they play yeah so I I think there's when it so the maybe the simple answer or once simple answers to say well Consciousness is so puzzling it's so difficult to grasp its different features and talk about what we are experiencing from moment to moment it's difficult to put that into words and computational models can help to make certain ideas a bit more precise and this might then just be very on on a very in in a very simple way um a use of computational models not that it's it's not even an explanation it's just trying to provide a better Des description of that which we want to explain what are the properties the different features of conscious experience that we need to explain and computational models I think can very legitimately be used to provide such more detailed descriptions and once you have that you can of course then try to make predictions about the implementation in the brain or make predictions about how conscious experience will change in certain situations or you can compare to to um descriptions of conscious experiences that we have to phenomenological reports from persons in Altered States of conscious experience and so on and then at some point you you may Wonder well maybe these comp computation models provide more than just a metaphor for this that is useful to describe complex and puzzling features of experience maybe they also point to the mechanisms and go some way towards explaining how conscious experience arises or why it has the features that it has even if we cannot maybe explain why there is conscious experience in the first place and to the extent that the computation models that are used are also neurobiologically at least not implausible and we might be able to find some empirical confirmation or to the extent that empirical neural biological and um data from cognitive cognitive Neuroscience are compatible with these models we might be inclined to make stronger claims about the relationship between conscious experience and computational models and neurobiological processes and of of course I'm so my I ideally we'd have very detailed computational models that can be used to describe predict and maybe even control many features of conscious experience and ideally we know how they might be implemented in the brain and therefore have some really have something like a computational um explanation of certain features of experience but I can also understand if some some people might be more hesitant in saying that though now that I'm thinking about it um I'm Tous actually I have to I guess I have to uh watch the episode with julan KY because the long one yeah okay yeah I'd be really interested in what what exactly his his view on these matters is yeah we go pretty deep actually um yes yeah he he was very much striking down the line of the irreducibility of conscious experience which I don't think is necessarily that controversial um but he was very you know he was he was being stubborn about that point I don't think he'd be upset if I said that um yes yes okay good um we can remain agnostic the hard problem is the the hard problem and unfortunately it's the most frequent question that I ask uh and no one has solved it for me yet and I don't think they will so I'm G to ask a kind of what Charmers might say is a less hard problem or an easier problem um which is about the features of Consciousness especially as it's lived by us um is all Consciousness self consciousness um I would say no it's not so I'm I'm I'm not an expert on this this topic and I haven't read Thomas's new book NE but I um I intend to and hope hopefully then I will know a bit more about this but I take um reports from people who have who claim to have experienced States of uh nonsubjective experience seriously or think we we we should not uh reject these reports and I'm definitely open to the possibility and also find the strategy of trying to look at the simplest form of conscious experience which may not be a form of self-consciousness I find that quite promising yes so do I um does this map on to something that I think you've written about indeed you have um subject unity and phenomenal Unity is there a link there what well maybe we can start with what's the difference between subject unity and phenomenal Unity yeah so that that's um quite can can can become quite complicated it and so first of all subject Unity can mean different things some people just mean well different experiences that are had by a subject are subject unified if they're had by the same subject of experience now what what is a subject of experience and some people just identify a subject with an organism so and in that sense subject Unity would not entail subjective experience or having a having some form of self-consciousness would just mean subject Unity would then just mean that there's a conscious organism that has different experiences at the same time so and these are all subject unified in the sense that they are had by the same subject but of course if you have a formal self-consciousness you might say that there's different form of subject Unity maybe one in which you're you you have different self-conscious experience or different conscious experiences that are all forms of self consciousness and somehow refer to the same same self something along these lines yeah so what going back to the kind of notion that all Consciousness is self-consciousness goes back to actually what Mr kin said um so he's got this paper I think it's a 2018 paper I'll double check that uh the no 2020 the free energy in the self an ecological inactive interpretation he Sayes very clearly um he says in line with the arguments of the phenomenologists I will claim that every feeling must be felt by someone it must have mindness built into it if it is to feel a particular way such a it's such a strong claim and again I haven't read Thomas's new book but I do kind of understand this perspective because at least for example let's talk about if if one was imagining depersonalization it's a depersonalization experience for who right or if you think about someone who's experiencing a psychedelic experience it isn't so much that perspectival itself is eliminated it's more that one maybe has this more Oceanic sense of self which which is dispersive and that but that still arguably is a qualia for the self right or for the the space of awareness that is inow with perspectival so I'm just curious about whether you can think again that this is a tricky question it's a big question um and there probably isn't in we can't probably conceive of this at all but sort of well I guess actually the question I'll start with is when I learn about Consciousness for example I learned that there were three fundamental tenants to a consciousness experience qualia intentionality and subjectivity this is what the British schooling system teaches you it when I hear sort of Julian speak about well you're always going to have that perspec iess or intentionality it's always something for you can we you know is there a way that we could say okay some features at least out of those three that I've just picked up are more fundamental than others and that we can have this very very minimal conscious experience or minimal phenomenal experience the MP another acronym um and what would you say are the defining characteristics of a minimal phenomenal experience therefore yeah I can only say it's an empirical question so we can speculate about what the minimal form of experience might be but it seems that there's a lot going on in ordinary waking experiences that can get lost in Altered States Of Consciousness but what exactly will remain I I I I don't know so Thomas can say more about that is there a problem with relying on phenomenological reports to inform such questions yeah so to to some extent there's of course the challenge that these reports are given in retr respect and oh how do you say retrospect yeah just yeah yeah yeah and then so some people say well it's it's a bit paradoxical if you say you have had an experience in which you were not present or something like that but um I I so and and one of of course the the mere fact that you can remember such experiences doesn't mean that you you you must have had a form of self-consciousness or that there must have been subjectivity in the experience and also when people say well I realize that I had not been there that there was no sense of self or no no form of self consciousness I realized that when I when I transition transitioned into um the ordinary form of conscious experience so while as as it were the the self was returning I realized hey there there's something additional coming to my conscious experience so it could not have been there before yeah that's very interesting that's really interesting yeah I guess it makes me think you know um to even have those reports whether that's in the internal speech or external reports requires propositional language and in my conceptualization of the scale of phenomenal self- modeling propositional language is super high up in the epistemic agent it's the way that we plan it's the way that we reflect on our own being and so on and it sometimes makes me think well is the lack of is there a bias there when we don't have the capacity for propositional claims either internally or externally we're biased to think that that constitute some form of self Annihilation and the reason why I think that is because like testimonies for example about flow States they'll say at least the testimonies won't be as concrete as this but the researchers interpretations which are problematic will say the self disappeared or there was there was a reduced self-awareness that's probably a weaker form of that claim well I think the all we're really coming to here is that you just need to get a lot more particular about what part of the self model you're talking about and how it's being attenuated or accentuated um and actually I think hopefully for the listeners what they're kind of gathering is the self is not this kind of single monolithic thing that we take it to be and maybe that's the influence of day cart and the tradition that followed from him but rather it's a complex hierarchical well appearance in many ways but also potentially underlying data structure that uh will oscillate and modulate and change given different contexts good um let's take that a little bit broader now into just yeah maybe just one one thing to to make it slightly more concrete so um what what is I I think very plausible is to assume that a sense of temporal self-location can get lost so you can have conscious experiences in which there's no time no temp experience you don't experience any now as it were or maybe only now but not as distinguished from future and past and then experiences in which you're not identifying yourself with some place in space so there's no spatial self location and if I understand Thomas correctly he would suggest that in such minimal phenomenal experience there certain some potential for certain control processes is is still experienced so what I mean maybe we can try to illustrate this with attention so you can either be in the process of controlling or changing your attention and have the experience of being in control have an an experience of attentional agency and you but you can also have a um a sense of control of the potential for changing your focus of attention so you you know now you're fixating focusing your attention on something or maybe on on my voice but you are aware of the fact that you could shift your focus of attention and this is so this this potential aspect might be something that in in one form or the other could still be present in a minimal phenomenal experience and Thomas can probably describe this more eloquently and more detail it also makes me think what are the prerequisites for attention it makes me think that something like temporality or just some Dynamic needs to be there right because how are you going to go from one thing to the other without it being overtime which also makes me think that it might have to be also over space because well I guess we also have covert you know mental attention not covert attention mental attention whether that's going through some space is kind of depends on how you define space that's a really interesting question I guess yeah there's a there's a nice link there you could say okay I've got a function that remains in the minimal phenomenal experience but let me think also about what the necessary features of the experience or the world would have to be for me to have that function um yeah it makes me think of these um so-called pure Consciousness events uh which I came to know about through John BVI and he sort of describes how in these pure Consciousness events um so adjectival qualia redness bless sweetness disappear but um we Call's adverbial qualia remain and by that he means nowness heess presentness what you know perspectival and maybe that's a nice Road in but um yeah I will I probe that with um with Mr matzinger your well I I read I've read your papers before and I read them again because I think they're so wonderful and interesting you have these two with call which I love um and in one of them you talk about sort of Life mind continuity which I've also been getting really into because I've been reading my Evan Thompson um and in addition to sort of life and mind distinction you also have a distin between basic minds and non-basic Minds which I think is important as a prior thing to understand before we get into a sort of Life mind continuity so at just a very basic level what would you say is the distinction between a basic mind and a non Basic mind um yeah so if I remember correctly I I think the uh we we mainly make this distinction in terms of representation so a basic mind would be one that does not have representations and a non-basic mind is one that has representations good and how does that feed so how does that feed so um when EV was talking about mind and life continuity he was kind of seeking underlying uh functions structures processes that are involved both in the constitution of mind and life so for example autop poesis self-organization um or what else would he have had um operational closure these are all things that were coming out of sort of the dynamical systems theory and Vera's work and now we've got Act of inference so I was wondering whether how does Act of inference because I think at one point you say in that paper um I won't missp speak I think I've got the quote here all systems possessing a mark of blanket have properties that are relevant for understanding the mind and Consciousness if such systems have mental properties then they can have them partly by virtue of possessing a Markov blanket and hence your marov and monism this is I think is this is the F this is a 2020 paper so not the life mind one but it is it calls to mind a sort of Life mind continuity because as inference postulates anything that exists has a mark of blankets and it's doing you know can be seen as if it's um parametrizing basian beliefs about the external state so everything has a markup blank anything that we can call a thing as a markup blanket and as you say anything having a markup blanket properties are relevant and I think you've been very careful with your words here for understanding mind why would that be the case and also how does that how is that the case without us resorting to a sort of pan psychism yeah that's a good question really fair question because I think what we say in that paper can easily be misunderstood and maybe yeah we should have found a better way of of conveying what where I I should have found a better way of conveying what I had in mind so the idea is not that as soon as you have a mark of blanket you have have a mind and and it just becomes more complex the idea is more that as soon as you have the mark of blanket if you are self organizing system which conforms to the free energy principle so there's a mark of blanket and you can then then you can interpret internal States as encoding probabilistic beliefs about external States given blanket States and this is the feature that is also relevant to understanding I would claim the mind it does not mean that once you have that you already have a mind in an interesting sense but it's just that if you have a mind then you can describe you can understand I would say mental processes in terms of minimiz ing variation free energy and then and and understand them them in terms of and in terms of computational processes that involve these probabilistic beliefs about external States given blanket States and so the the what what I really wanted to say is that this is not something that comes at at a later stage when we have really complex system but according to the FR energy principle we already have that for very simple self organizing systems and so to contrast this with um anactive approaches that would say well we have these simple systems and they are still that they can be quite autonomous and so on and remarkable and so remarkable in fact that even higher even nonbasic Minds in in a different sense or maybe I shouldn't say non Basic here but so even more complex system most complex organisms like us that have Minds um they they many of their properties can be explained many of their mental properties can be explained by reference to the same Dynamics and features that are already present in simple autonomous systems and maybe you don't even need to invoke representations to explain these more complex organisms and I'm suggesting well no because you already have some form of as if representationality or intentionality and even simple self organizing systems and this as if representation ality can then um or you can making some some further assumption you can argue that in more complex systems it's not just a useful way of describing them as if they had representations but they they actually have representations and so there there's something in in simple self organizing systems that already there uh that's also there in in more complex organisms that have a mind and Consciousness and in order to understand the mind to the extent that the fre energy principle and active inference are useful to understanding the mind we have to invol we have to refer to these internal States and how they encode beliefs about external States given blanket States and that's some something we already have in very simple set of organizing systems so that's just the the idea which I think um if described in the way in which we did can be really misleading no I hope this also suggests how it avoids pan psychism not I'm happy to elaborate them no I think so um and to be fair you make it actually pretty clear um you say that you sort of propose some rhetorical questions does it follow that all systems with a mark of blank have a mind are such systems conscious this formalism itself does not answer these questions so I think you I think you're fine I think uh maybe what people might be slightly confused over is this notion of an information geometry if they've ever read this this paper so the way that I understood it was you have sort of two informational geometries let's say two ways of uh describing a um a system that has a mark of blanket internal and external States right that coupled system and you have the so-called intrinsic geometry which actually just describes the behavior of the internal state if it you know um I don't would that well I'll I'll ask whether that includes the particular States I the blanket States and then you have the so-called extrinsic geometry which are the beliefs that the internal States actually encode about the external States so that's a very sort of rough um draft that the distinction between the intrinsic geometry and the extrinsic geometry would be great if you could flesh that out a little bit more but how does that pertain here to um mind because I think you also make it quite clear that that property of the mark of blanketed system itself is relevant to the question of mind yes so it it is in a sense relevant but I would say in a rather trivial way so yeah I I think this can be really confusing and I'm not sure how useful it is to even refer to information geometry to get at these more General conceptual points but so an information geometry is just you you have a space in which every Point corresponds to a probability distribution mhm and then you can um you can have different shapes and um manifolds in in this uh space so for example surfaces and compute distances between points distances between probability distributions and these distances will not be ukian distances so it's it's just um different form of um the different kind of space yeah and so every so the internal States if you interpret them as as U probabilistic beliefs about external States given blanket States you can identify them with points in the in an information geometry and then the way in which these beliefs are updated and which updated in which they change can then be described as a trajectory through that yeah um space and you can Al and you also have a different space of probability distributions for the what one could call the physical dynamics of the system so if you're not referring to probability distributions encoded by internal States but about the probabilities of internal States or maybe an paths then you you can also identify them with points in in such a space space of probability distributions but it's a different these are different probability distributions and the thing just is that you you can then describe trajectories through both of these information geometries and in in a way they are two sides of two different sides of the same coin so the idea is that you can describe the physical dynamics of these self-organizing systems equivalently by describing them in terms of the Dynamics the belief Dynamics or basian mechanics in terms of changes of probability distributions encoded by internal States rather than in terms of probability distributions Over States of the system yeah yeah okay so I think the reason why this might be a bit confusing for people is because then people have heard that all that we're talking about when we talk about internal States is this parametrized if that's a word beliefs about external States that's all the internal states are right they just are distributions over external States okay so that that that might be a commitment anical commitment to say that but let's take that as a kind of starting point that's what we mean by internal States and then we have an intrinsic geometry which is mapping the evolution of those beliefs right um and that's over time but that given that those beliefs just are over the external States is there not an isomorphism between the intrinsic and the extrinsic in so far as when the intrinsic changes I.E when the path of the state of the internal States changes by necessity the extrinsic information geometry would have changed because the intrinsic the internal States just are the probabilistic distributions that the extrinsic geometry defines so for me I can't right now see how there's a I say they're isomorphic I almost think well I almost can't see how they're not one and the same but I might be missing something I probably am missing I'm always missing something no I I think you're on the right track so there yeah essentially just just two different ways of describing the system but okay so but do they so what is the utility of that I guess is the question because to me it seems like you you just a very philosoph you know philosophy of science point the utility of two different descriptions of the same phenomenon it has to have some utility right like if we're talking about heat I talk about how it feels to be hot or I can talk about the velocity of particles within a heat bar or within whatever but that's useful because one I can attend to phenomenological facts and the other one I can attend to facts about physics whereas this it just seems like primy there are two dis inct descriptions but under the blanket because the internal States really just are probability distributions about external States there's nothing over and above their evolution beyond that which can be described by the intrinsic information geometry so is there something more to these two types of descriptions which make them distinct or is it is it just some semantics I I don't want to say that because that always sounds very derogatory and I don't mean to be derogatory yeah so um on on on the one hand what one could say yeah and to some extent it's just semantics but that doesn't mean that it's not useful to use one instead of the other description so think about describing a system in terms of representations so you you can of course just describe the vehicles without referring to the content and so you're dispensing with the representational description and just focusing on the physical material realizers of the representations and that that's fine but um you typically get some benefit of going to a different level of of description so when you're describing a system in terms of um representations you have you can refer to contents provideed normative description so the they the system can have true or false representations or they can be more or less accurate yeah and so and and you also have that for uh the the Basin mechanics so it's in a way it's just a different way of describing the system and you don't need that you can describe the system you can stick to your physical purely physical description um and don't need to refer to probabilistic beliefs but this gives you some benefit so on on the one hand it reduces complexity because when you're referring to internal States as encoding probabilistic beliefs you're actually C graining the system and uh not just talking about the say the the um billions of of neurons but about neural populations that encode different beliefs and so you can um reduce the complexity of your description but still um given that if the free energy principle is correct you um have an an equivalent description it's it can still be as accurate or almost as accurate but without having to deal with all the unnecessary details so that's one benefit that you get just a reduction of complexity yes I sense that that's a reduction of complexity for the scientist I guess really you very much put it nicely in terms of the distinction between the vehicle and the content which certainly pertains when we're talking about representational systems I guess my point really here is that I arguably think that there is no vehicle the internal state is not a vehicle of anything and I think this really comes down to actually how you describe it because the way you describe it is that they encode probabilistic belief whereas I think if you're abandoning the vehicle you can just say they are prob um and if I think if you have the vehicle but so sorry so then it seems like you're dispensing with the physical purely physical description and just happy to to say well we we only need the basil mechanics right I I would just say that um what we we are sometimes misled to think that active inference entails a uh representational approach and yeah you so you can do the descriptions in terms of the basian mechanics that itself will map on to some physical organization um but I don't think it necessarily dispenses with it it just says that when we as scientists try to carve up these spaces we are making well when we are making these very strong distinctions and this is something that I've been tackling with literally ever since I disc CED active inference and learned about the free energy principle which is what is unique about the internal States right what what what is there something over and above the parametrization of beliefs about external states there in the internal states that make the thing the thing it is I.E are is all that we are preferred external States or are we a thing that is trying to get to preferred external States if you can see the difference there so that I think that again comes back whether we embody a generative model or have a generative model and I think I've been leaning in terms of the just in terms of the physics towards the idea that we embody a generative model all that means is that we are just a bundle of external States and you can describe the the the direction the information travel of those external States in terms of Asian inference but the internal external distinction is somewhat illusory because we just are the external States might sound very s Buddhist actually but um yeah I think maybe that's where we we don't necessarily we're not disagreeing but maybe where I don't really see the strength of this this distinction because I don't really see the strength of the distinction between the internal and the external and arguably I just see it as a instrumental tool I don't know if that answers your question um yeah no no um that's a good point also uh speaks to what we talked about in the beginning right to what extent there's a fact to the matter whether something is internal or external yeah I just think a big mistake that people well I think a big stumbling block that people have although it may also paradoxically be a very useful tool for them is to think of active inference and this is more like a meta conversation about how we get educated on these things think of active inference as a theory that needs a homunculus and I'd argue that it's not but then you have to be very concrete on the fact that free energy principle and active inference is a Theory of physics um and it's just describing physical manifolds well not even physical manifolds in this statistical manifolds whether they're physical mental so on and that I think gets you away from the kind of more hunzed predictive coding predictive processing approach um and so again I mean ultimately I think it comes down to one's aims and I think as far as I'm whereare the math stands up on both fronts um and maybe it's a question I need to speak to KL about which is you know so the free engine principle rests upon the mark of blanket distinction why do we not just have one unified State space where things are tending well different things are tending towards different manifolds why do we need them to be tending towards those manifolds over the parametrization of external States and I think here the really important point is and we' come back to over and over again on this podcast the free energy principle tells you what things look like they're doing not necessarily what they are doing um and maybe that deflates to use Carl's favorite word it deflates some of our worries about really making any strong ontological claim right it's just a descriptive thing then that makes me think well what's the uh what's the point but I don't think what's the point so I think it's important and I think you do get some you do get some good stuff out of it so yeah that there's just one thing I I would like to add so um that I I think there's one perspective from from which we one can argue that it's not completely arbitrary whether we say we we interpret or we describe internal States as probabilistic beliefs and identify them with with these beliefs and just focus on this or whether we also think about the the other perspective other way of describing the Dynamics of um the system because the the same basian mechanics the same dynamics of belief can be realized in different ways and so you you can simulate this on a computer or you can implement it in a living organism and I think when we consider the possibility of artificial Consciousness this actually may make a difference because if we're just focusing on the if we're just seeing internal States as probabilistic beliefs and nothing else then we cannot make this distinction between different types different kinds of realizations of variation of free energy minimization and I think it's a an open question and very important question to what extent there can be a conscious experience in a computer in a digital computer with a classical architecture or to what extent it needs a biological body or maybe a robot that can interact with the environment and for for this reason I I think it's important to keep this to yeah not not to um ignore this distinction between two ways of looking at the system yeah fair enough guess uh ultimately as well I do think is important to say is that it depends on how you define beliefs um and that's something that we all like not me and you necessarily but all of us equivocate on the whole time because we're not clear where we're talking about folk psychology beliefs or basian beliefs and I guess when I'm talking about the internal States just being manifestations of external States I'm talking about basian beliefs in terms of the the beliefs that those internal states have when I'm talking about the rejection of the homuncular view of the internal States in many ways I'm re rejecting I'm not I'm not rejecting the basian beliefs that they have or embody or entail or so what I'm rejecting the folk psychology hunzed representational propositional beliefs that we talk about in philosophy so I think that's an important thing as well for people to bear in mind that there's often risk in Act of inference that we equivocate and talk past one another again not you and I generally but you know everyone because we don't get concrete on what we're talking about with respect to beliefs but that's a nice interesting um segwave because you wrote this paper in 2022 with Carl on AI eics in computational Psychiatry and it actually takes us nicely full circles to Mr metzinger Professor metzinger me um because he actually was the first person I ever read in the ego tunnel talking quite explicitly about the effects of generating artificial intelligence like re and in a very philosophically robust way obviously people have been talking about well what are the ethics in terms of job opportunities in terms of um you know trolley problems when my car might run over a grandmother or a child and so on but I think what Thomas said that was really impactful for me was we might be actually creating conscious life so it's not just the you know it's not just the the ethical effects on us it's actually the generation of sentience feeling Consciousness into the universe and uptick in that whereby those things start to actually have moral value which are arguably equivalent or perhaps given their greater complexity and depending on how you define your morality more important than us so you can throw out the window your kind of classic Sam Harris worry that AI is just going to stomp on us like we're ants right that's one ethical issue about us but also and again this is I don't mean that this should happen or will happen but arguably you know those AI creatures are going to have sentience and feelings and Consciousness just like us and we have to take their so you know rights or values if they have them if we give them that into account so it's not just a single sided relationship that's going to emerge I'm curious about what you think about that is it is it a concern that we really have to take seriously that if for example we end up making AGI and very importantly that AGI is conscious because I think there's a really important point there there's a difference here between intelligence and Consciousness um what concerns do we have to have not only about ourselves but also about what we are bringing into the world yeah good I think there are many different and to some extent related questions that are relevant here and one question is of course what what about the risk of actually creating artificial Consciousness what consequences would that have and should we do it or should should we refrain from even attempting to create artificial Consciousness um there's things become more complicated when we also consider the fact that there will likely be a lot of uncertainty about whether um a given artificial system is conscious or not so um Eric schwitz Gable has done a lot of very relevant and interesting work on this and he describes the problem roughly as follows I'll try to summarize the main ideas but there's um people who are interested in this can easily find his Publications and uh podcast interviews with with ER Eric schitz Gable um so highly recommend uh looking these things up and um so the the basic problem is this um there might be situations in which there are artificial IAL systems that may seem to be conscious and we might in addition also have no way of being certain that they are not conscious so there might be no um clear evidence as to whether they're conscious or not even from a scientific point of view um given that we don't have a consensus in Consciousness SS we don't really know what Consciousness is there's no um generally agreed upon Theory Of Consciousness and so on and many different metaphysical views about Consciousness that all have some currency so there's a lot of un uncertainty about which systems could be conscious and as artificial systems become more and more capable and have become have have more and more impressive cogn ative capacities there will likely be points at which they well seem conscious and also fulfill some indicators of Consciousness that we might have but they might still be quite different from human beings conscious human beings or other conscious animals in in many respects so that there there will be a lot of uncertainty and there there two types of errors that one could make one is believing that such systems are conscious and maybe also believing that they therefore deserve moral status maybe because they can feel pain and pleasure um so assigning a moral status to such systems believing that they're conscious although in fact there's nothing going on they're completely unconscious and then there might be situations in which we have to make tradeoffs between the interests of human beings conscious human beings and the seemingly conscious artificial systems which are in fact unconscious so just if we just think about uh um I mean just just uh a slightly silly example trolley case in which we we um can save five artificial systems that we believe are conscious or one conscious human being and of course if these systems actually are unconscious but we just think well we should U be well better safe than sorry uh we we should not um we we should just we on the side of being a bit too liberal and we might uh say would be a good idea to save the the artificial systems or in in other situations in general just um put more weight on their interests and in fact um they're they're completely unconscious and yeah so that that would be I think yeah that's a terrifying idea yeah of course the other case is that there are artificial systems that don't seem to be conscious and we firmly believe or we we um maybe there's also some uncertainty but um for whatever reason we decide no um these the systems are probably not conscious maybe because they don't seem to be conscious but actually they are conscious and then in certain situations we might without thinking much about it sacrifice them or um destroy them or whatever or and and in fact um maybe um induce a lot um um a lot of suffering in these artificial systems but without knowing that so these are two scenarios that we I I think would like to avoid and schwitz Gable certainly argues for this that we should avoid such situations namely by avoiding to create systems for which there's no certainty about whether they're conscious or not and so this is not not um it's a bit different from metzinger's position and um the the question of course is is this really feasible or is it realistic that we will in the future um only create systems that are either clearly non-conscious or that are clearly conscious and I think in in order to get there it would be really useful um to have a handle on some necessary conditions for Consciousness that might not be fulfilled by certain classes of artificial systems and if for instance having a body is required for being conscious then we could rule out that Consciousness in a computer simulation so I'm not not claiming that I have a good argument for this but um it's I I think it's would be extremely desirable to have a Justified account of necessary conditions for Consciousness that are not fulfilled by many artificial systems and so um that that's um the line of research that I'm trying to pursue of finding good reasons to believe that there are certain necessary conditions for consciousness of course the other approach which um I I must say from from um from a certain point of view seems a lot more compelling is to say well we don't really know what is necessary for Consciousness or not we cannot rule out that certain systems are conscious if they don't fulfill certain conditions but uh we can look at theories of Consciousness we can look at work on animal Consciousness and derive indicators for Consciousness and that's this um uh preprint from last year by um Patrick butlin Robert long and a whole bunch of other authors Eric schitz Gale is also one of the co-authors and they they do exactly that they say well um under the assumption of computation of functionalism uh we can derive certain number of indicators from theories of Consciousness and can think about how they could be implemented in artificial systems in AIS we can also assess to what extent they are already fulfilled by current AI and but based on this it's highly unlikely that current AIS are conscious but if future AIS fulfill many of these indicators it becomes more likely that they're conscious so each time a an artificial system fulfills one of these indicators the probability that it's conscious Rises a little sure and of course that's um very elegant approach because you don't have to make any strong metaphysical commitments you can just say well we we don't really know what Consciousness is but we can say what features make it a bit more likely that a system is conscious and as soon as we have systems that fulfill many of these indicators or many markers of Consciousness we might reasonably say well it's highly likely that a system is conscious and we should um assign moral status to the system but of course then the question is what what happens in the meantime when we have many systems that fulfill some indicators or many but not maybe not so many indicators that we can really be certain that these systems are conscious and how can we avoid these situations yes it's fascinating it's fascinating and we don't have time for me to put on my philosophers skeptical hat and uh and point out all the problems with trying to find behavioral indicators to Consciousness which are so obvious that I don't really need to say them but again that's the philosophers point and this more of a pragmatic point which is we are probably going to have to make that decision at some point and so why is actually kind of interesting we're saying up a sort of basian process with which to come up with a posterior that a given object is conscious or not so it's kind of fun that we're inverting the basium process to figure out um but as you know your model is only as good as its priors and if those behavioral priors or behavioral indicators are wrong then you are really barking down the wrong tree you might be Bay optimal but your Bay optimal for dysfunctional purpose um cool that's really yeah that's fascinating I mean I'd love to go further but I'm aware that we are running a bit low on time so you mentioned this is kind of your main focus of research at the moment what else can people expect from you coming up next couple of months this year and also how can people get in touch with you if they want to ask you questions or just chat yeah sure um so I'm I have a blue sky account and um I I think my blue sky handle is va. Visa probably should check but um I also have a Twitter account I don't really understand what it is I like Twitter but yeah so so I also have a Twitter account and then my handle is w a w s e I think excellent and um and what can people look forward to reading or or hearing from you about um and also maybe plug the workshop that you're at now because that's a really cool um thing that you guys are doing yeah so I'm currently at um the ik in gunner in Germany um ik is um the interdisciplinary College it's a spring school for cognitive science and it's an entire week with a lot of fascinating courses MH from AI to neuros science neurot technology um we also have some more philosophical courses uh some more theoretical some more practical it's a really great mixture and there many Fascinating People over here that you can talk to so I highly recommend coming to the ik and Guna and um maybe do you have show notes or something like that for the podcast maybe you can provide link to the website is everything goes in the description I'll put your blue sky in the description as well I'll make sure I do that thank you cool and also maybe maybe one thing what what people can expect um so I I signed a contract with MIT press um for a book on artificial Consciousness so working on and also um I think I I should remind myself that I should be busy working on the manuscript fantastic well congratulations is that uh do people know this already or is this a big reveal have we done have we done an exclusive break on active inference insights or do people is this do people know about this book already um I I think most people don't know about it I've just told a few persons about it but on the other hand most people don't know me so yeah true no one knows us well yeah I forget that I was just trying to sort of embody a you know speculate you know speculative Paparazzi esque person I it very well van this was super fun um I feel like there's still a lot to get into um so maybe when Thomas comes it would be great to have you on even if you know partially for a bit so we can get deeper into these ideas and um thank you for plating me and listening to my ramblings about recursive properties and operations it's no thank you thank you very much for for having me and then this was really a pleasure so um I think it we had a nice flow in the conversation we did we did all right thank you everyone for watching as well take care