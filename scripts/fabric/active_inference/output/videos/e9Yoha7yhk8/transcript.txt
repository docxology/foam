hello it's March 22nd 2023 we're in cohort 2 in our second discussion of chapter nine we're gonna Jump Right In to anything that people are thinking about related to chapter nine or just in general so whoever would like to bring something up go for it yeah uh so I have a question that you you said last last time I don't know whether it was in what context it exactly was that you would you would say we talked about or you talked about um about affordances and you said that policies are not affordances and then I was wondering what then affordances are because I understood policies are not affordances because they are in the future but but then I was thinking what that should mean because the present is a point in time infinitely small so which would imply that affordances doesn't exist or how would you see this so if one thinks that an affordance is yeah if we are in this in one state and the policy is a sequence of states in the future but then even if we have this embedded States I can be in the state of learning for instance active inference which also I mean implies some actions in the future so I was a little bit confused about this notion and why you would think that policies are not references maybe I misunderstood thanks Ali money of a first thought and then I'll be happy to add some okay well uh yeah actually uh well in fact in active inference literature there are some Divergence between the way terms uh used uh in this context uh as as compared to uh their other connotations or other meanings in some other contexts such as reinforcement learning and so on so uh basically uh in active inference by policy uh they generally mean a sequence of actions uh but for instance in RL learning policy is defined as just a single action and affordance again is a kind of problematic term because we have different Notions of accordance for example in uh ecological psychology or in some other areas but uh to the best of my understanding in active inference um affordance refers simply to a single action in some cases but in some other cases it can take on some other additional layers of mean so for example weaken ordinances or pragmatic affordances and they they somehow uh conflated with each other and uh they they can be confusing to uh delineate which uh notion of affordance is referred to here in this context so yeah those are pretty much the basic uh or at least some of the points that can help to delineate those two concepts accordance and uh policy but I'm sure Daniel would have some other thoughts on that as well awesome yes a lot of good points so big picture there are divergences between how the terms are used in active and in reinforcement ecological psychology we hope and basically believe that there's coherence in how the terms are used but that doesn't guarantee coherence within and across areas which themselves are not necessarily internally or externally consistent so policies are sequences of actions over a given time Horizon affordances are the instantaneous single action possibilities described by the E variable so map not territory if you're in a maze and you can be going up down left right then those are your affordances and over a Time Horizon of four you can have policies of a Time Horizon of four with all the combinatorial possibilities of up down left right to the fourth power um then there are there are those sometimes informally applied statements like a pragmatic affordance or an epistemic affordance which is like when action is being taken that is oriented around epistemic value but this is not like a this is kind of like a modifier like it's a risky affordance or it's a um you know fun affordance not necessarily like a special subtype in a formal way um and it's described by the E variable you could have a nested generative model so like live stream 42 with a slam simultaneous localization and mapping at the lower level the robot has up down left right affordances at the higher level the policy selection the affordances have to do with locations moving amongst locations and so you can have nested affordances because you can have nested models that's not any controversial or hot take on the system itself it's just describing the model and then um what we can look into more and what Paulo is researching uh and and some others is explicitly in contrast with the ecological psychology concept of the gibsonian affordance use what was also called like affordance 1.0 2.0 and then Maxwell ramstead taking the perspective that active inference affordances are affordance is 3.0 The gibsonian Advocates emphasize that affordances are directly perceived action capacities so for them indeed it is not making sense that there could be affordances in the future but people have also considered planning from an ecological psychology perspective but their emphasis is on the direct perception of action possibilities which coming from the e Vector perspective it's kind of like take it or leave it the E Vector might be known in a metacognitive way might be directly perceived or it might not sorry what is an e vector the E Vector is with the capacities for action here and step by step the E Vector is the habit these are the actions that can be taken are enumerated and the values in the cells reflect the prior on action we can see that in the textbook in [Music] um the figures for chapter five so here we have a dopamine mediated so neuromodulator mediated uh balance between two modes of policy selection here in some dopaminergic regions in the mammalian brain so in both cases observations are coming in in the indirect pathway the E Vector is basically passed along and the policy posterior which could be sampled from neutrally or you can have a shaky hand and erase differences in the policy posterior or you could have a precise hand and always select the maximum element maximum posterior action probability in the indirect pathway The Habit Vector is basically just passed along so action selection resembles action prior whereas in the expected free energy deliberative type 2 archetype of action selection there's this sharpening or updating of the action prior into a policy posterior that's been re-weighted by expected free energy This is highly schematic and like not all the variables are shown in many cases it's just schema so habits is something bottom up sorry and um and the g Vector is something top down so that's plant and the other one is hmm routine or something yeah yes um yes um yes as always these are aspects of generative models not of organisms so it's hard because we want to be referring to the habits and the deliberation patterns that cognitive systems do but also be aware that like e and G are phenomena of our model they're not phenomenas of the world but that being said the role of E is to through its membership or composition enumerate what instantaneous actions are possible if there's up down left right then the E Vector is going to have four elements if there's nine directions it can move then e has a length of nine the values within the E vector are the prior on those actions being selected in an instance so if there was a uniform e Vector across up down left right one one one one then there's no prior asymmetry towards taking any of those um actions whereas if the E Vector was 10 1 1 1 then that is equivalent to saying like that um in the absence of further expected free energy updates that action prior will be recapitulated in future action and so you can imagine a model where e is updatable or not like a simple updating model for e would be every time you take an action drop a pebble into that urn so that's the learning as counting strategy which works for for many things so that the um action prior comes to embody previous action posteriors that's habit and so what initially may have required a deliberative expected free energy expenditure becomes canalized or entrenched in e allowing for example skill or skillful performance to occur without the um deliberative High dopamine setting in figure 5.4 here the dopamine variables gamma and um yes two of the places to look for further discussion on that some of it is um the ontology project where with Paolo and others we're talking about like um ramstead and Camaro and all of these different perspectives on affordance and representation and also there's been an interesting discussion about like similarities and differences with A continuous in the discrete time model so the affordance is 3.0 discussion and then the other angle for critical perspectives on the octave strategies and counter rebuttals is the Markov blanket trick Ollie I just wanted to point to a kind of possible point of conf a point of possible confusion that can arise uh when dealing with these ABC sorry d e matrices and vectors uh because uh it's sometimes it's difficult to remember which Matrix or which Vector encodes what so one simple mnemonic that I found helpful in Remembering those notation notational conventions is as we go from a to e we move from instantaneous observations uh into our prior and learned and habit um beliefs about the world so for instance a encodes our beliefs about the relationship between the hidden States and the observable outcomes B is about the likelihood of the transition C encodes our preferences the encodes our beliefs about initial hidden States and finally e encodes our habits uh so yeah I think that might help to remember those terms awesome and and G some kind of metaphysical expectations or something like this or what is cheating um so well it's all metaphysical they're all informational because they're all variables although one can take the Chris Fields perspective information as physics yeah yeah yeah but that being said um we continue down the line with f as a variational free energy and um G as expected free energy um however these are all symbols and uh there's sort of a a common set of symbols in some sense but but they're they're by no means necessarily these letters I kind of goes without saying but it definitely can be a point of confusion but um let's look at our favorite step by step pull in the image for the 100th time foreign oh observation s hidden state d prior on hidden States a the emission recognition Matrix between s and O this is the tale of two densities because a can go from s to O emitting in the generative Direction plausible observations from hidden States or a can be used in its recognition capacity to update s based upon incoming observations so in the upper left static perception case all you need to appeal to is a b or I'm sorry A and D S and L then Dynamic perception it's still passive but it's changing through time and what changes the hidden State through time is B the transition Matrix on hidden States to enable policy selection at least two other things have to come into play well at least one but really two the one that must come into play is simply the enumeration of action capacities which is listed in the membership of E and the cells contain quantitative information on the prior probability of those actions being selected AKA habit you could have e and just be taking actions however what is it that steers the ship on which actions are selected well the way we do that in active inference is not by proposing a utility function and maximizing utility function in a reward function but to encode through C our preferences what we expect slash prefer we talk about them as preferences because they play a functional role teleologically as preferences in the sense that pragmatic Behavior reduces the Divergence between observations and preferences so in the sense that their preferences they are that but what C does is it's like a thumb on the scale of observations not by changing anything downstairs with the Tail of Two densities but rather through expected free energy selecting policies that are expected to reduce the Divergence between observations and expectations and by way of reducing divergences between observations and expectations about observations we acquire pragmatic value oriented towards C in the extreme case fully realizing C exactly having a homeostatic temperature exactly having how much money we want in the bank whatever it is and so functionally C is called preferences and then there's this little extra piece on the right that's also reflected in that dopaminergic image with gamma as a temperature gamma and beta is one over each other and those gamma being a parameterization of a big gamma distribution and then be one over each other so whether you choose to think about it as like temperature or inverse temperature that is a Precision on policy selection and then last thought on this this is not the only active inference model you could have a Precision on anything you can have a Precision on D you could have a Precision on a you could have a Precision on B so these are like some birds I've seen this is not the overall exhaustive zoo of all possible birds or the one possible bird these are like certain configurations of Base graphs which we can use a controlled ontology to describe so that we can apply them in cybernetic contexts for example designing ecosystems of shared intelligence Ollie I also believe beta is technically called stochasticity so in some literature they explicitly use this term stochasticity to refer to that beta parameter which sometimes uh for the sake of Simplicity is equated to one in order to not complicate the distributions especially the gaussian distribution so um but sometimes they can be just it can be arbitrary value of a stochasticity yes thank you um and when we see the um the learning figure 710 here learning in a Bayesian setting can be seen as as having a prior on that variable so if we have a fixed parameter d then it's just like a um like a Dirac Delta #category Theory but it's like one point that's just fixed and it's a fixed value there's two states and it's one zero so just it is the first day or you could imagine the instantiation of that prior parameterization to be drawn from another distribution and then you could imagine learning or updating within that setting but if you have just a fixed parameter then it it can't be updated but if you have a fixed parameter or associated with a prior then you've opened the door to learning and invoked all of these other kind of Bayesian considerations like making sure that your prior is not simply being recapitulated in the output so like testing for different priors and doing all these different things for standards rigorous Bayesian statistics Michael yeah so in this graph that you just showed the um an affordance would then be the relation between s and O um no it doesn't know hidden States and observations so a is the tale of two densities here's the temperature of the room s and the thermometer o so the recognition density is what's the temperature given the reading and then the generative density direction is from the temperature what's the thermometer so the downstairs is all passive inference downstairs passive inference here's our prior on the temperature in the room temperature in the room changing through time we're not doing anything about it and at every time step it's emitting an observation where action comes in is in the upstairs with E the actions that we can take and Associated habituality around them and then as to do more than simply recapitulate habit we have preferences which have a semantics of being expectations about observations I expect myself to be homeostatic and I'm going to take actions that make that realized so reward learning paradigm I'm rewarded by having homeostatic temperature and I follow policies that are rewarding active inference self-evidencing paradigm I expect to be homeostatic and so I take action selection to reduce divergences between the observations that I do get and what I expect slash prefer so so how does the can the notion of affordances then be explained with these graphs that you showed is it a vertical slide through this this architecture or I mean it has to do with uh with the o and with preferences that's what you just said right the actions are taken uh I mean in a way the actions are taken in the Adaptive case in service pragmatically of reducing the Divergence between C and O that is pragmatic value is reducing that and that's where the KL Divergence we're reducing the Divergence between C and O that's pragmatic value epistemic value is reducing our uncertainty about different things where the affordances can it be seen as like a slice in time in this graph so the affordances are enumerated in the E variable and in every single time step they are going to be crunched by G and then B let's just say that there are two affordances we can turn the heater on or we can have the heater off so B is going to have um two slices B is like a tensor it can be any the dimensionality is really important and looking at the notebooks and the code around these things is some of the best way to get intuition for this but basically B has a slice for every affordance so there's like a b like a transition Matrix for the heater being off and then there's a transition Matrix for the heater being on so like let's just say that in our hidden State there's three temperatures um cold medium and hot so again map not territory we're not saying that there isn't a quantitative temperature in the room it's just we're choosing to model the hidden state with three discrete States and so if the heater is off the B Matrix let's just say looks like the identity Matrix so if the heater is off the room's temperature does not change if the heater is on we bump from cold to medium medium to hot and we stay in hot and so then the ones would be like in different locations on that slice of B what do you think about that yeah so trying to digest so so you're saying the affordances are occur encoded in the transitions between states um the affordances are most plainly listed in the E variable however every affordance is also represented with a different transitions different transitions slice in the world if there was just one transition Matrix then our action wouldn't do anything because the world is just going to change the way it's going to change no matter what we select so then all policies would be equally meaningless in service of reducing the Divergence between our preferences and observations so again not a feature of the real world that there's actually a b Matrix out there that has a number of slices equivalents the number of actions that can be taken but given the dimensionality of E there is a slice corresponding to each element of e in b and then if affordance one is taken slice 1 is used in the transition if affordance 2 is taken slice 2 is used in passing s forward okay and what um what if there is somehow an implication if I'm in right now and there's an implication for the future and well perhaps not really a a deterministic one but um so I decide with my decision right now it's what happens in the future but the future would not be an affordance in that sense even though it's part of maybe a policy it's not an affordance because it's not related to to that transition that is immediately activated that's right now the case something like this that that's a a a commendable compatibilist position between the ecological psychologist and active inference is like saying well affordances are real in the moment and so policies which also include actions that are taken potentially in the future like imagined actions those are also those will be real in their moment and they're cognitively real in this moment and that's why this also invokes the discussion around representationalism because if one takes a realist perspective and says well this is what they're doing they're evaluating all counterfactuals in the organism's brain or in the computer program or something versus is this just an instrumental analytical framework that doesn't actually mean that there's an e vector or the enumeration of counterfactual policies at all so the realist angle would be this is the causal architecture and it's and patterns in this base graph will be associated with for example neural activity patterns which can be understood as neural representations of these quantities and processes the instrumentalist is under absolutely no compulsion for this architecture to reflect anything in specific about the slime mold the ant colony the civilization it's not like there actually has to be the enumeration of counterfactuals about hypothetical action sequences but we list those as a convenience and then we can apply tree surge branching time active inference etc etc as heuristics in the space that is combinatorially constructed but that from an instrumentalist point of view doesn't mean that's what the system is doing and that is like at one of one of the heart of the tension because the gibsonian affordance concept centers a quintessentially realist phenomena which is what the organism is actually instantaneously perceiving in terms of action capacities chairs are for sitting which means potentially under like some people's interpretation of radical inactivism like if you don't see the chair you're not having that instantaneous perception of action capacity whereas an act of inference especially from an instrumental reading were basically on the plus side completely free from that but on the downside people need to be very careful that they don't sneak the realism back in and say well here's going to be the central nervous system just conceptually decision making and here's going to be the nested model of the hand and then it's all good they go off on their instrumental way and then all of a sudden they're interpreting this is the elbow as if this architecture was reflecting for example something anatomical so instrumentalism allows one to fly freely with this analytical framework and leave a lot of baggage at the door however in the case where realist conclusions are being sought to be constructed one has to be careful that they weren't actually taking a covert realism along for the ride the good news is I think people can do that because they don't have any problems with linear regression but then again some do in some cases but the architecture of that base graph can be seen of similar to structural equation modeling it's not exactly the same but having edges and nodes is not the system's mechanics but given this statistical artifact it's very easy to say that this causes that instead of being proper and saying it's associated with that especially because you get into directed edges it's like well this is unidirectionally associated with that through time it's like come on then just say it what do you think yeah if you ask me I'm I'm digesting it I need some more time to get all this a little bit clear but thanks thanks so much to elaborate on this question thank you so much yeah this is like the heart of the textbook and the topic and this is a model architecture it's not the only model architecture but being able to interpret what these model architectures are helps us understand a lot about active inference and then I guess as we are seeing it also shines a lot of interesting light on broader questions about scientific modeling and bigger discussions which I mean to kind of return to chapter nine that's the metabasian perspective that's why we're centering this ethological moment with the modeler's construction of a cognitive model whose aboutness is the setup the experimenter has constructed and again that to make That explicit and encoded in our model structurally is the innovation because upon inquiry I don't think this is a contentious layout like if inside of the dashed line there was a linear regression or an SPM model and we said okay we gave we did the teammates and we had the rat hooked up to the whatever optogenetics or to the um confocal microscope or to the EEG or to the video camera or to the ultrasound it's like you got all these scientific tools okay we set up an experimental context and then we observe Behavior now what is it that was in between the stimuli and the Observer Behavior well obviously it was the mouse or the rat itself okay so we want to have at the very least some kind of model of our rats that is able to perceive experimental stimuli and then output Behavior so we could put a linear regression here here's temperature on the x-axis and likelihood of eating cheese on the y-axis and we make a regression or we do we we do model comparison we say okay is it better compatible with a linear regression or a break point regression or a quadratic regression and so you have the modeling discussion and they go okay we use the Bic and the optimal model to describe the relationship between temperature and cheese eating is a break point regression or it's just a simple linear regression would someone turn around and say why would you say mice are linear regressions the obvious response would be no we just use the linear regression instrumentally to describe our data check out the methods section look again we followed pretty standard process of modeling so that we were able to explain data but not overfit accuracy minus complexity and we use standard software tools and packages so that everybody could replicate it in its open source we're definitely not saying that mice are linear regressions but when figure 4.3 goes into the box different questions arise and I'm not even saying that what what I have just um proposed is infallible I I think people can have a different perspective on that for example they could say Well yeah if you do linear regression you're not saying the mouse is a linear regression but there's something different about active inference modeling where when you put figure 4.3 Inside the Box you've taken on a different set of commitments that's a totally valid point to make if somebody can point to those commitments and that's a discussion to have but simply considering active inference as like a software package or an analytics framework for Behavior just replace figure 4.3 in your mind's eye with linear regression and ask what claims are valid or not and there are differences between the models so there may be certain things that go one way for linear regressions and another way for pomdps however um there's also a broad set of criticisms that people level at figure 4.3 that are throwing out the linear regression as well but it's a format that people are more familiar with I assume this this expands much more potentially at least but you could generate a pomdp with zero explanatory predictive value and you could have a linear regression with a good r squared or not it's not a function of the type of model selected in fact the space of pomdps is just from a parametric perspective it's much larger like here this is still a relatively simple this is even without showing the dimensionality of these variables like if there's 10 affordances B is 10 is going to have 10 slices and then if s has um 10 um hidden even there's it's just 10 discrete options so you're talking about some large tensors and parameterizing them from data is non-trivial that's what chapter 9 is about and that's why we have often called for the development of statistical power analysis techniques because even simple models have many free parameters that might be related in complex ways like if C is like within this range then changes in a do or don't do that but if a becomes more ambiguous then this consequence happens over here and those are those those kinds of like Rippling effects in the model are not constrained to which edges are drawn so we need much better statistical power analysis techniques in order to anticipate the kinds of statistical considerations that people use for linear regressions and rna-seq analyzes every day um but there's nothing about this model that makes it fit any given data set better or worse these are all modelers choice any closing thoughts or questions on nine before we scan 10. I I also think it'll be interesting to see like as we have more notebooks and and accessible software packages that will help um support this deflationary perspective on active inference because it'll be like well what what what part of this um tiger is the is the B Matrix and we'll have like a notebook it's like well now here's the B Matrix in The Notebook but it's not in the world and and then just coming at that Nexus many many times will be useful but also I think including people in Empirical research is going to help with that because for one who hasn't read a paper and or for one who hasn't participated in empirical behavioral research with neither of which are bad or good States just saying some people have these experiences and some don't that um separation of statistical models from reality like mice are not linear regressions mice are not pomdps that is definitely like a posture and I don't mean it's a facade it's a stance that is built through statistical investigation at the very least reading it if not actually doing it oneself like once one sees that there's a hundred or an open-ended number of ways to model just the thermometer and the true temperature of the room that person will think differently about map and territory this is the Final Chapter 10. in general we are least aware of what our minds do best by Dr Minsky chapter 10 we're going to wrap up active inference main theoretical points from the first half of the book chapters one through five and the Practical implementations from the second part six through ten then we connect the dots abstracting away from specific models discussed to focus on integrative aspects a benefit of active is it provides a complete solution to the Adaptive problems that sentient organisms have to solve this is definitely a sentence that we've discussed in Prior cohorts does it provide a complete solution or does it set the table for a useful solution or or some other way of of saying that that you know have the previous nine chapters literally resolved all the problems or have they helped us learn the Linguistics and techniques that help us frame the problems so that we can come to heuristic Solutions but again these are the kinds of things we can discuss um 10.2 wrapping up this part all textbook offers a systematic account of the theoretical underpinnings part one practical implementations of active inference part two they review chapter one chapter two long low road chapter 3 High Road you need your Gym gear tomorrow chapter five highlights some of the applications and research in active inference in the mammalian nervous system chapter 6 the recipe to design active inference models chapter 7 and 8 discrete and continuous time generative models in active inference chapter 9 active inference in the context of model-based data analysis connecting the dots integrative perspectives on octave inference Daniel Dennett and the whole iguana hey instead of going deep down the rabbit hole with the prospective working memory module subsystem and then developing this whole just so story backwards from that how about modeling a complete cognitive creature and environmental Niche for it to cope with they talk about that whole iguana perspective and the way that diverse cognitive phenomena attention memory anticipation etc etc can be understood of using this active inference first principles framework active inference doesn't start by assembling separate predefined cognitive functions perception decision making and planning rather it starts by providing a complete solution or approach to derive implications about cognitive functions that helps us identify patterns of cognitive phenomena for example optimal foraging in different settings finally active inference offers a principled means of understanding corresponding neural computations it speaks to multiple levels of Mars hierarchy Mars levels and very briefly we'll discuss more in the coming weeks implications for psychological function as if we were sketching or prompting a psychology textbook predictive brains minds and processing what does active inference have to do and how does it build within the lineage of research on the predictive brain predictive mind perception and different psychological and philosophical lineages for example going back to helmholtz and before on perception Bayesian brain action idea motor Theory cybernetics optimal control theory utility in decision making Bayesian decision Theory reinforcement learning planning as inference behavior and bounded rationality free energy theory of bounded rationality valence emotion and motivation homeostasis allostasis and terraceptor processing attention salience and epistemic Dynamics role learning causal inference and fashionalization active inference and other fields open directions social cultural Dynamics machine learning and Robotics and summary with the Lord of the Rings quote ultimately we are confident that you will continue to pursue active inference in some form okay thanks for the chapter 9 discussion we will come back for the coming two weeks in chapter 10 and then one final session so thank you all