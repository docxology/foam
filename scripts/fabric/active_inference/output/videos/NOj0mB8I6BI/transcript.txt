hello and welcome it's active inference guest stream number 51.1 on July 28 2023 we are here with Tomaso Salvatore and we will be having a presentation and a discussion on the recent work causal inference via predictive coding so thanks so much for joining for those who are watching live feel free to write questions in the live chat and off to you thank you thank you very much Daniel for inviting me uh always been a big fan of the channel and I've been watching a lot of videos I'm I'm quite excited to be here and uh and be the one speaking this time so I'm going to talk about these recent preprint that I that I put out which has been the work of the last couple of months and the it's a collaboration with the with lookup in Ketty I'm in makarak barami Legend Thomas lukasiavich and it's basically a joint work between verses which is the company I work for the University of Oxford and uhuvian so during this talk I will this basically the outline of the talk I will start talking about what predictive coding is and the given interactions of what it is a brief historical introduction why you think is uh is important to study creative coding even for example for the from the machine learning perspective I will then provide a small intro to what causal inference is and and once we have all those informations together I will then discuss uh why I wrote this paper what was basically the research question that inspired me and the and the other collaborators and present the main results which are how to perform inference so intervention and counterfactual inference and how to learn the causal structures from a given data set using predictive coding and then I will of course conclude with some small summary and some discussion on why I believe this work can be in fact impactful and some future directions so what is creative coding creative coding is in general famous for being a neuroscience inspired learning method so what theory of how information processing in the in the brain works and very formally speaking the tier of creative coding can be described as basically having a hierarchical structure of neurons in the brain and and you have two different families of neurons in the brain the first family is the is the one in charging of sending prediction information so neurons in a specific level of the hierarchy send informations and and predict the activity of the of the level below and the second family of neuron is that of error neurons and the arrow neurons they send prediction error information up the hierarchy so one level predicts the the activity of the level below this activity has some this prediction as some mismatch which would actually going on in the level below and information about the prediction error gets sent up the arrow key however predictive coding is was actually not burned as a neuroscience as a theory from from the neurosciences but it was actually initially developed as a method for Signal processing and compression back in the 50s so the the work of Oliver Elias which are actually contemporary of uh clothes Shannon of Shannon they realized that once we have a predictor a model that works kind of that is well in predicting data sending messages about the error in those predictions is actually much cheaper than sending the entire message every time and this is how pretty coding was born so as a as a signal processing and compression mechanism in information Theory back in the 50s it was actually in the 80s uh that that it became that exactly the same model was used in uh in neuroscience and uh so with the work from Mumford or other works for example explain how the how the rating of process information so we get prediction signals from the outside world and we need to to compress this representation and uh and have this internal representation in our neurons and the method is very similar if not equivalent to the one that was used that was developed by by Elias and Oliver in the 50s maybe what's the biggest Paradigm Shift happen in 1999 thanks to the work of around Ballard in which they they are they introduced this concept that I mentioned earlier about hierarchical structures in the brain where prediction information is top down and the error information is bottom up and something that they did that wasn't done before is that they they explain and develop this theory about not only in France but only but also about how Learning Works in the brain so it's also a theory of how our synapses get updated and the last big breakthrough that I'm going to talk about in this brief historical introduction is from 2003 but is uh then he kept going in the in the years after uh thanks to car freeston in which basically he he took the theory of Robin Ballard and he developed a he extended it and generalized it to to the theory of generative models so basically the main claim that that carfiston did is that creative coding is an Evidence maximization scheme of a of a specific kind of generative model which I'm going through to to introduce later as well so to make a a brief summary in the the first two uh kinds of creative Corner that I described so signal processing and compression and the information processing in the retina and in the brain in general they are inference methods and the biggest change the biggest Revolution that we had in 1999 so let's say in the 21st century is the operative coding was seen as a learning algorithm so we can first compress information and then update all the synapses or all the latent variables that we have in our generative model to to improve our generative model itself so let's let's give some uh definitions that are a little bit more formal so operative coding can be seen as a hierarchical gaussian generative model so here is a very simple figure in which we have this hierarchical structure which can be as deep as we want and Signal prediction signals goes from go from one latent variable XM to the following one and it gets transformed every time via function GN or GI this is a generative model as I said and what's the marginal probability of this generative model well it's simply the probability of the last can you see my my cursor yes right yeah it's perfect so it's the genetic model of the last vertex is the Sorry probably distribution of the last vertex times the probability distribution of every other vertex conditioned on the activity of the vertex before or the on the latent variable before I I already said that it's a gaussian generative model which means that those probabilities they are in gaussian form and every endos function function G in general and uh especially since for example in Rambler paper and in all the papers that came afterwards also because of the deep learning Revolution those functions are simply linear Maps or non-linear maps with activation functions or nonlinear maps with activation function and an additive bias so we can we can give a formal definition of creative coding and we can say operative coding is an inversion scheme for such a generative model where its model evidence is maximized by minimizing a quantity that is called the variation of free energy in general the goal of every generative model is to maximize model evidence but this quantity is always intractable and we have some techniques that allow us to to approximate the solution and the one that we that we use in Creative coding instead of minimizing aberration of free energy which is a which is a lower bound of the model evidence in this work and actually in a lot in in a lot of other ones so it's the standard way of doing it this minimization is performed the ingredient descent um and yes perform we agreed in descent and there are actually other methods such as expectation maximization which is often equivalent or you can use some other message passing algorithms such as belief propagation for example and going a little bit back in time so forgetting a little bit about the statistical generative models if we can see creative coding as a I mean I said already a couple of times as a hierarchical model with the neural activities so with neurons latent variables that represent neural activities the sender signal down the hierarchy and with error nodes or error neurons the sender signal up the hierarchy so this and the error information back what's the variation of free energy of this class operated coding models it's simply the sum of the mean square error of all the error neurons so is the is the sum of the of the error of the total error squared and this representation is going to be useful in uh in the later slides and in how I'm going to explain how to use creative coding to model causal inference for example I think predictive coding is important and it's not is a nice algorithm to study well first of all as I said earlier it optimizes the correct objective which is the model evidence or marginal likelihood and then it does so by optimizing a lower bound which is called the variation of free energy as I said and the virtual finish is interesting because it can be written as a sum of two different terms which are and each of those terms of optimizing it as uh as important impacts for example in in machine learning tasks or in general in learning tasks so one of those term forces memorization so in the second term basically tells forces the model to fit a specific data set and the first term forces the model to minimize the complexity and as we know for example for the from the of outcomes razor Theory if we have two different models that perform similarly on a specific training set the one that we have to get and the one that is expected to generalize uh the most is the less complex one so updating a generative model via operational free energy allows us to basically converge to the optimal uh outcome razor model which is which both memorizes a data set but it's also able to generalize very well on unseen unseen data points a second reason of why operative coding is important is that it's actually not a doesn't have to be defined on hierarchical structure but it can be modeled on more complex and flexible architectures such as directed graphical model with any shape or generalized even more to networks with a lot of cycles that resemble brain region and the end result in the underlying reason is that you're not learning and predicting with a forward pass and then back propagating the error but you're minimizing an energy function and this allows basically every kind of hierarchy to be uh allows to go behind direct keys and allow to to learn cycles and this is actually quite important because the brain is full of Cycles as we have some some information from some recent papers uh that are managed to map completely the the brain of some animals such as fruit fly the brain is full of Cycles so it makes sense to to drain our machine learning models or our our models in general with an algorithm that allows us to drain using cyclic structures the third reason why operative coding is interesting is that it has been formally proven that it is more robust than standard neural network starting with black propagation so if you have a neural network and you want to perform classification tasks you creative coding is more robust and this is a interesting in tasks such as online learning training on small data sets or continuous learning tasks and the theory basically comes from the fact that imperative coding has been moved to approximate implicit gradient descent which is a different version of the explicit gradient descent which is the standard green descent used in the in every single model basically and it's a variation that is more robust I think okay I did a quite a long intran operative coding I think I'm now moving to the second topic which is causal inference and the what's causal inference causal inference is a theory it's a very general theory that has been formalized the most by Judy apparel he's definitely the the most important person in the field of causal in France he wrote some very nice books for example the book of Y is highly recommended if you want to learn more about this topic and it basically tackles the following problem so let's assume we have a joint probability distribution which is associated with a Bayesian Network this is going to be a little bit the running example through to all the paper especially when you're not with Asian networks of this shape it was based on networks the the variables inside they can represent different quantities so for example our visual network with this shape can represent the the quantities on the right so social economical Studio statue of an individual its education level its intelligence and its income level something the classical statistics is very good at and is it's uh while uh most used application is to model observations or correlations a correlation basically answer the question what is the if we observe another variable C so for example in this case what is what's the income level the expected income level of an individual if I observe this education level and of course if that person has a has a higher degree of education for example a master or PhD I'm expecting General that person to have a higher income level and this is a correlation however sometimes there are things that are very hard to observe but they play a huge role in determining those quantities so for example it could be that the income level is much much more defined by the intelligence of a specific person and and maybe that the intelligence or if a person is intelligent is also most likely to have a higher education level but still the the real reason why the per the income is I is because of the of the IQ and this can be this cannot be Studies by simply correlations and has to be studied by by a more advanced technique which is called an intervention an Intervention basically answers the question is what is D if we change C to a specific value so for example we can we can take a an individual and check his income level and then change its education level so intervene on this world and change its education level without touching his intelligence and see how much is a its income changes for example if the income changes a lot it means that the the intelligence doesn't play a big role in this but the education level does if the income level doesn't change much it means that maybe there's a hidden variable in this case the intelligence that determines the income level of a person the third quantity important causal inference is that of counterfactuals so for example a counterfactual answers the question what would the be and we change C to a different value in the past so for example we can see that the difference between interventions and counterfactuals is that interventions act in the future so I'm interviewing in the world now to observe a change in the future well counterfactual allow us to go back in time and change a variable back in time and see how that change would have influenced the world we live in now and those are defined by judapple as the three levels of causal inference correlation is the first level intervention is the second level in counterfactual is the third level other interventions I'm going to Define them more formally now now that I gave an intuitive definition and I'm I'm using this notation here which is the same actually throughout all the presentation so X is always going to be a latent variable s i is always going to be a data point or an observation and VI is always going to be a Vertex so every time you see VI we're only interested in the structure of the graph for example so let's assume we have a Bayesian model which has the same structure as the as the Bayesian model we we saw in the previous slide given that X3 is equal to S3 this is the observation we make statistics allows us to compute the probability or the expectation of X4 which is the latent variable related to this vertex given that X3 is equal to S3 foreign intervention we need a new kind of notation which is called the do operation so in this case X4 we want to compute the probability of X4 given the fact that we intervene in the word and change X3 West 3. and how do we do this to perform an intervention Judo Pearl tells us that we have to to have an intermediate step before Computing a correlation is at first we have to remove all to remove all the incoming edges to V3 so we have to study not this Bayesian Network but this second one and then at this point we are allowed to compute a correlation as we as we normally do and this is an intervention a counterfactual is a generalization of this that as I said lived in the past and they're Computing using structural causal models a structure causal model is a tuple which is a conceptually similar to a Bayesian Network but basically we have this new class of variables on top which are the unobservable variables they use so we have the Bayesian Network that we had before X1 X2 X3 S4 but we also have those unobservable or variables that depend on the environment you cannot control them you can infer them but you but they they are there and f is a set of functions that depends on all the basically f of x of x3 depends on X1 because we have an arrow on x2 because you have an arrow and on the unobservable variable that also influences extreme so yes intuitively you can see us you can think of a structural causal model as a Bayesian Network with those unobservable variables on top and each unobservable variable only influences its own its own latest variable X so for example IU will never touch X1 as well u3 will will only touch Q3 E1 will all influence X1 and so forth and so on so performing counterfactual inference answers the following question so what would X4 be at X3 been equal to another variable in a pass situation you foreign requires three different steps so abduction is the is the computation of all the background variables so in this in this step we want to go back in time and understand how the environment the unobservable environment was in that specific Moment In Time and we do this by fixing all the latent variables X to some specific data that we already have and and Performing these uh this inference on the used then we're going to use the U to keep the U that we have learned and perform an intervention so a counterfacture can also be be seen as an intervention back in time in which we know the environment the environment variables U1 U2 and u4 in that specific moment and what's the missing step so what would X4 be at X3 been equal to another another data point in that specific situation now now we can compute a correlation and the correlation we do it on the path on the on the graph in which we have already performed an intervention using the environment variables that we have learned in in the abduction step and this is a counterfactual inference this is the last slide of the causal inference present introduction and is about structural learning basically basically everything I've said so far relies on the fact that we know the causal dependencies among the among the data points so we know the structure of the graph we know which variable influences which one we know the arrows in general but in practice this is actually not always possible so we we don't have access to the causal graph most of the times and actually learning the best causal graph from data is still an open problem we are improving in this we are getting better but how to perform this task exactly uh is still an open problem so as I said basically the goal is to refer Council relationships from observational data so given a data set we want to infer the directed exactly graph that describes the connectivity between the system and the variables of the data set so for example here we have an example that I guess we are all familiar with thanks uh because of the pandemic so we have those four variables age vaccine hospitalization and and CT and we want to infer the causal dependencies among those variables so for example we want to learn directly from data that the probability of a person being hospitalized depends on on its age and on the fact whether it's vaccinated or not and so forth and so on so this is the end of the long introduction but uh I hope it was clear enough and I hope that I gave like the basics to understand the basically the results of the paper and now we can go to the research questions so the research questions are the following first I want to see whether creative coding can be used to perform causal inference so operative coding so far has only been used to perform to compute correlations in in Bayesian Networks and the big question is can we go beyond correlation and model intervention and counterfactual in a biological plausible way so in uh in a way that it's for example simple intuitive and allow us to only play with the neurons and not touch for example the huge structure of the graph and More in practice more specifically the question becomes can we Define operative coding based structure causal model to perform interventions and counterfactuals the second question is as I said that having a structure custom model assumes that we know the structure of the evasion Network so we it assumes that we have the arrows can we go beyond this and use creative coding networks to learn the causal structure of the graph basically giving positive answers to both those questions would allow us to use predictive coding as an end-to-end causal inference method which basically takes a data set and allows us to test interventions and counterfactual predictions directly from this data set so let's let's tackle the first the first problem so causal inference vibrative coding which is also the section that gives the the title to the paper basically and here I will show how to perform correlations operative coding which is uh already known um and how to perform Interventional queries which which I think is the is the real question of the of the paper so here is a causal graph which is the usual graph that we that we had and here is the corresponding creative coding model so the axes are the the latent variables and correspond to the neurons in a in a neural network model and The Black Arrow passing from prediction information from one neuron to the to the one down the hierarchy and every vertex also has this error neuron which passes information up the hierarchy so the information of every error goes to the to the value node in the up the hierarchy and basically tells it to to correct itself to change the prediction so to perform a correlation using predictive coding what you have to do is that you take an observation and you simply fix the value of a specific neuron so if you want to compute the probability of X4 given X3 equal to S3 we simply have to take X3 and fix it to S3 in a way that it doesn't change anymore and run an energy minimization and this model and by minimizing by updating the axis uh via a minimization of the variation of free energy allows the model to converge to a solution to this question so the probability or the expected value of X4 given X3 equals 3. but how do I perform an intervention now without acting on the structure of the graph well this is the basically the first idea of the paper oh this is still how to perform a correlation so fix S3 equal to X3 is the first step in the algorithm and the second one is to obtain the axis by minimizing the variation of free energy an intervention which in theory corresponds in removing those those arrows and answers to the question the probability of X4 by performing an intervention so do X3 equals three imperative coding can be performed as follows so I'm going to write the algorithm here so first as in a correlation you fix S3 equal equal to the iFix X3 equal to the observation that you get then this is the important step you have to intervene not on the graph anymore but on the prediction error and fix it equal to zero having a prediction error equal to zero basically makes uh sends meaning meaningless information up the hierarchy or actually sends no information of the hierarchy because it basically tells you that the prediction is always correct and the third step is to as we did before to update the axis the unconstrained Axis or X1 X2 X4 by minimizing the variation of free energy as I will show now or experimentally by simply doing this little trick of setting a prediction error it to be equal to zero is a prevents us to actually act on the structure of the graph as a as the theory of do calculus does and to infer the missing uh the variables after an intervention by simply performing aberration of free energy minimization what about counterfactual inference counterfactual inference is actually easy once we have Define uh how to do an intervention and this is because as we saw earlier performing a counter factually similar to performing an intervention in a past situation after you have inferred the unobservable the unobservable variables so as you can see in the plot I showed earlier about the abduction action and prediction steps the action and prediction steps they did not have those two arrows they were removed pretty coding allows allow us to keep the arrows of this uh in the graph and and perform counterfactuals by simply performing an abduction step as it was done earlier an action step in which we simply perform an intervention on the single node so we fix the value node and we set the error to zero and run the energy minimization to minimize the duration of free energy to compute the prediction so I think this is like an easy and elegant method to perform interventions and counterfactuals and uh yeah so I think the the thing we have to show now is whether it works in practice or not and we have a couple of experiments and I'm going to show you now two different experiments the first one is merely uh proof of concept experiment that shows that in the operative coding is able to perform intervention and counterfactuals and the second one actually shows a a simple application in how Interventional queries can be used to improve the performance of classification tasks on a specific kind of operative coding Networks which is that of a fully connected model let's start from the first one so how do we do this task so given a structural Council model we generate training data and we use it to learn the weights so to learn the the functions of the structural Kaza models and and then we generate test test data for both Interventional and counterfaction queries and we show whether we are able to converge to the correct test data using creative coding and and for example here uh in those two plots represent Interventional intervention and counterfactual queries of this specific graph which is the butterfly bias graph which is a graph that is often used in uh in testing whether a causal inference whether intervention and counterfactual techniques work is as simple as that but in the paper you can find a lot of different graphs but in general those two graphs those two plots show that the method works shows a show that the the the mean absolute error between the the Interventional counterfactual quantities we we compute and the Interventional and counterfactual quantities from the original graph are close to each other so the error is quite small the second experiment is uh is basically an extension of an experiment I proposed in a in an earlier paper which is the learning on arbitrary graph topologies that I that I wrote last year in that paper I basically propose those this kind of network as a proof of concept which is a fully connected Network which is in general the worst neural network you can have to perform machine learning experiments because given us a fixed set of neurons basically the you have every pair of neuron is connected by two different synapses so it's the most is the is the model with the highest complexity possible in general the good thing is that since you have a lot of Cycles the model is extremely flexible in the sense that you can train it for example on on a minced image and on a data point and on its label but then the way you can query it thanks to the information going back is uh you can query in a lot of different ways so you can form classification tasks in which you provide an image and you run the energy minimization and get the label but you can also for example perform generation tasks in which you give the label run the energy minimization and get the image you can perform for example image completion which you give half the image and converge and and converge let the model convert to the second half and so forth and so on so it's basically a model that learns the the statistics of the data set in its entirety without being like focused on classification or generation in general so this flexibility is great the the problem is that because of this it like every single task doesn't work well so you can do a lot of different things but none of them is done well and here I want to show how using Interventional queries instead of standard uh correlational queries or conditional queries slightly improves the results of those classification tasks so what are the conjective reasons of these uh the test accuracy on on those tasks not being so high the first the two reasons are that the model is distracted in correcting every single uh every single error so basically you present an image and you would like to get a label but the model is actually updating itself to also predict the error in the images and the second reason which is the one I said is that the structure is is far too complex so again from from an outcome raisin Occam razor argumentation this is the worst model you can have so every time you have a model that fits a data set that model is going to be less complex than this one that is going to be preferred but in general uh just to just to study it the idea is can query in this model the interventions be used to improve the performance of uh of those fully connected models well the answer is yes so here is how I perform Interventional queries so I present an image to the network I fix the error of the pixels to be equal to zero so this error doesn't get propagated in the network and then I compute the label and as you can see the accuracy improves for example from 89 using the standard query method of creative coding networks to 92 which is the accuracy after intervention and the same happens for for fashion means and I think that a very legit critic that probably everyone would think when when seeing those plots is that okay you improve on means from 89 to 92 still sucks basically and yeah it's true and I'm actually in the later slides I'm going to show how to act on the structure of this uh of this fully connected model will improve the results even more until the point they reached the rich uh performance that is not even close to state of the art performance of course but it's still up but isn't up to a level that becomes basically acceptable Kenworth investigation investigating so yes so this is the was the part about causal inference using creative coding and I guess to summarize I can say that uh the interesting part of this uh of the results already I just showed is that I showed operative coding is able to perform interventions in a very easy and intuitive way because you don't have to act on the structure of the old graph anymore sometimes the those function functions are not available so forth and so on but you simply have to you simply have to intervene on a single neuron studies prediction error to zero and perform uh an energy minimization process and these extended are allowed us to Define creative coding based structural causal models Now we move to the second part of the work which is about structural structure learning so instruction learning as I said Deals Deals with the problem of learning the causal structure of the model from observational data this is actually no problem that has been around or decades and and was has always been until a couple of years ago tackled using combinatorial search methods the problem with those community research methods is that they their complexity grows double exponentially so as soon as the data becomes multi-dimensional and the the Bison graph that you want to learn grows in size learning it it's it's incredibly slow the new solution that came out actually a couple of years ago in a new newspaper from 2018 show that it's possible to actually learn this structure not using a combinator research method but by using a gradient based method and this this was basically this skilled problem in general because now you can you can simply have a prior on the parameters which is the priority purpose that I'm going to to define a little bit better in this slide run gradient descent and even if you have a model that is double triple the size is uh the algorithm is still incredibly fast and for this reason this paper is a this is yeah I think it's kind of new and I think already has around 600 citations or thing or things like that and every paper that I'm seeing now about counseling friends and learning structure of the graph uses their method it just changes a little bit the they find faster or slightly better inference methods but still they all use the prior the this paper defined and I do as well and we do as well so here we will find a new quantity which is the agency Matrix the agency Matrix is simply a matrix that encodes the connections of the model so it's a binary Matrix and in general is a binary Matrix then of course when you do gradient based optimization you you make it continuous and then you have some Threshold at some point that basically kills an edge or or set it to one and the M3 IJ is equal to into one if we have if the Bayesian graph as an edge from from vertex I to vertex J or zero otherwise so for example this agency Matrix here represents the connectivity structure of this visual Network and basically this method tackles to two problems that we want about these uh about learning the structure of the equation Network the idea is that we start from a fully connected model which conceptually is uh is similar actually is equivalent to the operative coding Network I defined earlier which is fully connected so you have you have a lot of vertices and every pair of vertices is connected by uh by two different edges and you simply want to prune the ones that are not not needed so it can be seen as a as a method that performs model reduction you start from a big model and you want to make it small so what's the first ingredient to to reduce models well is of course sparse City and what's the prior that everyone uses to to make a model more sparse is the LaPlace prior which in machine learning is simply known as the L1 Norm which is defined here the solution that the this paper that I mentioned earlier proposed is to add the second prior on top which enforces what what's probably the the biggest uh characteristic of Bayesian networks the on which you want to perform causal inference is that you want them to be a cyclic and basically they showed that acyclicity can be imposed on an agency Matrix as a prior and it has this the this shape here so it's the trace of the Matrix that is the uh the exponential of a times a where a is the agency Matrix again and basically this quantity here is is equal to zero if and only if the Bayesian Network or the or the whatever graph you're considering is a c click so I'm going to use these in uh in some experiments so those two into Force those two priors on the on different kinds of patient networks and I'm trying to merge them with the techniques we proposed earlier about performing causal inference the operative coding so I'm going to present two different experiments so one is a is a proof of concept which is the standard experiments showed in all the structural learning tasks which is the inference of the correct Bayesian Network from data and then I'm going to to build on top of the classification experiments I showed earlier and uh and show how actually those priors allow me allow us to improve the classification accuracy the test accuracy of fully connected predictive coding models so let's move to the first experiment which is to infer the structure of the graph and all the experiments they all follow basically the same pipeline in all the papers in the field the first step is to generate a vision network from random graph so basically normally the two random graphs that everyone tests are Erdos renegraphs and scale free graph so you you generate those big graphs that normally have 20 for the 80 80 different nodes and some edges that you that you sample randomly and you use this graph to generate a data set so you sample for example n Big N data points and what you do is that you take the graph that you they have generated earlier and you throw it away you only keep the data set and the task you want to solve now is to is to learn is to have a training algorithm that basically allows you to to retrieve the structure of the of the graph you have thrown away so the way we do it here is that we are in a fully connected creative coding model on this data set D using both the sparse and the SQL priors we have defined earlier and and see whether actually the the graph that we converge to after pruning away the the entries of the agency Matrix that are smaller than a certain threshold is similar to that of the of the initial graph and there's also show that this is actually the case so this is an example and I show many different parametrization and dimensions and and things like that in the in the paper but I think those two are the most representative examples with an error Nursery graph and a free scale graph with 20 nodes and here on the left you can see the ground through graph which is the one sampled randomly and on the right you can see the graph the pretty difficulty model as learned from from the data set and as you can see they are quite similar it's still not still not perfect so there are some there are some errors but in general the structure is they work quite well we also have some quantitative experiments that that we that I don't show here because they're just huge tables with a lot of numbers and I thought it was maybe a little bit too much for the presentation but but the results show that they perform similarly to to contemporary methods also because I have to say like most of the quality comes from the on the acigli prior that was introduced in in 2018. the second class of experiments is the our classification experiments which as I said are the extensions of the the one I shared earlier and the idea is to use structure learning to improve the classification on the classification results on the means and fashion means data set starting from a fully connected graph so what I did is that I divided the fully connected graphing clusters of neurons so 1B cluster is the is the one related to the input and all the small then we have some a specific number of hidden clusters and then we have the label cluster which is the the class the cluster of neurons that are supposed to give me the the label predictions and I've trained them using for using the first time the sparse prior only so the idea is what if I if I prune the connections I don't need from a from a model and and learn as parser model does this work well the answer is no it doesn't work and the reason and the reason why is that you at the end the graph that you converge with is actually the generate so basically the model learns to predict the label based on the label itself so it discards all the information from the input and only keeps the label and as you can see here the label y predicts itself or in other experiments when you change the parameters you have that y predicts at zero that preex X1 the predicts y again so what's the what's the solution to to this problem well the solution to this problem is that we have to to converge to an acyclic graph and so we have to add something that prevents a cyclicity and what is that one is of course the one I already proposed and then I I show a second technique so the first one uses the SQL prior defined earlier and the second one is a is a novel technique that actually makes use of negative examples so a negative a negative example in this case is simply uh the a data point in which you have an image but the label is wrong so here for example you have an image of a seven but the label that I'm giving the model is a two and and the idea is very simple in is has been used in a lot of uh Works already so every time the models is a positive example it has to increase to to minimize the variation of free energy and every time it has a it is a negative example it has to increase it so let me move on the error this quantity to be minimized foreign with a lot of experiments and a lot of uh of experimentations we saw that the two techniques basically first lead to the to the same results and second lead to the same graph as well so here are the here are the new results some means and fashion means using the two techniques that I that I just proposed and and now we move to some which are still not uh great but definitely more reasonable test accuracies so here we have a test error of 3.17 for mins and a test error of 13.98 for fashion means and actually those can be those results can be much improved by learning the structure of the graph from minced and then fixing the structure of the graph and and do some form of fine tuning so if you fine tune the model on the correct hierarchical structure at some point you reach the test accuracy which is the one you would expect from a hierarchical model but those ones are simply the one the fully connected model as naturally converged to so so for example from a test error of 18.32 of the fully connected model train on fashion means by simply performing correlations or conditional queries which is a standard way of querying operative coding model adding interventions and the AC click prior together makes this a this test error much lower and we can observe it for for means as well I'm not going a little bit into details on uh on this last experiment and on how the acyclic prior acts on the structure of the graph so I perform I perform an experiment on uh on a new data set which is I mean calling in the new data set it may be too much is that I call it a two means data set in which you have the input point is formed of of two different images and the label only depends on the second image on the first image story so the idea here is is the structure of the model the cyclicity prior and things like that able to recognize that the second half of the image is actually meaningless in uh in performing in learning the in performing classification how does training behave in general like for example we have this uh input input node output node and only the nodes are fully connected and the model converge to a to a hierarchical structure which is the one that we know performs the best on on classification tasks well here is a is an example of a Training Method run so at c0 which is the beginning of training we have this model here so s0 corresponds to the to the seven so to the first image as one corresponds to the seven column image again we have the label Y and all the latent variables x0 X1 X2 and the model is fully connected so the agency Matrix is is full of ones there are no zeros we have self loops and things like that the model for a couple of epochs until and what we know immediately is that for example the the model immediately understands that the four is not needed to perform classification so it doesn't uh so every outgoing node from the from the second input cluster is removed and something we didn't understand is that this is this cluster is the one related to the output so we have a we have a linear map from s0 to Y directly which is this part here but we know that actually a linear map is not the best map for performing classification of means so we we need some hierarchy we need some depth to to improve the results and as you can see this line here is the is the accuracy which up to this point so up to C2 is similar to um so it's 91 which is slightly slightly better than linear classification but once you go on with the training the model understands that it needs some hierarchy to better fit the data so you you see that this Arrow starts getting stronger and stronger over time until it it understands that the linear map is not actually really needed and it removes it so the model you converge with is a model that starts from a zero goes to a hidden node and then goes to the to the label with a very weak linear map which actually gets removed if you if you set a threshold of uh if seller threshold of for example 0.1 0.2 at some point the linear map gets forgotten and everything you end up with is with a is with a hierarchical network that is that uh so it has learned the correct structure to to perform classification tasks which is hierarchy and it has also learned that the second image didn't play any role in defining the the test accuracy and this is all this is all performed also all those jobs are simply performed by perform by one free energy minimization process so you initialize the model you define the free energy you define the priors so the the sparse and the C click prior you run the the energy minimization and you converge to hierarchical to a hierarchical model which is well able to perform classification on minced and then if you then perform some fine tuning you reach very competitive results as you do in feed forward networks with the feedback propagation but I think that's not the interesting bit the interesting bit is that you like all this process this process all together of intervention and the acyclicity allows you to take a fully connected Network and converge to a hierarchical one that is that is able to perform classification with good results and yeah that's basically it I'm now oh yeah wow I've talked a lot and I'm uh this is the conclusion of the talk which is a I'm basically doing a small summary and I think the the important takeaway if I have to give you in one sentence of this paper is that predictive coding is a belief updating method that is able to perform end-to-end cousin learning so he's able to perform interventions to learn a structure from data and and then perform interventions and counterfactuals so causal inference in other and efficiently model interventions by simply setting the prediction error to zero so it's a it's a very easy technique to perform interventions and you simply you only have to touch one neuron you don't have to act on the structure of the graph you can you can use it to perform to to create structure causal models that are biologically plausible it is able to learn the structure for uh from data as I said maybe a lot of times already and and a couple of sentences about future works is that something that would be nice to do is to improve the performance of the model we we have defined because I think it performs reasonably well on a lot of tasks so it performs reasonably well on structural learning on for me intervention and counterfactuals but actually if you look at state of the art model there's always like a very specific method that performs better in the single task so it would be interesting to see if we can reach those level of performance in uh in specific tasks by by adding some tricks or some or some new optimization methods and to generalize it to to dynamical systems which are actually much more interesting the static systems so such as dynamical causal models and or other techniques that allow you to allow you to perform causal inference in systems that move so an action taken in a specific time step influences another node in a later time step which is a basically grandeur causality yeah that's it and uh thank you very much thank you awesome and very comprehensive presentation that was really think you're muted sorry muted on Zoom but yes thanks for the awesome and very comprehensive presentation there was really a lot there and there was also a lot of great questions in the live chat so maybe to warm into the questions how did you come to study this topic were you study in causality and found predictive coding to be useful or vice versa or how did you come at this intersection I actually have to say that the first person that came out with this idea was uh was Baron so so like like I think a year and a half ago even more he brought like a page with this idea and then he got forgotten and no one picked it up and uh and last summer I started getting curious about causality and the um I I read for example The Book of Life as I listened to podcasts I know the standard way in which you get interested in a topic and and I remember this this idea from Baron and proposed it to him and uh and I was like why don't we expand it and uh and actually make it a paper so I I involved some people to help me with experiments and uh and this is the final result at the end awesome cool yeah um a lot to say I'm just gonna go to the live chat first and address a bunch of different questions and if anybody else wants to add me I'm gonna turn the light on first because I'm I think I'm getting in the dark more and more yes who said active inference can't solve a dark room issue oh yes here we are so would you say the light switch caused it to be lighter yeah I think so no issues here um okay ml Dawn wrote since in predictive coding all distributions are usually gaussian the bottom up messages are Precision weighted prediction errors where Precision is the inverse of the gaussian covariance what if non-gaussian distributions are used is a basically the general method stays the different the main difference is that you you don't have prediction errors which as was correctly pointed out is the basically the derivative of the virtual free energy if you have gaussian assumptions yeah you even have that single quantity to set to zero and you probably will have to act on the structure of the graph to perform interventions and also you uh and colleagues had a paper in 2022 predictive coding Beyond gaussian distributions that that looked at some of these issues right yes yes exactly so that paper was a little bit the idea behind that paper is uh and we model Transformers that's the biggest motivation using pretty difficulting and the answer is uh is not because the the attention mechanism has a soft Max at the end and soft Max calls to uh like not to gaussian distribution but to yeah to soft Max distribution the I don't get the name now but yes and uh so yes that's a generalization it's a little bit tricky to call it once you remove the Gaston assumption is a little bit still tricky to call it creative coding so he's a so for example like talking to uh to car Freestone either he like creative coding is only if you if you have only Gauss and gaussian assumptions but yes that's more a philosophical debate than uh interesting and another I think topic that that's definitely of of great interest is similarities and differences between the attention apparatus in Transformers and the way that attention is described from a neurocognitive perspective and from a predictive processing Precision waiting angle what do you think about that well the idea is that um yeah I think about it is that in from a pretty processing and and also operational inference perspective attention can be seen as a as a kind of structural learning problem there's I think there's a recent paper from uh from Chris Buckley's group that shows that there should be there should be a reprint on archive in which basically they showed that the attention mechanism is simply learning the the Precision on the on the weight parameters specific to other data point so this Precision is not a it's not a it's not a parameter that is in the structure of the model so it's not a model specific parameter it is a fast changing parameter like the value nodes that gets updated while minimizing the variation of free energy and once they once you've minimized it and compute it then you throw it away and for the next data point you have to recompute it from scratch so yes I think the the analogy computation wise is uh the attention mechanism can be seen as a kind of structure learning but a structure learning that is data point specific and not model specific and I think if we want to generalize a little bit and go from from the attention mechanism in Transformers the attention mechanism cognitive science I feel they're probably two different to like to draw similarities and uh I think the structural learning analogy and the how important one Connection in is with respect to another one probably does the job much better cool gray answer okay ml Don asks in counterfactuals what is the difference between hidden variables X and unobserved variables U the difference is that you can I think the main one is that you cannot observe the the use you can use them because you can you can compute them and fix them but you cannot the idea is that you have no control over them so they use the use should be seen as a environment specific variables that they are there they they influence your process okay because the for example when you go back in time the environment is different so the idea is for example if you like going back to the to the example before of the of the expected income of a person with a specific intelligence of Education uh uh education degree the idea is that if I want to to see how much I will learn today with uh with a with I don't know with a master degree is different with respect to how much I would earn 20 years ago with a master degree is different for example here in Italy with respect to other countries and all those variables that are not under your control you cannot model them using your vision Network but they are there okay so you you cannot ignore them when you when you want to draw conclusions so he's yeah it's basically everything that you cannot control you can infer them so you can you can perform a counter counterfactual inference back in time and say oh 20 years ago I would have earned this much if I if I was this intelligent that this degree on average of course and but it's not that I can change the government policies towards jobs or the or things like that it's a deeper counterfactual yes exactly so yeah those are the use awesome all right have you implemented generalized coordinates in predictive coding no I've no I've never done it I've uh yeah I've studied it but I've uh I've never implemented it I know they tend to be unstable and uh and it's very hard to make them stable I think that's the that's the takeaway that I got from talking to people that have implemented them but but yeah yeah I'm aware of some papers that came out actually recently about about them that that tested on some British load encoder style actually I think still from Baron there's a there's a paper out there that came out last summer but but no I've never played them with them myself cool romper does adding more levels in the hierarchy reduce the distraction problem of predicting input adding more level in uh in which sense because the destruction problem is given by Cycles so basically you provide an image and the fact that you have uh so patches going out of the image going in the neurons and then other edges going back this basically creates the fact that you have a the error of that those basically these in-going adjust to the pixels of the image they create some prediction errors so you have some prediction errors that get spread inside the model and that's yeah and this problem I think is general of cycles and it's probably not related to hierarchy in general to the pixels if you don't have incoming edges you have no uh no destruction problem anymore cool and and the specification of the acyclic network through the trace operator that's a very interesting technique and when was that brought into play uh as far as I know I think he came out with the paper I I cited in 2018 I I don't know at least in the causal inference literature I'm I'm not aware of any previous methods I would say no because that I mean that's the highly cited paper so I would say they came out with that idea wow yeah that's that's quite nice that you can do gradient descent and learn the structure I think that's a that's a very powerful technique yeah sometimes it's like when you look at when different um features of Bayesian inference and causal inference became available it's really remarkable like why why hasn't this been done under a Bayesian causal modeling framework it's like because there's only been like five to 25 years of this happening and so that's very very short and also it's relatively technical so there's relatively few research groups engaging in it and um it's just really cool what it's enabling no yes yes exactly I mean that's also I think the exciting part of this field a little bit that is uh I mean there are definitely breakthroughs out there that still have to be discovered and probably like because for example like for as much as a breakthrough that paper was they found uh like they simply found out the right prior for acyclic structures okay is a yeah I mean I I don't know exactly but it may be an idea that you have in one afternoon I don't know about the story of the how the others came up with that but could potentially be that they they're there at the Whiteboard you're like oh that actually works that's a huge breakthrough and I simply yeah defined the prior and also a lot of these breakthroughs they they don't just stack it's not like a uh uh a tower of blocks they they layer and they compose so then something will be generalized to um generalized coordinates or generalize synchrony or arbitrarily large graphs or um Sensor Fusion with multimodal inputs and it's like those all blend in really satisfying and effective ways so so even little things that again someone can just come up with in a moment um can really have impact um okay ml Dawn says thanks a lot for asking my questions and thanks a million to Tomaso for the inspiring presentation so nice oh thank you very much and then Bert asks how would language models using predictive coding differ from those using Transformers um okay I think that actually if I would have to build today a language model using predictive coding I will still use the Transformers so the idea is that for example if you have a let's say this hierarchical graphical model of this or these hierarchical Bayesian Network I've defined in the in the very first slides one Arrow to encode a function which is the linear map okay so one hour was simply the multiplication of a of the vector encoded in the latent variables times the this weight Matrix that you can then make non-linear and things like that but that can be actually something much more complex the the function included in the arrow can be a convolution can be an attention mechanism so so actually how I would do it I will still use the I mean which is actually the way we did it in uh in in the Oxford Group last year is that we we had exactly the structure every arrow is a Transformer now so one is the attention mechanism and the the next one is the feed forward Network as Transformers and basically the only difference that you have is that those variables you want to compute the posterior and you make those posteriors Independence independent via VIA mean field approximation so basically you follow all the steps that allow you to to converge to the very to the variation free energy of creative coding but the the way the way you compute predictions and the way you send signals back is uh is done via Transformer so I will still use Transformers in general I mean they work so well that I I don't think that we can be arrogant and say oh no I'm gonna do it better via a purely predictive coding way structures but will still approximate Transformers anyway sorry you said structure learning would approximate the Transformer approach yes the structure learning I mentioned earlier in uh when when someone uh asks the similarities between creative coding and the attention mechanism very yeah very interesting um one thing I am wondering from Amazon I could not see the concept of depth in the predictive coding networks you mentioned most likely I missed it the definition provided for predictive coding involved the concept of depth what did you mean by depth no yes it's true it's uh because the standard definition as I said multiple times is a is hierarchical you have predictions go in One Direction some prediction error going the opposite direction basically what uh what we did in in this paper and also in the last one in uh which is called The Learning on arbitrary graph topologies we have relative coding is that we can consider depth uh like as a as independent uh basically pair of latent variable latent variable and arrow and you have predictions go in that direction and prediction Arrow going with the other but then you can compose these in how many um a lot of ways so you can you can so basically this composition doesn't have to be hierarchical in the end can have Cycles so then you you can for example plug in another uh another latent variable to the first one and then connect the others to and you can have a structure is that is as entangled as you want so for example in the in the other paper we train the uh a Network that has the shape of a brain structure so we have a lot of brain regions that are sparsely connected inside and it's partially connected among each other and and there's there's nothing hierarchical there at the end but you can still train it by minimizing operational free energy and by minimizing the the total prediction error of the network so you could have for a given Motif in a entangled graph you might see three successive layers that when you looked at them alone you'd say oh that's a three-story building that's a three layer model that says adaptive three but then when you take a bigger picture there isn't like an explicit top or an explicit bottom to that Network yes exactly and this is basically given by the by the fact that every operation in predictive Korean networks is uh is strictly local so so basically every message passing every prediction and every prediction error that you send you only send it to the very nearby neurons okay and whether the global structure is actually hierarchical or not the the single message passing doesn't even see that I guess that's sort of the hope for learning new model architectures is the space of what is designed top down is very small and a lot of models in use today albeit super effective models um although you could ask effective per unit of compute or not that's a second level question but a lot of effective models today do not have some of these properties of predictive coding networks like their capacity um to to use only local computations which gives biological realism um or just spatio-temporal realism but also May provide a lot of advantages in like Federated compute or distributed computing settings no yes exactly I completely agree because I think the idea in general is that and I don't know if that's going to be an advantage so I think it's very promising exactly for the reasons you said and uh and the reason is that today's model string with back propagation you can basically uh summarize them as a as a as a monitoring back propagation is a function because basically you have a map from input to output and back propagation basically spreads uh information back from its computational graph so every neural network neural network model used today is a function while predictive coding and another liberative coding like the old class of functions that the class of methods that that train in using local computations and actually work by minimizing a global energy function the they're not limited to model functions from input to Output they actually model something that that kind of resembles physical systems so you have a physical system you fix some values to to whatever input you have and you let the system converge and then you read some other value of uh neurons or variables that are supposed to be output but this physical system doesn't have to be a fit forward map doesn't have to be a function that has a an input space and an output space and that's it so the class of models that you can learn is uh so basically you can see like feed forward models and functions and then a much bigger class which is that of physical systems whether there's something interesting out here I don't know yet because the functions are working extremely well we are seeing those days with back propagation is a they work crazy well but so yeah I don't know if there's anything interesting in the big part but the big part is is quite big okay there are there are a lot of models that you cannot bring back propagation and you can train with creative coding or a bathroom propagation or other methods that is super interesting certainly biological systems physical systems solve all kinds of interesting problems um but there's still no free lunch in ant species that does really well in this environment might not do very well in another environment and so um out there in the in the Hinterlands there might be some really unique special algorithms that are not well described by being a function yet still uh provide like a procedural way to to implement heuristics which might be extremely extremely effective no yes yes exactly and uh yeah anything this has been most of my focus of research during my PhD for example like finding this application that is like out here and not inside the the functions cool well where does this work go from here like what directions are you excited about and how do you see people in the active inference ecosystem getting involved in this type of work I think a very probably the most promising Direction which is a uh she's something maybe I would like to to explore a little bit is to as I said there really is to go behind statical models so everything I've showed I've shown so far is uh is about static data so the the data don't change over time there's no time inside the definition of creative coding as it is as I presented it here however you can for example generalize creative coding to to work with temporal data using generalized coordinates as you mentioned earlier uh by by presenting it as a as a common Kalman filter generative model and and that's where for example the the causal inference Direction could be very useful because yeah that model uh at that point maybe you can be able to model greater causality and uh and more complex and and useful uh dynamical cause of models basically because in general the the do calculus and the Interventional and counterfactual uh branch of science is mostly developed on on small models so it's a like you don't do interventions on gigantic models in general so if you if you look at Medical Data they they use relatively small Vision Networks and but of course if you want to have a dynamical causal model that models uh a specific environment or a specific reality you have a lot of neurons inside you have a lot of latent variables they change over time and an intervention at some more at some moment creates an effect in a different time step so maybe in the next time step in 10 different time steps later and I think that would be very interesting to develop like a biologically plausible way of passing information that is also able to model Grandeur causality basically hmm where do you see action in these models where do I see action I didn't think of that I think as the actions in those models maybe in the same way as I as you see in other models because creative coding is basically a model of perception so so an action is you can see there's a consequence of what you are experiencing so by changing the way your your experiencing something then you can compute maybe you can simply perform a smarter action now that you have more information but but yeah I don't think action is very easy like yeah I don't see any explicit consequence of actions besides the fact that this can allow you to basically maybe do you simply draw better conclusions to them perform actions in the future I'll add on to that a few ways that people have uh talked about predictive coding and action uh first off internal action or covert action is attention so we can think about perception as an internal action that's one approach another approach pretty micro is the outputs of a given node we can understand that node as a particular thing with its own sensory cognitive and action States and so in that sense the the output of a node and then lastly which we explored a little bit in live stream 43 on the theoretical review on predictive coding we're reading all the way through and it was all about perception all about perception and then it was like section 5.3 if you have expectations about action then action is just another variable in this architecture and that's really aligned with inactive inference where instead of having like a reward or utility function that we maximize we select action based upon it being the likeliest course of action the path of least action that's Bayesian mechanics and so it's actually very natural to bring in an action variable and utilize it essentially as it as if it were a prediction about something else extra receptively in the world because we're also expecting action no yes yes exactly no I like the way of defining actions a lot actually and uh and I still think it has been like for example there are not so many papers that apply this method I think there are a couple from uh from Alexander or robria does something similar but in practice like outside of the pure active inference like applying predictive coding and actions to to solve practical problems hasn't been uh explored a lot oh well thank you for this excellent presentation and discussion is there anything else that you want to um say or or Point people towards uh no just a big thank you for inviting me and uh it was really fun and I hope to come back at some point for for some Future Works cool anytime anytime thank you Thomas so thank you Daniel see you bye bye