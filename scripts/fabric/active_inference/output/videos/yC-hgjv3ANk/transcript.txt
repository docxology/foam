[Music] [Music] all right hello and welcome everyone to active lab live stream number 39.0 it's february 25th 2022 welcome to the active lab we are a participatory online lab that is communicating learning and practicing applied active inference you can find us at the links here on the slide this is a recorded in an archived live stream so please provide us with feedback so we can improve our work all backgrounds and perspectives are welcome and we'll be following good video etiquette for live streams if you want to learn more about coms which is the organizational unit that puts on all these live streams and many other products or any of the other activities in the active lab go to activeinference.org all right well today in active stream number 39.0 the goal is to learn and discuss this really awesome paper called morphogenesis as bayesian inference a variational approach to pattern formation and control in complex biological systems it's by franz koochling carl firsten georgiegiv and michael levin from 2020 and just like all the dot zero videos and indeed all our videos it's just an introduction to some of these ideas it's not a review or a final word that being said we're going to go over the aims claims abstract roadmap keyword etc of the paper and then with a focus on the first parts of the paper and less so on the formalism and more on the big ideas we're going to go over the paper and the figures and that will put us in a good position cognitively or morphologically we might even say for the discussions in the coming weeks 39.1 and 39.2 when we'll get to unpack this so if you would like to it'd be awesome to have you participate live or if it's past 39.2 you can still ask questions all right we'll start with introductions and warm-ups we can each say hi and maybe one thing that was exciting or interesting about the paper which all reserved for after you but i'm daniel i'm a researcher in california and dean thanks a ton for joining uh thanks natalie i'm dean i'm here in calgary and what really got me excited about this was uh the idea that they talk a little bit later close to the end we may not even talk about it today is the uh role that epigenetics might play in terms of how cells behave and and what sorts of things we might be able to turn turn in terms of simply um what we see in biological form into some sort of static statistical prediction device so i'm really excited about that awesome yeah it's a complex paper about complex systems so we'll see what we can get done today but i'm really excited to bring active inference into this domain at least as far as our discussions go into the morphological and the morphogenetic areas and it's just bringing like another lens another way that we can apply active inference as a filter another set of phenomena that we're bringing into this active inference realm so we'll just go right into the big question so i'll read this and then feel free to give a thought the big question or at least one way to put one of the questions is how can we find an integrative path between math and morphogenesis morphogenesis means form like physical form morpho and genesis meaning how it arises so how does physical form arise and how is that related to math and to kind of unpack that here's some quotes the molecular mechanisms which are like signaling pathways of all different kinds underlying development and regeneration in biological organisms have undergone a tremendous amount of knowledge gain in the last several years due to genomics and biotechnology advances so that's kind of the one side with the biological and then from the mathematical and the formal the emerging field of the free energy principle in pattern formation not always morphogenetic patterns but can be cognitive patterns rhythmic patterns provides an essential quantitative formalism for understanding cellular decision making in the context of embryogenesis regeneration and cancer suppression so if that's the if then how might the mathematical formalism reveal new understandings about developmental change in evolution and for designing new interventions in regenerative medicine settings so what do you think about that well i just love anytime that two things that seem disparate or distant are are brought together because i think all sorts of good things can happen and i'm going to do a little shout out that's kind of what i would like to see if we can organize in august with a couple of other papers that don't start out necessarily appearing to be close or proximal but by bringing together all kinds of interesting things can happen awesome okay to the main aims and claims of the paper so the paper is in physics of life reviews 2020 and we already mentioned the title and the authors just to select a few aims that the authors represent and then a couple of key claims that are relevant for the paper so as far as aims go one of their aims is to introduce an overarching concept that can predict the emergence of form and the robust maintenance of complex anatomy another aim is to derive the mathematics behind bayesian inference and use simulations to show simulations that are consistent and within the bayesian framework to show that the formalism can reproduce experimental top-down manipulations of complex morphogenesis and then just a few of their claims more of which we'll be unpacking in the coming minutes classic i.e dynamical systems and analytical mechanics approaches such as last at least action principles are difficult to use when characterizing open far from equilibrium systems that predominate in biology so that's kind of a big challenge that's come up again and again which is we might have really great equations for a pendulum maybe even a pendulum with friction but how about an active pendulum that's doing strategy and trying to run away from you a bit harder to put those same equations on the bayesian inference framework treats cells as information processing agents where the driving force behind morphogenesis is the maximization of a cell's model evidence which is to say its reduction of uncertainty relative to a generative model which is what we're going to be unpacking and we had previously read this about how they're applying free energy principle to morphogenesis when it goes well like during embryogenesis and results in a zygote becoming like an adult life form as well as all of the ways that it's maintained during that stationarity of healthy life and including cases where it might be relevant to even think about making interventions like medical settings so those are a few of the aims and claims anything to add on it yeah just real quick it's really interesting that they said top down and then we're going to see some slides where there's a top top and a down down so stick around because there's actually going to be something kind of interesting happening here okay how about you read the first half of the um the top half of this abstract slide yeah sure recent advances in molecular biology such as gene editing bioelectric recording and manipulation and live cell microsc microscopy using fluorescent reporters especially with the advent of light controlled protein activation through optogenetics have provided the tools to measure and manipulate molecular signaling pathways with unprecedented spatial temporal precision this has produced ever-increasing detail about the molecular mechanisms underlying development and regeneration bought in biological organisms however an overarching concept that can predict the emergence of form and the robust maintenance of complex anatomy is largely missing in the field classic i.e dynamic systems and analytical mechanics approaches such at least action as least action principles are difficult to use when characterizing open far from equilibrium systems that predominate in biology similar issues arise in neuroscience when trying to understand neuronal dynamics from first principles so they're basically covering their bases here by making sure that we understand this is open system yes increases in tools in biological systems like genomics microscopy optogenetics are helping us reduce our uncertainty about the what but without a bit more information about the how and the why etc that's the overarching concept that's largely missing so we can grind up the cells and sequence the genome we can extract the rna and we can even tell what the ratio of different rna molecules is but it turns out that that type of information alone doesn't help us understand why two related species or the same species in two different contexts or the same genome in two different tissues or the same tissue in two different environments has such different morphology okay and then the second half in this neurobiology setting a variational free energy principle has emerged based upon a formulation of self-organization in terms of active bayesian inference the free energy principle has recently been applied to biological self-organization beyond the neurosciences for biological processes that underwrite development or regeneration the bayesian inference framework treats cells as information processing agents where the driving force behind morphogenesis is the maximization of a cell's model evidence this is realized by the appropriate expression of receptors and other signals that correspond to the cell's internal ie generative model of what type of receptors and other signals it should express the emerging field of the free energy principle in pattern formation provides an essential quantitative formalism for understanding cellular decision making in the context of embryogenesis regeneration and cancer suppression okay and then if you read the first um two parts here on the second slide yeah no problem in this paper we derive the mathematics behind bayesian inference as understood in this framework and use simulations to show that formalism can reproduce interesting experimental top-down manipulations of complex morphogenesis first we illustrate the first principle approach to morphogenesis through simulated alterations of anterior posterior axial polarity the induction of two heads or two tails ah spoiler alert as a planarian regeneration don't you hate it when the abstract spoils the paper then we consider aberrant signaling and functional behavior of a single cell within a cellular ensemble as a first step in carcinogenesis the formation of cancer as false beliefs about what a cell should sense and do inference perception action inference we further show that simple modifications of the inference process can cause and rescue mispatterning of developmental and regenerative events without changing the implicit generative model of a cell as specified for example by its dna this formalism offers a new roadmap for understanding developmental change in evolution and for designing new interventions in regenerative medicine settings speaking of the new roadmap let's look at the roadmap kind of cool that they actually say that it is providing a road map so we've talked about guides we've talked about road maps where do you see all of that before we look at the section titles well a guide i think basically gives sort of gives you um the parameters i think a roadmap is a lot more specific in terms of the sequencing but that's just my interpretation of it i think other people can interpret roadmap roadmap differently in terms of sort of the relational aspect of how the different parts come together and we've talked about that in other live streams but i don't want to get bogged down in this part right now because i think we got a lot of stuff to cover here cool yeah so the paper begins with an introduction to bayesian inference section 2 is mathematical foundations that are building on bayesian inference so going from kind of bayes theorem to several dynamical systems representations some of which we've discussed before others which will push it into a little bit of a new area then the key contribution and the focus of the paper is modeling morphogenesis and so instead of just presenting bays and then variational bays and then free energy minimization on a bacterium like we saw axle constant do in live stream number 34 we're going to take that momentum and move it towards an application of modeling in morphogenesis and that's where we'll talk about like what model they construct and how it relates to some of the formalisms that were brought up earlier and then there's a discussion and conclusion section which we won't go too much into today in the dot zero but it's going to be awesome to go into it in the dot one and dot two because there's a ton of awesome content and material all right so here's the keywords that were listed and we won't go into um [Music] most of them just to say that they're going to come up in this discussion we have free energy principle bayesian inference morphogenesis and developmental biology regeneration kind of got some mathematical stuff we've seen before we have a triad of developmental biology which broadly understood includes embryogenesis as well as aging and cancer and all these other developmental things that happened during biology and top-down muddling and maybe we'll see what that means coming up okay well to get right into it section one is an introduction to bayesian inference so here's a nice picture by sasha and here are the opening lines of the paper they wrote and then feel free to give a thought evolutionary change results from mutations in dna and selection acting on functional bodies thus it is essential to understand how the hardware encoded by the genome enables the behavioral plasticity of cells that can cooperate to build and repair complex anatomies indeed most problems of biomedicine repair of birth defects regeneration of traumatic injury tumor reprogramming etc could be addressed if prediction and control could be gained over the processes by which cells implement dynamic pattern homeostasis the fundamental knowledge gap and opportunity of the next decades in the biosciences is to complement bottom-up molecular understanding of mechanisms with a top-down computational theory of cellular decision making and info taxes movements towards information so dean what do you think what should we study and why and how is this related to active and fep okay well my background in genetics is is near zero but what i did come away from with that last bullet in particular was uh some one of the things that i beat like a dead animal which is that you need a minimum of two and i think that the the bottom up sort of building blocks aspect of it with the top down how do we get a better grip on what the signals are that are passing between all of those bricks um was really interesting and so carrying on through i i kind of wanted to open that up and see what that um that marriage looked like awesome so speaking as someone who started in the science journey with genetics pretty much it always was so interesting how genetics would frame itself as if the bottom-up information flow could just simply replace theory we'll sequence so many genomes we won't need to speculate about evolution or we'll have your genome so we won't even need to ask about what medicine is best and that's kind of this bottom-up molecular understanding which is vital it's essential it's important it's changing a lot but it's this bottom-up sub-unit description the what and the where of the subunits and how they touch and all of that and that is always met implicitly and increasingly explicitly with a top-down theory of cellular decision-making and infotaxes and so we're always kind of meeting in the middle with empirical wet lab biology revealing these mechanisms and these findings and we're meeting that as researchers doing model-based science with what are being called here top-down modeling top-down computational theories okay that's just how they open up and also set a challenge for the coming decades it's their expectation of the next few decades then they provide a math roadmap which is an awesome paragraph so they write we lay out the mathematical foundations of a type of bayesian modeling that they're going to use to simulate pattern formation so red bayesian modeling orange we start by identifying a lyapunov function that can be used to analyze and solve any dynamic system using the fundamental theorem of vector calculus i.e the helmholtz decomposition so we're using bayesian modeling and layering in what we'll talk about soon the leopard function green we use it to characterize the generalized flow of systemic states states of the whole system in terms of conversions to a non-equilibrium steady state a ness next layer blue we then introduce the notion of a markov blanket that separates the external and internal states of the system and finally purple we can then replace the leopard function with a variational free energy function to solve for the evolution of internal and active states that's of the particle and thereby characterize self-organization in far from equilibrium systems that can be partitioned into a cell and an external milieu that's the math that they go through that's the math rainbow then sections after that apply this formalism to illustrate morphogenesis and neoplasia which is the growth of new forms neoplasia using simulations and what's so cool is this trajectory from 400 to 700 nanometers from the bays through the vector calculus and flow states to the finding or the figuring out of a markov blanket and then the usage of the markov partitioning legitimated by the orange and the green steps to find a heuristic way to go about solving what was needing to be addressed right in the beginning we've seen some variants of this trajectory multiple times and then in this paper they studied morphogenesis and so then they model morphogenesis but say for a couple of words a different paper could have said we do the base thing the lyapunov thing the helmholtz the nest the markov and then we're back to doing far from equilibrium strategy in online teams and then we applied it to online teams and so let's keep in mind like the paper can be long there are a lot of equations but where is this broader trajectory that's helping us fine-tune our regime of attention and update our generative model about what we are doing here and how it's different than other approaches and then where is the part that's actually studying morphogenesis just things to keep in mind okay anything to add on this well you correct me if i'm wrong on this but i think what we're doing is essentially taking as you said we can we can look at a variety of things we can look at the physical nature of ants we can look at cells we can look at online teams whatever we're looking at what they basically said is there is a there is a parallel way of looking at the formalisms that exist in those contexts with that with that type of content that's essentially what this said to me there's a way of bumping it up into that sort of statistical mathematical realm and now we're going to walk you through what that is great okay so into the bay the bay's area where i grew up so sitting by the dock of the base all right oh i thought so i'm gonna say where the water well where the watermelons grow carry on base theorem rests on three basic axioms of probability theory and is used to relate the conditional probability of an unobservable event a okay so the vertical bar means conditioned upon or given and so what we really want to know is like the probability of something that we cannot observe conditioned on what we did observe be so you're never observing the lightning strike you're observing photons on your receptor and then you want to know about whether there was lightning in that cloud over a few miles away so we want to know the conditional probability of an unobservable event a that's this left hand side we want to relate that to an observable quantity b that's what the data are and that's going to be calculated using the bayes theorem as the probability of the data given the unobservable state which is called a prior so that's like had to do with cats and meowing or in a previous example or it has to do with like if there were lightning yes or no what would be the likelihood of me observing photons multiplied by the probability of those unobservable states happening which is of course a prior about them but it could be set with empirical data divided by how likely the data are which is called p of b the marginal likelihood or evidence okay so p of a given b is called the posterior because it's like after you've done your inference you want the correct posterior which is like updated beliefs about how likely the thing that you care about a is given what has come in priors are like prior to this round of inference what are your beliefs about how likely a is and then the evidence coming in is be okay and the likelihood is how likely the data are under the prior distribution so that's bayes theorem and we've talked about it multiple times and i'm sure there's other awesome videos and courses that can explain it even better how are they using it here to describe the dynamics of an ensemble of information processing agent like cells as a process of bayesian belief updating we need to relate the stochastic differential equations governing newtonian motion and biochemical activity to the probabilistic quantities above long sentence but it's kind of saying we need to connect these variables which are informational they're probabilistic they're statistical to movement in space movement in a newtonian coordinate system because we need these variables to measure spatial movement so we can study morphogenesis this is fairly straightforward to do if we associate biophysical states with the parameters of a probability density and ensure their dynamics perform a gradient flow on a quantity called variational free energy variational free energy is a quantity in bayesian statistics that when minimized ensures the parameterized density converges to the posterior belief as we will see below so yes this is our first slide on bayes theorem and we did just kind of go from the total description of the variables and what is bayes theorem out of first pass to this introduction of the variational free energy so it can be accordioned out and unpacked a lot more but what variational free energy is doing is helping us tractably converge to the appropriate posterior belief and that's its role here okay anything to add on this one dean well i'll ask you a question so if you were to talk to this to somebody for the first time not people who probably listened to other of our live streams would you say that it would be um dangerous to say that we're taking something that's kind of ratio based and now using that to try to build a model of what our predictions are going to be based on is that is that fair to say i believe so it's like one way to approach that i hope this would be accessible the ratio-based part is on the right-hand side and um one could say depending on like how much data you're getting and what you're trying to estimate it could be very hard to go from observations to inference on hidden states pretty fair conclusion so what we could do would be construct a smooth approximatable model so that when we slide to the bottom of our model just like the ball sliding down the hill we would actually be doing the same thing as fitting this effectively so instead of like number crunching and putting everything into this equation and running the calculation we're going to construct a bowl which is the variational free energy that we can do gradient descent on that is going to converge to a really good solution do we construct it or do they do they kind of tell us that we should assume it if we want to make it tractable assume the bowl when we pick up this instrument we're making variational free energy bowls yeah okay good and we've seen this before um in live streams 26 32 and 34 we did some variants on moving from bayes theorem and exact base to variational inference which uses this variational free energy value so those are a few times that we've seen this discussed before in neuroscience the minimization of variational free energy is referred to as active inference we will see that the basic when the basic condition for an inference type description of a system namely the existence of a markov blanket separating external and internal states is satisfied agents such as biological cells form into organized conglomerations based on their generative model of how their blanket states influence and are influenced by external states in the external milieu so the connection between bayes theorem and markov blankets is the unobservables are external states the observables are blanket states it's a pretty fair model whether it also provides like strong guarantees on optimal perception or optional action that's another discussion but at the very least it's a fair framing that external states are unobserved if you could observe them they'd be observables then they'd be more like b than a so we're talking about a situation where we have some a's and we have some b's and we're going to think about that in terms of a blanket formalism and the dynamics of a system with a markov blanket that self-organizes to non-equilibrium steady states can be described as a gradient flow on this computable variational free energy bound so we can set up the blanket and it turns out that we don't have to do the ratio number crunch we can do the bowl gliding down that's the beginning part on just bays that takes us from bayes theorem to introducing variational free energy and doing gradient descent on variational free energy so that one can effectively essentially perform bayesian inference cool perfect okay section two mathematical foundations all right so section 2.1 stability and convergence in coupled dynamical systems and subsection 1 the helmholtz decomposition so they write the helmholtz decomposition states that any sufficiently smooth i.e possessing continuous derivatives vector field f can be decomposed into an irrotational curl free so kind of straight up and down putting the ruler and finding the slope of a hill and a solenoidal divergence-free vector field the divergence free solenoidal is like putting the ruler at ground level and then being able to make an iso contour around a hill because an irrotational vector field has only a scalar potential and the solenoidal vector field has only a vector potential we can express the vector field as insert formalism two and just so people know the upside down triangle is called del or nabla which means harp due to the shape so del phi is the irrotational vector field del a is the solenoidal field we talked about this mostly in um number 26 and 32 where we talked about the partition or the decomposition into a solenoidal and a gradient as well as this housekeeping term which was everyone's favorite housekeeping term so we're not um having a housekeeping term here but we're keeping in mind that it's not implausible that it's still there it's just that there was a whole paper coming out after this morphogenesis paper that talked about the housekeeping etc so again it wouldn't be surprising if a future morphogenesis paper or project did have this housekeeping term but um 32 was actually a later paper so that might be a more advanced placed um or updated place to check out how the partition i'm sorry the um helmholtz decomposition works and here was a image from just showing how you could have like a kind of um hill and in physics you could have hill climbing and trying to get to the top or sometimes it's easier to think about that as like the flip and the ball rolling to the bottom of the hill so whether it's the optimistic biologists talking about going up to the fitness peak or whether it's the pessimistic physicists talking about going to the bottom of the energy well it's the same idea that there's a particle on a landscape and there's been a ton of work on passive particles that's not to say immobile particles but particles that roll and get trapped and then once they're trapped they stay or they jiggle stochastically we're studying active particles and so that's where action selection comes into play landscapes of energy with balls rolling down them but they're kind of like jumping beans where they also have a few tricks that they can play okay anything to add here just just a reminder to people that that's a density that we're looking at not not a not a not a vacuum it's a i know most people when they hear like if i was to talk to younger people and they started imagining a ball rolling down a hill they would they wouldn't necessarily confirm that it's an actual density that we're looking at so just reinforce that yeah like the bottom right here it's kind of like you're looking down at an ink drop and that's where it's densest is where it's darkest and then that is like a landscape where where it's darkest is highest right okay section two one two the openiv functions okay so the opposite functions have been used extensively in dynamical systems theory and engineering to characterize the stability of fixed points of a dynamical system the operative functions are generally defined for smooth systems through the following conditions so l is going to be the leopard if function and x is going to be a point so a fixed point is going to be x star and a non-fixed point is going to be just regular x so x star the special points where if you are there you're perfectly balanced so this is saying that at fixed points the lyapunov function evaluates as zero and it's not zero if it's not a fixed point and the leaping function change in l with respect to time it's below zero for all x equation three a requires the leopard function to be minimal for fixed points x star representing local minima and b denotes conversions to these fixed points over time so what does it mean to have a leopard value of 0 above zero or below zero so if you're at zero just like it said with the fixed points that means that it's not moving at all a leopard if exponent below zero means that things are converging towards the openiv bigger than zero means diverging away specifically what it means is two points that are really really close to each other do they stay exactly the same distance away that's zero a negatively operative means that two points close to each other will converge so that's a convergence attractor and then positively open of exponents the opposite values mean that two points that are placed very close to each other will diverge away from each other i hope i have not oversimplified or made unforced errors about the opponent functions because it's obviously a really technical area and they write following 16 we can generalize this local leopard function of stability so zero equal fixed point positive equals divergence negative equals convergence to a globally open a function that plays the role of a potential function of any dynamical system and we won't go into it but it is the citation to this ryoshi paper from 2013 and they do some pretty interesting math so if somebody's more familiar with this it would be awesome to hear about but what this is doing is it's taking this same dynamical systems perspective that we've been thinking about about things changing through time and then overlaying on that landscape a stability landscape and so if we think about like this hill on the top right again hopefully not being wrong or misleading here at the very top of the hill it's like a fixed point it's an unstable fixed point but if one were perfectly balanced there we could just say um it could get knocked off by stochastic things which we'll come back later but it's perfectly balanced it's like a fixed point two points that were very close to each other on a hill two balls placed right next to each other would start to diverge as they rolled down the hill so that would be like a slight divergence and so that is what the lyapunov function as potential function is allowing it's allowing us to take the landscape of ball rolling where gravity is the potential function the higher up the more potential you have and then it rolls down because the dissipation of potential energy and they're going to um show that any dynamics with lyapunov function so any smooth differentiable etc landscape has a corresponding physical realization a friction force a lorentz force and a potential function so we can think about this leopard function being related to potential functions like something that draws the system back that's where the negative lyapunov comes into play okay dean just a quick thing daniel when we were setting up the slides between those two bullets um they they talked about something called a saddle point did you understand what a saddle point was previous to reading this or do you know what a saddle point is now yes let us i'm just pulling up the um paper in the window okay so people can see it um okay so yeah the stability um okay so it's the following sentence so we can generalize the leop the function to a global function that plays the role of a potential function of any system this follows by generalizing condition a to allow for saddle points so a saddle point is when the landscape is shaped like a saddle and there's like um so if it were on top of a hill the curvature is negative with respect to all directions right in a saddle point the curvature is negative with respect to one of the dimensions but it's positive with respect to another dimension and so it's just like just like a saddle yeah okay why do they call it that um and so the ball on the top of the hill is like an infinite multifurcator like a little jiggle it could go any direction because it's unstable in every direction saddle points induce a symmetry where that ball is never going to roll up the hill it's going to fall to one side of the saddle or the other side of the saddle and one of those could be like um a certain attractor and the other one could be like another elevation basically um though i don't know the details of how the saddle point is related to some of this lyapunov stuff okay all right so following 16 so this is they're showing that the leopardive is equivalent to a potential function in physics a potential function psi can be constructed to describe the flow of or forces acting on a particle through a potential energy gradient so the potential energy function f is del psi so here's just one way to state the big idea of equations five through nine which are not discussed here so the idea is create a potential function and when you think of potential function think it's like kinetic energy based upon elevation but it's not for gravity and elevation it's like balls falling down tall buildings but for not gravity for something that's related to dynamical conversions so if you were like at the bottom of the bowl you'd only have a little bit of potential energy the potential function would be low if you were really far up the ball wall you'd have a high potential function you'd have a long way to fall that is going to be reflected by a balance of forces namely an attractor force which is the combination of the lorenz force and the potential energy-induced force and then there's the dissipative force and that's the frictional force due to dissipative random fluctuations so that's like the velcro ball on the velcro bowl the friction is so high that it still is being kept on the side or it's rolling down very slowly or something like that combining these definitions we can express the total balance total force as a balance of the forces defined above resulting in and so just like if it was two colliding vectors and then we were gonna express the outcome resultant as like the total forces being applied on something it's like that but it's not about the physical forces in the gravity it's like more about these forces abstractly and so equation 10 is expressing this balance of forces on x using a gradient landscape so there's that del psi and here's the combination of forces being expressed as del psi dean so they use the word tensor here and when i was reading this i didn't i didn't see it i mean okay so if we're having a tug of war on a rope it might appear to the outsider upside outside observer that there's a balance but really what i read into this and maybe i'm wrong was that there's a tension between these two forces between the attractive force and the dissipative force am i am i misinterpreting that someone has a different answer would be awesome to hear it a tensor is like a generalization of a matrix it's like a matrix through time i don't think that it is directly related to tensile or tensegrity okay that being said you're right that there is a tension between these forces or there can be and that they like tension can reflect like a compromised position like if you have a rope with tension on it then the ending of the rope is going to be like some compromise between the various forces and so we're thinking about like the various forces and then we're expressing it as like this matrix through time that's what makes it a tensor not the fact that the forces are in tension or um opposition with each other yeah okay i hope that's accurate okay um and then they follow 16 again and transform that expression in 10 into a more standard form using the diffusion tensor gamma and a tensor q this is like a rewriting that helps them get to this format where f x is describing the flow of states so that's the change in states through time and it's like a vector field and it is going to be q minus gamma so tensor minus diffusion both of that so that multiplied by that landscape so that's kind of like the decomposition but if someone could explain this more let's hear it and my simple words this is where i i i keep bringing up the idea that maybe when we're looking at these things through an active inference lens we're not just looking through a frame we're also looking through and they talk about filters later on so so like how do we how do we make sure that we're including both and that and sort of the tension between both of those views working together and being in tension with one another so yeah this is very this is very formal but i think it kind of reinforces that there's there's what's inside the the the partitions and then what's going on within them as well yeah and it um so it's describing the flow of states resulting from this conservative and dissipative forces so if q and gamma were the same then the flow would be zero if one is larger than the other then it's going to be dominated by that component with respect to being multiplied by this landscape so we'll return to it many times okay variational free energy um what did you want to add on this slide well i i don't know that there any i mean most people already know what we're talking about in terms of variation free energy but what they what they're doing is introducing it in terms of so now where does the model the model of a of a biological entity where is that sourced from and that's this sort of idea of these these these things like posterior beliefs the foundation or the the idea that we we don't walk into a situation completely blind we have some sort of prior and we're modeling situations where internal states can be interpreted and framed as a generative model so it's not they're focusing on the model aspect of this as opposed to the generative processing side they're gonna they're going to talk about what the external milieu is and where the generative process is here shortly great so good point to pause the video and read this because we're not going to read it out here but you're absolutely right they're focusing on the generative model of the agent of the cell not doing that analysis on the niche for example all right section 2.2.1 okay so this is a fun part we can describe dynamics in generalized coordinates of motion denoted with a tilde where x tilde is defined as x tilde equals x that's like the absolute state of x and then x with a dot is the first derivative of x that's called velocity x with two dots is um or a two double prime depending on the notation is the acceleration what people don't always know is that there are higher derivatives and they also have names so the third derivative is the jerk and then the fourth fifth and sixth are the snap crackle and pop so that's just kind of funny but the generalized coordinates of motion which came up in number 26 have to do with doing prediction on not just um how high or low something is or like on the number line left and right that would be like if x were just one number but even if it's just one number that we're tracking like body temperature for example we might be interested in kind of unpacking that into this generalized coordinate where we want to know body temperature and how fast it's changing and how fast that is changing and so one can imagine that once a zero has been achieved the higher derivatives are also zero if it's zero through time the higher derivatives are also zero if it's zero instantaneously that's not always the case but if it's zero through time then it's kind of like you've cashed out the derivatives the derivative of zero just stays at zero and so it's like if the position is unchanging the velocity is zero ends if the position is five miles an hour going in the same direction the velocity is constant but the acceleration is zero so keep on carrying that out to how fast things are changing how fast they change et cetera et cetera and then they're going to take that x tilde how x tilde changes with time x tilde dot equals the flow on tilde plus a variance so a noise or fluctuation a random fluctuation term this is the form of the langfine equation generalized coordinates of motion plus a random fluctuation term um any of the mathematical colleagues would be awesome to hear how this is related to the weiner assumptions etc but we're going to continue so using the helmholtz decomposition we can now express steady state flow in terms of a divergence free component and a curl free descent on a scalar of the operative function l of x tilde to obtain f of x tilde equals there's the q minus gamma that we saw a few slides ago multiplied by now the l so here we had f of x not generalized coordinates of motion q minus gamma del psi of x that was the potential function now because the potential function and lyapunov are related to each other we're looking at the generalized coordinates of motion using the same q minus gamma helmholtz decomposition but multiplying it now by the opening of exponents or i'm sorry the lyapunov function on x tilde it's the solution at non-equilibrium steady state and is exactly the same solution for the flow of particles in the classical treatment above crucially we can now see the operative function is the negative log probability of finding the system in any generalized state the leopard of x tilde is the negative natural log of how surprised one should be p of x tilde this is known as self-information of a state in information theory surprisal or surprise in bayesian statistics it is the negative log evidence so the change in the generalized coordinates of motion f of x tilde breathe is an irrotational solenoidal decomposition that's the left part of the right hand side multiplied by a lyapunov function which also has the interpretation of surprisal so if you are exactly resting so to speak you'd be totally unsurprised in summary any weekly mixing dynamical system at non-equilibrium steady state will events give us evidence for or look like it is a flow that can be decomposed into a gradient flow on surprise and an accompanying solenoidal flow because we can associate the lyapunov function in 18 with a free energy the system is effectively minimizing a free energy in its convergence to a set of attracting states which have a high probability of being occupied so it's a little circular it's like we're finding ourselves where we expect to find ourself and so if we just said well how surprised are we and let's gradient descend towards not being surprised just at a first approximation we would find ourselves in regions of low surprise and we would be surprised to find ourselves in regions of high surprise is it is it circular or is it kind of the byproduct of a recursive process again i'm asking i'm not questioning it's a great question in like a really meta way all of math is circular once the axioms have been stated because like the equal sign is there so we're just you can add one to both sides and it would still be equal so is that circular right um it's useful and that's what matters for this paper okay yeah um we're not going to talk about it too much but in a dot one we absolutely will and that's this least action principles in 2-2-2 and they even give the example we love to see for example in colonies ants find the path of least action to harvest food and bring it to the colony citation needed slash let's see that but conceptually no problem this example considers their paths as flow channels or trajectories finding the least average action for each instance of foraging given available resources so what does least action principle mean what does least action mean and what is it necessary or sufficient for because certainly foraging is not the least biochemical expenditure of energy that's like the sort of naive interpretation of least action meaning just stay where you are but we're thinking about a usage of least action that impels this ant to forage in an adaptive way such that even when it's foraging trip is hard and the seat is heavy and it gets like lost or something that is still a realization of at least action on something it's still a ball rolling down a hill as efficiently as it can in a space so it's a nuanced topic that it will be great to discuss because they also write minimization of action in an open system leads to structure formation so that'd be a good thing to unpack okay carrying on in dissipative random dynamical systems action is not minimized for each element of the system but on average over an ensemble of elements or repeated trajectories of the same element since self-organizing open systems are not conservative their structured flow is quintessentially dissipative good to think about that and hear many perspectives and questions on it classically for a conservative system the lagrangian is defined as l this is l not the operative now it's lagrangian equals t minus v so t is the kinetic energy of the particles and v is the potential energy [Music] and so that's how the trajectory of system states could be solved for a conservative system where the total energy is going to be conserved but they're opening up into this dissipative and open scenario where this is not going to cut it um [Music] a little bit more detail on least action which we're not going to go into okay continuing on two two three markov blanket okay a robust literature is developing about around the ability of cells and other a neural non-neural systems measuring aspects of their environment via specific sensors they introduce here the markov partition as this general case of separation of states into four categories e external states sensory states s active states a internal states i and so the little e is like it's a realization of big e that's the bigger space and then x tilde comes back and the generalized coordinates are going to be a realization of values of those partitioned states so we've talked about the markov blanket before but now we're interested in the generalized flow on the blanket partition states so here's what the markov blanket looks like and we'll talk more about it in the dot one and dot two what do the arrows mean and why are sense and action connected what part of the cell are we looking at is it a part of the cell is it a model of a cell all these things that have come up before but just to say that's their figure one and table one gives the math formalisms okay anything to add on markov before we continue no because we'll we'll unpack yeah so this is where they apply the markov blanket so m is describing the markov partition that defines the underlying random dynamical system such the cell so that is like um the uh model that's the partition markov partition of the cell so inserting c into a and b is going to give there's a is actions and i is internal states so the top equation is basically saying the flow on action is a function of sense action and internal and then it has a right hand side so the flow on action the performance of action is and then there's that gamma minus q but now they have a subscript a because it's those about the action landscape multiplied by del triangle on action tilde generalized action and then a self-surprisal looking like the self-surprise of sense action and internal conditioned on m partition and the bottom equation in b 30 b is basically the same but it's the flow on internal states f sub i on generalized states of sense action and i and that same gamma minus q del self-surprise condition on model so we're seeing some patterns come up and even if um it's like confusing and we all definitely are confused by it to some extent we're starting to see like some patterns why does it matter to focus so much on a and i the action and the internal states because those are like the ones we control we know we don't control external states directly maybe we can intervene so that they change differently but we know we don't control them we also don't directly control sense states we're getting dealt this hand every second by the niche the generative process and so we can take action so that we can expect different sensory outcomes but even then we wouldn't be controlling sensory outcomes and so a lot of active inference comes down to doing inference on internal model internal states generative model learning and action action selection flows on action um [Music] this bounds the surprise on the particular states which is the internal and the blanket states through control of the autonomous states which is just the action and internal states the states we control because of the sparsity of the blanket not every node is connected to every node there might be a factorized and tractable form to bound our surprise about the particular states in general it would be very difficult problem to solve however we can replace the lagrangian that's the one here that was like going to be used for conservative systems but it didn't really apply um with a variational free energy functional or of a probabilistic model of how a system thinks it should behave or how we think the system should think it should behave so it's hard to solve these generally but in practice there are heuristics such that these are approximatable section 2.4 goes like one layer deeper into kl divergence in the vfe but we're not going to go into it okay we're just going to keep on plowing through two three is bayesian filtering and self-organization we're not going to talk about it now but the big questions here are like how does bayesian statistics relate to identity and what is self-evidencing and there's probably a lot of other good questions we could ask like why does bayesian filtering and self-organization come here all right modeling morphogenesis so now we actually get to the contribution of the paper um which is the modeling of morphogenesis so they're going to illustrate self-organization to ness using the variational principles above by trying to explain the behavior of a model of pattern regulation by consideration of information processing and error minimization with respect to a specific target morphology in this setting the game changes subtly but profoundly it's a dean line if i ever read one um above which is what we've reviewed the dynamics of any random dynamical system equipped with a mark called blanket can be formulated in terms of a gradient flow on variational free energy that was just here the flow on action and the flow on internal states here we turn this formulation on its head by specifying a generative model an implicit vfe function and simulate self-organization by solving the equations of motion in equation 34. so they're going to specify the form of the attracting set v uh the generative model and then they're going to let it ride so we have to just talk down yeah they specify the external dynamics as the generative process that's the niche and the generative model of that process which is being described by the flow of internal states okay so we're going to look at the figures and then we're not going to even like go into the details so let's just look at the figures and see what they're doing so here's some empirical biology happening in the lab of mike levin and others so in a it turns out that when you dissect out the center of a flatworm a planarian those cells will remodel into a new worm so cutting out the middle and it reforms into this new flatworm and red is the head and then like blue is the tail so there's a self-organization of this target morphology even from an initially clumpy cell what they're going to do in b is showing like the final fixed point of these different cells so here we have like four different cell types there's like the red neural or head cells then yellow cells green cells and blue cell and then basically like this like three two one one um and then the bottom one it's this one maybe they change the green and the blue like i think these two should be green and the bottom should be blue but minor point but it's an attractor on this target morphology um and then c is describing a little bit about how it happens which is that cells are constantly comparing their sensed signal concentration like of a gradient of some um morphogen to expectations by minimizing their free energy functional so it's like what kind of a cell type am i and what should i be expecting flip side what should i be surprised by because to say what i expect is the other side of the coin of what one is surprised by okay so they're modeling this empirical scenario where a flatworm can regenerate its form from just a clump of cells here and that if we think about the location of these cells as being like a steady state attractor like we want to have this body form last then if all the cells just get in line like that everything's going to work out all right how do we take this first jump that we made from the empirical biology to the state space framing here it is an x y state space and now take the next jump one more mathematical here on the right side is that x y positioning of each cell this is reflected by the position in x and y of the cells so like negative nine and zero so that's like this top red one zero is the midline so it's like y and x and here like negative five it's a little lower and then like negative four and four it's like one is on they're on the same y elevation but then one is four to the left and one is um four to the right and so this e star of x is the position so it's um a matrix of position because there's like um eight cells and two location variables per cell so it's like a two by eight matrix and it changes through time so it's a tensor the e star c is the external signals and so in this steady state attractor all three red cells are getting like signal one here's the binary signal there are four signals but they only have an on or off state in reality there's many many more signals than four and there's a lot more uh nuance than just on or off but it's a it's a toy example all three red cells are getting the exact same signaling milieu of one one zero zero so factor a and b are diffusing near me but not c and d the yellow cells are experiencing those two diffuses and one other one the blue cells are experiencing the first the fourth and then the green one is another and so this is like the attractor state for a stable location and signaling expression so converging to this spatially makes your body look like that but the way that you get a beach ready planarian body like that is actually by reducing your your surprise on signal expression okay so here's them running it through time so it's a time-lapse movie montage of simulations of morphogenesis and so here it is converging towards on the right side the morphology that's been discussed here and so the cells start out with undifferentiated they know what they're sensing they don't know what kind of cell they are and they don't know where they are and then they sharpen their expectations about what kind of cell they are while also moving into a different spatial niche but they're not tracking their location like i'm at three comma two where are you it's like this is what i'm biochemically sensing and so it's a relational morphology that doesn't need the blueprint in the nucleus so it's a lot like an ant colony there's not the nest architecture blueprint in the brain there's the process for stigma g and then they show that with some other um changes in the generative process a positive squared gradient in the generative process they get double head formation which some modulations have been shown to empirically result in in the lab and they can also make it so it gets double tail formation so it's just recapitulating this basic example and then showing that like modifying the external field changes the morphology that gets attracted to so those are the key pieces that's modeling morphogenesis as bayesian inference reducing surprise with a variational free energy flow on action and internal states action states internal states okay um we're not gonna go into it here definitely for the dot one and dot two so um 3.1 is the construction of the model they then unpack that signal matrix the combination of the signals and then um [Music] they give even more information about modeling signals and they also imbue it here with like this steminess which helps the cells start out with um i believe a weaker prior about what kind of cell they are which translates to where they should be um in figure five they do a targeted intervention in their studying of anomalous cell behavior and so basically they start off with these um cells that have initially unspecified state and they converge in a this panels on a by 32 time points they're converged to the target morphology but in b they show that if one of the cells that gets hit with a white arrow here has a perturbed signaling response it fails to correctly infer its place in the ensemble so b is like sort of like um it could be like a genetic mutation or a targeted modification of the signaling and it's like that third red cell never forms and then in c the same aberrant cell from b is initially is rescued by an increased signaling sensitivity of other cells leading another cell green arrow to switch position with the aberrant cell pink arrow pretty cool okay yeah i wanted to come up with an analogy that would actually work that would explain this like if you're out geocaching one afternoon and then all of a sudden some something was able to turn all the lights off and then the person that was geocaching beside you change their behavior but i couldn't even come up with a valid analogy to try to explain this how about um uh we're playing american football and so there's a plan and everyone's trying to reduce their uncertainty about how the plan is playing out from their perspective and so if all goes to plan we're all going to deploy into the exact right positions but then somebody um doesn't move if each nestmate on the football team has low sensitivity then they're going to continue in their own expected trajectory as if nothing had happened that's kind of like what we see in b it's like a partial rollout whereas this is changing the environment mixing our metaphors etc so that a high sensitivity teammate fills in for that critical position so that the attractor state of the strategy can still be morphologically realized even though um there still is that one individual who's not moving but but they're not interfering with the strategy's attraction but we'll come up with probably some other and better ways to talk about it okay and then they um just mentioned that this is something that can be modeled and it's in spm and also on franz kuchling's um github so maybe we will um look at the code and then just to say that we're not going to go into it at all today but all of section 4 is super interesting they review some of the mathematical assumptions and limitations of the model there's a really fascinating discussion about variational principles and open systems and so um [Music] like just to read we have shown that the variational free energy minimization in active inference is related to the variational principle of least action it is worth pointing out with where these two approaches diverge two instruments in a wood diverged and then it's all about that divergence and the contrasting and so i think there's gonna be a lot of unpacked there and then they have some closing remarks on the applicability in biological systems and some of the predictive capacities of the simulations um in terms of like you could make a simulation of a healthy functioning tissue and then have predictive capacity about asking counter factuals well what if this happened what might i expect so that is a lot of info so thanks to everybody who's been watching and again hope that especially with some of these technical parts that we were able to represent it with high integrity so you won't have the last word but what would you say in closing as we move from the dot zero into the one two and beyond well first of all you went through a heck of a lot of stuff in a very short period of time so that's that's quite the gradient flow right there so that's impressive um i don't think much in terms of i mean this is a classic example of where you have to unpack as opposed to lots of the other papers that are maybe more philosophically based whether you you provision like you pack a bunch of stuff and then you kind of go off on a bit of a journey and i think in the point one and the point two we may still be doing a little bit more unpacking just because of the the the density of this kind of information but that doesn't i mean you want to be able to do both so i think i think being able to cover this and hopefully we got it right like i i did my best to try to understand it and i think he did a good job of explaining it so we'll see who shows up in the point one and two whether the point one and two or more unpacking or maybe starting to actually think of ways that we could employ this you already mentioned that we could we can apply it to digital teams but whether or not people have the confidence to be able to take this and apply it like they've done to morphogenesis maybe that's part of that conversation cool yeah i'll be looking forward to going through with multiple concurrent regimes of attention some of the formalisms that we either um disgraced or skipped in this discussion and then keeping it open to think about morphogenesis like where has morphogenesis been in numbers 1 through 38 why haven't we been talking about morphogenesis and if not morphogenesis then what else have we been focusing on um [Music] how does it relate to embodiment and to spatial and physical aspects of cognition there's so many interesting angles and uh i'm sure we'll have a lot to discuss so dean thanks a ton for all the help on the slides and for this discussion um [Music] hope to see you in the coming weeks all right thanks daniel take care peace see you later