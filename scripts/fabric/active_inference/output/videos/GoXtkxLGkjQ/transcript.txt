all right hello and welcome it's May 24th 2024 we're in ACM live stream number 57.0 doing background and context video for the active data selection and information seeking paper and Series so welcome to the ACM Institute we're a participatory online Institute that is communicating learning and practicing applied active inference this is a recorded and archive live stream please provide feedback so we can improve our work all backgrounds and perspectives are welcome and we'll follow video etiquette for live streams head over to active inference dorg to learn more about any of the projects including the live streams So today we're going to do together a background first pass on a very interesting paper from Thomas par Carl friston and Peter zidan active data selection and information seeking from 2024 in this video we're going to introduce ourselves talk about big questions go through the keywords of the paper then most of the sections section by section and as always with the zero it's just like a first pass and we'll look forward to speaking with hopefully some of the authors in the coming weeks and also looking what people ask about so Christopher let introduce ourself and go from there thanks a lot also for helping in thezero preparation happily um yeah so I'm Christopher Bennett I'm a bioinformatic scientist I do a lot of uh data mangling data analysis and that sort of thing um this paper was of great interest to me as we kind of go into this more data driven era uh in making sure that with such large data sets that we have making sure that we can actually select data for any of our applications going forward be it machine learning or some whatever we're trying to do and I'm Daniel I'm a researcher in California and also was drawn to this on one hand on the applied side the idea of more efficient and effective data sampling and then on the more theory side the connection with epistemic value Information Gain so here are some of the big questions why don't you add some detail to this absolutely there was five major big questions that I had after reading this um for the most part it boils down to doing our sampling you can do sampling over time and sampling of different data sets in different ways um is there a way that we can um intelligently select the data that that we're uh going for the time that uh the time that we're trying to select um is there a way that we can understand how the time aspect how to sample through time instead of just doing a like a dynamic uh or more Dynamic instead of doing a static like we're going to do Time Zero time 7 time 14 time 21 can we say hey the differences between time one and time two are very time point one and time point two are very interesting that's a lot of data in there alone so we'll sample one and two or and then maybe sample 10 is there a way that we can intelligently select the time points that we are sampling from when we get into the time series aspect um there's a number the piper mentioned a number of different uh time Dimension models that you can add to the core model that they're utilizing um one of which was a hidden Markov model another was they mentioned a differential equation in the actual uh model itself in the equation itself um is there one there are there situations that one performs better over than the other um or is what they have selected to use in the paper the optimal solution in most cases if not all cases um you know that in when it comes to clinical trials that was a section um in this uh that they discussed um there's a lot of FDA uh regulations of clinical trials and it's very uh heavy red tape right now um is there a way that there minimums ends that you need in many uh clinical trials to actually be considered passing is there a way that you can bound this uh model that they're they've developed in to something that you can guarantee a minimum number a minimum sampling that the FDA requires or any regulatory body um another point is the next step of how are we going to integrate this in with other machine learning models or any Downstream applications that you're going with is there a selection method that we can uh or how do you see these this method kind of pre kind of before machine learning how are we going to attach these things together so that we feed the right data into the machine ma learning um being an llm uh and then scalability and computational demands that's going to be a big one if this is going to be something that is used routinely in Industry you need to make sure that this is something that is as in as scalable as you can get um you know go from small scale which is a lot of what they show in this paper and then all the way up to the very large scale data sets that we use to train llms and other other models those are kind of the five major points that I add here thank you those are very insightful here were some of the big questions that I was excited about so first from a more General Information Gain epistemic foraging perspective how do we model the implicit and explicit constraints or trade-offs or dynamics of information seeking which is often addressing a question that is left unaddressed in data science of where the data comes from and it's just about doing analysis with the data that's there but even there as this paper will kind of get into there's still subsampling and all these other factors to consider um the clinical trial example brings a very serious and very real plot twist into the paper which moves through several levels of adding theoretical generalization and incorporating like the time Dimension and other features and then the plot is when the preferences for certain kinds of observations is specified then there's all this interesting behavior and decisions that come into play so I'm sure that'll be a great discussion and then also in section four they mention the streetlight effect which is quote the tendency to search where data are generated in a minimally ambiguous way I.E under a Street Lamp compared to searching Elsewhere on a darken Street and so there it's an interesting scenario and there'll be some fun art coming up and also how they distinguish the sampling method with the full information seeking from the maximum entropy sampling is a very subtle but very important point that I look forward to hearing more from the authors [Music] about okay so just to summarize the uh paper is active data selection and information seeking 20 24 Thomas par Carl friston Peter idman and just a few of the aims and claims of the paper and then Christopher will read the abstract this paper aims to unpack the principles of active sampling of data by drawing from neurobiological research on Animal Exploration and from the theory of optimal experimental design our overall aim is to provide an intuitive overview of the principles that underwrite active data selection and to illustrate this with some simple examples our interest is in the selection of data either through sampling subsets of data from a large data set or through optimizing experimental design based upon the models we have of how those data are generated optimizing data selection ensures we can achieve good inference with fewer data saving on computational and and experimental costs so if you could read the abstract absolutely so the main uh points in the abstract are um that basing inference is is typically focused on two major issues uh the first one is that you have to estimate the parameters of the model of the data and the second is that you need to quantify the evidence for alternative hypotheses uh and formulate an alternative model um but this paper is actually looking at a third issue which is in how you're going to select the data for your models um and either through sampling subsets of large data is typically used um or optimizing ter of design um based upon the models we have have these of how these data are generated um optimizing data selection what's going into the models can achieve a very good um inference with fewer data points so you're saving on computational time costs that sort of thing by actually reducing the amount of information that you're putting into the model so what they're doing here is trying to unpack how you're going to AC L select data and I mean actively select data to a machine um optimization protocol by drawing from some of these neurobiology Concepts um and trying to optimize the maximum information that a that the information can provide maximum Information Gain um so they offer overview of some basic points uh from these from the field and illustrates the application in some of the toy examples that they have will go through ranging from different approximations uh with basis sets uh to infant about how the process can evolve over time and finally they'll go through and consider how the approach to the data selection could be applied to design of uh clinical trials in this case and uh specifically Bas adapted clinical trial something that is more and more uh seeing headlines and kind of it's more and more used today now that we have the technology to do with great okay for the road map the paper begins with introduction section goes into basian inference generative models and expected Information Gain they go through a simplest worked example and then consider a few more ways to level up that model with function approximation consideration of time Dimension with Dynamic processes and then bringing the preference for certain observations in the clinical trials then there's a discussion and conclusion and they also have a paragraph explaining their kind of logic there the keywords for the paper were experimental design active sampling Information Gain and basian inference so the next slides are going to go into those four background topics after the four background topics we'll speed through the sections and just plant a few seeds for what we want want to explore more so first experimental design here's two kind of classical views of experimental design in the active inference and free energy principle uh eras so on the left is the statistical parametric mapping textbook toolbox documentation Etc has multiple chapters and kinds of analyses included in the package to specify and simulate and also to recognize data according to different experimental designs and one very Hallmark or common visualization of these kinds of patterns of experimental design are these design matrices and it's just represented in this black to white gray scale and it summarizes different kinds of measurements across different experimental settings like here might be six settings in the larger white blocks and then there was variability within each of those trials and those are the smaller row levels so that's like where the data are collected and a lot of this has to do with the linear operations that can occur on this kind of Matrix in a general linear modeling framework and then on the right is the experimental design experimenters perspective where the experimental stimuli they output as actions are the observations going into the subjective model like of the rat in the teamas and then the action output of the Rat is the observations of the experiment of the experimenter so there are kind of two different perspectives SPM with more of a matrix multiplication fmri optimal design and then active inference with a more General graphical basian modeling starting to broaden the consideration of what optimal foraging and what Information Gain epistemic value mean these are kind of the experiment design themes and how they connect a little bit with other experimental design factors want to add anything yeah and keep in mind that a lot of these experiments experimental design is a very big um and Mo and very important consideration when you're actually running any sort of science or analytics of any variety and these experiments can actually get very large with huge huge amounts of data and not all of that data is relevant for every application that you want so you want to be able to design your experiments in a way that you can collect information in a intelligent way rather than trying to go through and just collect every data point that you can because humans in many cases are running some of these experiments and they have limited time um I certainly do when I'm running these things so I have to be very intelligent in how I set things up and how I actually collect data and what data I collect because you only get in many of these cases you only get one shot to collect the data if you miss it it's over you won't have that data point so it it's very critical that you actually take the experimental design seriously when you're setting these things up great so connecting that kind of experimental design experiment on a budget perspective with a more statistical and biologically statistical based uh perspective active sample so they wrote when we look at the world around us we are implicitly engaging in a form of active data sampling also known as active sensing or active inference so this is referencing the visual Cades and just to kind of highlight how extreme the relative Acuity difference is between the center of the eye where the Gaze is focused on and the offc center among other visual changes and vision is just being taken as one sensory example here it could also be thought of as like looking for books within a library or any other kind of selection of what data are going to come in even if it seems like all of it is coming in that still is going to be uh perhaps addressed with a different sensors that have different variability profiles or like there's different RNA sequencing kits that you could buy and so how do you balance the kind of more samples or Wich samples especially as those spaces grow massive and then just to contrast that whereas digit recognition in a cade based Paradigm would focus on the motor patterns and the small centrally focused visual Acuity and then the motor patterns that relate to cating around a digit whereas in the kind of machine learning taken all at once approach a matrix corresponding to like the pixels in the mnist data set are simply taken in all at equivariant level so that's just kind of taking in the data there's still is another higher order data selection question of like which digits do you take if there was a large number of digits in that Library so this is uh active data sampling on multiple scales which records you pull at all and then how the resolution and all the trade-offs that are associated with using the data processing or making the experiment yeah add more though and you know keep in mind that in the when you're talking about something like the visual system you know our visual system has access to untold amounts of information but our brain can't take advantage of all of that at once there low energy usage of the brain it needs to optimize the relevant information think you know your nose is right at the end of your face your eyes are always seeing your nose but your brain is filtering it out and this is happening all the time at all points in time there are literal blind spots in what you are actually capable of intaking and processing all at once uh and then additionally when you're moving away from something like your the ey or biological systems and into the experiment design itself you know you often times can't run a full factorial design and there are other methods like a fractional factorial design but those are random based and this is trying to actually talk about actively selecting how you're going to set up that design so it's kind of a a you can think of it in multiple different ways awesome the factor that's going to come into play as driving the active sampling is going to be the information gain and there's some quotes here and equation two is shown they write we have conditioned our model upon the variable Pi which represents a choice we can make in selecting our data so data recognition interpretation analysis and so on it's often framed as kind of like an observation type or sensemaking type activity here Pi for policy as with usual is Being Framed as a control or an active data selection policy we're applying to some data set so it adds a action element into this sequential epistemic foraging rather than just taking a large data set and just munching it like all at once it brings in this sequential question of where to sample and potentially updating where is informative to sample through time and the if of Pi is the functional on that policy distribution or specific choice that can be decomposed all these interesting ways that we can explore more in the coming discussions what else would you add though about Information Gain I think this is one of the biggest points in this whole paper is you're measuring how much information you are gaining in your model by adding these different Vari Ables in here and selecting different variables you're effectively automatically taking out or trying to remove things that have high Mutual information that don't add as much so if you have parameter a and parameter B that are effectively just transformations of the same data then you can easily remove one of those and still have all the information that you need um so it's a really really powerful way of saying I'm trying to optimize and maximize the amount of information that I'm adding in into the model by selecting data that actually has the information that is going to improve the model awesome one other interesting angle here is often in the control literature utility reinforcement learning Etc the epistemic value component is added in whereas in the structure of this paper they start with the pure Information Gain perspective and then in the clinical trial they bring the preference in so the pragmatic value comes in secondary to the information gain in how they build it up step by step um basing inference is the last keyword a lot of places to go here's what they showed for equation one and they wrote basian inference is the process of inverting a a model of how data y are generated to obtain two things the marginal likelihood and the posterior probability so anything you want to say about basan inference or do you want to say something about basian networks and graphs I think that you've kind of covered it here it's I think fairly textbook on this part yeah how about graphs on the basian graph side of it um there's multiple different ways that these basian statistics is done nowadays and the basing networks and graphs is is a really powerful method going forward um I know that uh right now in The Institute we have an RX and fur uh group working right now which is a Julia package for actually building these Network graphs these basian graphs and doing message passing between the different factors and the different nodes of the graph so this is a a very big upand cominging area right now it's it's very early in the um in the time frame that this is going to become big it's kind of on the upswing right now um and it it's kind of at least I would predict GNA be kind of the next big thing going forward uh in the next five years or so yeah we've been having a great epistemic time and live stream 55 explores some of this in more detail okay that was the background now on to the paper so first just to get the last part of the paper out of the way they have a GitHub Thomas pars GitHub with the active data selection repo and maybe in one of the upcoming discussions or somebody in the time between can explore and and transform and play with the code and also all these different ways that we we have fun discussions around the language of the active influence model and how building it in different languages or using different styles like is or isn't plausible these have been very fun discussions that that help us get out what the core of the math really is and how that's independent of whether it's written in mat lab or any other language and then also as it is simulated it's written here in Matt lab and so that's kind of interesting any thoughts on that or just like coding in RX and fur or or yeah I think that with ARX and fur being I think relatively new on the scene you have some of these other traditional uh approaches with mat lab and pimd and that sort of thing um it'll be very interesting to see how these techniques uh evolve over time with packages like RX and fur um really I think changing how we approach building these models and designning them I think that it's going to be even more critical now um in this current environment to select the data intelligently going in so that you're not muddying up your models or having to build to Big of models that might have information that's not as useful to the application at hand yeah great all right section one introduction so we'll try to hit on some of the key points I'll say something briefly and then feel free to add something if you want section one situates that inference an action cycle or Loop or partition in terms of a statistician's job or process in modeling observations data as sampled and latent variables as models and the process by which there's kind of snapshot or bulk summarization or generativity or and how it's possible to have a continuous resample sampling of informative data or how you even evaluate how data are informative in which way want to add anything I think you've captured that very well I'm GNA actually pull out my notes so that I can actually uh remember all the symbols y are going to be used for data and Theta for the latent variabl so distributions of data distributions of latent variables conditioned upon data coming in so that could be seen as just one data point sequentially or a big bulk Vector coming in like all at once um just continuing to move through this section they wrote careful data selection is especially important when we consider the problems associated with very large data sets of the sort that are now ubiquitous in machine learning and artificial intelligence settings so just to summarize a little bit or add a few notes that came up in the paper so other than this topic being very fascinating and very integrative in terms of a unifying approach for information Behavior Etc also this is definitely one of the active inference questions that has a lot of pragmatic relevance as dealing with with data sets of different kind is totally day-to-day and especially the way that even the examples specify important settings is very clear very direct though also the mathematics are very general about epistemics and this motivation that they lay out in the first section about how if this challenge could be addressed then there would be all these kinds of benefits that could be realized with current systems and data sets and then they provide the approach to at least getting there or towards it to optimize data selection we first need to identify an appropriate optimality Criterion and so they're going to kind of go through several stages of with different generative models how that optimality Criterion is defined anything else T and keep in mind that this is the expected Information Gain that they're talking about it's effectively how much do we think we're going to gain by adding this information in there and then you can of course train your model by looking at the actual Information Gain if necessary and go through kind of a learning cycle but we're basing this all off of what do we expect to gain from this information all right section two phasing inference generative models and expected Information Gain in this equation three I won't read it all it models the marov blanket formalism in terms of upstream and downstream causal relationships in terms of messages that are passed along edges of a factor graph that they introduce in this paper the Lambda operator to indicate either summation or integration so this is across continuous variables or discrete variables and we'll explore this more with the authors hopefully anything you want to add on equation three uh more that you know the information um gain is a function of the data that you sample so depending on how you sample that data you're going to get different information gained out of it as you would expect um and then you start to get into the message passing which is that base graph and Factor graph um I guess challenge going forward that that construct when you build it in a factor graph model you have to be able to pass the messages between the nodes effectively yeah and to to kind of ground that in the data science situation if you have a latent State estimate and you're generating data generative AI synthetic data then the latent variable is Upstream causally statistically from the data pseudo observation but that might be the actual real observation if you're interested in the computer model whereas the data recognition case where the data are Upstream of the estimate of a parameter like a risk score or something like that then the parent of the lat and state estimate is the data so that's the recognition Direction so this kind of covers the whole basian update possibility Spectrum in this essentially markof blanket but it could be in face base or time or a few other situations that explore all right three a worked example this section lays out the overall pipeline for how you get from the graphical notation of the basian network whether it's viewed visually graphically like with a variable dependency structure or whether it's just written out in terms of the plain text with the analytical the bayy network is transformed into a factor graph probably constraint Factor graph discussion for another day on that graph certain messages are passed at inference runtime conditional and predictive entropies are calculated as part of the way that this system outputs or is described by different probability distributions understand in a kind of statistical mechanical way in terms of entropy and then that is going to come together into calculation of the objective function which is the expected Information Gain which is basically conditioned upon the cognitive model of the sampler so just because the sampling is active data sampling doesn't mean that it's going to lead to like an Adaptive Behavior it just means that where the learning rate is perceived to be highest informationally iteratively there is a ranking by which those can be uh which this the space of experiments can be ranked by and it can connect to pragmatic value in terms of e epistemic and pragmatic coming together for the full expected free energy like in the clinical trial anything dad and you'll notice in for this story example uh that they are discussing here um the factors that they have in their graph in each of their uh nodes is actually a cosign so that's why you get that kind of oscillation in that bottom plot there um so you'll have uh areas of maximal uh information and then areas of minimal information just based on the Tog EX example they have um and this doesn't always have to be cosine but in this example it is and so it just kind of gives you a really good graphical understanding of how your Information Gain uh can be viewed over a sinusoidal sort of oscillation yeah just to kind of double down that if you sample right here on the number line or right here the lines are indistinguishable so the Information Gain Is expected to be low under understanding the parameter family that is being generated and sampled from which in this first example is the same same type of equations whereas where the functions are maximally distinct The Information Gain associated with reducing uncertainty about which one of those five the the data point is coming from those are the informative points at the zero on the number line and far out that's where just perceiving one point uncolored would give you the most ability to even perfectly resolve which one of the five situations it was so oh they right in effect this model amplifies or attenuates the amplitude of the predicted data depending upon a periodic function of our data sampling policy Pi so here the the policy distribution is like that kind of Around the Clock Direction which is not a common setting but the the general idea of sampling amongst a finite set of Alternatives where a control variable is going to result in the most informative data point is a theme that is going to be expanded upon and also uh one interesting mathematical move once all terms that are constant with respect to Pi are eliminated we are left with equation six so equation five comes down to equation six or maybe not exactly only 5 six but six has removed all the the the variables that don't change as policy changes so if the question of policy selection is taken alone like gradients on policy updating then everything that's constant with respect to it doesn't come into like the Delta Pi Delta something so it just simplifies it down to only a function of policy and that just kind of reflects how like the Sens making and belief updating component is partitioned off from the policy selection component here yeah you're looking for change in um your belief based on the observations that you're gained so if it's not changing it's not as informative in your information model yeah uh continuing on equation six there which is modeling the policy dependent components of Information Gain as an objective function that ranks decisions about where to sample uh equation six is a special case of the third row of table one which highlights analytical expressions for expected Information Gain for a few common model structures as we might in it the most informative places the sample data aligned with those in which differences in data lead to large differences in the predicted data in which our choice of Pi maximizes the sensitivity with which why depends on data so here are the the categorical the darish lay uh and other functions in terms of how they'd be written out in the probabilistic like specifying a distribution way and then how there's this relationship and analytically to a related distribution which is an objective function that ranks the information content of sampling the likelihood distribution in a certain way and that's closed form in certain situations and then also the Explorer where it's intractable formally and so then that's where the variational approximation comes into play anything to add no I think that Su summarizes this slide okay section four function approximation we next turn to a generic supervised learning problem that of trying to approximate some function based upon known inputs and the observable outcomes they stochastically cause pretty General neural network or latent State observation setup um that information is composed and concatenated so so that there's a a common variable with that that's describing the statistical object that's going to be describing the inputs and the relationship with the observable outcomes and then that uh function approximation from sequential data in figure 3 is simulated with random but potentially you could call all of them random but this one is a a flatter or uh a a less informed and iterated model of data sampling just going to show that uh samples of random data with even this minimal non Information Gain driven model has a certain Baseline prediction that's associated with certain choices about sampling sequentially from this generative model want to add anything yeah it's just I like that they highlighted in this uh that choice diagram there that um you can actually get the inefficient sampling just by random that you start to Rand you can randomly select two things very close together um and you've effectively maybe not wasted a choice but you know not gotten the maximum gain from that choice that you could have have yeah they write a little bit more about figure three figure 3 illustrates a depiction of this model as a basy network and a visual representation of the data generating process um now they're going to bring in Information Gain so they write this is where Information Gain becomes relevant into designing a a more informed way to sample data then from a flat or a non-updating prior data sampling distribution it's like equivalent to having a policy prior that's fixed which might be a heris in certain space um they write substitute substituting equation 7 into equation three so here's that um Markov blanket parent child concept and here equation three is describing the policy dependence on The Joint distribution of The observed and the unobserved and this is combined into equation 10 to show what equation 10 does in terms of now that we're sampling from this distribution or like statistical distributions that this describes um they'll differentiate figure three from figure four kind of like bring in this model change between those two figures now samples are drawn from a distribution whose log is proportional to the information gain in equation 10 so it takes the flat policy prior and in a fixed way has remapped it to be proportional to the information gain so here's three on the right and then four on the right and um the figure uses the same format as figure three but now each choice is sampled to maximize anticipated Information Gain and they point to some specific uh quantitative patterns but also like qualitative patterns so want to add anything on figure four just that now if you focus on those choices because that I really didn't I think like that choice plot there you can see that the walks around kind of choices around your data space are a little bit more uh distributed evenly distributed a little bit less random but you start to get I think a more cohesive sampling of the data without entire range this putting things too close together putting selections too close together yeah okay continuing on uh well they set up the question as this raises the question as to how many samples should we collect So within a foraging bout where should one look and then at the kind of like pulling a layer back in the strategy when should you halt looking like if you have already sampled all three records from a data set then unless you had some other reason you could fully stop sampling there but you also what might want to have a softer stopping Criterion that would relate to how much information you're gaining from continuing to sample in that way before like halting and so they include that by having like an exit policy in the state space of foraging possibilities um so how do you resolve that an answer to this question can be drawn from behavioral neuroscience in the so-called exploitation exploration dilemma um and they introduced the notion of sampling costs to help decide that so this method is still going to require parameterization and situation specific modeling of the relative costs versus the relative Information Gain however at least there's an accounting that includes costs into the sampling equation to give any possibility of exiting because if no costs are provided for sampling then the model might just converge and continue to eek out very small amounts of variance explained um if it doesn't explicitly have that stop option so they take the policy uh Vector the the list of locations that can be sampled from and adds a zero element which reflects the information gained if we were to stop sampling and then there's a preference over those observations Express in the C Vector preferences and this brings in the information seeking and the cost of vers of imperatives into the same objective function in 11 anything to add on 11 yeah eventually the idea is that it just gets to a point where you're no longer whatever you set your kind of stopping like energy to be um kind of you're breaking energy eventually it's just going to get to a point where the model just says Hey I've reached what I can you've set this you're not gaining any anything beyond this point we can just stop at this point which is nice since in the random selection case there not necessarily a stopping parameter as Daniel mentioned you could continue to get eek out very very small marginal changes um but you're not going to gain anything else and so you're just spinning your wheels for no reason so this is a very elegant way of saying hey I've reached kind of an inflection point of data gain I'm done so figure five they're continuing in this genre of 345 and now they've added in to the policy decision which which has an upstream dependency on the data that's the active policy Edge they add in this uh cost to sampling so we can explore more however it now includes not just the Information Gain driven choices within the trial But it includes a a specific probabilistic but decisive stopping point for that trial as parameterized by how sensitive it is to Information Gain and preference so this is one of the most interesting parts and and discussions in the paper they they ask it out loud a reasonable question to ask at this stage is why bother with the full information seeking objective and basically how does this differ from Maximum entropy sampling and um let's look forward to the authors or other guests but here's just a few notes on this because I think it'll be a great place to explore what it really means to do uh statistical and physical modeling on cognitive systems they directly contrast maximum entropy sampling and their whole Information Gain uh family against each other and then the rebuttal is in figure six so just to show figure six for a second the measurement noise increases in variance from the center of the function domain so the the the variability profile of the function is nonuniform this me this means the amount of unresolvable uncertainty is heterogenous through the domain of potential sampl so I in some kind of ways of thinking about what they're really getting at and just putting this out as a a speculation or starting point for for this key technical point so if there were a case where the latent states were equivariant they had IID variability profiles then sampling the most variable sensory data is the most informative like if you're taking a picture of a solid black image then sampling from the noisy pixels is going to potentially provide more information gain you're reducing your uncertainty more about something you might be overfitting but you can select as a heris wanting to sample from where variability is high at just kind of a first past layer however as we start to think about richer or more specified statistical patterns generative models there become dependencies that are sparse but important amongst all different kinds of things so things that are variable from a sensory perspective provide High Information Gain potentially to one part of a generative model like um a screen and static but then other events might be less variable from a sensory perspective Ive but smaller differences even in that variable relate to some other component of uncertainty resolution from some other component of the the model like those are going to be the cases where cognitive modeling does differ from just dispersed decision making however they're both going to result in dispersed decisionmaking profiles like looking at the choices in um the figures but the choices to sample from the less ambiguous parts of the actual distribution that leads to a much narrower policy path in this cognitive control setting versus in a variability sampling where it would go for the areas that were just more variable but not necessarily providing more information question mark add on this with the maximum entropy or anything and I would even highlight um kind of on the next slide effectively what it is doing is accepting that you're not going to gain a lot of resolution in these highly variable regions and so you don't really have to sample into those deeply because you've accepted that it is variable it is not something it is inherently variable in the data we're not going to gain a a lot of information from these regions um and I it's highlighted in blue down there and I think that's one of the big highlight notes of this figure is there's less Information Gain available in these highly a variable regions and that's something that makes this method more robust and Powerful um when you're dealing with some of these non uniform variable data yeah awesome and then the the um street light effect is brought in there so the avoidance of sampling in ambiguous locations is sometime referred to as a streetlight effect the tendency to search where data are generated in a minimally ambiguous way I.E under Street Lamp compared to searching Elsewhere on a darken street so I made some GPT 40 images some fun street light and on one hand there's kind of this sense of like is it constraining to look under only the street light isn't that kind of absurd and then there's the joke about how what the person's looking for is elsewhere but they're still searching under the street light but they're looking for something they they know is elsewhere so that's the kind of tragic element of it then there's this limited element however there's also this realistic element which is like well are you supposed to search where you can't sense or outside of where you are at that moment so how could you you know say that that wasn't just and and then this paper is more framing it as just a general condition of perception like you're in your tactile street light that is the part you can see at all you can have latent modeling of any and other things but if it's not grounded in some way to a measurement made in a street light under the metaphor where the light allows for observation then you you're not connected to data unless you're connected to that street light so that's just a very interesting kind of topic and and reference that the authors use what do you think absolutely I mean it kind of boils down to you can't know what you don't know or you can't observe you know if you can only observe what's underneath the street light then you can't really know what else is outside of there and so your inference necessarily should be constrained to what you are able to actually observe you can't observe the unknown and so not necessarily in this case um because you don't even know if even exists that you have no data to confirm or to refute it all right section five Dynamic processes so in that previous example there was a data selection challenge whether it was approached from the flat fixed prior or all these other kind of subsequent variants with the adaptivity Andor with the cost now there's going to be a time element brought into the underlying generative model we'll just go quickly here because that's the big point they take the static distribution that was sampled from and now give the underlying process also variability through time so this is like a very SPM brain Laten State causal modeling type set yeah anything you want to say on that before we go in oh no go ahead okay okay so they consider processes that evolve in time equation 12 can be interpreted similarly to equation 8 in which the expectation of the data is treated as a function approximation which now includes a Time AR so here was eight expectation of the data given late and state parameterization and policy equals so on and then here there is data also being a function of parameterization and policy and then also bringing in an element with a subscript tow for time uh then you mentioned in your big questions the different approaches that they raise here with the three ways to bring temporalities into a model so let's definitely talk about that but just to show their images seven and eight are the pair for this dynamical section so figure seven shows a graphical representation of the matrices involved in generating our data and the inferences obtained after sampling so here it is sampling from a Time variance function and then figure eight goes into more detail and notes predictions based upon current data can be used to inform predictions about nearby spatial locations and to predict and post dict the values of the function at different points in time so just like you could have a 2d plane grayscale and infer the location of the street light by pursuing like a gradient up the light and then there would be this optimal sampling like if you just got one observation you would want to sample on a line that was orthagonal to the one that you couldn't resolve lots of ways to think about this sequential prediction but now the underlying landscape also changes so there's some temporal Dynamics and then that can be fit with all these different time series models and autocorrelation and so on however that's specified statistically in the generative model but this section just shows however you do make a statistical model for time it's basically going to be the same thing where information is going to be drawn from a distribution and now time is a variable in that distribution uh they right in this in the previous section we have demonstrated the way in which smarter optimal sampling may be used to select data in a manner that balances the cost of sampling or performing further experiments against the information gained from those samples or experiments each of these examples has relied upon relatively simple and analytically comfortable linear gussian systems next we address active sampling in a situation where analytical Solutions are no longer possible so to highlight the key formalisms that they're working with in that kind of background section uh or setup section they kept one thing constant which was that the the generative model the generative process or however it's considered with the family of equations that the agent is inferring and tracking hidden states with and that being the same as the actual family of equations that's generating the function of observations and here that is relaxed so that opens it up to all empirical settings where you can just say right off the bat we do not have access to the generative model of those data so we're making a map statistical map with all the associated trade-offs and statuses of like that genetic data or that trans cryptomic data all those different kinds of data sets starting from a position where it's going to have to be statistically approximated and it isn't going to be based unless explicitly otherwise on actual knowledge about the causal elements of the system any any thoughts on that well in something else that they noted in the paper by adding this time element when they're actually going through the time series the model itself will will preferentially select different data beyond what it just recently selected so time point one it selects X and Y data time point two it might select l and m data so it actually will go through and select different types of data and it'll take a little bit of time um what the time is can be variable but it takes a little bit of time before it revisits some of that previous data um at a diff at a previous time so by this you kind of have a lighting window of data that you're selecting over different time periods yeah all right that's all going to come to play in this clinical trial which is the big final contribution section of the paper in our final example we demonstrate the potential utility of the ideas outlined above in the context of a more concrete example so they model the statistical setting here as an Adaptive basian clinical intervention methodology experiment for example the kind that was done during the 2014 West African Ebola outbreak the active sampling approach advocated in this paper offers two main opportunities to augment adaptive trial designs first it allows us to adapt the design to maximize the information we obtain about treatment efficacy so that's the pure sensemaking information gained learning sampling from where it's informative not from where like we habitually or prefer to look and then second to to balance and bring together that information gain with costs and that was brought in with the cost of the sampling section which was done in this paper by adding the stop policy option which can be probabilistically selected and then as other sampling locations become less informative or or if somebody was just sampled and you know that there's a slow Decay through time then on that subject the stop policy cost would outweigh the information gained from an experiment and this is also I think will be a very interesting discussion this blows the line between clinical trial and public health intervention and can be seen as analogous to animal behavior that is never fully exploitative or explorative but is a balance between the too so how do we think about that in terms of biomedical and health security and all these different topics and any thoughts on this before we go into the formalism of the clinical trial just like about clinical trials or anything yeah and I think that that's going to be like that last point there is going to be a big one going forward of like how do you balance benefits to the patient benefits to your trial benefits to um essentially the company like there's a lot of different benefits and costs that you have to weigh into this and so these models are going to get very complicated um when you start to distill this into something especially with health related um so it'll be very interesting to see how this evolves okay so here's how they do it our setup is as follows for each new cohort of participants we decide upon the randomization ratio to adopt that's the orange subscript R of policy so this is policy on a randomization ratio there's three options so this is a discret but linearly ranked not fully categorical policy decision where 1/2 would be the 50/50 sampling between the two groups whereas you know a priori that sampling in a skewed ratio is going to be less informative like if you sampled only from one you would obviously be maximally uninformed about the other however what's going to end up being reflected in the policy decision to shift to a 1/3 or a 2/3 which is focusing observations on one branch of a study more than the other is going to focus on the explicit quantitative preference for observations of survival so that's going to be very interesting to see see how the time variable which relates to the experimental design but by way of modeling the death curves of the participants and how different preferences for complimentary processes of reducing uncertainty about the treatment specific death curves and not preferring to see death observations because that would introduce the pragmatic imperative to measure low survival experiments so there's a lot of complexity in there from the public health side also in this very simple and interpretable way that like this is like a basian light switch with 50/50 information seeking mode or tilt it one way or the other to bias observations whereas if no information had to be resolved then the policy selection would Orient towards observing long survival whereas if that was somehow changed then it would have to be adaptively sampled on the Fly and changing these ratios and all that what do you what do you think about this yeah and what we're gonna kind of get into is um especially with these sorts of Health decisions you want people to survive like that's your that's your primary goal in a lot of these you want to see an effect you want to see a positive effect of your treatment um one way or the other you know if it's the placebo that's the positive or it's the actual treat treatment that's a positive you want people to survive so this is kind of getting into that ethics of making sure that when you design these things that you're doing the maximum good to your participants um who you know may not have you know much hope to sand on um during some of these crises or epidemics or whatever they are experiencing at the time um so you want to design this in such a way that you know you keep them the patients in mind that is the whole point of this and so by having a basian kind of preference and bias to keeping the patient alive and the best outcome you're maximizing how the patient's outcome in the patient's life thanks for adding that another point to make this is from figure nine that's going to come up but it really highlights how sparse and few and interpr able the basian graphical formalism is and message passing which a lot of the equations describe and the discussion about RX and fur touched upon message passing gives procedural ways to implement this in computational systems because it's sometimes hard to go from the Simplicity of like this graphical model to fitting it iteratively on complex data sets but it's pretty clear to see how different variables are up stream or Downstream of other variables and also how the time uh sampling can be shown to be which is Upstream of data sampled as these other factors are but it has a separable interpretable calculable epistemic value that doesn't have a certain kind of connection to randomization ratio for example so being able to have explicit statistical calc calculations and directedness is where the follow-up time doesn't influence the treatment group ratio or the randomization ratio or other processes gives a type of interpretability that the generative model gives us the equations for and then the pragmatic challenges are about actually implementing that and then even if the computational component were totally addressed and abstracted away that would basically Center these broader questions which I think the health examples are great like jumping off point4 yeah and uh you have probably recalled from all the other different uh figures despite how simple this figure is the other figures the the plots were very basic the models themselves like you just had the three nodes you know converging on the Y so despite how simple this looks you are adding more complexity to these um to these systems and the more complexity that you add the harder it is the more computationally intensive it is and so this is that question of how big can you go you know how how many nodes can you add how many parameters can you add how much complexity can you add to the system before it starts to break down or not perform as well as you would hope yeah so other than bringing in that randomization ratio kind of expression of preference this model differs from the prior one in that it's defined that the kind of cognitive map is not the territory they're different families so that's what motivates this um approximation approach so this is a simple displacement where still it's a trackable problem as they'll unfold however the simulation family chosen for the for like the approximation basically the approximation could apply to any data set but it might be woefully inadequate like it might fit only one component of it so that's Again part of the interesting question is like how similar does the statistical model have to be or what information does it really bring in and how to to model or work with an empirical side um but just on a more General statistical level uh equations 156 17 describe some of the technical details of the incremental optimiz ation gradient scheme the Newton optimization variational loss we'll talk to Thomas at all figure N9 is displaying the kind of before picture for the randomized control trial so here's where that graphical model is that was shown earlier and then here are these two groups and their survival through time and different sampling uh choices that are made then just to to jump to figure 10 has the same layout as figure 9 but now using the expected Information Gain from equation 18 to guide sampling of data so this is just to show the impact of that active data sampling and then we'll drop back to the equation uh there are some notable differences between the choices made in figure 10 compared with 9 9 choices 10 uh the most obvious of the is that the followup times selected have been moved later once optimal sampling is employed this makes intuitive sense as a later follow-up time is informative about the survival probabilities at all prior times whereas an earlier follow-up time is not informative about survival probabilities at later time um where it gets in the final uh simulation brings in the random sampling plus the preference element here's where the Symmetry is broken to also want the measurement of survival as more likely than death which is how the preferences are specified in active inference um and then the policy switch is reflected in this like um part where the observations are shifted later because there's Le there's less than a threshold of information to gain by having them earlier and then they uh even if there is equal variance I'm not exactly sure we can ask between the two branches there's uh an over sampling for the group with a higher survival which in this case was the placebo group so anything to add on this this this is the the like the Crux of the whole making sure that you optimize you know the patients's outcome on this because the treatments and this scenario were not um were not beneficial they're actually harmful and so throughout the course of the study this by utilizing this model you actually randomized more people into the placebo group which caused a greater survival of these uh individuals and so you're you can already see the effect that this sort of methodology has on clinical trials because you're optimizing the outcome and I think that is exactly what you want to do in these Health decisions in these trials in these things that impact human health uh or Humanity in general you want to optimize the outcome uh and you know in this way you're actually reducing the overall harm to patients yeah interesting um here's the specification for the information gain so uh bringing in the the form of the messages required for equation three now with all these extra components that have been added in with the time variability demographic and the sampling they write out some of the technical details for the approximations in the variational lloss and then some aspects about those models which we can ask about but figure 11 basically shows the big change which is that uh as you go from having a a flat sampling distribution across time and across treatment groups you can actually do better than that basically by choosing a sampling regime that makes sense given the costs of sampling so that's just very interesting because it it really does look like given the the possibility for these two lines to diverge their Divergence would be largest later on whereas if you could only schedule like one check for every person if it was something that was expected to happen later in life then sampling all the young wouldn't even make sense so then one approach is like flat sampling but that is kind of sometimes erroneously called uh like unbiased or or uninformative but it is very informative and then this is pointing towards how there can be better sampling than just trying to go flat across the entire late and state estimate if there are priors relating to something they can be leveraged as part of the probabilistic sampling and adapted to the data set at the in the end however for picking prior families for the active data selection that's a big question about how how much it will change how the algorithms work so I guess that kind of takes us to the uh discussion the paper's Focus has been on illustrating how we might make use of information seeking objectives augmented with costs which gave kind of the exit Criterion or preferences which gives the biased pragmatic part of data selection to choose the best data to optimize our inferences and they highlight that the maximum entropy would yield identical results in several of our examples so that'll be interesting like what were the examples where maximum entropy and the Information Gain are identical and then what are the real world or the statistical settings when the variance around predicted outcomes is in homogeneous how does the full cognitive epistemic modelbased objective do differently than the max ENT distribution dispersal kind of null hypothesis any thoughts on this I think you've captured it very well okay um then there are several technical points worth considering for how we might Advance the concepts reviewed in this paper so let's talk about each of these one refinement of the active selection process two empirical eval ation of active versus alternative sampling methods and three identifying the appropriate cost functions so we'll talk about those coming up um conclusion here's the entire conclusion the key ideas involved in appeal to fobal like sampling of small portions of the total available data to minimize computational cost that's a very cool way to put it and it highlights that kind of like sequential scanning but also opens up some very exciting directions about how efficient that could be for some but not other kinds of problems and how those problems could be identified or those patterns could be filtered for to where different kinds of cating models would be adaptive or not so like these are all fun discussions we'll have um and then they kind of brought all the theoretical components together at the end with the bay adoptive clinical trial with the costs of sampling uh constraints on sampling and also the preference for survival so what are your overall thoughts or what are you excited about for the ones to come I'm excited to kind of see I mean this is a fairly recent paper I'm excited to see kind of where they have gone since this paper was published you know they had a number of kind of next directions I would love to see what of those dire have they've taken what uh they've compared it to other other sampling techniques um this show shows a lot of Promise going forward for very complex and you know ethical uh situations or situations where ethics are going to be a huge component so kind of where that is what they're going into and kind of where they see you know further improvements I still kind of want to know what would happen or what of these other time metrics um or what other situations these time metrics uh would or alternative time models would be applicable to or if this really is like the de facto just the way it needs to be done totally totally fair I think that could very well be the case um I would just love to hear exactly you if you did a hidden marov model how would that look you know is is there a benefit of that over the selection that they have um is there does it provide more or less versatility in the models um these are things that are going to be I think very interesting going forward and then um you know how do we like like you noted in the discussion how do you optimize those cost functions what's what's a cost you know you're dealing with clinical trials it's a human life that's a cost time it's a cost there's also just computer type how much you can actually get um how much compute you can get at any given moment of time some of these uh machine learning models that you might want to apply this to are you know select data going into um sometimes takes a long time to train um how are you going to sample data that's going into those models how are you going to continually feed those models appropriate data um going forward so this is a huge broad category of um directions that you can go clinical trials was a a very wonderful uh example of a complex situation that is you know right there applicable to human life um but then you also have just data science in general like how are you going to utilize this to you know going more broad how you going to utilize this just going forward in any data sense data is growing it'll continue to grow it will never really stop growing so it's going to be more and more important going forward to have these methods more broadly used and random nice random really really good um but this holds a lot of promise to being and I would love to just hear their thoughts on where that's going where they see that yeah lot of lot of interesting directions a few things that made me think of one was about search and about relational search Concepts page Rank and everything syntactic semantic new kinds of search algorithms and personalization for search and learning and updating and to what extent like explicit cognitive modeling would change the way that different recommendation algorithms or different kinds of um computer systems would work I I'll read a question um and then any any other questions otherwise this is our our last slide so thank you Christopher um okay Gia maximalist wrote interesting point about biased and unbiased sampling schemes perhaps this points out the fact that unbiased approaches are the wrong thing to strive for in research study design what do you think about that unbiased research in study design um I think there's a time in place for unbiased and I think there's a time in place for bias I think that but you when you accept bias into your model or refute take bias out of your um model you need to understand why you're doing that certain bias you don't want to have you know researcher bias is something that's a huge bias that you want to not have for example um but in certain cases um like in this paper where you actually do want to have a bias um you want to make an intelligent decision note while you're making that decision call it out and then build it into your model that would be my thought yeah that's interesting like there are certain statistical distributions the bias or the constraints on which Define the research study whereas other ones that can have an explicitly strictly negative like data loss or something but then the tradeoffs of how that distribution actually interacts with others can enter into this more complex experimental calculus that relates to like well all these different experimental factors and so the optimal experiment for for different Labs that or different moments for the lab could look extremely different and that's going to be the case there's going to be dispersed Behavior either way but then the question is how is that actually driven in a way that is doing better than drawing from distributions however even that does interestingly well for the right variables and you can mine bias all over the place I bias in data design in experiments is can be very useful um so it'll just be interesting I think it'll be Case by case is the way I see it okay well do you have any last comments uh I think that the main thing here is I'm just very excited to see this paper come out um I would love to see how this is going to evolve over time see if this can be uh applied to different Technologies different areas um I'm really excited just to see where this is going because I think this is just right on the cusp of what's needed awesome thank you okay we will look forward to it thank you see you all right thanks guys for