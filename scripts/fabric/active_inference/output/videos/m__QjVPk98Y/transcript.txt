hello and welcome everyone this is active inference guest stream 88.1 on September 17th 2024 we're here with hunar Abdul Raman and we'll be discussing what is the limit of our brains there's a fun backstory here maybe we'll go into there will be a presentation followed by a discussion so I'm very much looking forward to it and to reading people's comments and questions too so honard thank you again for joining and to you for any backstory and introduction and for the presentation so thanks again H thank you Daniel for inviting me to this nice stream actually it's the first time uh as I told you before we start to do a live stream uh using this software so I hope the audience will forgive us if there is any upcoming technical problem problems hopefully there will be not uh so thanks a lot for inviting me again my name is hun I have a PhD in Neuroscience uh I spent many many years trying to learn how our brain works using functional MRI EEG so I did my PhD at from I I get my PhD from the Cambridge University uh and uh and we we will be talking a bit about what I did in my PhD and how I try to link my the concepts that I learn about brain with with the outside world with with with other Concepts like the free energy so I'm actually a newcomer to the free energy principle I hope that people with technical background forgive us if I have any technical errors but hopefully maybe we will I I'll try to learn and share my insights about what I have discovered from my searching in the past few years so uh is it can you see the slides if I start great so uh the topic is actually about what's the limit of our brain and I will try to uh talk about two two concepts I I I'll talky about some few Concepts and later on we will link them all together so first I'll try to talk about the brain as a predictive machine usually the predictive coding account then I will try to use into the free energy principles and uh and then later on I will try to talk about what makes prediction difficult I will talk about extrinsic factors so even if I have if we have the best learning machine the best machine learning algorithm or even if our brain is perfect in learning there are still a lot of uh difficulties uh basically because of computational irreducibility principle which I will be talking more about it in the upcoming slides so I will try to I would love to start with repetition suppression is a well-known Concept in Neuroscience so uh if if somebody wants to go into the details with repetition suppression I will recommend to you uh this article by my PhD supervisor R Hansen uh but it's a bit difficult to wrap your hand around the results so I I'll try to make it easy basically what repetition suppression means uh the activity that we record from our brains whether using EEG fmri or uh single cell recordings is the for for example if you see a sequence of pictures of elephants and then later on you will see something surprising or novel like the kangaro image here the activity of our brain increases increases however when we when you see repetitions of the same image again like the Kang here the activity decreases that's what we call a repetition separation if you repeat something the activity of your brain your your brain will not be responding in the same way it responded the first time then you will see something new like this beer here uh because it's novel The activity of of your brain increases again so so this repetition suppression is not only for repetition it sometimes we call it expectation suppression so so even if something is not repeated but not expected the activity of your brain increases but if you expect something so during it's usually repetition and expectation are synonymous if something repeats a lot it will be expected if something is novel it's unexpected so these results you will be finding in whether repetition studies or uh expectation studies they will tell you if you see something unexpected or novel The recordings of your brain increases if something become expected or repeated the recordings decrease so that's the repetition suppression now uh during my PhD we we uh saw a a very interesting paper titled Les is more expectations sharpens representations in the primary cortex so so normally a neuroscientist will be interesting why this happens why repetition sepration is there so this paper uh proposed a new idea which actually uh a bit surprising for us so the paper tested these are grating orientations uh the subject will see different orientations sometimes it's expected sometimes it's not expected so the results they found is that the activity of the brain decreases when something is expected or so this was expectation study not repetition study but same usually the results will be similar so the activity decreases as you see here uh I I you don't see my mouse can you see my my curser oh okay so the activity decreases however for classification uh they they tested classification accuracy so so they have like two orientations they so if you repeat something if you use machine learning to classify between orientations in the repetition the class ification accuracy is more so let me see uh okay so during uh this is the classification the the the bottom panel is about the classification accuracy so as you see in the repetition the classification accuracy increases and they their explanation was that because sharpening happens so I will give you an uh uh an illustration so this is not the exact experiment but this uh registration so for example here you see the number five if you repeat that basically it will become sharper I mean the the neurons that's the concept that are not directly representing number five will be suppressed so when you repeat something or when something become expected the non-interested activity will become suppressed so that's their explanation basically it's sharpening something the image will become sharper uh I think this this is intuitive explanation uh however we uh so during my PhD we did have a lot of data set about repetition so two different data sets we have one data set was pictures of faces versus scrumbled faces were shown to the subjects so you see here two faces similar repeated and then you see here two scrum faces repeated we also have the data for grings orientations it's similar we do have either repetitions or novel uh so what we found in our uh results is saying the repetition the activity decreases we saw but uh for the phase data set we saw that even the classification accuracy also decreases so it means like when you repeat something uh the brain activity decreases but for the greatting we all we saw that the classification increases so the same result as the previous Group which I talked about they found they they they explain that as sharpening so how can we explain this results because for the grating data set we see the classification accuracy increases so we can say oh it's sharpening but now for the faces the classification accuracy decreases so what is that uh so we thought like it will be very very difficult without simulations just uh just uh explain the data with our minds intuition doesn't work to be quite honest without simulation so the reason because functional MRI is uh even though it's high resolution it's still very very low each pix each boxel here represents the activity of millions of neurons AAG together so so basically when we are try saying that uh sharpening it means that non interested neurons will become less active we are talking about the aage activity of many many many neurons and it will be very very difficult to intuition about that without simulation so so this representation will tell you like for example uh here we we are talking about uh different uh uh representations of the data it will be very very difficult to uh to to conceptualize what happens really in the underlying uh the underlying mechanism uh so what we proposed was we thought like maybe classification accuracy also decreases for local scaling or local uh so so what people think uh you see here in the uh first panel so I just I'm just wondering where can can you see the mouse when I am moving it yeah it's small but we can see it I'll I'll also go with my mouse too because I have two screens to be quite honest I I mean which screen you see the mouse moving so that yeah we see the mouse we see the mouse on P1 uniform oh okay okay so so this screen okay I I just okay great so so five here H if you repeat the five people usually think that Separation Will happens uniformly so you can see the five suppressed with all the videos so sharpening will tell you no that the suppression will not happen re uniformly it only happens with the non interested neurons or neurons that doesn't represent five but we say that even if neurons for example the neurons that represent five even we if we selectively suppress those neurons like in the bottom panel we may still find increase in classification accuracy depending on how many voxels or we we suppressed so basically this was our conceptual idea before simulations so how do we simulate data I mean how do we go from the neural activity to the fun MRI because the simulation is kind of difficult because we are trying to express neural activity in the functional MRI so one idea is for example this is from neural activity studies from a single neuron uh let's say this neuron is very active uh for orientation if if the orientation is 90 degree so you see a lot of spikes here and and the if you if you represent that with a tuning curve you will see that it will have maximum response when the orientation is at 19 but but the response of the neuron will be less if you go because we will say this neuron is very selective to the orientation 19 so the way we simulated that we we simulated that using orientation curves so let's say this orientation curve is uh is selected to the horizontal uh uh orientation uh but it's less selective to to the orientations what sharpening means it means it becomes sharper when when you repeat that the neuron will be more selective to the horizontal selum so this is less sharpening this is more sharpening so that's how we try we are trying to simulate that now on the other hand scaling or dampening it means like the the activity will be decreased the activity of the neuron will be increased for for the horizontal stimulate now we we have a lot of neurons not one neuron so this was only a representation for one neuron but we have a lot of neurons some neurons are responding to the orientation 19 some neurons are responding to or to the horizontal orientation and some in between and there is overlapping and when we want to simulate a voxel we usually sum this line the activities on the sline uh so I I I don't know if it's is clear or not the the the procedure that we are trying to do so uh hope you interrupt me if something is unclear so when we sum the activities we will have a representation for the activity of a voxel now uh in this case we talked about sharpening and uh scaling but we have we may have a Global Effect and a Global Effect means everything will be suppressed everything so so this is the global effect the local effect it means know selectively a part of uh neurons will be suppressed so this is similar to the sharpening uh we call it remote effect it means that the neuron that responds to the horizontal uh stimuli it won't be suppressed but the neurons that respond to other orientations they will be sup according to their distance so this is a parameter that we can find to and local suppression it means the opposite the neuron that is selected to the horizontal stimul it will be suppressed so you see there are many ways that we can stimulate the the repetition suppression so we identified six ways to to represent repetition suppression either we have Global so the red one represents the after repetition what happens to the neural tuni curves after repetition so either the global everything is suppressed or everything is sharpened become narrower or we we have local the the stimulus of Interest the effect will be more concentrated on the stimulus of Interest or we have remote the effect will be more concentrated on the neurons that are far away from the stimulus of Interest so for the completion we actually examined six other models we call them shifting models but they are not important because we don't think our brain will behave like that but but just for completeness so so for those who want to do a mathematical modeling it's just like for here G is the tuning curve which is represented by X and mu which is the mean of the tunic curve and sigma which is how how much narrow is the tunic curve and then we multiply it by a factor which is C that's the suppressing Factor so so in local scaling we suppress the tuni C in in in sharpening models we suppress the uh the sigma or the how much narrow is and then in shifting models we we shift the tunic C so for more technical details you can actually go to the to our paper and see more details about how did we simulate that uh uh and as I said we have two data sets the phase data set and the grating data set so what we want we want to see if our Sim if we can use our simulations to to match uh our findings uh and actually using functional MRI we actually identified some other features we didn't only use uh repetition separation and uh classification we identified uh six more uh data features and we want to see if we can actually use the simulations to uh explain that and the results which we found was very very interesting so this green uh circles it means that that specific model so remember we we We examined 12 models in total 12 different models so if it is green it means this model can explain this functional MRI feature if it's red it means it can't explain so for Global scaling you can see it can explain a lot of features but except BC which uh I didn't have time to these are functional MRI features you can see this is the data and we are trying to fit it uh so the interesting thing is you only see local model local scaling can actually explain all the features so you don't see any red circles here for both data sets so it can qualitatively explain all the features that we saw in our data all the other models they they can individually they can explain individual features for example here sharpening model can can uh explain uh repetition separation can explain within correlations can explain between correlation but it can't explain for example the features of sharpening in our phase data set so the short story long is as as the long story short story we find that local scaling best represent our uh the findings of our data so the the basically the local scaling it means that the Bas model is the model that predict when we repeat the neuron that uh that are selective to that feature it will be suppressed the most not Global and not sharpening the the suppression of the neuron that so basically what that means if you see a horizontal orientation the neurons that are specific to this uh horizontal orientation they will be suppressed more the more selectivity to that they will be more suppressed the there are reasons we like the results like that so basically later on the paper which we actually uh introduced later they did similar uh simulation to us and they actually found similar conclusions that uh these model this neuron is uh this model is based explains the our data set so the the reason we like uh local failing or dampening uh it it's become it's because very parsimonious it can be explained easily without like instigating complicated explanation so basically it just means that AAP synaptic fatigue so when you when you stimulate a neuron when a neuron is stimulated it it will get tired and then it will be more suppressed when you repeat something so this is a parous explanation and the second reason why we like this result because now trying to connect it with predictive coding literature and with the free energy principle but first with the predictive coding literature we think this result is more in line with web because you see in in predictive coding literature you usually see this image Al lot you will say oh you have a a stimuli and then you have a prediction the lower upper even of your brain try to predict and there will be an error and you have a prediction error so the question is that what this prediction error represents we think that these results will tell us that the prediction error is the Unexplained data so it's nowhere says that the prediction error is the noise it's usually the non explained stimuli so the part that you can't explain and that we think is actually more in line with with the suppression with the with this model I will actually come back to this uh later uh but but uh first I want to talk about so so we established that our brain is a prediction machine and and the results in our functional MRI actually supports that our brain seemingly it it's not interested in expected stimulate because it has predicted that our brain trying to predict the nonexpected that's why more activity is being exploited for novel or non explained uh stimuli so what's the enemy of prediction so if our brain is a prediction machine what makes uh what's what are the obstacles in front of our the ability or our brain to predict things so I'll will tell you a story that I faced I I'm usually interested train MRI at some point of my of my life I was trying to train a neuron Network to predict mandal bradet and the reason why I thought mandal bradet is more interesting than language predictions predicting the next token because from Mandel Mandel br you actually know the ground truth the ground truth is actually if you copy this JavaScript line into a JavaScript it will produce a mandal bro it's very very easy it's few lines of Goode just one equation it will produce and then when you change these numbers you can zoom in to this mandal bradet so for mandal bradet I know actually what's the ground truth it's not like the language I for language I don't know what's the best ground to it is is my sentence is the best is my is your sentence which phrasing is the ground truth we so so that it's very difficult to identify the ground truth in language models but for Mandel bro we know what's the ground truth and that's why I was interested to train neural networks to predict Mandel bro said uh so the surprising thing for me I thought this will be easy because Mandel bro has a lot of regularities a lot of uh places where it repeats so I thought this will be easy task but I was shocked I mean even when I used a neural network uh with very very big size to predict different parts of so you can train a neural network to do to predict a specific part that's easy but when you want to generalize it will be very difficult the reason is because I was underestimating melro there are it's true that there are a lot of regularities but the more you zoom in there are there will be always new features it's mindblowing how this simple line of precursor they will always present you with something new that your model or the newal network no matter how bit how how good is trained it can't predict any anything so so so that the puzzle for me actually we know that record neuron Network are twoing complete so it is possible that you can train a neural network to simulate the code but in that case the neuron network will not help you in prediction it will just simulate the same code for you the the the main hope that we have with neural network is that we predict ahead of time we predict two steps ahead of time or three steps ahead of time not not just recursively uh predict One Step because that's what uh which I will came later on on computational iru of that uh so so before coming to computational irreducibility so this is my first time when I saw there is a challenge in prediction it's it's it's it's very difficult uh to predict these intricate features NeverEnding emergent patterns so one one of the reasons this is phrased by Steven walram is the principle of computational equivalence so basically if you manage to train a recurrent neural network to simulate the same that that predict that that actually generate mental BR it means that in the underlying Le at the underlying level the they are doing the same thing they are doing the same computation so you basically according to this principle you cannot simulate a rule with another rule that are more efficient that basically if you if you simulate them at their most basic level so you can simulate rule a with rule B and then rule B can actually predict two steps ahead of rule B that's not possible so this may be difficult to understand but the way Stephen Wolfram did it he explained that in his T talk so uh he actually so basically that in in his T talk he was like I'm paraphrasing he was like saying okay you have this simple rule so this is just like a mandal br rule you you just gave this rule to computer and then it will prod use for you a pattern these are stepbystep patterns and then it will tell you if if you could is it is it possible to predict ahead of time just from knowing the rule I mean you know the rule just just like we know the Theory of Everything can we uh can we actually predict ahead of time without simulating the intermediate steps and I actually don't know if it's true or not but I believe that because Steven Wan have spent like his Decades of his life trying to do this and he says that this is not possible you have to you have to compute all the steps you have to compute all the steps and he even put a price for that uh the reason why I believe computational reducibility principles should be it must be true because it's uh in essence it's similar to two other uh principles godel's incompleteness theorem and the halting prod problem in in spirit if you think more about it they you you will see them that the these are all talking about probably the same phenomena but in different so what I learned is that complexity is easy to generate actually uh it was a very shocking thing for me but I have been simulating these simple rules and then they for a while and I I they always surprise me what they are can produce very simple rules you find in them and you can generate but the problem is it's hard to understand and this is because of um that principle which is was which was formulated by Steven W which is the says computational irreducibility principes so basically let's say we have two systems system one and system two and then system one tries to predict system two so if if system one can predict system two with less computational power then we can say that system 2 is reducible and this system one is analogous to our brain and system two is analogous to the environment on the world which we are trying to to learn about so what stepen w found that he examined so many different rules uh and and the reason why he examined actually cellular automata because of their simplicity so what he found that is each rule are producing unique patterns so uh actually by by looking at these uh patterns you can see what computational equivalence means it just means that you you can you can stimulate for example this uh pattern using another Rule now there are some rules that are faster than itself that's what I mean now there are rules that are T in complete like the rule 0 but even if you manage to initialize the rule number 10 to produce another rule it will not produce it faster I mean yeah you can't use it two steps ahead of time so so some of these rules will be uh trapped into repetition and some of these rules will never be able to predict what comes next and I thought there is another phenomena like that it's the irrational numbers versus rational numbers they are actually similar to that because we have irrational number and their their definition is if you go what the definition they they will never trap into repetition so we have Pi which is a very simple rule it's just the circumference divided by radius it's a very very simple rule if you simulate that rule it will always give you a new pattern a new number and the same for the square root of 2 three so this is amazing I mean I I don't know why I didn't thought about that before Steven wol from talking about SAR automata think because I thought like these are actually have the same amazement so if you have a generative it's just and and actually we usually talk about universality Turing complete universality so they will tell you uh if you have an infinite T and if you have a reader a writer and speciic rules you can compute everything and they will call that tuning complete universality now according to Steven moram he actually revised the what what does it mean by computation universality so so he usually uh explains that in the term of cellular automata but I will try to explain that in in the term of irrational and irrational numbers so it's actually a bit mindblowing but we we we usually don't think about it like that so let's say Pi that's the definition the definition means this rule will never trap inter unlike the rational Ru so the rational numbers if you divide them at some point they will repeat they will repeat they will never give new patterns uh but but irrational numbers so that means if you if you compute Pi for Infinity it is possible that at some point you will find the same pattern that the square represents the square Ro of two so so if you if you compute Pi for Infinity it's possible that you can find a squ of one one one one one but but it will never trap into that rtion at some point it will it will change so so that means in every irrational number you have the other irrational numbers embedded in it it there is no way to say this is not true because if you say this is not true it means that these patterns will be trapped at some point into a cyclic repetition but if they don't trap they will always give you noil and that means so someone can tell you Pi is toing complete why because he says like if you if you if you keep Computing Pi for Infinity at some point you will find that compute my genetics the same sequence that if you represent it as a number I I I you can say this is not true can you I mean do do you have a comment Daniel about oh it's a it's a great connection it just makes me think like within Pi is every possible operating system every possible Note file you could write to yourself so it's like it contains all of these things and also it's a great connection with the computational classes from Wolf exactly exactly because from usually represents rule number 30 it says that oh this rule number 30 you can see all patterns are there so if you go for Infinity I think it's a computational universality is there it's just he just can't formalize and I think it's the same to be quite honest I mean if you go if you say it's it doesn't repeat it means that it even though the rule is very simple Pi is the simplest possible rule it's just the circumference divided by radius it's the simplest possible Rule and and then you have an imaginable sequence patterns so okay this is interesting but this is also problematic because it tells you a prediction with 100% accuracy is impossible possible remember we talked about the super intelligence we said that oh AGI is is actually near but many people will say oh if AGI is near then we will have intelligence ASI artificial super intelligence will be just in the corner about the corner I don't think so because of computational irreducibility it means that AGI will also face the same problems that the problem is you have to compute to be this system you have to you have to have Universe siiz computer that simulate our universe faster and I don't think AI can have that because it lives in the same environment like this so so that it it reaches the same ceiling that we actually reached which means that at the age of unknowledge at the age of uncertainty the AGI will also suffer from uncertainity just like us so H okay so I talked about that that even if we know the rule of everything so I was when I was younger I was always following the physics news because I was very very happy to see if a physicist will find the theory of everything because I thought oh if stepen um if if step Hawking can find the theory of everything that will be the happiest day because it can we can explain but but now I see this is not possible I mean even if you know that even if you put theoretically I thought like this is the difficult part but this is not even the difficult part even if if we say this is easy we have all the atoms the state their velocity their position in our inside our computer or even if we have a a very powerful computer that compute uh that compute and predict the next St it will just produce the next update which is the next p second or whatever is the smallest type update plank level so that means it means to to simulate the to predict the future you have to simulate the future you have to simulate the present past than the universe itself and that's impossible unless we are outside the universe and we have we can somehow simulate everything faster than our universe so okay so how do we how do we do that I mean in the beginning I told I told you that our brain is a prediction machine you know we can predict things so how prediction is possible in this system the only way I can think that prediction is possible is because two things memorization and OB abration the reason why I didn't put memorization before abstraction because memorization is not very without abstraction memorization is not useful because memorization it means if something repeat then if you memorize it later on you just cat that and if something cat that it will be computationally very easy to predict but that will be possible if we if we live in a computationally reducible universe if something repeats memorization will be great but if we live in a computationally irreducible when there is always emergent pattern memorization is doesn't help the reason because you should have infinite size memory to pred to to store all the all the emergent patterns you have to have abstraction with memorization it means just like uh so so remember that previously before AI people store pixels inside the computer just using memorization but what neural networks do does is they memorize but not just using that it will abstract the information before memorization so so so you just don't memorize the data like itself you you have to find a way to find the useful uh so so that's the formal definition I actually gave that to Jack and that's his which I like it actually more than the Wikipedia definition uh is the process of reducing complexity by focusing on main ideas and knowledge specific details so that's the only way that we can beat the comput isal irreducible it's just we pay attention to what matters for our survival so you can see I am trying to actually reconnect back to the active inference so there are many ways to abct there AR many different algorithms but I think the easiest one is uh that's what they usually introduce you in category Theory they just say oh we we just gave a same name to everything because uh so let's say we have Bob Al Jo and if you if want to do statistics or you want to find any any relationship we just need to group things according to their similarity so similarity is actually a very complex topic it's not just easy to say according to similarity but but be with me right now so course graining is actually simpler because course graining you group things according to proximity proximity is easier to Define that similarity you just say if things they have audian distance then specific threshold you just group them so course graining actually used everywhere I'm I'm surprised course graining is not not so much well known but it's it's it's used everywhere another thing which may be more familiar to your group is Mark of blankets I think Mark of blanket is also a more sophisticated way of abstraction uh the reason why micro for for example here you see these notes the parent nodes the children nodes and the partner nodes they are and and eternal nodes so in the mark of blanket become stable you can just treat this as one entity so just just like another way of abstraction so we say anything inside this membrane is just one entity anything inside this house the house is one entity with everything that happens inside I don't care about only when somebody comes outside the house I should care about but when they are inside about I I should just look at the house so my my point is that the stable membranes can abstract things for us uh linear regression is another way to abst information but linear regression is just a more sophisticated way of course graining because we are using a weighted in course grain we just aage uh the nearby information but here uh we we are doing uh weighted regession weighted summation uh so we have neuron Network as well neuron network is the most sophisticated way of obstruction so far uh so so course graining let me just give you a bit about Co grain the importance of Co graining so I mean it's self-explanatory you just aage the nearby pixels or the nearby uh so so what I think about talk about why course draining is important there is a simulation called part particle life simulation I have a video about that a detail B but let me just I don't know why this particle simulation is not more uh familiar among the scientists uh it's it's actually a more interesting extent of the game of life I don't know who invented that but there are old videos seven years ago doing this particle simulations I didn't have the code back then when I wanted to restimulate that so I improvised the code and I was shocked that the reason why I I I just wanted to simulate a primordial soup where you have uh where you have some particles attracting each other so so you can see these few lines of code these few lines of code just represent present particles attracting with to each other according to Newton's law something similar to Newton's law so the the inner loop here is just says if if the distance is this you have an attraction force or a repulsion force uh parameterized by G so so g g parameter actually determines the attraction of repulsion forces so so just a less than a page L of code and and when you have this rule you can simulate this R for example you can specify how green particles attracted to each other and how red particles attracted to so just few lines of code and you will have so many interesting patterns so many interesting patterns so so we we have made a C++ software about that it's available on our GitHub uh so it's it's just amazing how complexity is easy to to generate so you just have these parameters are just attraction and repulsion between different color particles so so you just Define how much red particles attracted to read particles and then you let the simulation run and you will as you find in this so maybe maybe if you are interested I can give you a live demo is it possible is okay oh yeah okay so so so so if you go to the GitHub uh there is actually a link a JavaScript uh let me let me reshare the screen okay so so you can't see the the the the the screen okay so so if you go to the GitHub uh hun 4321 particle life uh and then we have a downloadable version so you can download it and we have an online version a 2d online version so let me just open that 2D online version I hope you can still see it do you see it or should I Y and I'm I'm also pasting it in the chat so people can go to it okay so the interesting thing is so you see I I will just so here are the parameters so so I'm trying to change the parameters but even if you push the random button so here is a random button so this random button will just randomly revisit the attraction rep Force so even even if you push the R button you can still see interesting patterns emerging on the screen so let me Zoom yeah so so I'm I'm now just so you can see I'm just now pushing the random butter and you see cellular things like very very interesting things coming to so so we will come soon to Mark of blankets you'll see that Mark of blanket is very natural it's something when you have local rules that's what car froston usually says when you have local rules there will be always a mark of bran so because we have local rules but if Global so the attraction are repuls rules they have a threshold so you usually say this particle can attract this particle but there is a cold it can't it can't attract very far particles the same power as very nearby particles just like in real life just like the gravity in real life so you can let these systems evolve they will produce but what interests me is even if you push the random buttons the random uh uh this random rul push it and and you will have interesting patterns wow right there just like these chasing chasing around got the so now you see a bit a bit stability now you can see a stability but this stability will not go forever because of computational R sometimes something comes to disturb system so now they have a mark of blanket they live happy they they they have their internal system but at some point you see this okay now the the system is Disturbed so they they they liveed for a period of time they have nice Mark of blanket but there something outside happen don't know that's the uh the halting problem is could you look at this at a given time all the rules you know every single particle State all the rules could you say what the final end point will be or what will happen in a certain number of steps and you might have a heris but you can't know without actually going through the procedure without actually going through with me simulating the system I mean if why if I want to predict the future I have I should have a super computer that is faster than this I should put the initial settings and the superc computer can simulate the system faster than me but but if I am living inside this system I don't have this Leisure to to see the system faster than it so how one other one other interesting piece there which you've brought up a few times with like having a more powerful computer somehow outside the system so as you start to look deeper and deeper into Futures it's almost like the procedure has runtime n like it's just whatever complexity class it is it's just one or X but if you start looking further and further ahead there are more and more adjacent possible so that you actually it's like trying to run up a wall that's getting exponentially steeper because the the faster supercomputer even if it's it's a million times faster but then if it starts looking several time steps ahead each of those time steps have a bigger and bigger adjacent possible So eventually that one millionfold increase gets eaten up pretty fast yes yes yes so so that's why I think this part actually car is this paper that it has primordial suit but he usually I think he uses mlab and then so I mean people nowadays usually use more sophisticated tools M that have nicer visualizations and and you actually couldn't find these interesting pattern if if you do not have a real system so so when I was cing this system it's impossible to find interesting patterns without having a guy a guy system to explore easily in real time uh and that that's what made us discover so many many interesting patterns so now there are other systems that are similar to it actually I think there is a system called lenia which are smoother I think it's also very interesting but the reason why I like that it very naturally connects to mark of blankets and and active energy so so I will actually now go to to what we can actually elist from these systems and how can how can we uh do abstractions and how can we reconnect what we have learned to our findings that I explained in the beginning of the video so let me share reshare my uh uh my screen again uh so I'm I'm sharing the slides again okay so so you can see the slides again yep okay so you saw like like these parameters I found these interesting patterns but somebody can reproduce it if I download the software the C++ one not the online one because the c+1 one is more powerful you can simulate more particles without u i mean the computer can handle it so so you can find amazing amazing patterns just and this just four particles four colored particles I mean you can go five colored particles six colored particles okay so why so my point is how how how course can help us uh in in this case so let's say uh I mean this Buck shape to be quite honest I actually produce this bug shape from from so so so this is also not the pro part the pro part is just for the illustration but this bug which you can see this is from the particle life simulations this is believe it or not this is just from these rules and I accidentally happened to me so green attracts to Green with this power red green attracts red or repuls red I I forget whether the negative is attraction or the positive but but these simple rules of attractions it can produce you this flying shape a bug like flying shape so this is some screenshots uh how how it how it flies around so my point is that let's say this frog is inside this system and it's a predator it wants to predict because without prediction you can't catch this F you can't catch this part but the frog is inside the system according to computational pre it can't simulate the system faster than itself so it can't know the only way it can do is does some some way of abstraction and the easiest abstraction as we say is course graining so if if you do course graining so here I did course graining this is not a simulation it's just illustration to be quite but I think it's tvial to understand so so now the number of particles becomes 70 particles so if the if the brain of the Frog it just samples the the it just do sample all the 600 particles it just samples based on locality I mean local things sample them and then uh in the future I mean repetitively local things will be aggregated together you will have a a CO grained image and this course grain image is very very easier to simulate for the Frog now it deals with 7 particles instead of 600 particles and that's why maybe even if the frog is inside the system it can actually predict the simulation of course it won't be exactly the same simulation because we are simulating a course grained world but it it should it it will be close enough it will be close enough for the FR to survive so so if you do the real simulation the the bug may be go this way and then go this way but if you do the course train simulation inside the brain of the Frog the it may pred a different path but if the path is close enough for the Frog to survive then that's it so this is what we come here into a very interesting conclusion living things like a frog will value accuracy and will value efficiency it values both accuracy and efficiency so you see we we we are closely intuitively coming to the pre energy principle which tells which is tells you you have to minimize surprise and complexity that's what the equation of free energy so so it's the same you you you can say so let let me go actually I I explained that in the video that course graining is a very underrated concept it's it's used in physics in chemistry do you know there is in physics there are so many theories under the name of effective theories they use course graining to explain so many things and usually do you do not see physicists telling people oh we predicted but we used course graining i i s that this is like hiding a different fact because we usually talk about uncertainity principle and things like that okay but you use you use course graining course graining is part of uncertainty so so in this simulation now it's true that we can predict the bug but now we are less certain about the individual particles because we did Co graining but but that was okay for us because the aim of the frog is to predict the whole system not the individual particles so I'm actually surprised why physic usually don't explicit say hey we use for graining so they they used everywh to be quite honest so many theories of physics depend on they they just use all they even only when you go to the details you'll find them they have course grain the system before doing the simulations whether it's a flute system a particle system anything well well I think everything is course grain don't think we can measure anything precisely so course graining is there whether we like it or not okay Mark of blankets I think Mark of blankets is well explained car FR have many many videos about a mark of blankets so Mark of blankets is a different way uh of abstracting information so the nodes that are surrounding let's say we want to predict X so if we want to predict X exactly we have to know the we have to know the position and the velocity of the particles in the system but according to mark of blanket you don't have to if you know the state of the mark of blanket you only need to simulate the state but the problem is how do we know the state of the mark of blanket we know we need to know the state of their Mark of blanket but how do you know the state of so so that will defeat the purpose it means that we have to simulate the entire system but as I said luckily these Mark of blankets are sparsely connected I mean you you sometimes see uh the world the reason to be quite honest I'm still not sure why why our world is sparsely connected the only reason that comes to my mind is because we have different Force ranges we have nuclear force which is very very short range we have uh electromagnetic force which is wider range we have gravity force and then because there is a speed limit of light if you combine the speed of limit of light and the the range of forces you can have various ranges of forces just like just like in our simulation so just like in our simulation so we can also say that the particle simulation is also sparely connected because we have simulated different ranges of forses that's why close by particles so if they they will arrange sooner to to produce lumps so that's why I think a mark of blankets are possible stable Mark of blankets are POS because of of sparely connected system why sply connected system because of different range forces that's my my explanation for that and this makes prediction easier now the reason why I think this makes prediction easier uh so I will give you this example last example of partic simulation because to be quite honest the reason why I like partical simulation is it gives you intuition about a lot of things so one of the intuitions I usually pull up stepen wolfram's video he usually say oh I understand entropy now I think entropy is the feature of observers because we observers are computationally limited that's why entropy is there I was usually think what the what the hell he's talking about it's a bit so I finally have AA moment when I was trying to understand how entropy works when watching these particle systems so so let's say this was the initial uh set of the before we start the simulation this is all the particles if if somebody sees this system it says this system have half High entropy it's intuitive I mean even if we don't specifically Define what's entropy here it's it this system is all spared around different colors everywhere so if I tell you can you predict what will happen to this particle here at the middle which in circle by the where does this particle go h i mean you don't know I'm sure you don't know the reason you don't know even you have the rule is just your brain cannot cannot simulate all the particles inside your brain are the forces you can't you can't figure out what's the direction of this particle will it go this way this way but if your brain is unlimited power I mean if you can compute all these particles right away there is no uncertainty you can tell me I know this particle will go this direction but the reason you can't tell me because you can't compute all these particles now as the system evolves like you you let the system now we have different entities with different Mark of blankets they are stable so you have chunkers so now your brain can meaningfully course grain so so you can easily course grain you can say oh we have four systems and these four systems they appr everything so now if I tell you can you tell me where this dot goes according to the attraction rules I think now you can say you can say oh this this dot is very close I think it will go down so the entropy in your brain is increased so the the entropy I mean the way that the uncertainity is decreased sorry because now you can predict where this dot will go and the reason you go because now your brain can compute what happens because because your brain chunked course grain all these particles together as one entity that's because of the mark of blanket or because of these stable blankets which which encapsulate the entities you you treat them as one entity and the system is now become more predictable so now you can tell these particles will go downward and uh and you can say this will go from high energy to low energy so so basically you can use these particle systems I actually didn't do that it's in my plan to do actual simulations not just intuition about these systems so this is Gibs free energy in which car pron actually deres from the concept of page in the living beings it just relates entropy with enthalpy so so we know the entropy of systems increase but local entropy because of these local forces local entropy decreases but the entropy overall entropy decreases because particles will go down and then uh the energy as a light will will go into the universe basically these simulations are so simple to capture all the detail but all the details the global entropy either stays same or increase but the local entropy decrease and that's what self-organizing systems like us living beings will try to do they will go to that so so what ceston does is generalize this concept to living beings and uh to be quite honest I don't know the details that he do that but he usually use these sequence langine equations with pullback attractors fuer plank equation M then he comes to the m of blank once it reaches the back of blanket it can connect to the Living World basian world and then and then we have so these partical world can be connected with living world that's what car usually does and the interesting thing it's the same objective so that the high leval equation in which the carg pap uses it just you have a living systems want to reduce surprise and want to reduce complexity and if you remember we told you because of computational irreducibility we want to be efficient and we want to increase the accuracy so we reach the same intuition without driving it just because we have computation we have to be efficient there is no way around that so this part and that's what makes because long time ago I didn't understand what's exactly the difference between fre energy principle and the predictive coding so the main difference is that the Fergy principle also added efficiency it says that we try to predict but we also try to be as efficient as possible as as simple principle way or the least action uh way so it may it tries to reduce the complexity and I think that the the reason why we want to reduce the complexity is because we have comped principle so now we come to active inference because according to active inference there is a trick we can do we can not only predict the system by learning about we can actually be participate in the system so so you either learn from the word uh which I call to bottom up system or Teach the World Teach the World it means you you are trying to change the world so it's just like if you go back to this to this particle it's just like you see so this particle either it attracts the entire system to itself or either the particle goes to the bigger system so we individuals also do that either we are trying to change the community or either we adapt to the community and we usually have to do the the later the majority of us will be just slaves like we will just say we can't change the world usually but I think the analogy is very easy to to see uh so so there are a lot of questions uh so I I usually usually this question comes up if we try to predict the systems why we just don't go to the dark room uh I see I I I also see the answer to this from the computational reducibility principle because computation doesn't let you there will be always emergent factors so locally you can do that as an individual but collectively we can we can do that because the system will always change uh this is analogous another example which I like I don't see it's used why we don't use fascism because fascism actually makes the system predictable everything behaves According to some order uh I mean we can use a less uh inflammatory word than fascism actually actually people do that people to try I mean you can see religion as a way to make everything predictable so if if you follow a community a strict Community they will tell you you should behave that you should do that the holy day will come out so everything will become predictable and that's why these systems sometimes are appealing for people because it it encapsulates the idea but the problem with that again computational res doesn't let you to live that forever there will be you will be trapped at a a local Maxima and that and you you can do that you can live in this predictable system for years for thousand thousands of years but the outside world will always change will always change and at some point these changes will either affect you collectively or individually that's why we have to change so so that's why we have curiosity we want to learn I mean we can never so so according to the simulations that have been done in free energy principle even these particle systems they are actually modeling the outside the reason why they did that so if you if you try to uh follow the activity of these particles they you will see they are correlating with the outside if a change happens in outside you'll see a change happens in the inside so as if the inside of these entities they are trying to model and the reason why they are trying to do if if you see that the mark of blanket just actually just looks like a neural network so it has sensory nodes it have inter internal nodes it has active nodes so it's just like a neural network it's just like how how how it's train so either use evolutionary technique to train it the the some blankets survive some will not survive so we are using evolutionary technique to train it or you can use back propagation or you can use the technique that happens inside our brain it's hian learning although there are lot of announc how how learning happens in our brain but but the thing is same so so nested levels of Mark of blanket you can see it as a nested level of of neural net it's same it's same level of abstraction uh okay so so that's what makes us that's what I'm saying we can beat the computational irreducibility because so all the brains are local they they can't compute the entire system but collectively the the lower brains they abstract the information they don't send the entire information to the upper the higher level brain they abstract it away and they so the the leval brain even though it's computationally very limited it has the same it can actually simulate the system because it's abstracted it's course grain uh so I it's usually a balance between top down bottom up so basically what happens is that the inner levels will be more predictable but the outer ede will always be less predictable or the higher levels will always be and we are I'm usually saying Consciousness lives at the higher level age of uncertainty so we have subconscious everything is predictable like for example if a fire here my hand will go away the the the GL ganglions in our spinal cord will decide even before goes to our brain the decision so predictable things are happens in your subconscious the unpredictable things happens in our conscious uh okay I think uh I think I have tried to explain all the important things that I want to do but but just before finishing the uh I want to just reconnect this concept uh back so so far we are talking about how do we do abstractions we generally the best abstraction as I said we have neural networks and how neural network work using back propagation and how back propagation work we really don't understand even people who who who produce Char they say we can qu the the system for you but we don't know how back propagation will decide how abstractions are fored so I I mean few years ago I came across a algorithm which is which actually uh drives multi linear regression I I thought this is beautiful because it it matches with our predictions with with our simulations very very well the the simulations that I did in the beginning so uh I don't know have you heard about lattice filters lattice filters yeah go go for it though continue yeah so latus filters are actually they used all the way in kman filters and Signal processing filters and I just don't know why they are less famous in the machine Learning Community they are more if if you go to the signal processing Community you will see a lot of talk about Lattis filters and K filter and things like that for me lce filters are actually very very similar to how the brain is depicted how because the predictive coding system will tell you we have predictions and we have prediction errors and they they match very very uh neatly together and these lce filters are very very easily derived so if you have two groups for example uh let's say we want to see which group are more liable to have a blood high blood sugar we have obase group and uh less obesity and usually in scientific tests we have more variations and these variations will affect our results so the best experimental design is to remove these variations uh that that's what we say control design but sometimes you can't do that you can there will be always variations so many multifactorial that you even not aware of it so what you can do that you can do that post H uh so so let's say we here X we we want to predict X these X's using X3 and what what's not predicted is we call them prediction error so the prediction error will go to to the upper levels and then we use the residual errors to predict the the other remaining errors so you do that until you end up with the last uh prediction error which represents this feature in this case obesity this is where you you can actually find the relation with obesity and uh why the factor that you want to test and if you do that squential for a squential data you actually end up deriving the Lattis filter again which which I talked about here so you can you you will drive latus filter and this latus filter is actually very very similar to how a prediction error works and this this way it's similar to what our findings in in our paper when we say the expected stimuli will be suppressed so these L filter will also tell you the same thing it will tell you in multivari linear regation we are trying to predict the stimulate the prediction error which is not predicted it will go to the upper level and then the the outer context will try to predict that and you will go increase the context to predict the remaining errors so I thought this is really an interesting connection but these ltis are not used in machine learning the reason is because mostly they are linear systems there are ways that you can make it nonlinear but they are because they learn very fast they are very very sensitive to noise so if you have a big small noise they will just learn the noise too and that's why that's why I think people in machine Learning System they actually go to uh use optimization methods using back propagation because in back propagation you have a learning rate which you can reduce it that means even if a noise comes it will not affect the entire system so that's why my only explanation why people don't use this method but I like this method because it connects our brain the predictive coding error and it it is very similar to the uh findings that we have in our paper and and I think it connects nicely somehow to to the free energy principle so uh thank you a lot for for for uh listening and I'm here if you have any questions awesome okay well thanks for the awesome and and wide ranging presentation while I crop and get everything back if anyone wants to write a question in the chat go for it and just to kind of begin the discussion I mean could you share a little bit H how how did you get to studying the suppression uh repetition suppression in your PhD then what what Journey has brought you to making the self organizing particles and all the cool YouTube videos oh thank you uh well repetition suppression uh it's my PhD supervisor is actually a very big name in repetition separation so he he have a lot of reviewed uh review papers on repetition suppression and I found this is interesting my beginning PhD I was interested in episodic memory because that was my my Master's Degree uh was about episodic memory uh but but later on I thought there is a very nice connection between repetition suppression and the predictive coding literature uh by then I wasn't aware too much with free energy principle but more aware with prediction predictive coding literature so I thought because there is this connection and and and and it was always surprising to me uh that the phenomena of repetition suppression it just means that when something becomes very expected when when you when you finally predict something your brain will go idle so usually I thought in the beginning it's counterintuitive because usually you think oh if something becomes very predictable you should your brain should be more active uh but but that's interestingly not true your brain is uh is usually what what I think is is more active at the age of uncertainty when when you because because let be honest if you if you see noise it's completely unpredictable but at some point your brain will go idle uninterested so we uh our paper was not about that but I'm sure if there are papers uh it's a you care a you shaped curve so if something is very predictable your brain will be less interested less activity and if something is completely unpredictable again we we are not interested in it so I think the for some reason I think it may be connected to Consciousness I'm not sure about my my studies was not about Consciousness but I think repetition suppression is probably the the closest phenomena that we can objectively examine and it some ways connects because because subjectively uh when something BEC predictable you also feel it's boring and you feel sleepy so so so the objective findings that we see the activity decreases also correlates with the subjective findings that we actually feel and because these are to Connected I think it's probably the closest uh objective phenomena that we can test and somehow we can correlate to Consciousness yeah I mean the example of the just a random pattern that could be intelligently core grained and you go okay frame after frame the core graining of this whole picture is just gray so then the cor graining is unsurprising so then even if the pixel level details are still surprising you've reduced or bounded surprise at the slower or the deeper layer so again that becomes not interesting oh wow that's actually a video so so I I actually didn't thought about it like that but the course graining idea if you combine it it will it will just reconnect back to the more that that's very nice actually I really liked how you connected the core scening with the the Markov blanket a lot of work has connected neural networks and the loss function that's used in training the neural network with the variational free energy and then in the neuroimaging setting core screening like you brought up it's a really simple heris CU it's just spatial proximity you don't need to Cluster things by their functional similarity you just use the anatomy and then it's interesting to think about the Markov blankets as coar graining in a causal space like if you had um 10 10 different uh sub procedures but then you say well one procedure one two and three are like one unit and then that becomes like its own thing but procedure one might be anatomically close to seven but then 1 two and three are causal and so then it's like building these parallel maps from your PhD it was more grounded in the spatial in the temporal and then the Markov blanket abstracts that into a causal but then abstracting away from space and time is where we get patterns and that is how abstraction helps us predict the future exactly oh that this is interesting I think I think I think course braining is just like a door for understanding so many things and I usually I I sometimes interested in physics to be quite even in my high school I was interested in physics I don't have a formal education in physics but I am very very interested and I am very very interested in the phenomenas of uncertainty principle and and Bill phenoma and and I usually I'm afraid to ask physic because they usually get angly is there a relation between course graining and uncertainty they usually tell you no and uncertainty in physics is fundamental they I I don't know whether they maybe there are maybe physicist outside outli physicist like Steven wam or uh some other physicist they they have more deterministic uh uh view of what certainity means or what Randomness means at the lower level but to my experience usually when I go discussing Reddit groups and they will get angry they will say no you don't understand anything about the underlying atoms they will just go random it's just a a true random generator well I I I don't know who will get mad about what but in a way the movement from Quantum scale physics to classical physics is like core scening it's like saying well if you go to one atom it might be difficult to know what Vector it's going to move in next even if you knew the temperature maybe that's near the limits of of um a true ontological uncertainty but then if you have a ball moving through space you can get a really good prediction on a slower larger thing and then that's classical mechanics where you don't have the same uncertainty you can just assume this basically infinite Precision but then Quantum is where you can't assume infinite precision and people whether that's ontologically how it is at a certain scale or whether that's an artifact of our interfacing with small things but regardless things that are about as big as we are it's kind of like these are like pebbles that are about as big as we can pick up those are the things that we can think about that's what makes sense to us and then those are the classics and then things that are um more challenging to abstract or predict they're nonsensical or they're they're outside of our our scope of understanding yes um but but from earlier H how did you get from the repetition suppression to to working on what you're doing now and and making cool videos uh actually uh particle making videos as I told you before I actually learn more when I make a video about a topic so I call that Active Learning uh there are so many topics that in my life I want to try learning it's just like because I see many intelligent people they say oh this this topic is very important this topic is so right now in in current situation I trying to learn Mona and I I I look at many videos I don't know what the hell they are talking about but because so many intelligent people they say oh monat is a very interesting way of abstraction in programming just like I have to learn that and at some point I think when I fail understanding it I say oh if I have if I if I try to make a video on it I will finally understand it so usually making videos on something it actually pushes you to understand it I don't know why this is true but I find it very interesting because our brain course gains a lot of information and self attention it always tells you this is not interesting this is not interesting it has a lot of a big selectivity so this part of selectivity tells you which direction you go so when you make a video on something it will actually now say okay now I I know this is important so it gives you it g it makes your attention on on the topic without that it will always something tells you to procrastinate and not not pay attention to it so the reason why I make videos is just interest to be quite honest I make videos when there is some idea and I like to represent I I like to learn about it and I like to represent that in a video uh so one of the these ideas which I like local Maxima idea I I find it it fascinating and actually it links back to computational irreducibly in some way because local Maxima tells you that because we are limited because our brain limited we we every now and then we will be trapped on a local Maxima and that will be very difficult when we tra on a local that's it we we have to become conservatives there is no way around either you risk something some people risk their lives go outside otherwise local Maxima the direction will be lost when when you when you are trapped on so that idea was very interesting and particle simulations I was trying to explain to some friends how because usually when you discuss Evolution Theory they will tell you how P cells arise and I thought I I most thought the fair cells are actually easy to explain I mean people usually think that the fair cells are the complicated cells like now we see no the fair cells are probably just a membrane and a nucleus and I thought that this is very easy to simulate with some particles attracting each other and I was looking at YouTube videos to see and then I came across this particle life system uh I don't remember the name of the guy but he was explaining uh these uh cellular shapes with attraction and repetion forces and I thought wow this is very interesting actually I tried to implement that by myself and I improvised that and I was surprised I was trying to do that and then a buck on my screen appeared a flying buck so that was very very surprising I was shocked I mean how how can I I I'm just randomly examining some simple rules and I see something like a flag and then I actually uh made made a video and that video actually have a lot of views and the code have a lot of participants they they made the code way more sophisticated so now it has a lot of gooey parts and thanks to the participants uh and I think I think it's the the most uh uh yeah I mean many many people actually become more popular the particle life uh after that video and the reason why I think is because the code was the simplest possible code I thought I thought because it is educational I have to make it the simple as possible I I actually reduced all the parts that I thought uh it may not be interesting and because the code is very simple and the patterns is very complex I thought that that's what attracted and I hoping more people actually come to the partic life because I know game of life is very interesting it's touring complete it's very but particle life is less known about but they are more biologically looking yeah lot lot lot of insights there about the formation of well first the joy and the fun of Open Source and of people's participation in science around the world and then in the first cells forming there's like hydrophobic and hydrophilic and then also ex that's that my concept about how so how the material gets there is is you know these are all inquiry to to explore and then also just just about the videos so one thing about video is it's it's an audio and a visual component now some videos you can watch with no audio and and vice versa um but when audio and visual are happening together it's kind of like two touches from across the Marco blanket like if someone's doing hand gestures while they're talking then they're both being emitted from the same cognitive state whereas if if it scrambled what hand gestures were happening with the audio it would remove that meaning but synchronously they're experienced together so then they're seen as meaningful so then like I was paying attention to the presentation and it was like slide after slide I would be initially surprised and then through through the suppression of surprise I I keep seeing in in these two images here it's like sometimes you connect with a layer above or below which is top down from the Top's perspective or bottom up from the Bottom's perspec or you go sideways and so that could be in a grid World lateral spatial that could be through time like on a timeline it's like those are the local moves that can be made you can move up or down a layer of abstraction and generalization and then you can move around in space and time and cause it's like those are our that's like the pushup and the pullup of the local interactions these are the moves the dance moves and then the question is just like what what does the party look like and that's the particle simulation what really look what what starts to happen when all of these moves what if some of the particles can do abstraction yes yeah um by can I show you a demo another oh yeah go for it okay so uh so so this laus filter I I I do have a a video another video on it but I have also a demo so I I I can show you a python code uh so let me open up my so do do you code in Python I I saw you you code in Python what what IDE do you use um I I use uh cursor for the AI augmentation or just vs code oh Visual Studio code I use a what's called spider oh yeah for for Scientific Python yes it's very similar to mlab because in my PhD I I LIF M up I I I hate it as a language but it's very nice IDE it has a very nice ID hate it as a language love it as a friend exactly so when I trans transition to python code I saw spider as a home because it looked like P uh it looked like uh the M lab the yeah also like R Studio oh yeah yeah okay so so you see them ID now huh yep go for it great so let me for okay so I'm pasting a previous okay let me paste a put from okay so can you see uh can you see the code okay yep yep okay so so this is I I I like this algorithm uh I people usually call it ltis filters uh as I said I drive this algorithm just from the prediction coding uh multi linear regression system and I have a video about that uh it it's titled regression and brain so it's very very simple code but it somewhat explains repetition suppression so if you if you run the code okay so now this this will this is activity this is the error and this is by the way do you do you see the plots or you just see the spider IDE no plots just the IDE okay so I have to share the screen the screen is better so let me share the screen I think you should see all right looks good okay great so I run the code uh and this is the pattern so so let's let's simulate a sinodal pattern in the beginning so so let's say we are just simulating signus okay so this is the truth the green and the and the Orange is the prediction you see in the beginning it doesn't predict the the the Orange Line doesn't overlay the blue light the sinusal activity so the sinusal activity is our data the truth and and the prediction is that is the algorithm which I showed you it's just it's just few lines of quote here so I I will just explain it right now but but the interesting connection I'll try to make to repetition suppression so it see you see after few iteration it can perfectly predict the the sosal activity uh and and you see the error plot actually reducing in the beginning it's high but then it's reducing uh to zero and and this actually tells you how much activity do we have in in different layers so you can see in the beginning in the lower layers we have higher activity let let me zoom in so we have higher activity in the lower layers and then as we go to the upper layers we have less activity that's why because because the system can predict what Captain this now I will introduce a surprise to this system let me uh in this code now I'm am for every for every two steps I am just changing y to one it means just sinusoidal wave but I'm introducing one to it so it's just like now we have a surprise okay now you see it's it's more difficult so in the beginning it can't predict the entire system but then later on it learns it learns to predict the squence so you see it's just same sign but I have introduced number one uh I have introduced something surprising uh but then later on it predicts and then the error goes down and then again we have the activities uh but now the activities can go to higher layers before it it's suppressed to zero okay now I I will just introduce one surprising event so just minus one at at 17 so at 17 I will just introduce a a surprise to the sequence and see what the algorithm how the algorithm behave okay so you see okay so you see it predicts the system but here when I introduced a surprise it it can't predict it it can't fit the data and and if you see the activity you see when the at the level at this level when I introduce the L Sur prise you can see the prediction error goes all the way the upper layers so just like repetition supression when you see something surprising the activity increases so just like that in the beginning so this algorithm is actually a very nice view to tell us how our brain may be working and and here we we even see that that almost diagonal propagation up and to the right as it sort of normalizes and calms down at higher exactly exactly so so maybe maybe that good thing and a bad thing because the algorithm learns very learns this surprise that's why even in the upcoming uh steps it it needed some time to come back so maybe maybe maybe we can put a filter there we can say oh if the prediction error is very high don't learn the pattern so maybe we can put a thresold and maybe that will actually tells me that's why we have belief system in ours that's why our brain is actually fixed on some idea sometimes if something very surprising and it doesn't conform with your previous beliefs because the learning algorithm inside our brain is very fast if we can learn everything that even if doesn't conform to our previous beliefs it means it can mess up sometimes they it's similar to catastrophic forgetting it's just like the activity the new activity May superimpose to the previous activities in your brain and can mess up everything and that's why maybe some people are actually hard to change their minds even when they say new data when they see new things uh people usually if if if it doesn't conform with their beliefs they will just deny it because sometimes you need to fix that you need for this surprise to become a pattern so that your brain surrenders says Okay I want to learn that that's what I think I mean I think this algorithm can tell us more about our brain that we even uh so so it's very very easy it's just it's just like the prediction yourr system so so you have a sequence of data Ys and then you just have just just focus on these two lines because everything happens here so you have so you just have a forward prediction and backward prediction basically W this is the weight multiplied by the activity current activity it will try to predict the future activity F and the substraction the difference between these two is the prediction error so if that that prediction error will go to the upper level so we have a a nice illustration on that so so this is the code just illustrates this so y5 here this tries predict Y y4 and then the prediction error goes up and then y tries to predict wi5 the prediction the the forward prediction and the backward prediction so the prediction error we have two prediction error the forward prediction error and the backward prediction error so each level tries to predict the previous prediction error and each prediction error will go up hierarchy and hopefully at the higher hierarchy you will have less prediction error it means like your brain can predict everything I I'll just add a note on prediction error the prediction error is denominated in the units of the measurement like if you expect the room to be 30° and it's 31 then the error is one and then the move in active inference is to translate that error signal into information units bits surprise and then surprise if you can compute it exactly for a simple system go for it but then in cases where it's intractable or you want to do an optimization on bounding surprise that's variational free energy and that's been used for decades variational Auto encoder all these other kinds of variational methods and physics so those are all kind of aligned like if you B if the error were zero the surprise would be minimal the free energy would be minimal if there's a large error the surprise is higher the variational free energy is higher so like they're slightly different formulations but they're all monotonically related they related I think they are using other optimization algorithms to learn this so they maybe better optimization that's what I say that you have to learn gradual the the problem with this system it learns try to exactly learn and that's why when you show something surprises prediction explodes well that that kind of even comes back to the earlier numbers that you showed with the decimal points it's like um are you trying to predict to one significant figure that's core scening to just one digit but then if you give a computer program a float Precision number it might have a ton of decimal points and then it will think that those are just as important to compute as the earlier decimal points and then it gets catastrophic because it's doing really well on like the the 50th decimal point but it lost the plot on the main thrust oh I sometimes Precision error uh by the way floating floating Point numbers are also a form of course graining because we can't actually simulate real numbers real numbers have infinite Precision so so the moment we say we used floating point it means we have course grain the real number there is no way without course graining even in in the computers even if you see if you use double Precision it's it's just you have at some point you just cut the the number yeah um cool so what are your next research or or directions that you're going to be exploring okay there are two directions one is I actually want to explore more free energy what happens in these particle systems but not just intuitively because to be quite honest the things that I showed you some some stuff that I thought it is Trivial we don't need to even simulate it uh but I I I have to simulate that because sometimes simulations gave you surprised just like the first example which I showed you I mean you think this happens because of this but sometimes this is not true uh the next thing I am actually working on a different algorithm I call it fun predictive hean unified neurons uh I am so far I'm not successful with this algorithm we can see this algorithm is a variant of this algorithm which I just showed you uh but but I'm trying to make this algorithm more local I mean learn locally uh the problem is because you so so what's the problem with the current neural network approach the neural network works very good we we saw magic with GPT but the problem is these systems they learn very F very slow uh training they have sample in efficient they you have to give them so many samples so that they can learn the reason why because they you have to tweak the learning rate to to lower levels because if you tweak the learning late higher if the system learns fast it will have a catastrophic forgetting that the moment it it sees something new novel it's because it has high learning rate it tries to incorporate that new thing into all the systems all the neuron Network nodes and because these systems are distributed it means it tries to F between every node every weight and that could be catastrophic especially if this outlier is just a noise it's just an noise you need to ignore it but if you have a high learning rate algorithm doesn't can't learn it that's why you have to make the learning rate small but if you make the learning rate small it means you have have to iteratively learn so many samples and variations and that's why only big companies nowadays can train neural networks because it it needs so many iterations and even these big companies they can't make a realtime system so even if they make a robot that robot can't learn on real time it's just like the company can tell you oh this this robot can only learn do things that we have trained in in 2020 you have we have to take it back and update and retrain again on on the data from 20 23 or something like that so it's not real time Learning System so even Char now is not a real time Learning System it if if open a I need to retrained again it needed it updated it needed to retrain everything again so basically it means these algorithms are not real time but this algorithm is real time the one I showed you means once you see the data in in just few samples it learns it but again the problem with this algorithm is this catastrophic disturbance I mean this unstability once it sees something surprising because it tries to learn it it it just messes up and that's uh that's uh what I try to figure out something that lears fast but it doesn't disturb the entire system so I'm I'm actually trying to do that uh but so far not very successful but but every now then I I have ideas to implement and then try again and again uh I think now I I I mean few months ago I have a new but I still don't have time to implement it so maybe maybe you can hear more about me in in the future about the predictive hean unified neurons which I shortly call it fun which which is not fun to it doesn't work it's not fun yet planning for fun is still fun um okay do you have any last comments uh no thank you very much for actually inviting me inviting me to to this uh and I hope you continue I actually find active inference uh uh Channel very interesting and I find the topic is very interesting actually the entire topic that you specialized yourself to just this one topic and it's a very very interest I I thought is a very good candidate for The Theory of Everything I mean people usually think that the theory of everything should come from physics but I think it will come from Neuroscience that's why I mean it it doesn't make sense to have a theory of everything without Consciousness that's why it has to come from Neuroscience I mean physics can help in Neuroscience but The Theory of Everything it comes from Neuroscience there is no way around that's my or it comes from a new combinatoric Fusion I mean one of the key Moves In free energy principle is to talk about the cognitive particle so then if it's a basian mechanics if it's a statistical physics for cognitive particles then it's not surprising that it has a lot to do with particle physics yes yeah yeah maybe maybe com that that's the best thing to to actually do com actually I mean I have maybe one extra uh animation slide I I I can show you before sounds good yes about this combinatory things I usually show that to to friends and and they usually like it and I explained that in in in my videos in some of my videos so I mean if you if you if you see this graph as the entire human knowledge and then this child it it likes to learn it's just born and it doesn't know anything so the problem is our age is very limited so by the time the the child the Curious child that tries to collect information it will get old and it will at some point it will die before learning about everything and that that's the reality okay now what what I think actually better is specialization it means that child shouldn't try to learn everything in the beginning it tries to learn all the things that are surrounding and then should specialize if you specialize at some point you will reach the age of knowledge and once you reach the age of knowledge this is where you can find a new information the the extrapolation That's What I Call extrapolation okay but the problem with space ization is we will be trapped at a local Maxima it means so it means if this guy is a doctor uh it tries to treat cancer it specializes in cancer but maybe the true treatment of cancer comes from an engineer engineering Treck someone can find a new radiation that doesn't affect normal cells only affect uh cancer cells so I mean if you trap yourself just reading medicine you can never find this solution uh so so this solution how how it comes so let's say uh so so that's my point you can never make distant connections long-term connections because you specialize you you trapped yourself now if if other people who are also specialized in different topics and if they collaborate with each other that's why I'm coming back to your so if physics and collaborate with chemistry with chemists and they collaborate with neuroscientists and then this collaboration we can overcome the local Maxima TRS totally agree and there there they they are working on the interdisciplinary team sending each other papers sending each other jokes and memes that reflect their worldviews to give a kind of qualitative sense of their understanding and also I I think in the core screening I think about nestmate ants returning with food and so they're not saying what temperature or anything it's just interacting with Nest me yes there was food someone else came that way with food and so that's like a binary coar graining that tells you something about that direction and so it's like every node is a local sense maker receiving and sending and that's active inference yes yes that's a nice way to complet okay unar thank you good luck with your with your work and with your education so it's been awesome thank you very much Danielle see you soon thanks a lot bye see you bye for