hello and welcome this is active inference guest stream 71.1 on February 22nd 2024 222222 and we're here with Ryan Smith Rowan Hodson and Mishka meta there will be a quick overview and then discussion on their recent work the empirical status of predictive coding and active confence so thank you all and let's hear about it um okay so you just want me to jump in and go yeah okay cool well thanks a ton Daniel for um you know inviting us on um you know fun to get to uh present some of this stuff and you know hopefully get it out to the the broader Community a little bit um so just I'm gonna quickly just kind of walk through sections of the paper to orient people to generally what the point is and what we're trying to do and then um at that point I think the goal is just to kind of launch it a discussion and um see if we can kind of extract out some of the more the more interesting points that might be most um you know relevant or interesting to the active Insurance Community um so just to um to start out with here so the paper as Daniel said is called the empirical status of predictive coding and active inference um the main point of this is just that you know as a lot of people in this community know um it's you know at its kind of beginning and for a long time time um you know like the active inferences primarily so the literature you'll see has been um very focused on theoretical um sort of conceptual work and um and simulation based work right so you'll see a lot of things out there that's kind of you know an active inference model of X um where X is just some interesting psychological um phenomena or condition um and usually that involves showing some you know fun interesting simulations um that are kind of potential computational explanations for you know whatever the you know specific phenomenon of interest is um and that work is great and I think there's been a lot of developments there but um you know at a certain point um you know we can come up with as many theories as we want um but without actually being able to test them scientifically um it's really hard to be able to say with any confidence that these are kind of accurate stories of what the brain's doing and what are the kind of yeah again like empirically supported um um Theory you know what which of all these sort of models than simulations people are proposing sort of actually correspond to what the brain's doing and whether they can actually explain uh human behavior um so what we were interested in doing is actually kind of taking a step back and um looking at what the what the empirical studies that have um been done using um these sorts of modeling approaches um what they actually say um and how supportive the the evidence actually is for um you know the hypothesis that the brain is doing things like predictive coding and active inference so that's why it's called the empirical status right as we're trying to say okay what is the current evidence um and where is evidence missing right so what should future work um and future studies focus on to um to try to actually you know like like fill in and answer questions and provide additional support or not um for you know for um for these theories as hypotheses for what um for what the brain is doing um so to kind of walk through sections here so we focused you know so people use this umbrella term of like predictive processing but that's really a fairly vague overarching kind of umbrella term um and so we picked kind of the primary you know actually sort of like well-defined algorithms you know in um that are most prominent within the kind of under the predictive processing umbrella which is predictive coding and active inference these are kind of well- defined mathematical algorithms um that can be sufficiently precise to to test empirically um so the first section is more or less just kind of an introduction that says more or less the sort of thing I just said about um predictive coding and active inference being the kind of most prominent um precisely formulated algorithms um that the brain might be doing and the importance of testing these things empirically etc etc um and so um I should say that you know most of the credit for this paper should really go to the first author which is Rowan Hudson here who I'm hoping will um certainly say much more after I give this kind of brief overview um but you know so what Rowan did is he started out um in each of these sections by defining the algorithm and laying out the the the the associated mathematics um in a way that was uh really very clear I thought um of course I'm bragging a little bit about a paper that I'm on so take that with a grain of salt but um but I thought he did a very good job of laying it out you know being explicit showing the mathematics but describing it in a way that was um um what I think should be very accessible to people that don't have a ton of mathematical background um and the idea was that we would just you know introduce this so that what we were talking about was clear um but the focus really isn't on you know just the mathematics we're just in introducing a mathematics so it can be kind of more understandable what um you know what the studies that we review are actually testing um and so so we just kind of walk through a lot of the and I'll come back to this figure in a second but you know the the underlying mathematics of for instance you know here is a definition of the negative free energy um when when applied within predictive coding um and just kind of how you get to some of the predictions and prediction errors and things like that that we actually use um and uh this this figure is a figure that took a long time to make and to try to be clear on but you know we thought it ended up um being pretty uh you know colorful and and uh engaging and and it looks complicated but um we tried pretty hard to kind of walk people through step by step what this is what this is hypothesizing but this is just a representation of one way that um cortical columns in the brain might Implement hierarchical predictive coding and this is a particular form of a particular predictive coding algorithm that um allows for a certain type of temporal depth to it um where where you have um essentially a higher level hidden cause that's being represented that actually predicts Dynamics in the representations at the level below as opposed to just predicting and trying to minimize prediction eror with respect to some sort of static um equivalent temporal scale representation at the level below um so we try to kind of lay that out um so that people have an understanding of what again what the kind of General basis and what the hypothesis is um it's kind of important here because predictive coding at an algorithmic level is a different thing to test than than trying to test a theory about the the specific neural mechanisms that Implement predictive coding right so so it's I think it's a really important point is is that you can test a theory empirically by looking at the brain to try to like test a hypothesis about a specific way the brain could be set up to do predictive coding but the brain could be the brain could be set up in more than one way that would Implement predictive coding so to be specific about testing something about the brain process you need to specify what algorithm you want to see whether there's evidence that the brain is doing that um more generally though you could also just test for evidence of predictive coding at the algorithmic level and you could do that behaviorally just by looking at whether you know people's people's what people detect perceptually and how that evolves over time um whether that is just consistent with the with with the predictive coding algorithm so just just the mathematics not some more specific hypothesis about the way the brain is doing it um through different patterns of connectivity um so then as I mentioned we kind of go through um now just uh we lay out what the proposed neural implementation is or as I said one commonly proposed implementation there's actually a couple that we talk about um and then here in this section we have the empirical studies of predictive coding and we review more or less what the evidence is um for these different uh for for um different kind of aspects or um testing different predictions um that predictive coding might make about what you would see um either behaviorally or or in the brain um and I won't kind of go into it in detail here we can obviously talk about it when we get more into the discussion but um you know take-home is is really there is a lot of indirect evidence um but um more there's a lot of studies that still kind of remain to be done to test more specific hypotheses about the neural implementation um you know whether or not for example there actually are separate neurons in the brain that are responding just to prediction erors and other ones that are representing just predictions and and things like that um there really is more kind of explicit model fitting that needs to be done to test out this you know predictions associated with really with quantitative simulations um and what those predict um based on the predictive coding algorithm um one place where probably the most kind of related evidence is is um not with predictive coding proper but with hierarchical gaussian Filter um which is a a different model than predictive coding but it um it has related it has it predicts dynamics that are related to predictive coding um so for instance it does have prediction errors in it and it does have a Precision waiting on those predictions um and it can be the up updates can be modeled in relation to prediction errors and um one one difference though is um instead of being hierarchical in the sense of each level in a hierarchy representing different causes um in the hierarch Gan filter higher levels represent predictions about the the stability of the contingencies at the level below so so basically the highest level is representing something like how quickly it expects the um predictive relationship between hidden States and outcomes how how quickly it expects those will change over time um and so it can do this kind of like Dynamic Precision um waiting depending on essentially how much you should trust the predictions you have in a given moment based on how you think those predictive relationships will change over time so it's not the same thing as predictive coding but it's related and people have done neuroimaging studies um for example um and looked at the explicit relationship between the prediction ER dynamics that this model um the predictions it makes about those prediction and prediction ER Dynamics and whether or not you can find uh neural responses that look like they match um those predicted simulated time courses um and there have't been a few studies that do support um the specific brain regions are encoding prediction errors and predictions and things like that um um and different uh precisions um so it's not the same thing as testing for decoding directly but it is testing um and finding evidence for a neural basis of um of encoding of precision weighted prediction erors which again overlaps in interesting ways um as kind of again indirect but but important evidence um so then um after we go through that then we switch to talking about active inference um and again kind of similar structure um first uh Rowan introduced the mathematics um associated with the active inference framework um and you know for people that are watching uh this you know this um U you know the active inference Institute um program um regularly um should be aware that active inference you know nowadays has evolved into um kind of also being a broader umbrella term for multiple different um specific mathematical formalisms um and uh so to be clear this this one that we go through here is is just the kind of standard initial partially observable Markov decision process framework um so this is a specific model of decision making um based on a particular explore exploit trade-off in a model based way um where instead of just using reward um as a cost function um or an objective function um it's based on the expected free energy which is just this combination of expected reward and expected Information Gain um so it's a it's a talking about a specific algorithm and kind of the original algorithm under under active inference but now there's there's lots of different kind of variants of it um so we're just going through the basic one um so again you know we talk about how it's related to predictive coding um and what's different about it from predictive coding and then um in this case uh what we do is there there is actually um quite a bit more um in active inference at least this version of it um there are a number of empirical studies that have directly um fit active inference models to decisionmaking behavior um you know several of these come out of um our lab actually um but there are some other ones that haven't and um so we we reviewed um each of these in in detail kind of laid out how the model um how the models were set up um to model specific decisionmaking or um or perceptual decision- making TX tasks um you know so for instance here we kind of introduced a the model for a specific task but used to model interception so cardiac interception um and then yeah here you can just see this is just kind of a standard you know version of a depiction of the active inference um model um and then let's see you know again these are sort of standard things you see in lots of active inference papers right so just describing and laying out the mathematics of the of the general update equations and the the overall algorithm and then um a very kind of coar grain generic sort of representation of one way that the brain might Implement those those algorithms kind of inspired by cortical column structure um but so anyway you can see this is a model that we used to an active inference model we set up to model a three Arm Bandit task um that we used in um in substance use disorders to show that um and in this one you know what we were able to show for example was that um substance users showed slower learning rates from negative outcomes than healthy individuals so you can see it's much more based on trying to answer psychiatric questions about clinical groups because our our lab is focused on computational Psychiatry um in particular um so we walk through that we walked through a task that we modeled using an approach avoidance conflict um Paradigm and that model also was able to show differences in decision uncertainty and um what we call emotion conflict it's a type of preference Precision effectively um that um also differed in affec of disorders and substance use disorders from healthy controls in an interesting way um there was also a couple others one really cool study that was um not by us but got by um gson was the first author um and they took they took for example a set of publicly available data sets for uh what's called a two-step task which is just a common task used in reinforcement learning models and um in that task uh there's a standard reinforcement learning model that's used that's a essentially kind of a mixture-based model of of what a model free reinforcement learning model versus a modelbased reinforcement learning model would predict um and the the what that task was designed to do um initially was to use this kind of mixture reinforcement learning model to test individual differences in how um kind of modelbased versus model free people are um if um we can talk about that a little more if people you know listening aren't totally familiar with the model based versus model fre distinction but um but what they did which was really which was really cool was they um took that data and fit an active inference model to it and then compared the ability of active inference to explain um Behavior compared to the standard reinforcement learning model I just mentioned and um what they were able to show is that the active inference model um in two of the four data sets um was actually a little bit better um at explaining the behavioral patterns than the um than the reinforcement learning model was in the other two data sets the models were about equivalent um so so that was probably the most direct evidence um that um that has been shown and this was a one of the major points I think that that we wanted to make is that even though it's the case that you know us and other people have started to do actual empirical studies trying to fit active inference models to data um the main purpose so far and what people have done really hasn't been to provide unique evidence for active inference it's just been using active inference um as a way to try to identify individual differences or group differences in in a um psychiatric research context um so so one thing that is still really needed um aside from this one gchen study I mentioned um is more studies where people will actually take um you know behavioral data or collect behavioral data um on decision-making tasks and fit a bunch of fit different active inference models to it and also fit a bunch of sort of competing models like reinforcement learning models to it um to really show that the active inference the the behavioral patterns that active inference predicts are um that that active inference can can do a better job of predicting that behavior than competing models um can because that's really the only way it's not enough basically to show that active inference models fit well you need to show that active inference models fit better than um competing models because that's how you'd really show that um that active inference is more likely what the brain is doing when people are making decisions um and so you know the the overarching conclusion is that um you know the the evidence is is promising right I mean there's nothing that suggests that the brain isn't doing active inference um and and certainly it's consistent with people doing active people using active inference but um a lot more still needs to be done to show that active inference is a is a better explanation for what people do than simpler competing models um so that's you know just as a a kind of broad brief overview of the the general structure of the paper and the message we were trying to get across um so you know we can we can certainly talk about it more um just kind of interactively now um lots that I didn't talk about um but hopefully that starts as just kind of an initial launching point for for a discussion so um I guess I'll just stop there thank you awesome perhaps the other authors could give the first takes introduce thems sure I'll start um yeah I'm I'm Rowan um I'm a PhD student uh Ryan's my supervisor I'm at Institute for brain research um I did my masters at the University of Cape Town under Jonathan shock Mark SS and Ryan as well um I think yeah just to talk a bit more generally about this paper this this paper started off as um a book chapter actually which was only going to be focused on Act of inference and sort of especially uh particularly empirical states of act difference and in the process of writing this um I filed myself uh what needing almost to write about predictive coding um it's it's I think whenever we can we should take the opportunity to really um present this in a in a very methodical and complete way and I think sometimes I remember when I was first learning about active reference it's very hard to dive in in the into the middle and I think that's how it sort of became it morphed from just being focused on active inference to being focused on active inference and predictive coding where you Prive coding acts as a sort of foundation um for a large aspect of active inflence um and I think that's how that sort of happened and then of course it morphed a little bit from just uh just talking about predictive studies to also talking about the sort of the the background mathematics and the theoretical foundations and so I I think this is the sort of field where um it's a noble cause to try whenever we can get the opportunity to try present a a quite a thorough review of all aspects of this because um it's a difficult field to learn uh it can be very confusing so yeah I really hope that this review on top of presenting the empirical side of things also acts as uh a reasonbly intuitive way to look at the foundational theory of PR coding acence yeah and one thing one thing I will say just to kind of add to that is is that um you know for for people that you know have more of a kind of broad conception or philosophical interest in um inactive inference as opposed to you know more the kind of like detailed mathematical modeling sort of understanding um often what I've seen in the past is is that um predictive coding and active inference get a little bit kind of conflated right so you know people think that active inference is somehow just predictive coding plus motor control or plus decision- making or something and so making it clear that's actually really not the case I think is important right that predictive coding is actually an entirely different algorithm it has a different generative model associated with it um you know it uses continuous date spaces whereas active inference uses discret State spaces and discreet time like to really lay out like I think Rowan did very well um you know with mishka's help also um was um you know to kind of state clearly what the connection is between predictive coding and active inference but but that they are not the same thing and they're not even directly connected to each other so to make that to make that a little bit more more clear and more intuitive maybe so that was just another thing I wanted to say that I thought I thought that they um that they did pretty well and there another kind of maybe useful take home point from the paper hi I'm arishka um so I'm also like Rowan a second year PhD student at The laurate Institute and Ryan is my supervisor my background is more um neuroscience and psychology so this paper was like a really cool and challenging first step in my PhD where I come from a more empirical background so kind of working on this paper was uh kind of going not taking baby step but deep dive into the active inference and the predictive coding literature and again um I'm the people that Ryan was talking about who had more interest on the empirical side and kind of going through this journey like really helped me like walk step by step into like different aspects of the just like pred cing or active um inference literature that you should take into consideration and think about really like the algorithmic side the neural side of things and kind of like connecting those three levels how we how different people kind of just think about from one perspective but what really is needed is connecting all those three things and I felt like I was playing a supportive role in this paper but this really was a great Learning Journey for me okay why not to Mr empirical Dean um so my interest in This was um anytime I see a title where there's a minimum of two uh ideas being brought together as the unit unit of analysis I'm I'm always curious is it okay if I just because I have one question that's sort of an unpacking question around predictive coding and one question related to active inference at the conclusion would it be okay if I read a little section of the paper to maybe pull it apart unpack it s you just start just just start just there's a little microphone thing could you just repeat again okay so I'm I'm on page eight of the paper and the section I just like to get a little bit of unpacking around is thus fitting predictive coding models to responses on perception tasks and testing with quantitative predictions from simulations remains an important direction for work going forward this is crucial because simulated Dynamics and predictive coding models can make predictions that are not always straightforward a priori and that depend like this depend on the specific hypothesis built into a formal model Ryan kind of touched on that in his introduction for example the specific mathematical form assumed by the mapping between levels in a hierarchy the direction in which neural activity is assumed to represent a particular posterior estimate often this is the thing I was hoping somebody could unpack for me often sequential dependencies between task trials and patterns and Dynamics can be missed in summary statistics that average over trials so models are necessary to predict and test for the presence of those precise D Dynamics I was hoping maybe somebody could feel put some color on that that process and what it [Music] means um sure I can take a stab at that and um I mean you know Rowan or Mishka can as well but I'll um I I'm pretty sure that was something that I wrote so maybe sense for for me to be the one to at least take a start on it um so yeah I mean that in in so in the field of computational Psychiatry more broadly right so not just active inference but um you know the goal is really just to take a take a set of task Behavior right so we can ask people to do say some kind of like sequential decision- making task that involves um usually like explore exploit dynamics of some form right so so say like one common one would be I give people like a three Arm Bandit task right so I give people they play some little game and there's three different options and they don't know what the reward probabilities are um so and then they can just trial and error in the beginning they can say choose option three and they can see whether they win or lose and if they win you know let's say they probably stick with option three again um but if they lose maybe they try option two and then say if they lose again they could try option three again or they could try option one um and so on and so forth right and so predictive and active inference model in this case I'm just using this as a kind of a simpler starting example um an active inference model um under different parameter settings in that model right under different learning rates or under different um um directed exploration drives or what however you want to parameterize it um would make different predictions about what that sequence of choices would be um and there's a sequential dependence because the choices on each trial are not independent right so what a person chooses um on trial two depends very much on the outcome they saw at trial one um and what they see in option three what they choose in option three will depend on both what they saw Cho you know after Choice One and choice two um so if I do this standard right empirical thing that you would like analytic thing that you would do for a task like that that's not model based is you might just have some summary statistics right you might do something like a common thing to do would just be to count the number of times they switched what option they chose after they lost or how many times they stuck with the same Choice after they lost so we call those like win stays or win switches um or same thing like if you lose did you STI the stick with the same one or did you switch so this win stay win shift lose stay lose shift you could just kind of count the proportions of those right so you could see something that you know maybe you know how often people um lose switch for example might might tell you something kind of like their learning rate for losses right like they they might learn more quicker they might learn more quickly right update their beliefs more after a loss um if they if they're the kind of person that switches away right they'd be more quick to assume okay if this option led to a loss this time um that's probably not a good option anymore so I'm going to switch to something else right whereas if a person has a slow learning rate for losses then maybe they'll stick to the same one a couple times before they decide okay this is definitely a bad option they' have to see like a few losses in a row right so but the point is is that if all you do is kind of average over trials and get some kind of summary statistic about how many times people you know win shifted or lose State Etc um what you're not going to get is anything about the pattern in the Dynamics right so if they like for instance if they like lose shifted in the early first few choices right like that tells you something pretty different than if they lose stay or lose shift on some of those later choices um right the early choices might be driven much more by like exploratory drives right by information seeking whereas on later trials that much might be much better explained by differences in learning rates um so so fitting models to behavior which again just means you have the actual behavior and then you see what the model predicts under a bunch of different different parameter values right and you try to find the parameter values for a person that best reproduces their behavior right so point is this is that we've done that kind of thing several times now for active inference right which you can do with just by taking patterns of decisions right that people make on games um but you can do that same thing for predictive coding right you can give people perceptual decision-making tasks right where people say okay this is what I perceive this time okay this is what I perceived this time Etc and those are also going to have sequential dependencies because people are going to build up prior expectations about what they're going to see next right um and so predictive coding models again under certain parameter values might say okay well if they saw the same thing the last five times they're GNA probably a lot more biased right they're probably going to have a much more precise prior that they're going to see that again so the probability they're going to say they saw that again even if you showed something different would be would be higher right and so and so there are the point is is that it's not always the case that predictive a predictive coding model is going to predict some trajectory of choices that's going to be really obvious without actually fitting the model um you know if if for instance the person like has no tendency whatsoever to um be more likely to say they saw one thing just because they saw it a bunch more times in the past right um that wouldn't really be very consistent with the idea that people are using predictive coding um um and um it gets even a little trickier than that because predictive coding is um based on the continuous State space so it's not really even something like a person would be you know just like choosing I saw this I saw that it'd be much more something like them kind of continuously turning a dial or something you know as they see something get brighter or dimmer or you know like Motion in a Direction or another Direction and um because the prediction error equations are are set up in this kind of continuous way they also have these kind of like oscillatory Dynamics to them right so it's like not like you get error and then it drops as the thing resolves but it kind of oscillates up and down a little bit right and so that would also predict pretty kind of sometimes funny like not definitely not something you could just predict a priori like exactly how someone's gonna like turn a dial um so that's that's the kind of thing I mean okay uh in my in very simple terms Daniel and I have had some conversations around if you're in a and if you're in a situation where your focus or your concentration is on the next move or if you can look and see the entire space and take an all moves perspective so my asking you the question was to get out of the sort of model piece of it and that so what what do people actually do and I think your the question around the oscill the answer around the oscillation sort of speaks to that it's it's difficult when you're focusing on that next part of the sequence to be able to take in the entirety of the and vice versa if you're focusing on the averages maybe you're not able to pick up on the nuances of The Next Step can I ask one more question sure or would the other authors like to continue to fill in on that first answer um I think Ryan explained that very well I think this is a general um I'll talk about I know we that is referring to predictive coding but in something like something I'm very interested in active inference is along the lines of differentiating for example between um a model that uses reinforcement learning and a model that uses active inference and um yeah using summary statistics sometimes it can be hard to actually see differential Behavior right this is what we care about when we are looking at comparing different models what do they actually predict differential behavior and that differential Behavior can be difficult to capture in summary statistics sometimes um so in general I think in the world of sort of um yeah model fitting this is just a common common theme and as Ryan said while we're doing the stive reference they are limited limited applications of that methodology inli coding so okay Mish is so I'll ask this the other thing this was in in the conclusion of the paper um again I'll just read it in contrast to predictive coding research in contrast predictive coding research can be traced back nearly four decades and make specific predictions that can be investigated across a variety of fields so there's a deeper well of priors there I assume that's what that means um it will be an important direction for future research to further develop the neural process Theory underlying Act of inference and allow for precise implementation level as opposed to Simply algorithmic level predictions about brain and behavior I completely agree until that time confidence and active inference as a neural model of decision- making should remain tentative but this is the part that I thought was really interesting he wrote another important limitation associated with the current active inference scheme is that of scalability which constrains the phenomena that can be examined in empirical studies that is while these models work well in the context of simple tasks become less tractable if applied to many real world problems with high dimensional sets of States observations and policies my question was um is the idea of strategy because it's active inference is known kind of as a basis for strategizing behavior is the is the question around scalability one that ties into the idea that even when humans are are trying to strategize um how far out they can generalize their strategy is a difficult measure to get precise given that most context are Dynamic and changing so there's there's several kind of related things here um so so the the tractability issue kind of comes in two different flavors so one flavor is tractability with respect to like our that our ability to like use these models to even simulate behavior um in in in contexts where the the kind of space of options and how far in the future people are planning right when that gets big right the other the other question is more about psychological plausibility which is that um even if I can get you know an active inference model to simulate kind of like St 10 steps ahead and you know where there's like ends up being like 30 or 40 different combinations of like 10 moves or something like that right um it's not really very plausible that humans are really doing that right that the brain is really doing that and you know standard computer it's G to take like I don't know like Rowan you know Rowan has these fun planning models that he has this paper that um you know we uh I think are pretty close to submitting there's a preprint of an earlier version that's out um where you know the thing does like plan right a bunch of different possible paths that it can take to you know find you know different sorts of rewards um and uh you know it takes like hours right to run like simulations on a computer to do something that however humans are doing it they can do it just like you know in a minute or something right right so so um you know I don't so it's just not very plausible that the way that active inference is solving problems like that um is in any kind of exact form the same way the humans are doing it um so there's kind of scalability with respect to what humans can do because humans can't do this explicitly in a fully model-based way it doesn't seem like um after a certain sort of level of complexity to the the planning problem that needs to be solved and then the the other part is just tractability with you know actually doing the modeling itself because of just like how just um intractably long it could take um to actually run these simulations um and so both both of those things kind of come into play and it's not super clear exactly how you know to address this I mean there's there's certainly ideas out there but most of them involve um taking additional kind of machine learning tricks um you know like adding like adding like deep neural networks to active inference models for example or you know doing doing um you know very various other sorts of um you know little kind of heris short cuty things that make stuff tractable right like not actually searching all the way down every possible branch of a decision tree but using some heuristic to kind of say two steps in or something no this Branch seems bad I'm just G to cut this off and not consider it anymore you know things things like that or like sampling based approaches um for exploring just kind of little bits of a decision tree at a time um you know it doesn't it's no longer pure Act of inference anymore right I mean it's it's a kind of combination of active inference and a bunch of other machine learning things um but you know to a certain extent like that's probably just like necessary and I mean bottom line is the brain probably has to be doing something other than fully model based active inference um to be to be tractable and so figuring out exactly what parts of what the brain doing is doing might be pure kind of active influence and what parts are these other things to to make stuff tractable um is is I think part of the question yeah look the scalability issue with active inference it's not an active inference issue it's just a basan learning and decision-making issue yeah um it's there's nothing inherent to active inference that is that slows things down um any any technique that can be used in any any other sort of beian decision Mak method can be used in active inference um so yeah this is a the grand question of how the brain is so efficiently able to do this um where there's yeah like Ryan said I mean you run these very basic tasks and because of this the exploding State space of uh beijan decision- making right where just these this exploding stat Bas of prob probabilities um you get a massively expanding search tree ultimately and yeah nothing to do with active inference of of course active inference is um aan framework and so it's it has to sort of use this um but that's just a I mean if we can solve this then uh that's a yeah it would solve a lot of things if it could solve how how we can perform beian inference and especially B ban inference in the service of decision- making how we can do that very efficiently um that would solve a lot of things um um but as of yet yeah if we want to try speed active inference up we have to speed the general field of basan decision making up part I wasna sorry okay I was just gonna say it's part of it perhaps from a strategy standpoint not trying to generate the world's biggest plan but actually going back to that rules business and saying can we start there instead of a plan that because of its just its size makes things intractable can we could we swap something else in for something we know won't work which is world's biggest plan um I mean I mean look there there's lots of different you know things that you know might you might consider like like one one thing you know for these like exploding decision tree um sorts of problems is you know finding some way to um chunk things together right to make like the you know so for instance instead of you know say I'm going to go I decide I'm going to go walk to the store or something right like in a certain sense I've got a ton of different options about you know where to put my feet at each step and you know like what door to go out of and things like that um but it's not really clear that when I'm planning like to go to the store that I'm really explicitly considering all of those details right like I chunk it into you know I'm gonna walk out to the street you know I'm gonna walk you know 10 you know I'm GNA walk a mile to the store and then I'm going to walk into the store right in which case if I've chunked that to just kind of three steps right then my decision tree is is already much more tractable and then you just need to tell some story about you know how you know when we get to certain points in that really abstract chunked um plan when we get into those kind of Chunk States how we make these kind of more local decisions about what to do when at at smaller scales like when we're in those States so you know there's lots of kind of hierarchical chunking is sorts of things that you know you might think that um the brain could be doing to make these things tractable but and there's lots of different kind of options on the table and things that people um might try but all things have certainly all these things have not been um kind of you know tested against Behavior yet to see you know which ones are are are the most plausible but there certainly certainly different possibilities for what might be going on um you know another example you this is something that we test empirically in my lab right now is um the way people might do something called like a verse of pruning um and so so what you're kind of doing there is you're just and this is kind of similar to what I said before is you know when you start kind of planning down some tree if there's some early outcome where you're imagining that it's going to lead to some really negative outcome right like on like if like on step one or step two in a possible plan I think oh there's going to be some big negative thing then I will just no longer simulate down the rest of that Branch so it's a way of kind of reducing the number of branches in a tray after to search and um and so that's it's often called again aversive aversive decision tree pruning and that um you know obviously you need to do something like that right to keep it tractable but at the same time it can cause problems right because sometimes the best plan might go through something negative in the short term but lead to the best thing in the long term right I mean so that's the kind of thing we we test in the lab is whether or not different psychiatric conditions involve kind of doing pruning too much right or too little um and how that could lead to suboptimal behavior in the long term um the other I think the other aspect of the the previous question you asked also had to do with you know you read part of the thing talking about um the uh the the neural basis of of active inference and how that should kind of remain tentative and um just to kind of clarify that a little bit I mean the the main the main point is is just that again this kind of involves being clear about the separation between algorithm and implementation right so the the algorithm is basically just a mathematics right that we um you know that we kind of lay out but then the implementation question is you know what are the different possible ways you could kind of set up the brain to to carry out those equations and it's a separate question what the you know how the brain um how the brain was doing that even if you think that there's good reason to believe that the brain is doing the doing something that's well characterized by that the mathematics um and um unlike predictive coding which has been around a long time and you know there's been much more opportunity to test um at least um qualitative predictions right you know things like whether or not there's evidence for like Omission responses in the brain right like when there's the lack of a stimulus when it was expected leads to a neural response um which is you know one of the stronger pieces of evidence that the brain is doing something predictive like predictive coding um you know for for active inference uh there really has been like one Imaging study and it was done like in 2015 and it was like an older version of active inference it wasn't the current for based on the current formalism um you know so there's this just just hasn't been done right and the and even the um you know the little kind of column structure things like what's in the um like what's in the review in our in our in this paper um is super just kind of like promisory heuristic sort of thing it's like here's a bunch of here's a bunch of little balls that will pretend are like neurons and here's how you could connect them together roughly you know to um do some sort of you know some message passing algorithm that you know you're thinking is you know you're imagining or hypothesizing is the is the one that the brain's doing for this kind of approximate inference process um and um you know even when it comes to um the current mathematical proposal um for how the brain might be doing something like this um there's different hypotheses right so like initially most people when they were doing simulations with active inference models were assuming um something called variational message passing which is just a particular way of kind of repeatedly doing local approximate basian inference on different kind of nodes in a graph um and they youu this kind of over and over again and thing kind of converges to a good guess about what the posterior should be over stes each time point right but but you know then after that a little bit more recently you know Thomas par and Carl um and uh maybe other people were on the paper I can't remember they proposed a kind of updated version of that called marginal message passing um which is a little better um it does a little it's slightly more it can get it better um approximate posteriors um you know on average um but then there are others right there's belief propagation as another sort of message passing algorithm that's you know been considered so there's a bunch of these right and each of those even if they're doing active inference right like they will also predict different neural Dynamics um so so those are also even just active inference under what message passing algorithm um separates into a bunch of different competing hypotheses about what you would measure in the brain awesome I'll read a question from the live chat Andrew P writes curious for Dr Smith where might he place his previous work like simulating the computational mechanisms of cognitive and behavioral psychotherapeutic interventions insights from active inference in relation here would this kind of work be more on the side of theoretical exploration like the cognitive affective behavioral interactions construct or is there a direction for empirical testing I mean as is absolutely it was a theoretical simulation work sort of paper right I mean we weren't fitting that model to any sort of empirical data um it does I mean that one that paper in particular does lend itself to at least certain that that model is a little too General like the patterns of behavior that it predicts are really not specific enough to like test in a you know some sort of task um you could you could make it you could modify it in a way that might make it specific to some sort of uh task that would involve um you know specific sorts of explore exploit decision-making choices under kind of expected negative outcomes things like that um but uh it does make a kind of sort of qualitative prediction um that could be that could be tested um you know so one one one parameter that you might fit right based on that model that I think would be super interesting if you could kind of turn it into a task is this um parameter that reflects like the degree to which your cognitive beliefs influence your automatic effective responses or expected effective responses um the um so I mean it would be really interesting to to try to use that to figure out whether or not there are we can measure individual differences in this kind of what what often gets called like cognitive penetrability right so whether or not I you know because I might explicit believe I'm safe right in a certain situation but I might see something that still makes me feel really this automatic kind of fear response in my body or something even though I explicitly believe it's safe right my affective responses don't always have to match my explicit cognitive thoughts that's often a thing you see right in people with with um with affective disorders so this kind of individual difference that you could estimate about the degree to which these two um essentially these two uh um um different uh hidden State factors you know in in the model the degree to which those things interact effectively um but the the other the other um prediction that it makes um again it's a little more qualitative but certainly something that could be tested or made more precise is um that you know in that in that model um one of the the interesting things that came out of the simulations is that um you actually it's probably actually not a good idea to make people think that they're explicitly believe that they're in a safe context um before you do something like exposure therapy um because if you do that then basically what you're learning what the the beliefs that you're updating in your your likelihood right about like what actions are going to lead to what outcomes those will be updated under the belief of safe context right so that means all you have to do is switch back to believing you're in the dangerous context and then you're just right back to the problematic avoidance behavior again right um and this a bunch of other there's recent empirical work that's um very consistent with this idea actually about you know explaining using this kind of lateen causal inference um framework not not an active inference in particular but just Laden causal inference more generally that um you know to really get exposure therapy to work long term um you need to kind of prevent that people are inferring that there's a new latent cause in operation when people are doing exposure um because otherwise they're they're just learning safety under under a context where they can really easily get the get their um maladaptive avoidance to come back just spontaneously um just by kind of being uncertain about the context they're in later right like they're not they're not actually unlearning the problematic belief they're just inferring there's a new cause where under that new cause it's safe um so so it was much better um the the prediction of that of that paper would would be that could be tested right and again like guess said there is now some evidence consistent with this um is that it's kind of better to do things to keep people uncertain or keep people believing that they're they're still in the same context so that when they go through this exposure therapy and get unexpected outcomes they're actually kind of overwriting their previous beliefs as opposed to just inferring they're in a new Conta awesome all right oh oh ask kind of general question that that I'd love to hear everyone's perspective on we have active inference or predictive coding or some other type of formal framework that does interface with empirical data like we're discussing so on one hand we have the empirical system or the measurements coming from it existing data sets data sets we create and so on and then on the other side of this kind of statistical interface is like numbers free energy principle category Theory stuff that is really not having its validity or truth um or Essence described by any particular system so how do you just approach this usefully as a graduate student researcher or as like a broader clinical research program and like think about what system are you choosing what statistical interface and how how detailed do you go there and how do you think about like what's on the other side of the statistical interface because a lot of times the discussion around like the validity of active inference and free energy principle is a super philosophical question as if a philosophical discussion would resolve uncertainty about the empirical status of active inference which is actually the direction that you all took it from the interface back to the system rather than interface as outcome from something theoretical to debate um I feel like I have been kind of hogging the show here a little so I'll let um other people uh answer that first at least um okay sorry those was quite a long questions so I'm sorry if I missed some of it um and just correct me if I'm not answering right uh I think I will talk on um this idea between yeah on the one side uh sort of mathematical formulations representing something like uh brain processes and then yeah sort of mathematical formulations brain process and behavior and um how these are sort of seems as unified I think um as Ryan said about uh talking about neuronal implementation um there's many ways in which um we could set up neuro like a neur neural implementation to to uh achieve um something like predictive coding or active reference uh the same goes for algorithm where um there's many different sort of forms of algorithms could achieve uh or statistical Windows as you said if you want to go more broad um could achieve the same um neuronal implementation so uh and then ultimately Behavior so uh in terms of and please stop me if I'm not answering correctly um but yeah in terms of sort of as a graduate student choosing what to focus on um I think it's sort of a evolving process where you constantly just try read and come up with new ideas about how one can think about how these can connect and how one can represent the other um and and for me it's been particularly interesting just actually understanding what active inference is in its um mathematical Essence right we've got this first principal account of it um developed from the concepts of homeostasis and yeah it's it's can sometimes feel a bit strange when you look at um quite simple mathematical implementations in an algorithm and see that well this isn't so different from something like basan reinforcement learning with specific directed exploration um so there are these there's a sense of of that sort of first principal account um that comes all the way from Mark of blankets um where is that cap in these algorithms and um that's something I'm still trying to figure out to be honest um it's I think it's it's in in general it's a problem right to and I think that's why um when Ryan mentioned sort of uh looking at more complex tasks I think more complex tasks would allow us to explore more complex representations of of Act of inference um that can that can perhaps capture um some of the foundations that friston laid out um so does that answer the question sort of yeah that's awesome yeah I mean the other I mean the other things I would say I mean I think I understood at least part of the question a little bit differently um was that um you know there's sort of what by that I don't mean that you misunderstood Ro and you just answered your different that's all good my answer uh part part of what I took your question to be was something about you know to what degree answers about the you know quote unquote validity of active inference or the free energy principle can be established through kind of like philosophical argument versus what can be um or what needs to be answered um through kind of direct empirical testing um and um and I think um you know here I think it depends a little bit right so I mean I think what you know what philosophy is really good at is actually more finding ways that something couldn't be true right I mean I take you know I mean I have a philosophy background um as well and I think I think philosophy is really good at like conceptual analysis right so trying to find you know where some particular conceptual framework um you know where there's tensions right or where there's things that don't sort of at first at first need sort of appear and seem like they're contradictory have some sort of internal tension um but when you really drill down you find certain contradictions right that you know rule out something or make it really implausible um either through sort of direct logical um um argumentation or um through kind of like um just proposing sort of thought experiments that that really kind of pump intuitions in a way that that make a difference so so I think you can rule out with philosophy philosophical methods um things that are conceptually problematic right so you can get down to kind of the set of Frameworks or the set of yeah the set of sort of interl Concepts that make of a theory you can find a set of them that are at least internally consistent and and have some sort of General sort of sufficient coherence to them but once you've weeded things down to the kind of subset of possible theories that are internally consistent right and and don't have any philosophical problems associated with them then then I think um things really kind of need to get empirical um you know because because you know to the extent that different kind of competing um conceptual sort of theoretical Frameworks to the extent that they make different predictions um and to the extent that the goal of this whole project is to try to come up with an accurate theory of what you know what brains are doing right um if that is the goal then the way the only way ultimately to validate that is by actually looking at brains and seeing what they're actually doing um and um and so and so I think I think that's kind of where rubber meets the road WR a bit right is this is that um um yeah you need to know what's plausible right and that's where I think philosophy can help a lot but after you know what's plausible then testing what's kind of actual right is is is kind of the next necessary step and um and this kind of comes back to what Rowan was saying um was that testing the unique predictions of say some given active inference model versus some competing model from another framework like reinforcement learning um can be tricky um usually you have to do this in an incremental way and you do that by finding by identifying some prediction that is different between those two models and then designing a task that would really put people in a decision in a in a position where they have to make choices that are consistent with either the prediction of one or the other um and um it really requires some creativity right in coming up with the right kind of to task with the right sort of decision-making demands um and constraints that will do that because there's lots of tasks um where say the kind of simplest most straightforward um active inference model will really make like almost exactly the same predictions as what like a simpler reinforcement learning model would make right so in those cases you really can't differentiate with two because they pretty much predict the same thing um and um you know as as Rowan mentioned even though it's true that AC of inference is kind of motivated from these sort of first principles um which is super nice um the the thing that you ultimately end up converging on in terms of the decision-making algorithms in active inference start to look pretty similar to the sorts of things that people in machine learning and reinforcement learning have ended up kind of coming to anyway they just haven't come to it from a first principal perspective they've come to it because they just kind of like tinkering around and figure out what works um and so um and so that that's also kind of an interesting question is is you know where can we find differences between active inference and the other stuff that's out there that has nothing that has no connection to active inference but it's kind of converged on a similar type of solution um and um you know then you get to a point where okay well if we've gotten to the case where we have two algorithms that have different Origins but are basically doing the same thing right then there is no competition anymore we've just gotten to the same solution two different ways um so that's uh I don't know I guess I guess goes a little bit beyond your question but but I think um hopefully is all sufficiently relevant that's awesome maybe um Marka and then like kind of just in closing here um how did people pick up and run with the work and just how do people continue with it but first how do you approach this at a bigger level yeah um so I come from like a different side to this I come from more empirical background like what Ryan was saying so to me it's more about taking all of this information kind of accepting the broad literature that that's out there not just in active entrance or predictive coding but also more from the psychology neoscience side of things and kind of seeing where these things fit in an empirical setting where do these algorithmic ways um can be tested in a plausible manner for example like how Ryan was talking about uh the last fmri study was done in like 201 uh 15 that actually tested like um active inference models that to me is like the first things where we would want to test what is actually happening in the brain whether it's through fmri EEG kind of testing at different levels through different computation models what the brain is doing to me that's the most interesting next step like taking the computational work out there and trying to relate it back to brain and behavior oh Rowan and then Ryan or anyone else can just kind of give any last thoughts or what they're going to take going forward go for it go for it ran if there's anything you want to say sorry I was muted um yeah I think I think active inference is in a it's in an interesting spot and um I think the world of AI is in a very interesting spot I know you know this uh by a I mean artificial intelligence not active inference um if we want to look at active inflence as sort of um an element of artificial intelligence um it repres presents uh a side of things which is uh sort of Neuroscience inspired artificial intelligence um and as we all know there's a there's a bit of a war going on between that and um the large language model and the kind of things um and I think active inference is yeah I think while it's tempting to sort of go ahead with uh amassing more data and training larger models um I think that it's really important not to to forget about this aspect of um trying to not just come up with with you know more architecture and more data but to come up with more interesting Frameworks I also think that unlike traditional artificial intelligence or machine learning um it's important to remember that there's this tension between as we mentioned before scalability and um and just the efficiency and biological plausibility we don't always want um a solution a model to just be better and quicker um that isn't necessary going for we know that in many cases artificial intelligence can do things better and quicker than the human brain but we shouldn't actually only care about that sometimes um yeah it's important to get a solution where it it doesn't act more effectively but acts more like um data empirical data that we have gotten from actual human behavior and that it even if it isn't the most efficient sort of architectural algorithmic structure it matches the structure the brain might Implement so I think it's important to remember these factors um in this world where yeah it's F developing into uh you know big data and massive models um sometimes I find myself uh drawn to just always trying to make active reference faster and always trying to make it more efficient and I have to check myself with that um and and remember what I'm actually interested in so yeah yeah and I guess I guess as a you know concluding in my end I mean you know Daniel you asked specifically kind of about future directions um you know and and the kind of thing that we're doing in the lab right now is you know very kind of inspired by what we said you know needs to be done in the um in the in the paper right I mean it's always a little bit of an advertisement for in a certain sense for you know here's what we've done and here's what needs to be done and you know then we're trying to kind of Follow That ourselves um but um you know and again you know very much kind of in the context of of trying to also use these Frameworks to you know be of some kind of practical benefit to the world right so I mean you know we kind of in tandem right use this as an opportunity to to one you know test theories about you know how brains and minds work but also to um take it as a as a simultaneous opportunity to look for where these sorts of mechanisms may be um you know going wrong a bit and people with different sorts of disorders and whether or not that can um you know give clinicians right like ideas for novel treatment Target right like to Target mechanism X versus y um you know as kind of shown by what the differences are in models when we fit them to behavior and say like healthy versus clinical populations um and um and so you know the sorts of things that you know we're doing now on the on the cor of more basic science side is is um you know I have another grad student um coping um Chia who's not on the call here but you know she's done um some very extensive work now fitting um um something like 50 or so different models um to um some decision-making behavior that we have in both a Taiwanese sample um where she's from and and an American sample from around here um and you know trying to find right like which model fits best and so these are a range of simpler kind of reinforcement learning models and a range of different active inference models that is parameterized in different ways right so ones that assume sort of like you know static versus Dynamic decision noise or static versus Dynamic learning or I mean again there's tons of little variants on these things and so you know she's she's found in in both samples that you know the model that best fits the data um and wins in model comparison is a is a specific um active inference model that has six parameters I think um that involves uh you know dynamic learning or damic decision noise that includes particular sort of forgetting rate function um that's you know not including Ed in kind of the simplest version of active inference um and um you know so showing much more kind of conclusively in two different data sets um you know that um active inference um at least wins in model comparison against some of these other um uh other kind of competing models um that being said I think it's important that even though it wins in model comparison when you actually look at the predictive accuracies um they're very similar you know we're talking about active inference being able to explain like 81 0 five% of the you know like data versus uh the best reinforcement lot reinforcement learning model being able to pick like 80.6% of the behavior you know so I mean these differences are minor it comes down to being better at predicting just a couple of choices um but sometimes if those choices follow from different sorts of expected Dynamics along the way then that can still be meaningful um you know so that's the kind of thing you know that we've been doing on the on the more kind of basic science end that that follows up on you know what we were saying needs to be done um you know on the sort of clinical end still not super clinical is you know we have an A study that we're that's ongoing right now um that has both an online and a um inperson component where we came up with five different um five different tasks that um where different models would predict different patterns of behavior um in distinct ways in each of those tasks um a couple of them were designed specifically for active inference um others were designed like more in relation to the hgf the hyan filter um and um you know so we're in the process of collecting a lot of data in those where again we'll be able to fit different models and um that one we're also focusing a lot on um indiv on whether or not we can find models and parameter uh values in those models that predict um individual differences and subjective well-being um as well as um negative effective stuff so we're trying to go for not just pred like symptoms and negative emotional stuff but also um positive emotional stuff and what makes a difference to decision patterns that are say more consistent with um greater satisfaction with life and subjective wellbeing and things like that so um you know we're doing that we're also doing some computational sort of basian um modeling of interception data so how well people can like detect differences in their um heartbeats or differences in their kind of like respiratory difficulty things like that um and how they relates to anxiety disorders so so we're um it's very much kind of a combination of this basic science stuff and the and trying to move the the usefulness of this thing clinically at the same time so it can be kind of practically helpful to people that's awesome Dean and then anyone else and then that will be awesome but where where where do you go from here Dean um have a shower I don't know I'm not I don't have anything really planned but I appreciate the uh I appreciate the explanations and like I said when you start from a place where you take two things and hold them up together at the same time that's that's the part that I uh appreciate here and I think it again reading through all of this um I didn't understand all of the math but um it also I think based B on what you were able to show I wasn't sort of questioning what what process you went through to draw your conclusions and and state what some of the limitations are until those tests have have been uh carried out so yeah yeah thank you for the very clear very relevant paper so good luck and you're always welcome back to share more we can follow up and um it'll be an ongoing rolling literature meta analysis across different systems there will be thousands of fractal sub reviews empirical status in the amydala on this kind of thing so it's great to hear how you did it this time right thanks for having us yeah thanks so much bye byebye bye