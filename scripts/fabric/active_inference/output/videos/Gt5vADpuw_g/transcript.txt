okay welcome back cohort 6 we're in our first discussion of chapter 4 so Andrew however you'd like to begin and for everyone else any questions in the chat or raise your hand or however and let's jump into four perfect um yeah welcome everyone we're going going over chapter 4 for the first time with cohort 6 um for warning uh for anyone new to active inference this chapter is a bit more mathematically involved than the preceding chapters um but this is where we actually start to relate a lot of the concepts and kind of uh overview ideas that we've already been introduced to we begin to kind of map these uh more mathematically to understand the computations involved inactive inference models um so more specifically this chapter goes through the typical forms of active inference uh generative models will'll see both in discret and continuous time um the relationship between those models and uh the Dynamics of minimizing their free energy um at the very end we're also briefly introduced to other things that we'll see in later chapters including inferential message passing so um I would like to I I think this chapter does well at highlighting the importance of approximate inference um we've seen before that the a lot of the underlying assumptions in active inference uh involves uh the minimization of free energy now really the idea is that agents would want to quote unquote want to uh minimize surprise but because uh we need to actually render the computation tractable we instead are minimizing a quantity known as free energy um quick note that the mathematics involved here draw from different mathematical Fields primarily linear algebra differentiation in in multivariate calculus and the use of tailor series expand and some others um there's some nice appendices in the back of the textbook for anyone who's either new to those uh areas of maths or need some kind of refresher and would like to get a closer look on their relationships specifically with the computations involved here um and so sort of the core here is that we're introduced with a CA equation 4.1 we already know from previous chapters a generative model in a in a certain way can be reduced to a prior and a likelihood um those fit right into basis theorem that's equation 4.1 and so it relates the prior and the likelihood on the left hand side which you could just replace with you know uh oftentimes there's a notation the letter M to denote a model and then on the right side um those end up equaling a posterior distribution which is your your hidden States conditioned on your observations times um why or your your observations so your your evidence and so you can imagine whenever the agent basically takes in new observations all these quantities can be updated um and and that's the kind of nice easier kind of introductory view of how how this works um as far as rendering uh everything track [Music] um we also exploit something called Jensen's inequality um put in simple terms Jensen's inequality says the log of an average is always greater than or equal to the average of a log um so we we can exploit that and rewrite basis theorem using logs um and we use a different notation rather than a capital P that might be used to denote an exact distribution we can use a q which is used to denote an approximate distribution um and and replace that in there and so the whole idea is by minimizing free energy as a kind of proxy that is always greater than or equal to surprise the agent again quote unquote once to minimize free energy in order to minimize its surprise if you can get those two Quant ities to be virtually zero and virtually uh equal to one another that that would be kind of the general overall goal um and to kind of Zoom through a bit more of the rest of what happens in this chapter we get a further breakdown of what comprises free energy um it involves um using Kack uh colak leer Divergence between that approximate distribution the Q I mentioned earlier and uh an exact inference uh p and then subtracting uh log model evidence from that um figure 4.3 excuse me 4.2 were introduced to uh the kind of factor graph notation that's often used in act building active inference models um these are not yet active inference models there're simpler static perception models but they give a nice kind of quick view of here are the kind of things we'll be getting into we have variables uh every single one of these involves something we're already familiar with which is a for a generative model we have a prior we have a likelihood so all of those models involve the core components of a of a generative model or agent right so um from there we it it shifts into figure 4.3 um which will have very similar components but we're now introduced to active inference in that uh we now have actions that the agent takes which then impact uh State transitions right so we've moved from figure 4.2 of just none of the models in 4.2 have action involved none of them have like necessarily show some kind of temp temporal sequence of things playing out over time you know it's simply just these more static perceptual models that there's a nice example there where the one in the top left can be modeled as like um um a disease and uh taking a diagnostic test that then computes like the the result of you know if if you uh administer a test on a person who has a hit we're trying to uh derive a hidden State here marked as X do they have disease like what is it or or do they have it or not why is the result of the test right so that's that's kind of a way of looking at how these things are linked together we have a prior which is the prevalence of the disease we have a likelihood which is um you know what is the result of the test given the disease we can use bases theorem and what could be called Model inversion to switch around see okay what is the is there a disease given the particular result of the test um strongly recommend uh just kind of reading through those couple of paragraphs to get a better sense of what's going on there because it's much more descriptively clear than probably how I'm describing it here but uh in any case yeah it's good resource for getting started on these things um and then yeah 4.3 the difference where we now have active inference models is that we actually have a temporal Dimension which is we're now including State transitions over time so you can read those graphs in figure 4.3 from left to right you know T minus one to T the current time step to t + one which is the next time step uh so the agent is basically taking in those obser ations at the bottom of that particular graph that that Daniel has zoomed in on um you know we have these linkages with the hidden States as we saw before but now we have policies impacting the state transition as the agent uh engages in actions or sequences of actions which is another way of saying what a policy is in order to try and uh the agent tries to impact the changes in the states so that is kind of the active part of active inference right um and then from there section 4.4 it's a little bit more involved uh we can take all of these ideas that we've been introduced to likelihoods um Transitions and so on we can map those out to different uh components of our models so now a likelihood model um is now called an a matrix or a tensor um a trans the transitions model is now the B Matrix or B tensor the prior Over States are now a vector called D um we also now have preferences that the model has uh which are uh in a c Vector super important for um the agent actually realizing its preferences or expected observations which is an idea we're already introduced to in uh previous chapters so the idea here is that we're able to just kind of map a lot of the more uh verbally described ideas that we've already seen in preceding chapters to these different components of a model and then seeing how computationally we can and uh minimize free energy over time couple other ideas that are brought up but I won't go into too strongly right now because I want to allow time for questions uh in in discussion are expected free energy or otherwise known as G um that's related to planning this is where uh the the agent ju doesn't just look at past observations or current observations to minimize its free energy but it also wants to realize its preferences and so it has to kind of plan what it will do in order to realize those preferences or goals that it already has right so G plays in in that that the agent actually wants to kind of plan ahead of time what what should it do um so the C Vector of preferences plays into that um you can look at the way that the agent chooses different actions or policies to take as um it's actually Computing expected free energy for each policy and then it scores the policy see should I do X should I do y or let me revise that because that the the notation I don't want to get mixed up should I do policy number one policy number two policy number three well let's score the expected free energy for each of those policies and whichever one has the lowest expected free energy at the end you go with that policy and you go with the actions that that policy entails um and order to impact the environment in order to impact the state transitions based on your transitions model which basically is how do you think your actions are going to impact the environment around you um even more quickly some other Topline topics that were introduced to Markov blankets we've already seen some references to those uh in previous chapters um there's a nice box uh that descri rpes more on Mark of blankets and not just how Mark of blankets are a kind of conceptual concept that separates an agent from its environment but furthermore kind of the maths uh underlying what a Markov blanket is about statistical independencies and dependencies between variables and so on we get more on continuous time models which are frankly much more mathematically involved I would say um involves more uh in the way of differentiation in looking at temporal derivatives and applying tailor series expansions uh a concept called generalized coordinates of motion that's involved as well as the Plass approximation and uh finally at the very end of the chapter we're briefly introduced to what's called basy and message passing just kind of how um if we think about these models as graphs as we've already seen um messages are being passed around between nodes via edges um and that has uh significant amount of neurobiological plausibility behind it theoretically and and and through continued empirical study and so that's kind of the that's the kind of neuroscientific or neurobiological uh backing to to being able to say how a lot of this works and for anyone's especially interested in message passing we we'll see a lot more of that in chapter five um I would also recommend to anyone more interested in uh planning in these discrete time models with the A and B and C and D components and so on if you want to skip ahead to chapter 7 um there that chapter is entirely centered on discrete time models um it'll have more breakdowns of these different terms that are involved in Computing G like we see terms like like expected ambiguity and risk in this chapter there are other ways that you can break down how we compute G and it's it's nice to have these kind of words like risk or expected ambiguity that maybe gives a better intuitive sense of the maths involved and how it's useful how it plays into the explore exploit tradeoff uh Model Behavior anyway I I I feel like I've already covered the gist of of what's going on this chapter and maybe even overs spoken so uh if anyone has any questions um thoughts on any of this or any other particular topic they want to get into um please feel free to uh to raise your hand or just unmute yourself and go for it yeah I have a couple questions related to the statistical side how would this relate to calculating something like the r not like we look at in epidemiology where you're looking at a predictive state with an N value of zero I'll give a short answer there there's probably multiple ways you could do it but I mean one way to handle it would be treat the true AR not as a hidden State and then you make observations so you have an epidemiological infant trying to estimate an underly Ling parameter that could be the temperature in the room with the thermometer it could be the rot with the sampling from the noisy tests that's kind of the general approach it's it's what SPM does you have the underlying neural activity unobserved and then you have neuroimaging data which is being caused by very um nonlinear relationship with neural activity like with the blood flow that's a general process of perceptual inference is pretty much separate where you're really the underlying variable hidden state that you're trying to estimate and then separate that out from the observations you're getting and then you load up onto the a how the hidden state is related to the observation synchronously then you load up onto the B how that hidden State changes through time and then you can layer in the policy okay can you do that recursively with elliptic curve then so would you step back over so you would have to do linear step function back over through right again not sure how the curve you mean like the so I'm just thinking in terms of the math with like the heavy side step function so if you're going down from a three state to a two State see how you have like you're almost jumping that zero state but really what you're doing is sinusoidally passing through it with an elliptic curve in a way but you're passing through a negative with a positive direction sketch out an agent that's doing that or having it done to them and then try to make it look like figure 4.3 and then you'll probably be close to an answer okay thanks for the summary Andrew this is one of this is the dense chapter um yeah spending time with yeah chapter one introduction two and three low and high road getting two active inference chapter four it's active inference chapter five neurobiology case studies of active inference that's the first half of the book and then chapter six recipe for making it yourself chapter 7 and 8 revisit sections 4.4 to 4.5 nine bringing in data chapter 10 summary so we get a significant amount of kind of back and forth between kind of more verbal descriptions of the the ideas and Concepts but we have to come back to the maths right that's That's essential and that's I think that's what chapter 4 does is just quickly like give you a broad stroke of here are the maths underlying a lot of these ideas and how the Dynamics play out um Jr made a really nice comment in the Discord a few days ago this is the a new paper active data selection information seeking and here there's a slightly new and different uh notation Lambda operator introduced to indicate either summation or integration depending on whether we're dealing with continuous or discreet variables so here we're approaching that in the time setting but it's kind of like this comes up a lot like whether the variable is continuous or discrete and then whether time is being treated continuously or discreetly those are Options under the umbrella of active inference models so the actual kind of pseudo code is not predicated on the variables being continuous or discret M that to me intuitively just seems really nice and allows for a more direct relationship between the continuous and discreet variables because yeah this chapter 4 here as well as comparing chapter 7 and chapter eight it's like this book The Textbook kind of presents discreet and continuous I mean of course free energy minimization is an in lot of other concepts are shared between the two but I mean we get a kind of sharp distinction between using discret and continuous variables all the way down to the very notation being different your S's and O's for discret versus x's and Y's for for continuous and so on so it's nice to see an equation that can kind of relate or or compound the two to where you just need to kind of know if it's discret continuous and then similar process for each while knowing of course that discrete variables you're working with Point masses and summations as opposed to Integrations and so on with continues that's another point to be taken for the ontology sure um Peter or or anyone sure thank you Daniel um so I loved this chapter I thought it was really cool um I'm uh pretty excited by the uh the Lambda notation that was just described I was I was unaware of that and uh there's a lot to think about there um in some ways this was the chapter that uh I was personally like least comfortable with in terms of my my ability to sort of grock everything that I need to get um my personal background is mostly on the neurobo side and I have much less in the way of mathematics um I was wondering so I haven't checked out the um the references at the back yet so maybe maybe that's actually going to answer my question but I was wondering does the active infant group have any kind of like a learning path for the supporting mathematics uh that you would need to really be able to be really um kind of fluent with this chapter and like for example be able to plug in values and and do things with the model like do we have any kind of a guide of like hey if you want to learn you know um the Taylor series expansion here's where to get it if you want to learn linear algebra like here's a particularly good text um because I'd be interested to sort of take that stuff on over time thanks yeah um in the math learning kind of subsection this is you know quiescent till um or when people don't want to do it but then as people want to do it like anyone's welcome to just say this time UTC I'm going to do this uh like in Discord or however or just make the edits directly here this math learning and resources has it at least many [Music] um I think the language models are really good at this right now this kind of like um like undergraduate level math which is hard that is a good specialty of them and just put and then another possibility for with the learning is from the um equations here all the equations have been put into latch then this can just be so even if you're working with a language model that doesn't have the ability to put in a screenshot you can just put in this or look at what we have here and then look at the explanation why would a high schooler be interested what's the pseudo code where is it important what are the variables these are just tenative but they do um even where they contain like some like I guess factual you know omissions or or errors they they give it the style of what information is in the equation and just like 1 plus 1 equals 2 1 plus one equals question mark like you could spend the rest of your life truly pondering it so there's never going to be a moment okay I'm done with B equation I finally you know don't need to wonder about it anymore but then knowing that it will never be fully resolved getting to kind of just like a stopping point with feeling like you don't know at all what it does and then just seeing a bunch of related natural language um descriptions and then also our handwritten natural language descriptions which anyone can ALS so add to sometimes just seeing it written out linguistically instead of only symbolically can help especially because then you can replace x with hidden State and Y with observation and then from there that can translate to other languages but also you could replace okay hidden state with temperature observation with thermometer and then this starts to look more like the probability of the temperature times the the thermometer given the temperature and so then it's like easier to jump between a tangible example um and all these other like kind of aspects of the holistic math understanding and like Jonathan shock and Ali blue others have um like also thought about how to what what kind of math is important to lead up to the textbook group and in the in the appendices they do mention what they see as the important background areas I think it's a linear algebra so doing operations on matrices um adding and multiplying products on matrices tailor series approximations this is important for the continuous time this is where you take a point and then you try to extrapolate a continuation around that point variational calculus and stochastic Dynamics like this appendix may still not be the perfect resource to learn those four topics but the fact that they listed them out as the four topics than going to any like highly rated online course or like popular videos on these topics is probably pretty helpful linear algebra very much is and stochastic Dynamics or just statistics I think also is critically important it's fantastic thank you it's uh Beyond helpful really appreciate it Peter I'm in the process of learning all of this myself so I'd be willing to work with you if you wanted to do um something as well um within Discord or something through Cota sure that'd be great thanks are you uh sorry go good are you on the Discord just so I can uh yeah I just joined a couple days ago okay great there is a textbook group Channel um you can you can try to join in or just post somewhere if you can't find it or anything but then we can just kind of keep that discussion alive and um like yeah knowing knowing what this symbolizes helps there probably is a point of diminishing return with learning any of the background maths but also they're their own reward so they're fun to learn I might throw this into the um Kota as well but just sharing if anyone is familiar with um like corsera courses for you know for me I I've had to do a lot of learning async SL from The Institute and I I really like this one um just because um you know it has a couple courses there it's very intuitive and uh especially for anyone who wants to move in the direction of like implementing and learning with um python it mainly focuses on that but yeah the first course is linear algebra but in the context of like we're learning matrices we're learning how to multiply them and so on um and then by time we get to the second course it's multi very at calculus and so all of a sudden you're learning about like gradient descent uh with multiple variables involved so just the first two courses of of that link I shared um I find immensely helpful for at least as a starting point it just walks you through everything so yeah depending on where someone's at with their programming or engineering or anything it can help just to think of these as variables like s can be kind of H treated with one handle as like a mathematical variable and if you want to go into the um like the abstraction and the analysis and the category Theory then it is going to be helpful to just pick up S of t with one handle but then at the same time when you actually write the pmdp code s is going to be like a matrix of a defined shape so then going to the pmdp documentation and examples and just seeing like okay what shape is AB c d okay that's the whole agent that's the active inference agent that can help ground it that's not the general case but seeing how um minimal a small case can be is helpful to know like what a complete um generative model is and kind of calibrate how challenging different kinds of phenomena might be to model yeah pmdp open source package discreet time but this is a good um package that's really focused to like getting as fast as possible to the discreet time agents whereas RX infer as we're exploring week after week um is en and continuous and all these other things PDP gets you really fast to the PDP like chapter 7 model um there are great demos including that you can just open it up in a notebook you can copy the notebook or use this version and just like run it right here and see the full active inference model you can also clone it locally into like cursor. sh with a code enabled development environment and then you can chat with the code base and ask questions about like pmdp or any other package so this can be extremely helpful yeah I think that's great um I would say for for people who are just getting into this and thinking about how to set up a model as well some things uh if you want to start with pmdp or otherwise um and again if if you want to jump to modeling I would strongly recommend having a and you have the time for it have a look at Chapters seven and eight that'll definitely go over more like more specifically how to construct models um for anyone who's thinking like okay I have a particular project how do I map the variables to these different components of a a pomdp for example you could have a look at chapter 7 it it'll get into things like okay uh we have States we have observations like two crucial parts of of a model um well maybe I have different forms of data that I'm bringing in like for example someone doing something um more physiological and clinically uh based in a lab or something maybe you're collecting neuroimaging data in addition to heart monitor data so suddenly you have two different data streams coming in um you can map those as different like observation modalities is what they'd be called and basically you'll just be constructing your your matrices the A and the B and so on that account for like these different data streams that account for different hidden States that you're trying to inferring uh trying to infer so on um pmdp is great for that too uh if you are wanting to use python or at least using it as a learning tool um because all of these examples there's the T one that Daniel scrolling through there's another one that sets up a two armed um Bandit model which is like uh an agent who um you know picks from one of two like kind of slot conceptually what are like slot machines and um so you have it it shows you how to like oh you have multiple forms of data or observations that are coming in you have multiple hidden states that the agent is trying to infer you will set those up as like matrices or tensors um and that's kind of where the the linear algebra plays in and being familiar with Matrix um operations becomes really important but uh it's it's really nice yeah David you have your hand up uh yeah in regards to the choice function there would that apply to what we covered earlier in terms of the Lambda function or the Lambda operator rather see um okay we can we can look back at the lamba but about like the behavioral selection itself let's find like kind of exactly where it comes into play um okay okay so um in this this is the uh tutorial one there's going to be uh they they first have a simpler version with no planning so here's an active inference loop with no planning then planning comes into play so big big question um like AR ing when doing the modeling is like are we working with something that plants um and even behavior that kind of like seems plan likee might be underpinned by simply heris sixs like a flock of birds you might not need to appeal to it doing a long-term planning for its coordinated movement you might just be able to explain that with single time step behavior of the birds so just because something is like acting adaptively through multiple time scales doesn't mean that it needs to be planned that's a um but you may still model something from the outside as if it's doing planning um whether or not it is map and territory and all that okay now given that here's here's where when you're in um the planning setting here's where the the choice comes into play calculate expected free energy of actions so here we we actually are using expected free energy G and it it is calculating the expected free energy based upon essentially all the variables that come into play and then they um so it takes in the policy prior which is like e or habit which is just your your before thinking about what is your habit so if you're doing like a fair teas rat it might just be 50/50 or if it's a um if it's a teamas rat but it has like an 8020 bias for One Direction um then each of the policies get um reweighted the policy the policy variable sums up to one and then here they're reweighted to update to a policy posterior and then here chosen action is sampled from the posterior earlier Andrew also said you could just pick the lowest one or you can sample from this distribution and there's other things you can do so expected free energy isn't a choice function itself it's a reweighting of the likelihood of policies that then enables you to take different kinds of choice functions secondarily so would policy Q be in essence the quiescent point of Pi which one so the the so where you have qore Pi is the soft Max at negative G so would that be like a horizon Point essentially where you're measuring at um not or measuring to a distance at soft Max the the time Horizon is Big T that so here this is a five time step simulation and here policy length is considering all um combin ations of policies of two affordances so if you can go up down left right four affordances then there's 16 policies of length too and you have a range of four values with the N actions as the okay yeah the actions at each moment are the affordances policies are sequences of affordances for a given time um and then playing around with these variables is sweeping across them making like summary diagnostic statistics about portfolios of simulations is when you start to see interesting things okay great yeah I've been kind of modeling similar to this and I've been seeing similar things so I'll start working with this a bit more to solidify things perfect thank you [Music] cool and yeah as uh as Daniel mentioned earlier for anyone who's more directly interested in in modeling um again I'm I'm personally trying to learn both PDP as well as our RX infer at the same time uh two different programming languages because RX infer is based in Julia but uh we do have an ongoing Institute project Thursday mornings um it's the RX infer project and with great is that um one of the folks from bias Labs who's developing the RX infer package um is actually directly involved with that group so we we have some some nice uh communication with one of the developers basically um and there we are um going through different examples right now that ARX infer like those folks have directly made available just like we were going through an example for PDP so they've done the same for ARX and fur um there's a nice kind of reci reciprocal relationship going on because we have the opportunity to tell the representative from bias Labs like hey we think you should you know maybe update your documentation to make it clear on this particular point or something like that and then they help us with with the learning but yeah anyone who wants to kind of get more involv with that um not to mention the the ARX and fur package seems to offer some capability ilities Beyond uh maybe what other methods allow for so um we were able to look more at like continuous time models which are certainly uh in certain ways more mathematically involved with all the Integrations and so on so yeah this is a nice um example here like this is trying to model um a car that needs to have the it needs to take the right actions to exploit um like its velocity and acceleration in order to move up a hill landscape to reach a goal that it otherwise couldn't if it just put the the pedal to the floor so to speak um and so the agent like learns what um what it should do in order to reach that goal um but yeah so they're just like toy examples but um yeah super cool yeah stuff and I think useful for yeah if you have your own project that you under want to undertake using this as kind of like a foundation for that Daniel you're going to say yeah yeah yeah this this is a different syntax different language Julia um than python but with with many similarities and again like even with limited code familiarity it helps calibrate like where someone is at like this is just a coin toss this isn't even like it's not a coin tossing Quantum agent this is just like literally a coin being tossed but this can help calibrate learning in terms of like what does it take to make a coin toss and then okay here's a slightly more involved example with a hidden Markov model but um you know then this this is um and then we're also going to bring this back into the um textbook Group by looking to replicate PDP and textbook examples in RX and fur because like although it can feel and and it is true on one hand that it's like more more more flavors or like more material or more variants it's actually a very important decision that they took in the textbook to have like figure 4.3 like they're not in they don't introduce just the discreet time and then later go to continuous time they introduced them jointly to emphasize that there isn't only one way to treat time in active inference so then that's how I've been approaching it too so that's awesome cool yeah I mean it's like there's I I don't know if there's any um any oneway streets like if there's one there's another one and so having there be multiple languages it's like not about one person being able to generate all the scripts for all the languages for all the cases you know in a moment but basically code models can already do that first off and then so we're just able to look at that and then try to um connect the dots and and think what's this deeper space that's able to have multiple Julia and multiple Python scripts corresponding to a teas and then how do we make sure that that kind of like broader latent or dark space that we're thinking about is active inference and what makes something actually an active inference model as opposed to just like any other kind of broader input output cybernetic or control or reinforcement model which might be totally valid and adequate for a setting so there's nothing wrong with like not making an active inference model it's just that there is a difference between it being an active inference model versus being like a reward learning model and right so I kind of see that sorry no go ahead so I kind of see that also as like being a parameter of the time frame or the frame that that constraint is set in and so if you're using the language in that sense as a filter it would be applicable to that model for example in that discrete time range where it may not fit to another model with the same kind of parameters due to you know other other separate constraints for example you mean like kind of using the um validity of the active inference ontology to kind of check whether the script is an octave inference model yeah but in a way by being able to apply it as a filtering model without energy it it kind of reduces the friction on the surface doesn't it so if the if the language that you're using within that frame works with the frame um without it adding too much context because of you know the parameterization versus dragging dropping that filter into another model where the Lang which doesn't fit um you would have to use a different model but that doesn't make the first model not valid would that be a correct statement in that context I I think so I mean I I don't know this too broad but making model two cannot make model one invalid model two can yes and it might be be yeah it might be fewer parameters or more or more or less accurate but but it can't invalidate it's just merely another addition like into the blockchain of everything and then in terms of the ontology and the variables I mean you can just look at the variables oh added more comments here but um if you've defined if you've looked at figure 4.3 and this is the rough setup of your set you then you can ask I is there something that is here that I don't don't have and then is there something else that I have and that and either of those if you make it simpler than this um you might be dealing with a special reduced case if you add more things I mean that is pretty much all of like the research advances in active inference is like well what if we added a variance um you know parameter here or what if we added a nesting here so it's like more can be add added um and and hence the textbook just like try to throw the fast ball down the middle and show it in its like plain way and then to be able to map anything to the plane version if you can bring it back and if it's a valid return to the to the kernel you know then it's like oh it's a heavily modified Linux kernel but not everything is a heavily modified Linux kernel something else might just be a totally different construction so it might be compliment it might be better might work well with in a computer system but it it wouldn't make sense to say that it was a modified Linux kernel unless you had started with either pruning down or adding to the Linux kernel okay perfect yeah you don't want to end up in Temple OS when you're looking at Linux I would just also briefly add to that that point if like just for inspiration or otherwise but if you wanted to kind of just literally just flip through not even necessarily read but for the time being flip through chapters seven and eight and just look at the other figures going on in there they give um many more ideas of like how you could construct this from the standpoint of like looking directly at these this kind of like graphical notation um we've been talking the RX and for how it seems great to be able to use graphical notation in the first place one just for being able to track all the different variables and how you're setting up the model but then also two just like steeming on like what what do you need how does the model need to be changed or or otherwise um like in seven chapters seven and eight we get more into discret and continuous time models we also are introduced to hierarchical models you can add a second level um probably one of the most involved graphs is yeah these um like Daniel has pulled up I would say especially figure 8.6 um is is pretty great what it does is that you have a hierarchical model at the top level you have the PDP like discreet uh time uh model setup and then the the bottom half of that graph is actually um using continuous variables so so it's not just hierarchical it's also like a hybrid model so you're in including both types of variables in there uh you could almost think of this as like at the lower level that bottom half you could have something like um uh continuous time neuroimaging data and then at the higher level there's some kind of discret uh hidden state that you're using that that real time observational data to then uh infer like you know so it's um yeah it's just steaming modeling doing the mapping from uh you know reality to to variables on a graph um awesome yeah this all uh all fits together so yeah I might have to uh join you guys on Thursdays that'll be interesting thank you yeah or or um or the the RX in foras in the chat also on the math background so the SPM statistical parametric mapping this is what Carl friston at all were working on in the neuro image group at UCL in the preac and FP days and continuing um it's a Matlab toolkit it continues to be developed and the documentation is all online that being said this 2007 textbook is very informative it has like 40 or 50 chapters but they're Standalone short chapters um that that don't really reference each other it doesn't Focus so much on the ACT and control theory side because they're focused on like the neuroimaging setting of taking in um multi- sensor data doing the Sensor Fusion doing the dynamic caal modeling I find it really informative because it it quickly reviews and and uses parametric statistics non-parametric statistics and basian statistics so it's very very strong for learning about this setting which is where you have a prior on a hidden variable and then you're getting observations and then the hidden variables changing through time like neural activity control theory then then injects into selects out a slice of B to control how the system evolves and so that's why that was brought into play because if you're only observing the neural system then you only need this but then if you're going to be selecting behavioral um stimuli or you're going to be doing like transcranial stimulation or something like that you need to have um a bir directional interface but in terms of like the basic statistics and weaving together parametric non-parametric basian this is like one of the best textbooks okay awesome I think I've read some selections from it but I definitely need to uh I might pick up a copy of it I don't know how much the physical version costs but um I'm sure that there's a PDF of this one we we probably have it and also the online documentation is is more updated okay and there's and there's also tutorials for SPM um so even if you don't do neuroimaging I've never I've never been in an MRI um slash analyze the data but still just reading through this because these machines are creating a lot of data and it's a very transferable setting okay great yeah I'm interested in the noise parameters on that too yeah and comparisons the kinds of um the kinds of Statistics that you need to account for like within and among participants in a clinical study and statistical power calculations like that's really where it comes down to it like trying to understand the statistical formalisms in their nals 1 setting is almost like I don't know if ironic is the right word but the whole point is we're using distributions so that we can take in multiple data points so it's not meant to just be like kind of looked at on the Shelf it's meant to be like played around with different priors and testing how different observation sequences lead to different updates so that's kind of how I've been approaching it as well is testing as n equals z is equivalent to one which is why I asked the question in regards to the Lambda is a choice function of Z or one um but that would so I've kind of been approaching in terms of like at t0 n zero at T1 And1 and you have expansion from that set back to and will always still be the N1 Plus or n minus 2 and that sends back to just what we had started talking about earlier but yeah there's a lot there that's kind of like when when the when the when the mouse is planning it's it's now it's t equals z but also it's the next time step but also it's an arbitrary time step but to get lost in the fact that it could be an arbitrary time step it also has to be through other frames right well um next time later in the day let's just begin with whatever questions people have or other added questions to the table and upvote the questions that you like and we'll start from the top next week okay thank you all awesome thanks everybody thank you byee thanks folks take care