welcome back everyone this is our third session of the applied active inference symposium with professor carl fristen hosted by the active inference lab and it's june 21st 2021 we're here representing the dot tools organizational unit of the lab the third organizational unit in the lab and the goals of dot tools is to enable effective tool and instrument use for all active inference lab processes so that's just using the digital tools affordances that we have better as well as exploring and designing affordances for our niche modifying our niche resulting in effective action as well as innovations in tool development as with the other groups we've been meeting weekly in tools and having a lot of awesome insights related to where active inference might come into play and that's what we're excited to talk to you about some of the core insights from the work in this unit relates to learning by doing the recognition that modern systems are cyber physical everything is really intercalated with the digital and also we found it really refreshing kind of like a two-stroke engine to be sidestepping or complementing or augmenting some of these philosophical discussions with technical clarifications and two ways in which we've seen that play out on the left here is a quote from you during a 2019 dropbox blog post when you wrote that technology is the natural extension of active inference beyond the single person which of course brings technology far from brings being something artificial into the realm of extended and embedded cognition in our niche and then on the right side is a slide from a very recent talk by bert devry on beyond deep learning natural ai systems speaking to several applications in hardware and software of active inference for example gesture recognition robotic navigation and also audiometry for hearing aids and one effort that we're starting up now is a net hack challenge it's kind of a video game played in text characters and we're assembling a team with already multiple interested participants to get an active inference agent on the playing field so to speak and have people maybe update their generative model when they see that it doesn't have to be a three billion parameter neural network trained for six months on the gpu but what if it's enough to just be curious and to want to succeed those are the kinds of things that motivate us in dot tools so we can start right off the bat with asking how can we use active inference to structure the process of innovation and tool development and how can active inference concepts help us design for complex agents that are interacting in complex niches for example thinking about niche modification extension of affordances reduction of uncertainty or structuring of communications again great questions um so the use fact of inference to structure the process of innovation and tool development um that is um in itself um an entertaining notion um in the sense that um you are a realization of active inference and you know i'm mindful that um your your nice use of um the combination of of you know well the emphasis on curiosity um as the imperative that drives most of our behavior is exactly the imperative that as a scientist drives me and most of the people i know um and in a sense i would imagine also drives your initiative and your laboratory so all the questions you are asking are really you know how how do i make the next move in order to resolve uncertainty about uh about about your particular um model of how say artificial intelligence or human communication is going to is going to evolve um so yeah in that light i think there are two levels to the answer the first one is just to celebrate and um you know um acknowledge that you are engaging in the scientific process as formulated by active inference that you are on a journey of trying to satisfy curiosity that will be never ending um and that speaks to your one of your themes in the previous slide about learning is doing the only way you're going to um resolve or say that curiosity is to go out there and see what happens and that is um that that is exactly the right thing to do a more practical level answer though i think speaks to the tool development because one of the um one of the fundaments of of active inference is the appreciation that if you just want to maximize the likelihood that this uh your kind of um world model or generative model that entails the way that you exchange with and interrogate and ping a world is the right world um that is articulated out there in terms of the sense of extended cognition for example in terms of the the software tools or the your educational tools that you're you're making available then all of this is still subject to the imperative to minimize complexity so in maximizing the likelihood that these tools will be out there and in a sense you're saying this model this way of narrating uh the way that the world works you provide an accurate description that is as simple as possible so there's a you know you cannot escape the complexity i'm speaking like you're going to schmidt over now which is a good thing in this instance um so that means you've got to find the simplest tools and it's interesting that you um you you um highlighted visa's contribution because you know again just practically thinking what's the game here the game here is to write down the or find the best hypothesis the best explanation for my lived world and my me could be active inference labs and the lived world is everything that you have to engage with in terms of educational commercial or academic partners um so you've got to write down you've got to um explore the model space in terms to find the right model generative model of the way that your your system or your organization works um that um the first steps in writing down the generative model are basically to um define its structure in terms of the sort of hidden factors or latent factors and their interactions and all that good stuff um but it has to be done in the simplest way possible um so what's the simplest way of writing down a a generative model while it's to write down a bayesian um um graphical model what does that mean for the actual coding practically and the software schemes and implementation that you would either offer to people or pre-package in terms of user interfaces then it's going to be message passing on those graphs um and that and i'm trying to get back to bert davis's um factor lab a foreign lab formation so to my mind that's the simplest most generic bit of computer science that you would come across in the service of finding the right software tools to build absolutely everything because absolutely everything can be written down as a generative model if there's a generative model there it's a bayesian dependency graph if there's a bayesian pentagraph you know there's a factor graph if it's a factor graph then you know there's a message passing scheme what is that message passing scheme it's just a free energy variation free energy minimizing message passing scheme so um i would i would imagine that as tool development increases that there will be a move towards a common language that will look very much like um bert's um phony style message passing and within that um you know you've got very limited choices um which is a good thing because that again speaks to this minimization of complexity and just course graining the world and your world um at its courses level that will sustain an accurate account or a precise account of what you want to want to achieve um so i'm thinking here the tools just have to come in two flavors they have to deal with continuous state space um generative models to interface with you know of the kind you need for robotics um but also uh the other flavor will be in discrete state space and your latent states um latent um discrete late states uh models uh that you need to do say computational linguistics or you know modeling the climate in in various states um and we know that the um we know all the message passing schemes that would be entailed by a commitment to one of those two kinds of models um in the sense of generalized bayesian filtering for the continuous state space um and by generalized ui generalized courts and motion uh which generalize things like kalman filtering um and on the discrete state space side you're talking about either belief propagation or variational message passing so when you just think about it what you have to do in providing tools of a software kind or a simulation kind um you know happily there aren't many choices you have to worry about um so you know you know in that sense um all you need to do is to make sure that your tools accommodate both generalized bayesian filtering and bleed propagation and or variational message passing and then you're using off-the-shelf technology which brings us back to well what's the real problem then well the real problem is writing down the charity model what sort of problems how would you unpack those problems in terms of innovation and tool development well it's solving the model selection problem um so sometimes i think you sort of when describing the the the space of problems that are faced say with um generalized ai or aji um you know you you can unpack them at different different spatial temporal scales into the inference problem into the learning problem and into the selection problem by which i mean using bayesian model selection to get the right structure you know do i use six or twelve layers in my deep neural network do i use a convolutional model or do you use a transformer these are basically problems of um that are solved if you have a mechanics that can score the structure enabling you to select the right form so that i think is going to be um a focus of innovation in the um yeah it already is but certainly in the in the near future in terms of development and in the sense that i think the inference and learning problems they're solved problems that you can just go to burton and get your favorite uh message passing scheme or you can uh keep at the level of your educational or academic um message passing user matlab schemes that we generate you know here here in london for toy problems and what is not i think um a sole problem and will require an innovative solution is the structural learning problem or the selection problem now exploring not the right hypothesis but you know we're in the principled way um exploring the space of generative models you might want to bring to the table um and that you know that um that has many many different issues and you know things that come to mind are of course that you could do it in um in a bottom-up way by trying out new hypotheses where you get those from you get them from experts in the field because effectively they are bootstrapping themselves on the basis of our prior beliefs or your knowledge about how how something works you can do it in a top-down approach by having over-parameterized but um over-expressive models but with very weak imprecise parameterizations and then use basic model reduction to solve the selection problem these are ways that people are thinking at the moment but this thinking is innovative innovative because i don't think there are any any clear answers so um how would you use active inference to solve the uh structure learning problem well in a sense um it's already being used in the sense of basic model selection as natural selection but you really want to speed that up and make it work within your within your commercial academic lifetimes but i would imagine that exactly the same principles would be brought to me there and you know that almost answers the next one how can active imprints concepts how to design complex agents interacting in complex niches you just have to build these things as as a proof of principle and hypothesis testing and the nice thing is you know all the um the machinery and the tools that would be requisite in building these things right from the variational message passing using say forney lab through to now you've got the right fitness function when it comes to using say a genetic algorithm to explore a structured space and what is that fitness function it's it's it's the you know the evidence low bound or the variational free energy um so you've got all the maths in place this is a question that i think of of of simulating these things and providing proof of principle how you would translate that into the real world i i i i don't know at this stage i'm afraid i think you know a challenging first step would be um you know to to actually use uh robotics uh or in silico or you know sort of hardware or possibly you know a lot of excitement at the moment using soft uh soft robotics and actually um you know in you you design your niche and and um see what happens and then turn your attention to niche construction where you now acknowledge that the niche itself is also succumbing to the principles not of active inference enough in and of itself um in the sense that niches don't plan um but certainly um in the fep sort of um vanilla um free energy minimizing approach um so yeah i haven't actually thought about that before that but that's a you know an interesting asymmetry when it comes to simulating multi-agent interactions uh in the context of niche construction where often it is the case that the the niche is just the other agents in an ensemble um but if you now actually include the the environment as part of the niche that is playing host to all the denizens that are the ensemble of uh active infants agents um then i there is this distinction between um the um the ability to to plan the consequences of action um that would entail optimization the expected free energy versus simply reflexively minimizing surprisal by um um by minimizing uh free energy as an evidence bound um and put that more simply more intuitively and you're either with generative models that support planning or not you know so there's nothing i think fundamentally different between these approaches it's just if you've got a generative model that is a model of the paths into the future consequent upon what you how you act upon the world that's a much richer deeper genetic model than the kinds of genetic models that would be applicable for a thermostat or an environment um and it's likely that the environment that you know i have in mind here which is um you know a warehouse that you've got a sentient robot going around trying to collect the right things so the robot can plan but the environment the niche can't it will still conform to the principles the very you know the free energy principle there will still be particles and things that are conserved and they will still fall and behave in a predictable way that may even be a thermostat controlling the temperature but none of these things are planning so there's a there's an interesting asymmetry that gets into the game when you're talking about complex agents interacting in complex niches part of that complexity has to be a specification of whether the complexity entails planning or not and it just creates different problem spaces certainly in the context of multi-agent simulations so that's that's how i would um sort of carve up the the problem spaces um you know in terms of implicitly um problem spaces that will only be explored by doing and by doing i just mean actually realizing physically these processes in the kind of situations that you think are going to be useful for for the future thanks for the answer and it's really fascinating about using simulation so that selection can happen within the generation of for example a startup rather than between generations because of course we can let organisms or startups proliferate and then let pruning occur at the generational scale or there could be ways to design so that that selection occurs within a generation more like learning and development rather than intergenerational selection so awesome points there this could be a broad question but we're curious what areas of applied active inference you think just might be exciting promising or important so my my personal usual response to this um comes in um in two flavors the first is from the point of view of a theoretical biologist um and a psychiatrist so if you know if you can understand how a a normal sentient artifact or person behaves then that creates a space in which you can think about false inference and false learning um or certainly some optional from the point of view of um minimizing surprise or or free energy so that's a fancy way of saying understanding the computational basis of psychopathology so the you know there's a whole literature on using active imprints as a if you like a normative framework within which to um provide an ontology of false inference or failures or aberrant active inference um and why would you want to do that well if it can all be reduced just to the good belief updating and the good message passing we actually have a very um quite a comprehensive understanding of neuronal message passing and all its physiology and all the um the roles of various neurotransmitters and you know microcircuits and uranus made that underwrite that kind of neuronal message passing and implicitly we also then have a fairly um a fairly fine-grained understanding of um the role of neurotransmitters and the pharma of the consequences of pharmacological interventions in the context of uh experience dependent learning and an influence of the kind we've been talking about so from a translational perspective um literally translating um the formalism on offer from active inference into the clinical domain that would be one you know one motivation for the for developing this theoretical framework the other one is more you know more in the line of technology and artificial general intelligence so then the question is well i now want to build sentient artifacts and not only build them but build brothers and sisters so they are complex and interact and learn to love each other in a complex environment that could include me um and you know then you've got you've got um a a clear offer from active inference as to the design principles you might want to use to to actually um build these artifacts and then they're interesting questions about what the what kind of art artifact do you want to build um and we've already discussed the difference between a thermostat and a uh a sentient robot going around collecting your um your next sort of um home delivery um there are different kinds of genitive models so now you ask the question okay what are the promise the exciting and promising kinds of artifacts uh as defined by their genitive models um that one might expect to see in the future and then we get into the world of um you know genetic model support planning so we're talking about deep charity models where they have a temporal depth what are the next stages that you might be looking at well there's a also a sort of hierarchical depth um that would at some point um first of all include the capacity to deploy precision um and why is that important well as soon as you have um the deploying the precision as a process of inference you are now um you have now a normative theory for this kind of mental action or covert action so one example of this would be i don't know how the the technology but i can almost i can be assured that i know i know um what it's trying to do but thinking about transformer networks and um the way that attention selection operates in this in this context what you're saying is you can actually optimize the attention selection as an inference process using active inference or an evidence lower bound and where you're now predicting what things to attend to and what and what does you know what particular ways to switch on which which ways to switch off um and at that point you can understand that as mental action so when when the transformers or variation auto encoders start to now optimize their estimates of the posterior precision at lower layers in an auto encoder it's now acquired the capacity for mental action and it now will pay attention to various representations and possibly even various data sources that's not magical we do that every day in the sort of mdp and you know and use it to explain a lot of the attentional mechanisms implemented in in the brain if you can migrate that technology into deep learning you would have taken one baby step towards true sentience which is mental action the next uh step would be um okay so um how can i now minimize the complexity of my genitive model where my genitive model now actually includes this meta inference in the sense i am now providing predictions about my inference because i'm controlling the precision of hierarchically subordinate message passing and at that point you start to think well perhaps one simplifying um one way of simplifying uh the computational complexity of the you know the complexity part of the um the generative the the inference um would be to carve up different states of attentional deployment in exactly the same way we're talking about carving up people into biden versus trump voters you know a simple stable uh complexity minimizing carving up which suddenly suggests to you that you can now equip an artifact with states of mind so that they can be in four states of mind they can be happy they can be sad they can be confident they can be unsure and they will have to infer given all the evidence at hand including the message passing lower in the hierarchy what state of mind it is in and if you now include in terms of the sensory evidence you know the voltage on their batteries or you know some measurement of their interception you now have something that's going very very close to say ryan's um notion of um of emotions so now you've got um a part of the genitive model is now inferring what state of mind am i in as the best explanation for all these interceptive um embodied sensations not just the proprioceptive you know state of my actuators but also um you know are they getting a bit sticky um uh you know um are they is there some wear and tear you know all my batteries charge all of these things come together um as part evidence in conjunction with all the usual visual laid out auditory um uh sort of sorry acoustic inputs um to to actually um supply evidence for a posterior belief i'm in this state of mind i'm anxious my battery's running out this immediately creates different prior preferences cost functions if you like that would be applied to your policies because you've got a deep changing model that plans into the future so now you've got an artifact that not only has the capacity for mental action it's now got the capacity to be in different emotional states the next step is to say hang on so there are these different states can i now equip it with the mineral selfhood can the hypothesis that i am actually an artifact provide empirical priors that reduce the complexity of my message passing at subordinate levels that is generating um that is inferring the state of mind that i am i'm in that in turn um um um you know optimizes the uh posteriors of the precisions of various likelihood mappings or or preferences over policies so at this point you're starting to get to artifacts that could have minimal self-awareness the next stage would be that's only going to be ever um that's only going to be i think useful um when it when you consider dialectic interactions again because the only rationale for having self-awareness is to disambiguate um um self from other which means that there must be some confusion in um or some uncertainty um at hand in order to justify the resolution uncertainty justify that complexity of the model um which means that you um have to be interacting with or exchanging with things that are sufficiently like you to license the inclusion in your genitive moral of a self versus other or that you are like me or not like me so we actually come down back full circle to what we're talking about before in terms of inferring who i am i talking to so this i think this you know structurally something quite fundamental about this inference problem are you a creature like me or not or are are you like one of those are you a pet are you a plant um you know just being able to carve up this world in a way that is self-referential necessarily entails a minimal selfhood in the inferences of these that speaks to the importance of getting the the necessary evidence from the environment that would um be if you like license that degree of complexity and the only kinds of environments that can supply that degree the license that degree of complexity are when that environment that econish is actually is actually comprises other agents like me that make it if you like worthwhile me inferring oh it's me not you doing that so i would imagine then the most promising applications um of active influence in constructing sentient artifacts pets and you know carers or or convert people things that you can converse with and would be to grow them certainly with themselves but more importantly with you there so they can learn by they're doing with you there so they they want to they're curious about you and you're curious about them at that point one could argue that's the only scenario which you're going to have any empathetic interaction um you know you know with these artifacts so i'm sure there are other applications in terms of um climate change or commerce or whatever but in terms of imagining what you could produce you could sell i would i would imagine that you know a mindful robot that actually is curious genuinely curious about you because that will teach you something about itself thanks for that answer um the idea of tools for attention and of design and engineering for regimes of attention to use an active inference term is really essential and what you were talking about there with the phone first off before the internet when there weren't other devices of similar kind there was no need to communicate out and what we've seen is that as there's more and more devices of similar or interoperable kinds new levels of organization have to emerge and then i thought about the anxiety that a person might feel when their phone is running low on battery right now that sensor reading is getting emotionally offloaded to the human so we could have that anxiety on device so let's have a more relaxing relationship with our phone and then as you pointed out it would be the um incipient steps of selfhood or perhaps what they could even call a cell phone if i'm allowed one pun per symposium the next question is what kinds of tools have been most helpful in your work in research which includes many areas such as spm and dcm that a lot of people who are just learning about active inference might not be very familiar with and what kinds of tools don't exist yet but might be helpful for active inference work um so the mathematical tools so you know and i'm often asked this question uh of students you know do i need to be able to do maths to to contribute to this field um and if so what kind of maths um um i won't tell you what my answer is but what i have found useful is certainly mathematics but not not necessarily very high end this is always wikipedia level mathematics and in particular um dynamical systems theory information theory and linear algebra are probably all you need to to to to do everything really um and indeed you could read most of quantum electrodynamics as basically linear algebra with a bit of probability theory underneath it so that that has been the mainstay that that is you know you know if there is one tool that it would be the tool and the language um of maths and relatively simple maths and the second thing is to um the learning is doing um you know a c1 do one teach one um um ethos i think applies very pragmatically in this context um which means it you know it's actually um very useful if you can get students to actually build their own little um simulated artifacts um and even more useful when you know when they can actually code it out themselves which means you need access to a high level at least third generation programming language um that you know a student can get um fluent with should they want to not only to use the existing tools but you know try and write it down themselves without having to spend years training as a computer scientist so i found matlab very useful in that respect not because it's terribly efficient although i have to say actually some of the matrix operators and under the hood tensor operators are actually much more efficient than people give them credit for um because it actually came from x-ray crystallography however what's really useful about it is it uses the same syntax that you would find in a book on linear algebra which didactically or education is really quite important when it comes to writing and reading the code so we have deliberately stuck with matlab not because it's computationally efficient or that it's open source um it should be i don't think it is um but simply because it's it's configured in a way that that people reading um standard texts one-on-one texts and in the new algebra and the like would be able to see how it transcribes into a computer language so that's been a really useful uh um a really useful tool and looking ahead um i imagine that you know you one's gonna need open access and possibly more i i um i don't know could go out the way i'm just thinking about first of all people like bert and forney lab in terms of very generic very high-end specifications of message passing in computer science um that may be that that's the level you want people to actually compose their genitive models and their their artifacts and they don't even need to know about linear algebra and even less information theory what they need to know is that the language of relational you know the object relations and and how to specify just different classes of exponential probability distributions and you know is it categorical is it continuous is it always positive or it can be positive and negative and that may be quite sufficient to write down a factor graph or a generative model and then everything else is just off the shelf a little right itself um so that would certainly be um possibly helpful in the future and so i'm moving on to what kinds of tools don't exist at the moment so i'm thinking of it what i never used it but i would i imagine would be bert's forney lab facilities but uh offered as um an application or a user interface that allowed you to compose genitive models and then just hit compose a genetic model compose a genetic process the actual world that's going to be modeled and then there's click run and see what happens that you know that would that would be that would be really useful i think um having said that the other side to to to future scoping here is i repeat this sort of um leveraging um more specialized or other fields uh and the you know um amortizing certain parts of of inference or learning to infer um or indeed inferring to learn or learning to plan or learning to infer how you plan so or starting to sort of see what parts of the inference process are so conserved that they could actually be amortized and learned and certainly that looks as how that's what the brain has done for example there are people who think that the cerebellum has basically learned how the motor cortex does its online kl control or um carbon filtering and therefore um lens of fluency and a computational efficiency to the message passing which um you know we which in its absence um it doesn't mean you can't do something it just means you can't do it as fluently and as gracefully as quickly as you your as you know as you could with a cerebellum indeed when you um have a cerebellar lesion all that really happens is you become a bit clumsy um and slow um um so um that those kinds of tools your a quick and cheerful integration or importing um various amortization and deep learning technology um into a um a forney style message passing scheme that could support any kind of genitive model i think would we you know would be really really useful awesome thank you approaching this nexus from another angle what kinds of tools and platforms could inform transdisciplinary highly contextual and engaged teams that are working with these approaches active lab we hope to be working with others to be developing the active inference curriculum and body of knowledge more broadly but when teams are actually using these kinds of approaches what kinds of platforms might exist to enable their work um yeah okay i have a strong suspicion that you know the answer to this so i'm trying to guess at the answer that you you know is the right answer and i'm not doing very well here um so um i you know i think that you you you that we've already talked and and certainly implicitly in the way that you presented the ambitions uh and implicitly send the questions and you know all the answers are there whether that's trying to engage through education whether it's trying to engage through insight um using say you know embodied experience illustrations of the basic principles whether it's supplying um games or user interfaces graphical user interfaces to facilitate the designing and enacting and the playing with um gender models and an active inference i think these are all um uh your obvious and laudable ways of um of you know of leveraging um what what what what what um active inference has to ha has to offer um participatory yeah that's um i mean the the learning is doing thing and the c1 teach one do one you know keeps coming back to mind um and the course completely licenses the participatory aspect um but what kind of participation did you have in mind are you talking about sort of hackathons are you talking about sort of um playing games with active inference computers that start to start to hate you or love you or what what level of participation were you yeah stephen do you want to give a quick thought on a few kinds of participation or what does that mean to you yeah one area is quite interesting is in psycho drama they use action methods like action sociometry or spatial activities to look at how people relate to their experience in a dynamic way so physically so i've been looking at ways that spatial participatory approaches can unpack people's relationships to different niches or different workplaces or different types of embodied experience and then that could be visible to be put into active influence type geometries i see okay right right well there's a great example so um so two things um that i've come across before are the um architectural design um and the um the importance of um not just uh sort of pragmatically afford and says you know can i walk up but i can i sit there but also the epistemic affordance is you know if i look over there um what would i learn about the space around me if i go around that corner so um there is um you know embryonic interest um in in you know in my world um from um the architectural sciences and you know and architecture in and of itself that um is is could in principle be motivated it's not discipline because it's half like art and half-life science but certainly some of their ideas are very much um aligned with certain gibsonian notions of performance and also um the um the affordances the dual aspect performance is brought by expected free energy under active inference so it's not just you know am i the kind of creature that can sit on this on this particular chair but also what will i learn if i'd if i so do and so things become epistemically attractive to engage with the other domain um is um in entertainment and in music and in particular um the joy of synchronization and mutual predictability are minimizing free energy through mutual prediction uh prediction when singing or dancing together or indeed um interacting with a slightly greater asymmetry in terms of being a member of an audience um watching a band for example so um you know one of the key things that comes out of that kind of research is ways of measuring the implicit generalized synchrony that you get from having this information geometry that i was talking about before that rests upon there being um a synchronization manifold between the inside and the outside but if the outside is another inside from another person's point of view what you now have is something called a synchronization manifold so there's a mathematical image or space um to actually talk about mutual inference and mutual active influence and engagement and communication singing together for example or die chronically exchanging messages that does actually translate mathematically into movement and belief updating on a synchronization manifold and that has real world correlates you can measure that using um kinematic you're putting leds on people who are dancing together for example or measuring heart rate variability or galvanic skin responses or doing eye tracking or indeed eeg and start to so there's quite a lot of work in um [Music] in things like hyper scanning and in um you know sort of ethology and dance disciplines um where in the arts in the life sciences where they do use a lot of these techniques to quantify the degree of generalized synchrony what it would be nice to do is actually try and model that synchrony or understand that synchrony in terms of um movement on the synchronization manifold which is sort of the mutual uh belief updating and one thing which comes out of that just in discussion if not if no if no further is the reciprocal the circular causality that is necessary um to maintain um that generalized synchrony um the particular synchronization manifold we're talking about for from the point of view of active imprints of course is mediated across the markov blanket as of the active and sensory states and but in general the [Music] um you need to have reciprocal coupling um in in order to to get to get synchronization so directed coupling doesn't work um and if that's true what that means is that engaging as an audience for example or participating as a spectator will only really work in terms of establishing that generalized synchrony that you are chasing and while you're chasing it well as soon as you have a generalized symphony you've got predictability for for free for all and that's a good thing because that minimizes free energy you know more predictable you can make the world the better the better it is um from the point of view of free energy um but you can only do that if as a member of the audience or a witness to something you can actually actively intervene on it so that brings to mind how could you get for example discussion discussions with um friends of of maxwell yeah if you wanted to promote virtual concerts on you know online for example during the pandemic what you don't have online which is what glues things together things like mosh pits in in sort of carnivals and festivals um is you don't have the audience participation the the applaud the wars the you know the um the lighter waving or the light waving um so how would you get that back into into a virtual um virtual experience because that would be absolutely essential you know i think to actually engage people otherwise you know you you'll be you you'll be just a pop concert on television so you know more than just if you like um revealing the underlying correlates of that generalized synchrony in terms of the eeg traces of the the dancers or doing some sensory mapping from um the their motion to auditory import you know just making it making the sensory evidence that supports the mutual inference um more precise and more available just by having it displayed say by putting putting motion in sound or sound in motion um or eeg electrocathographic measures of performance or the audience um visualizing that and that has been done by people like paul bushur in barcelona more than that to actually um enable the audience to change what the performers are doing you have to make you know or perhaps what other members of the audience are doing so you have to empower them to close that um that circular causality to get that dynamical coupling place so you get you get the right kind of generalized synchrony so that um you know that that sort of um dynamical systems perspective on synchronization free energy minimization certainly speaks to a particular kind of participation and engagement that does indeed rest upon action-oriented approaches but crucially it's the action of the audience on the performers not the performers action on the audience uh that is is is usually what you need to pay more pay more attention i don't know if that was that the kind of thing you were you were thinking about yeah that's really a useful answer actually yeah we were thinking about that and and some participatory immersive theater type events and other participation in collective meaning making so that's the type of thing that we're looking at and it reminds me of the live stream affordance which is relatively novel but allows people to be asking questions and it enables not just efficient production of material in a one-shot approach but it allows the feedback and i can't help but add that it's that affordance for participation for example speak now or forever hold your peace that expands the wedding into the community because there is the opportunity for feedback it's not just a breakaway click it's actually something that remains integrated through the affordance for participation so i'll turn to the last question for this section how might future modeling involve large-scale patterns in social data sets and working backwards to infer their hidden causes for example in the case of pandemic modeling governance economic other situations [Music] well this is a very practical and very prestigious question because of course a lot of people are asking themselves that now specifically with respect to pandemic morals but also the people who are exercised and um have the interventional clout um when it comes to covert are generally also the people who are invested in climate change problems as well so there's a lot of um there's a lot of noise out there at the moment about um you know how we can harness the um data assimilation and modeling advances made during um the during covert 19 and keep the momentum up to tackle climate change and what you know not just climate but the economic structures that um and financial structures and informational um structures that are deeply interwoven in terms of um and climate change and my answer is going to be somewhat deflationary um um and i've had this kind of conversation before again with um um with maxwell and and john clipping and kim jones and related friends and um due actually to have another conversation with him on um certainly open um open world or open cameraman um um in the near future um there's a temptation to take all the high church of the free energy principle and active influence and epistemic foraging and all of that good stuff we were just talking about and say oh well now let's make it work in terms of understanding um say the pandemic and you don't need to do that all you need to do is to apply the good scientific principles that things like active infants appeal to to the problem at hand and it all comes back to the generative model so you know all you're saying here is how might future modelling involve large-scale patterns of social data um to infer the the um hidden causes is just a statement of we need the right generative models to make proper sense of the big data at hand and in saying the right charity models we need the equipment both to invert those models in the sense of inferring the parameters interactions using the simple tools we've just talked about they will just be lifting it from the laboratory or um you know continuing to you to use matlab um but the bigger problem is what we talked about which is the selection of the structure learning problem so this goes beyond just um higher you know how many layers do i have in my deep network much more important i think it's a factorization it's knowing how many conditionally independent factors do i need to minimize the complexity to get the right granularity the right way of carving up um the latent causes behind all the data that is available to me so i think the pandemic modeling is a beautiful example of this um because you know the factors that determine whether i infect you can certainly be written down in terms of virology and the ace receptors h2 receptors and and basically production numbers and transmission strengths and transmission risks and you know the spike proteins but that's only half the story the other half of the story is how likely are you to be at work or at home when i'm at work are you likely to be wearing a face mask are you going to are we going to be one or two meters apart so all these behavioral aspects start to become really important factors and even beyond that when it comes to making sense of the model the likelihood part of the model that actually generates the data it can become extremely difficult to optimize when you start to think about what kind of data is at hand for example just notification rates of um of new cases per day in the um of of coronavirus now you might think oh that's that's really great data it's really difficult data to handle because the different kinds of tests not only have differential um false positive and false negative rates but the different ways in which they are deployed um really compounds that in terms of the selection bias so are you testing people who are symptomatic what's the probability of being affected if you're symptomatic are you not are you doing survey testing are you doing the same amount of testing uh this week as you were doing last week all of these what would be if you like from an epidemiological or a behavioral science perspective really under interesting factors suddenly now become the most important factors in making sense of those data but you only know that when you start to do the uh the model comparison of the structure learning when you actually commit to writing down the congenital models and that's certainly what i've learned um over the past year uh now coming up for a year and a half um you know you know the future of modeling is is is um first of all it's obvious what the future is it's just basically writing down the right kind of um dynamical um state-space models that account for data but the future is really dealing with the problems of structural learning and and model selection for any data um but in particular from the big data at hand in terms of pandemics or um trafficking uh on on the web um you know or climate change um so it's a really exciting opportunity why do people want to do it well once you've got the the most evidenced i.e the you know the minimum free energy um um model at hand and you've got posteriors over all the model parameters and all the right interactions then you can do all sorts of stuff in terms of um reducing people's uncertainty about the future because you've quantified the uncertainty and explained to them things that were once uncertain about and what isn't uncertain about that has enormous implications for mental health and well-being and uh possibly even um feeding back into finance because you always hear well the biggest determinant in terms of the markets is the market confidence it's all about the uncertainty so if you can do uncertainty quantification in a principled way using um using um this kind of modeling uh you've you've done a big thing already but then you come to um monitoring putative interventions you've now got a direct um handle posterior estimate on the latent states you actually want to make decisions on so it's not the notification rates or the number of new cases in california today it's a number of new people that have become infected today and that's a very difficult thing to infer given all of these complicated aspects of the of the generative model and then of course once you once you've established the validity of this model um in terms of its construct and predictability then you can intervene on it then you can say well what would happen if i changed this or what happened if i changed that um and what would happen now what would happen in the future so that you know you're suddenly in a world of quantitative modelling um where you can start to ask some very powerful questions and also share with everybody who matters and the products of your inference so you can now start to think about having supplementing the weather forecast with a uh an epidemic forecast you know the virus in your area and tomorrow we expect you know you can also do that the markets and these kinds of things i think are going to be more important um when people um or when the current generation get to your generation i guess um start to wrestle more with climate change because they're going to want to not just know what whether it's going to rain tomorrow they're going to want to know you know at the level not just the weather but the climate what are the indicators because those indicators um really contextualize and inform their generative models about their place in the world and that global that global scale but to provide that kind of weather forecasting that meteorology beyond the weather um you're going to need to have these these state space models probably optimized and you know you know in a first principle way in relation to their their marginal likelihood on their or their um the the their evidence evidence bounds um and we've just read governance here because governance is just positive decision making based upon counterfactual outcomes so that is always underwritten by um these these bayesian beliefs but you can't get the basic beliefs unless you've got a genetic model and perhaps the consequences of action in the future uh there would be also interventions either politically or financially or um or otherwise thank you so much again for joining this symposium it was really a special moment for the lab and we look forward to continued interaction so much appreciated and we will see you all soon thanks for everyone who's watching and we hope that you participate in acton flap so thanks everyone bye