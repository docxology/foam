all right hello and welcome this is active infer an stream number 2.1 looking forward to everyone's live chats and comments big picture today we're heading towards a more structured active infra ants and apologies for the choppy frame rate audio should be fine it's August 17th 2024 and the big two topics are going to be P3 if and the 3r systems how they're being implemented in active infrance package right now let's start it off as we do with a GitHub push refresh starting active infrance we're live at 3M PT all right little bit of a Z fractal do0 on bolts and a little bit about where and how structure comes into play especially across domains within domains too and then we'll look at P3 if then 3 RS so first the zero This Acronym bolts which was used heavily and or invented by Scott David to refer to different aspects or different domains for a given Organization for example like business operating legal technical social never claiming to be exhaustive or the only possible acronym way to break it out and in a 2021 work with RJ where we also brought together the UDA Loop and the active inference generative model we talked about bolts and about the ways that organizations and entities can interact in niches different epistemic niches and that active inference can help us understand those different kinds of bolts interactions and also the the causality networks that underly bolts connections and risk patterns so bolts is one way to break up a system however there are many many ways to do systems analysis and that's what sort of motivates the usage on one hand in the shorter term more tractable what can we do today are pulling Frameworks off the shelf that exist or Frameworks that are being shared amongst communities and then more on the research side developing these meta ontologies or methods for Federation of ontologies and entity reference all these kinds of things so I think with that shorter and longer term eye open that is how we can look at some of the work happening in a p3f and in 3r okay let's go to p3f first so this code is in zero folder context systems it's a systems engineering contextual tool again not the only way to put it just the current file structure and then p3f the pattern process perspective integration framework it's actually inter framework but it was generated is a sophisticated system designed to integrate and visualize complex data relationships across multiple domains the readme provides a comprehensive guide for setting up p3f system generating synthetic data and visualizing the results so we'll look at that read me and we'll go through these steps and look at explore what the code is but first let's go to pf.com and see what the properties processes and perspectives inter framework is and that's important that it's an inter framework it's not proposing some list of things to consider for any given situation it's a way to inter relate the Frameworks this is explained in a lot more detail in the preprint publication from October of last year with Tom Wilkinson RJ Scott and I we'll look at just the website for now again there's more detail in the paper one of the things that we did in the paper was we did a meta analysis across various things that are known as Enterprise Frameworks so these are kind of whole of organization Frameworks for data management and security and other kinds of operational considerations but also across bolts domains like legal compliance and so on and they range from very simple such as the CIA famous other confidentiality integrity and availability Triad to for example developments adding different letters into c i and a like safety and cyber security on through the Arcane Baroque esoteric the cubicle an incredible Cambrian explosion of these different systems of systems modeling techniques and tools and all of their accommodating Evolutions in fact so we were able to trace out Enterprise frame Works have what we were able to categorize well last thing I was saying was The Inheritance patterns of these different Frameworks where do they add mix and and evolve from each other the different lineages we were able to copy out all of the entities and things the attributes that were described in these models and categorized them into three higher order structural categories which we titled as perspectives processes and properties so that's the basis of the P3 is taking in different ways to categorize systems and instead of going well uh oh what what are we going to do when you're using this framework and I'm using this framework we can break out the attributes from these different Frameworks in terms of PP and P perspectives processes and properties and get really detailed with separating out with full nuance and expressibility and then recomposing them here's what I did in the code here started with taking in the article and then distilling the article into a PF spec representation so that was reflected in here PF system overview and let's go see it in GitHub system overview gives gives the usage and what the files contain so let's run it and see all the pieces so first I'm going to show a full SQL type uh implementation of pfif and then going to use a Json CSV based for for a continuing Python 3 just primary p. py runs it successfully made a database let's zoom out a little bit and see what this file does this was a first kind of all-in-one approach data class patterns are defined between the P the pattern is the top level that's what connects it to Atlas pattern languages and so on then three kinds of patterns are described properties processes and perspectives so pattern gives us that top level handle on what whatever may come into any of those three categories relationships are defined as a kind of category that can be nuanced and then a P3 if is defined in terms of creating an SQ light database at the p. DB location with PP and P and their relationships synthetic data is generated summary statistics are created visualizations are created different abilities to Multiplex subset do network analysis export and import from Json are defined and then there's this main operational component where it defines it so then I moved from the SQL to a little bit more of a step-by-step explicit script based way that we can walk through the PPP here's here's the uh overview it's pfmd need for a new approach rigidity Silo perspectives integration challenges scalability issues limited adaptation what p3f does not by proposing some other list of words to figure out or to use in place of any other words but rather for taking things as they come across domains annotating or partitioning the exact ontology used by a given domain or system into the properties processes and perspectives and then giving these abilities to work with different dimensions 1D 2D 3D 4d+ Plus+ pot swap attributes Multiplex attributes do different kinds of implementations and analyses from here so let's Trace out on the step by step so first this is where cursor cursor. shc cursor. comom comes into play so using the control K which I'll do if anyone puts a domain they want to see analyzed put it in the live chat so here under the healthcare domain here's 50 properties 50 Pro CES and 50 perspectives so have blockchain video chat going down to really small processes like API request handling active inference Grant proposal structurally ensuring the theoretical and empirical and operational Integrity of a grant proposal National Security power grid immigration all these different domains science research domain let's go to the bottom and look at what else we we have pipet use in lab so this is somebody using their thumb to make a pipet we'll just add one more domain add a new domain in same format for if anyone types something I'll add it for now I'll just see what happens with William Blake's poetry and life the weird thing with a video frame rate is it's actually like my computer goes down to six frames per second not just OBS having frame limited all right awesome so we get another Jason object William Blake poetry and life properties different themes now this may be drawing from the field shift to work the thousands of documents and phds in this repo related to William Blake so this is why it's so fun to build and contribute to the otive infrance Mega repo because terms that are tuned and brought in elsewhere in the blakean components like in one prepare those can come up again now in the p3f and vice versa so it's going to be epic okay so we brought in William Blake now let's go to synthetic data this is a very short script first it loads in the Json and it parses those different domains like again the William BL like from the pipat use in lab uses the same ontology schema as the SQL with the patterns generates relationships here just randomly sampling creates the P3 export exports everything so let's go Python 3 synthetic data it generates into p3f export and let's see the William Blake so here we have the sampling of visionary imagination descript uh description for Visionary imagination it's just a this is just a um not that informative description the whole point is it's a description field and then it got broken up into a a a more granular kind of microtransaction by transaction level which is going to facilitate um analysis because also later on in this file here's the 150 IDs those are PPP 50 of each PPP were were pulled and then here's relationships so here's connecting relationship number one is connecting 18 to 92 with 146 and it has a strength of 8371 so right now that's just a randomly drawn number between zero and one but of course that could be tuned using llm statistical methods using the kind of basian graph methods for example that axle constant and others have been exploring in the legal setting so that's synthetic data let's run visualize and then analysis and meta analysis and then see all the things that come out um visualize method is going to load in the data visualize 3D Scatter Plots visualize networks visualize the strength distributions visualize heat map visualize dimensional comparisons process the domains then a wrap around even that for processing all domains and then it runs process all domains here while it's running visualize let's look over analysis and meta analysis it's pretty similar script loads the data analyzes p3f data it's going to Output some basic statistics on the sampled properties perspectives and processes as well as the relationships which it'll output we'll take a look in a second do different distributional analyses on the types of patterns distributions relationships with the strength distributions identify the strongest and the weakest relationships do a network analysis do a centrality measures like with between this degree and I Vector centrality measures do correlation analysis visualize that correlation with heat map pattern name analysis just by word word clouds cluster analysis determination of the optimal number of clusters so that's kind of interesting like if you have a situation where there's veridical information even partial uh sampled on different processes and their properties whether we're thinking in the the 3D cubic or just on some reduced number like we're only interested with the process of a and so then we're thinking about the other two just like a a slice from the cube plotting the elbow curve and the optimal number of clusters is interesting because it can be like okay so is there one big cluster in the middle of that slice or there four sep clusters in the quadrants visualizing and then it runs it meta analysis this one's going to Output um one kind of dashboard of dashboard control tower of control Towers because it's going to iterate across the analyses that are carried out and then plot differences of differences in their summary statistics so that's kind of like Mega meta but you could also think of that being very decentralized and local and empowering for example being able to think about for a farm the nitrogen coming in and out as well as electricity and the bill and Communications other kinds of things other channels other interfaces and being able to have a coordinated dashboard of dashboards for that here domain analysis reading in that's pulling up the domain analysis in terms of like parsing the basic statistics parsing pattern distributions parsing the relationship strengths parsing the network analysis then here's the meta analysis method it takes in all of that ingressed data converts it into one frame this is all logging not only is this helpful for the code which of course is being written at a massively industrial pace and style but also it can help it understand itself so then if this fails then it'll understand oh I got this printed DET terminal but not this so this is exactly the breakpoint that's what logging can do make heat Maps create relationship strength statistics violin plots domain comparison box plots total patterns relationships box plots each of these are hashtagged off with their positioning on this faceted plot that's going to come out then Network metrics seven relationship strength distribution eight unique pattern stacked block uh bar plot and then it just runs the meta analysis method so it's doing the the the visualize method that we ran might be the slowest because the creation of the word clouds can be somewhat slow however what's cool is we can open up a seconds terminal and already run analysis and then we'll run meta analysis we could follow up maybe we can do that on the side with this user warning but it won't affect the the outputs maybe it's skipping one of the outputs or it's giving it's defaulting to some step of the algorithm as the number of examples like the size of the synthetic data here's the Jason we could have generated a smaller number of relationships to have a sparser graph we could have selected a a smaller different number of um patterns that we wanted to consider so still going with a visualize still going with the analysis yeah I'll fix what's happening with this computer but meanwhile we'll prep up the meta analysis but wait until analysis is finished just so that it uses the most updated versions um this is all going to visualization meanwhile let's look at these um the structure the p3f export folder so uh briefly we looked at this one before this full Json export for each domain it gives a ID for each pattern of one of the three kinds and then the second section of the Json is identification numbers for relationships with these ramp randomly sampled uh strengths okay here's William Blake just getting popped into visualization so that one should be finished then we'll look at what's in the William Blake so this is what visualization is doing there that one just popped in okay okay heat map just popped in okay let's just look at this in there we go all right 3D scatter so here we have Visionary imagination with all those processes and just it's randomly scattered in with the relationships amongst those three okay there we go visualize completed analysis is still running let's look at the other outputs we have Dimension comparison so here because it was randomly generated we see kind of what appear to be um Speckles uniform sample distributions for each of the three ways you could project or slice like property versus process property versus perspective process versus perspective and then strength across them it's it's essentially uh uniform with some sampling variability next one in the folder is another way to see that this is a heat map so let's just zoom in on one of those big file okay so here the gradient is darker red is a stronger relationship towards 0.1 that could be like a total relevance could be a relevance realization score and then the light yellow is zero or close to zero so for example here just from random sampling Artistic integrity advocate for visual symbolism that cell is very high so that's just because we've compressed or projected down to property versus perspective but again these could be like situational awareness heat maps for for different domains we have Network this is kind of a half-hearted network analysis showing correlations between different topics which again at this point they're just randomly sampled but we could even try something like we could we'll make sure that we'll resync the cursor index and then we'll see if we can prompt it to like bring um kind of relevance to the strength values for different relationships but here's the network and then this is just a plot that's also and then oh great it pops so that was the one that was the bottom right facet from the four plot appropriately and then oh here are more coming in here's a textt file okay more are just flooding in here's a correlation matrix it's not necessarily calculating the most interesting thing in this moment but just an example okay analysis finished let's run meta analysis finish looking through William Blake look at the meta analysis and then see what we could do some tiny improvements on then we'll look three R okay here in the meta analysis we see it is going pretty fast because all of the statistics were already done let's look at what the statistics are with this text file okay 150 patterns four uh 100 related relationships 45 unique properties 43 processes 41 perspectives the pattern types were equally drawn from the 3ps there was 100 relationships they ranged from 02 to 9916 the strongest relationship was artist artistic marketing and allegorical narratives so this is where p3f is just so expressive it's like from the artist's perspective what would make artistic marketing have the property of allegorical narrative which is totally something Blake did with his writings to individuals and like for art shows so that number could be related to generating a text for ex now let's just contrast with the weakest relationship we have from the perspective of a dualism philosopher what would make artistic marketing highlight dualistic themes again an interesting kind of structural question move the 996 it's all good but then you could imagine using the llms to generate natural language like somebody saying as an artist I think that artistic marketing it's essential that it use allegorical narratives or as a dualism philosopher when it comes to Artistic marketing I just don't think dualistic themes are that important maybe that's like how they truth drop the dualism it's like no no we don't do that there network analysis clustering coefficient path lengths diameter um top five patterns by centrality measure so here we get a ranking of the degree centrality randomly drawn could be more realistic for artistic marketing painting artistic innovator Etc between this centrality you can see different kinds of centrality measures and probably just because of the structure of the graph we see like artistic marketing is the top on all but then here paintings number two and here's painting number three so just these are the kinds of like plural statistics and then paintings number four down here plural plural methods in statistics super effective correlation analysis that was the visualized graph not that informative here here's just pattern name analysis so like if that was router brand ID on the network then you could do different kinds of descriptive statistics super super fast K means clustering okay so that's what the visualization outputs these images oh here's the what the elbow plot looks like elbow method for optimal K means clustering on that p3f export William Blake poetry and life so here one could use these kinds of measures and say like okay clearly we're getting a lot of gain from going from k equals 1 to k equal 2 K three sounds good but the device only has three slots or actually that's fine and we're taking so much longer with that or whatever it happens to be okay let's go to the what the meta analysis of that looks like so here's all those folders let's just look at one more for fun let's do video chat could be live stream 3D scatter plot for video chat and wordcloud for video chat video audio quality cancellation specialist background bandwidth rendering Network again those relevant terms were not typed in manually those were generated synthetically within cursor here's what the metanalysis plot looks like big plot just an examp example not all of them are super informative here's the pattern type distributions across domains we okay oh Healthcare was even we just in terms of our library science archival science here we had an equal number of patterns proportionally from property processing perspective for healthcare Healthcare and blockchain but huh artificial intelligence it looks like our library is more about property but we don't know the absolute number but of course that could be plotted here's the uh relationship strength statistics across domains so there a violin plot and so that's on average across domains the average strength is 0.5 but because it was drawn from random uniform 01 but one of the domains like seems to have a strength average of like 0.57 so it kind of flipped 100 times or 400 times or whatever it was and it came up with a 0.57 average and then these different envelopes for like the 25 50 and 75% minimum Etc here's total number of this is uh comparing our library inventory across domains all of them have 100 relationships because it was sampled for 100 no matter how many patterns came in but apparently different number of patterns across domains total number of patterns and total number of relationships so we can say okay that's why this total number of relationships is at 100 because all the orange bars are at 100 but here it looks like Quantum Computing is the one with 43 patternss whereas the ones that are slightly more was like the ATM withdrawal of course the classic ATM withdrawal situation and the octave inference Grant proposal different processes by patterns oh H maybe there's a correlation what's happening here um Network visualization I don't think it's working right now relationship strength distributions across domains this is another way to chop up that 05 centered but each of these count one two three is a whole domain so this could be like okay across my Farm's biophysical energetic Financial communication narrative domains what is the strength distribution what are the number of patterns coming through so that's pretty cool um that's where the p3f is at as with everything just right in the live chat or set up a GitHub issue or make a poll request let's do one experiment to see like can we make it relevant like could we make the causal attribution we'll just give one try and then we'll go over to 3 R and then we'll see by then where where we're at let's go to ATM withdrawal one issue that might arise is it's kind of a long folder so first let's make sure everything's synced up in cursor okay all right syncing up the last few new things there we go also super curious like cursor devs or people who use cursor or other kinds of code assistants like this is just one short rule I provide we've also been experimenting with some Json based code sets for rule creation for code creation but I'm really curious like how do people use it what do beginner and familiar programmers in different domains find useful what kinds of rules for AI what kinds of swapping of rules of AI okay so now let's go to this so it's it resynced into the um context so we have the ID of the different patterns now let's select the relationships and see if we can get given the property slpress SL perspective IDs in this very file please update the strength field for each of these relationships so that [Music] zero veridically represents this is not important and one repri sense this is a vital consideration for the ATM withdrawal situation okay okay 0.54 to 085 0.99 drop down to 0.9 7 65 so th this could be um abject and hallucinatory in the sense it just wants to look like it's correcting the numbers that would be kind of like the ungrounded confabulation or it might be doing total perfect on the Continuum of with total perfect recall looking at the super simple operation okay ID number is just an ID number it doesn't matter what are the pp and P involved how vital is that then we'll rerun let's we'll copy the um ATM analysis and then um just call like ATM old then we'll rerun the ATM analysis from here and then it will use these new numbers okay but it only did like 60 or 70 so of course it could be just partially because um the uh computer's acting strange but let let's just see if that changing 70 to real estate matter at all actually let's just up update them all there's not that many more just 30 more try a different prompt update the could have copied could have used repos of prompts could have used meta prompt generators all these other things of just kind of typing out because it's fun update the strength field to represent the relevance of the actual p p p from close set 01 could be Claude 3.5 Sonet thing could be cursor could be my computer okay we're still getting okay 15 oh. 39 see what's what's interesting is like okay it's actually raising all of them oh this one got more for far away from 0. five but the other ones are very commonly coming closer then again it's like but that is what you'd expect from a random distribution okay so here's ATM withdrawal I'm going to rename that folder old now let's there's old in the visualizations now let's rerun analyze so once it pops out a new ATM withdrawal folder then we'll have the old one which won't be touched or maybe it was visualize we'll just have both go p3f export that was I think that's like the pure synthetic one it's it's it's kind of it's not a real domain what is it though not sure it's just it's a two-dimensional ex it's a two-dimensional two-dimensional simplification just for working with the 2D case okay here's um export Healthcare okay so how about while this is happening I'll flip over to okay blockchain so let's flip over and get a little preview so that was p3f basically got the p3f py with the SQL uh import export to Jason situation ation then there was the synthetic data which calls upon this Jason Jason that there we can just see right there Quantum Computing and AI had fewer these are just shorter lists that's what it looks like to have more processes than than perspectives so that's kind of the database for these synthetic PPP synthetic but relevant PPP and then if somebody comes up with like oh you forgot about this perspective it's like amazing contribution add it into the text file and then all future updates get this rolling improvement with that person adding what that perspective was so such a cool way to contribute incrementally synthetic data reads that Json re uh repository and then um synthesizes pseudo um I I don't even know they're really what they are but they're PPP structures visualize and Analysis they have some overlapping features but they read and do some analyses and then the meta analysis looks at the analysis folder outputs and then does a meta analysis right now just um feel free to add any comments or questions in the live chat as soon as ATM comes out we'll we'll pop back to it but first let's go to three R okay so 3 R is it's this is in the under bolts under legal 3r so let's go over to that and GitHub bolts cognitive sovereignty another day legal let's see what bolts MD is that is giving more information from the AIC paper the 2021 paper that I showed earlier but again similar Paradigm bring in the paper copy in the Raw full text even if there's weird line breaks and page numbers and stuff like that distill out say distill this with a super focus on towards the bolts and then just there it is so then that contextualizes for human and otherwise okay that's why this is b o TS okay legal legal and legal engineering that's uh some earlier playing around let's go to 3r okay so this is the 3r recognize remember respond system the folder contains components of the 3r system for functional privacy analysis and legal context so the files the repo there's the original Three R functional privacy article let's go to that first so here's the The Source this is from corporate compliance insights.com functional privacy New Concept functional privacy A New Concept to simplify legal analysis in-house counsil and practicing attorneys face challenges as advancement of Technology outpaces regulatory response this is by Joe Andrew Scott David and Lynn Parker dpri from July 2 seconds and they set up the context and problem of digital interactions and AI driven processes advancing rapidly more rapidly than regulatory Frameworks so how can privacy identity all these kinds of topics be handled they introduced this concept of functional privacy it's super cool it's really related to like phenotypic privacy and interaction based active inference based shared expectations cultural preferences Norms regimes of attention not mentioning all these things but just speaking about it more on functional privacy understanding the three Rs how how can legal counsel how can people who care stewards of different kinds of situations use these three Rs and then they end with something that reviewers always ask for like give a table of examples setting parking lot the recognized component is performed by the key the remembering component is performed by lock and the response that's enacted when the correct recognizing and remembering comes into play as correct key opens lock so they gave however many are here 10 or 15 examples and they point that this could be a a promising direction to go into so first thing I did was I brought in the plain text and just formatted it into markdown so this is just exactly what they had before and it sourced uh then using a very similar strategy to what was just done in the P3 if section there's going to be many many examples from subdomains in adjacent file a synthetic data generation step is going to happen where that Json is used to generate synthetic 3rs and then there's a 3r analysis script that that analyzes it so let's just check back on our ATM transactional friend see if that happened okay so let's see refresh okay so here we go here's old and here's ATM export let's open that in new windows so we can do a side by side this was again just to refresh this was exploring would it work old is the one where we said now update things the new one the the old was the one where the relevance strength was sampled on a random uniform 01 so that yielded this scatter plot let's look at the dimension comparison interesting so this is before and this is after we asked the llm we said okay now given what these PPP are update between the 01 interval for a relevance or like how how important is this consideration so on the whole it moved up so this is always an interesting question is like how do you calibrate because you drew the PPP from a domain so it's really PPP at an ATM like it's the person using the ATM or it's the bank's perspective or it's the keypad and then it's the security like those are all relevant so then how do you decide on the N equals 1 relationship or on the N equal n relationship like should this strength distribution maybe it should be centered at 0.5 because it's an intr domain calibration or maybe this is um calibrated such that 08 means that it's legally culpable at this level 0.9 means it's legally culpable at that level and one means this is essential this must be done okay let's look at a few other comparisons 3D scatter okay probably a little bit hard to um interpret just cuz it's 3D but clearly there's more lighter on the right side but we knew that cu the distribution shifted but the topology didn't change but that would be another prompt like make prune relationships that don't seem relevant to the actual PPP but again it all is going to be like plausibly relevant because if you're talking about like things happening on a farm it's like well there is the goats perspective on the security of the home network or you could say well that's very not important so then that's where there's these all by all and that sort of abductive logic pragmatic approach to explode prune explode prune rather than try to trace through only one thread really interesting um um would there be any other well let's just look at the text outputs so then like if it says maybe one part will will okay so here's the new one okay strongest relationship this is in the new this is in the the updated one the cash management specialist for the process cash replenishment the noise level like that that's where again there's another level it's like but who's to say maybe that is the most important thing for them it's like or maybe like noise level I don't know so okay we'll call it there with the p3f and go to the 3r but just provocative interesting to explore okay so let's now Trace through that three r situation so first let's look at three R domains this should look kind of similar and one of the future steps is of course to do a 3r p3f and there's some things we've done towards that but here I took in their paper and then in a new file just said okay control all Etc generated examples of three Rs in different domains so here we have the physical security domain so we have the settings a hotel check in the subdomains hospitality that's kind of cool with domains and subdomains then recognize reservation number remembrance is the book system responding is aign room so it it does basically line up with that sort of key lock unlock situation and that's in fact the first example key lock and correct lock um so generated here oh not sure what happened here so let's just say fix the Json JD n let's let it fix it it I think somehow either just right now or right before I started the stream I just pasted in their original table but it's like that's right that was a deletion okay so we're back all right so that's these domains um we could add another domain let's add the domain of a chess board a domain of a chess game with many examples and we'll switch from Claude 3.5 Sonet to like GPT 4 okay chess game Cool opening phase middle game end game Blitz game tournament play online match simal exhibition chess puzzle chess coaching chess commentary so we can imagine like rrr on the PPP so then we say well how would the goat's perspective on the network security of the house on the farm relate to what does it recognize remember and respond to and okay what does it recognize that's where you pop over to the active inference ontology this can be like related to observation and lat and state inference remember it can relate to learning atten memory Etc and then responds as the action element okay so we have these three R domains then three R generate synthetic data this is going to take in the Target look at this it even suggested maybe consider including chess there let's what a what an incredible thoughtful thoughtless thought ambiguous suggestion carser so check that the legal data folder exists make it if it's not there um OS make dear like cool command chosen domains education Hospitality environmental monitoring chess game then generate synthetic data is going to iterate and just make up numbers for the three parties involved just from random number from one to 100 so that could connect up to like a CRM or another database and then you go for each domain and you pick out rrr examples and assign them a Tim stamp in the UTC and a risk score from 1 to 100 save that to a CSV so let's run synthetic data Python 3 3 R generate synthetic data so here's we see a chess example coming into play so this is like saying it was it was in in in the mid of the middle game in chess the board position was recognized the Tactical patterns were remembered the strategy was executed as response that happened on August 17th at this UTC time the recognizing party was 98 remembering party 45 responding party 38 and the risk score was 88 so confabulated and delightful let's look at the legal data so it output to synthetic 3r data CSV and that's exactly also what it just in this situation output to terminal except here it's um in this format okay then three R analysis 3r analysis first checks that the output folder 3r analysis exists loads the data from the CSV that's we just looked at it's going to do some basic stats and then print a summary then it visualize the summary does word clouds bar plots for the different methods violin plot for the risk scores Heat map of the different R versus R methods scatter plot of risk scores versus the settings filing plots more word clouds these could be tightened up and improved a lot just showing where it's at time series plot of risk scores adding Jitter and then the main just basically runs print visualize save let's run it three r analysis okay here it just reads in the data count plot count plot so here's three R analysis with the files coming in and then we'll look at them in in the files here popping back up to systems bolts legal three R so completed running 3 R analysis we'll look at it in a list okay this should be fun so let's see we have one PDF and then a bunch of pgs let's look at the PDF okay this might be all them concatenated which would be awesome these could use titles count of recognized method so how many times was the book ID something that was recognized 10 whereas experiment setup so this is from the research domain this might be from the ticket maybe that was from another domain remember and respond here's a violin plot of risk scores going from zero to 100 word clouds heat map of recognize versus remember methods this is kind of cool so like this relates to the examples that were put in and sampled from so here we just see this kind of um bunch of zeros like the appointment schedule and the weather patterns were never related in this data set but the appointment schedule and the client ID were related six times book ID got related 10 times to borrower records but book ID didn't get related to any of the o to any of these other remembering situations Scatter Plots violin plots so here's oh hm so education has a lower risk score distribution than chess risk scores over time so here's just haphazardly plotted times and then it could be like we could add splines or something it's like huh all the education risks are happening more recently the red ones but they are lower on Blue there was that one really risky time back then but then it's been growing since then or maybe there's other ways to read it oh during here there was no high-risk situations let's just see if these are the same yeah cool so this one just concatenates all of the PNG into that PDF maybe with one or two other ones or something there's the cool um um let's come back to the readme so 3r uses a very similar pattern to the p3f there's a repository in ad Json a synthetic data file a script generates synthetic data by subsampling from the fully synthetic data sampling that into CSV or other Json or SQL databases and then from there you can have analyses and you could kind of run it back and you could have your own data using one of these Json formats and then all of these analytic scripts would still work so that's kind of the idea okay that's one hour if anyone writes a comment they can go for it otherwise let's just take um look back to our live stream over view see if we got to everything see what anyone asks okay so we looked at p3f and 3r p3f talked about the process of taking in the article distilling it getting the p3f spec then generating the synthetic data doing analysis doing visualization we did that let's also do a get push yeah everything running very slowly right now through int stream but again if anyone has any questions now that um p3f and 3r we went over go for it it'd be cool commit it you can see here's what it was the same file was this was deleted and that was added okay push it writing the big images but it's on the way okay all right we turned to the 3r same sort of structural process publication from one month ago more recent paper took in the article formatt at it for markdown explained importance kind of distilled down the 3r then generated more examples of 3r from that library of of plausible 3 RS that that one also was was already set up but you could imagine well let's let's even let's do one of these let's see if we can generate a 3r generate a 3r from uh P3 if. Json we'll get there okay did the analysis integrate okay an integration with p3f that's kind of exactly where we're at so but first like more future future and this is all copied down below so more future future um connections to field shift 2 that was the active infant stream number d1.1 and this is where there was the all byall field shifts the PHD dissertations the translation into different languages the explaining to different audience the evaluations from the different Grant Managers from different programs all that so this could be connected up with grants um gen 24 maybe to be shared more on soon but this is ongoing connecting to the Social and legal domains dissertation and grant opportunities discuss potential research directions and funding opportunities well anyone can make a donation to donate. active inference do Institute and they could earmark it for the active inference project and then we could possibly have some semi discretionary funding to allocate for hackathons Bounties stip in software apis in kind donations okay Q&A if anyone asks us specific question I'll look at it next steps outline future live stream topics okay let's come back to that but first let's try oh two areas this is in measure here's a some category Theory methods morphism compose morphism find isomorphisms check find epimorphisms monomorphisms that would be awesome to collaborate with the applied or theoretical category Theory and to to bring in some of that structure because there's now the ability to do these structure API calls to llms so where to check that out is in the Clone GitHub repos structured output these are some repos that I found that are using the new open AI Json structured interface for interacting with like GPT 40 mini which is the one that I had been using like last time so that's super exciting we could have Json formatted schema for everything p p p rrr AB bcde e FG and then we can use those structures category theoretically defined and have some really amazing flows like just to give one kind of look towards where it will go could go last time we were taking in the whole dissertation as a markdown file and then saying add this or that or consider this but with the Jon for each field we'd be able to have so much more flexibility in rendering we could do something like remove the author and affiliation and then that could be part of blinding for peer review or we could say for each of the methods give 100 experiments whereas if you take in the whole text file and then you say for each of the methods described take in 100 experiments best case scenario it's not confused and it's able to still come up with the experiment so best case but then worst case it just will delete some other section because it's like well I was being told to come up with 100 experiments so why did they need the introduction section and that happens in code too like if it's a huge file or if the edit is large and sometimes even if the edit's very small it'll fix the one line you'll say please fix this error and then part of the prompt that uh cursor Auto adds in is please can you know fix only this one most recent error so then it might fix like a comma and then it deletes the rest of the script just as but I fixed the comma but structured outputs is going to be epic and that ties in really nicely with the category Theory okay let's try we'll get to wrap up and see if anyone has asked a question let's see if we can generate a 3r from a P3 so new file in 3r 3r from key3 if we could do this let's try it two different ways let's try it first this will be with cursor and then we'll also try 3 R from P3 if. py this will be a script okay save them save them all right I'll make an output folder 3 rore P3 okay so first let's do the cursor strategy so remind ourself that we're wanting to make we are wanting to make R three R examples that align with at original article and use the domains entities from at P3 if synthetic data.js output output in the same format as 3 R domains. Json okay so here we go it has changed it was immigration in p3f and now it's immigration management but government accessibility was the actual one let's see if we can get it kind of refine that refine the words and add many accurate examples from the actual P3 if have synthetic data for3 R to come into coherence we we'll do the who's on first dialogue how could P3 if come into coherence we with P3 if okay now meanwhile pop over to the sidebar can I get a sidebar write a who's on first style oh interestingly it's not who's on first question mark it's who's on first exclamation point that's so funny because it's not it's who's on first that's the declarative claim but it also could be like the exclamation point overpowers the question mark that's where you get the kind of Intero bank that connects P3 if with 3 R okay so here it just didn't it didn't go Ure this is accurate oh no it's going to be funny with ensure this is accurate with at P3 if synthetic data let's just again not sure if it's the cursor version the language model my computer with this weird discreet time situation okay interesting so safe to say that among what is safe to say could include clude that this is perhaps referencing the semantics of P3 if synthetic data I'm not sure if these terms were in there but at least this prompt came through a lot better let's see add add all domains that are included and then let's see if it'll add more domains but this is so cool so just even with that cursor alone again cursor meaning rapper for all these other models it's possible to have PPP like there could be open source just like Adam pce does with sumo with the midlevel ontologies there could be like p3f here are just when it comes to traffic stops here are PPP if there's one we missing add it then that as as well as with three Rs or people would then have the biggest PPP open Source library to draw their three Rs from ensure that all domains in at p3f synthetic data are represented with veritical 3 RS here because we had William Blake there so until we get Mr Blake with the three Rs we might have to beg for that specifically though okay meanwhile but we'll we'll read the who's on First and one go so let's see how it does here okay math education interesting so it's okay okay artificial intelligence and Quantum see wow it's like but why delete those why why do that bring in three r with accurate entities and and semantic relevance from PF synthetic data specifically about William Blake okay okay but it was just one in P3 if and then classic oh so you wanted me to bring in Blake so I'll just delete everything else you had no worries so we kind of see that um the cursor method again at this snapshot moment in this one funny snapshot way that I did it gives you some of the semantics brought in but you have really hard time with the information supply chain and ensuring like are there false positives are there false negatives so before we go to three r from p3f which will be a script let's have a brief intute okay okay it's a it's a who's on first interesting with a question mark there mandalo effect situation style dialogue connecting P3 if predictive preventative and prescriptive intelligence framework with three R okay so I'm going to do another one because it's it's not going to be grounded in the actual between p3f and 3r reflecting accurately EG original and p3i off. MD so now by more explicitly bringing in the context okay who's on First p3f and 3r edition let's let it finish then we'll okay okay we'll put it where the script will be all right from p3f hi 3r I heard you from focus on recognizing remembering and responding how do you manage that that's right we help systems recognize remember and respond to entities how about you p3f what do you do I provide a flexible framework for visualizing and organizing requirements risks and practices across diverse domains I use properties processes and perspectives to achieve this interesting so when you say properties do you mean like recognizing entities not exactly properties are qualities or characteristics a system should possess like confidentiality or scalability Rec recognizing entities would fall under processes for me oh I see for us recognizing is about identifying entities like using a key card to unlock a door got it what about remembering how does that work in your system remembering involves maintaining records like an employee ID registry it's crucial for ensuring continuity and trust and interactions that makes sense in my framework remembering would be part of the processes like data collection and storage and responding how do you handle that responding would be part of the processes too like how a system uses stored information to interact with users we ensure these processes are adaptable and interoperable we focus on how systems use identity information to provide services like dispensing cash from an ATM using a debit card pin fascinating it seems like we both aim to manage complex systems but from different angles I integrate various Frameworks and adapt to changing needs while you ensure systems can recognize remember and respond effectively exactly we both help systems function better just in different ways it's great to see how our approaches can complement each other absolutely together we can provide a comprehensive solution for managing complex information systems and ensuring they meet user expectations agreed let's keep working together to bridge the gap between technology and legal requirements sound like sounds like a plan here Che to a successful collaboration cheers to that who's on P3 if3 rmd I'll paste it in but the issue was please make this dialogue much more funny culturally hip and with with esoteric hilarious multifaceted pun playay baseball pun playay keep all info about P3 if and three are accurate this might get us somewhere then we'll do the script okay okay let's just see if it's going to be funny hey three R I heard you're the MVP in recognizing remembering and responding how do you hit those home runs you got it we're like the utility player systems always ready to recognize remember and respond what's your play P3 I'm the coach with the playbook for visualizing and organizing requirements risks and practices okay let's go one level deeper go one level deeper more funny more baseball culture relevance more hilarious pun play for the whole dialogue and make it funner and longer okay we'll go one more who's on first attempt by gbd4 maybe it's kind of like humorless or something today but then we'll make the script we'll see make a script that that operationalizes this who's on first style dialogue yeah not really changing it I think I think it's time to switch up go over to Claud side let let the other side hit make this dialogue significantly funnier in terms of puns baseball esoteric references pep Pace with the culture relevance and fun then we'll go to the script this might be overplaying the hand but you miss 100% of the responses you don't prompt okay okay maybe Claude is better at this kind of dialog like so many interesting egles but definitely let's let's go with this one okay all right hey three I heard you're the Babe Ruth of recognizing remembering responding how do you keep knocking it out of the Privacy Park you beta we're the shoh Otani of systems a triple threat at the plate and on the mount always ready to recognize remember and respond faster than a Nolan Ryan fastball what's your secret sauce PF spitball ha no doctor pitches here I'm the Billy Bean of the digital world using my Moneyball approach to visualize and organize requirements risks and practices across the major leagues of diverse domains I've got properties processes and perspectives it's like having OBP SLG and W all rolled into one framework whoa slow down saber metric Superstar when you say properties are we talking about scouting reports that make Branch Ricky jealous close but no cigar or should I say no chewing tobacco properties are the stats a system needs to make the Hall of Fame confidentiality scalability you name it I'd put recognizing entities in a different ballpark that's more a process play in my league I see what you're pitching for us recognizing is like a catcher identifying the batter's tell it's all about using that key card to unlock the door to the clubhouse of secure interactions you're rounding the bases now what about remembering is that like keeping track of player stats better than baseball reference you're catching on faster than a Cubs fan hopes in Spring remembering is our Bullpen Ace it's like maintaining the team roster and knowing which reliever to bring in for the save we're talking employee ID Registries that would make Cooperstown envious it's crucial for ensuring continuity and Trust like a good closer in the ninth now we're playing ball in my framework remembering is part of the processes like data collection and storage we're turning more double plays than Tinkers to eff to chance you're really covering all the bases but here's the curveball how do you handle responding got an trick pitches up your sleeve responding is our change up it keeps the Batters guessing it's like calling the right pitch based on the batter's history but in our case it's how a system uses stored info to interact with users we keep our processes as adaptable as a switch hitter and interoperable as a well-oiled DoublePlay combo always ready for the hidden ball trick nice we focus on making sure systems use identity information smoother than a perfectly executed hit and run it's like can uring every player gets their personalized walkup music but for ATMs and debit card pins fascinating sounds like we're both aiming to manage complex systems but from different dugouts I'm integrating Frameworks and adapting to changes quicker than a manager's lineup card in Extra Innings while you're making sure systems can recognize remember and respond more consistently than Cal Ripken Jr's attendance record you said it Skipper we're both helping systems function better than a well- greased mitt our approaches complement each other like peanuts and Cracker Jacks absolutely together we're the Dream Team the 27 Yankees of Information Systems we'll provide IT solutions so comprehensive they'll make the infield fly roll look simple you bet your Pinar let's keep bridging that gap between technology and legal requirements we'll be clearing the fences so often they'll need to move them back it's a grand slam plan here's to a collaboration that'll make the shot her around the world look like a bun cheers May our partnership be longer than a cricket test match and more successful than murderer row now that is funny okay here we want to write a script that generates real generates data structured like three R domains by iterating and sampling over the records in atp3 have synthetic data the output file should be in this folder as. Json call it 3r from P3 if. Json we already had that that was that was we'll call that one cursor using cursor okay okay import Json and random random Json open the file actual one load it up for the properties processes and perspectives generate 10 samples okay let's just see what it does on this first pass okay here we can how many layers it might need another layer fix it to reference and get really to P3 if synthetic data meanwhile let's just try another layer there we go yes there we go there it is how did it come up with the rrr wow they're all using handle how is it saying that handle handle with by handle accessibility with Jitter buffer management by journalist handle crossplatform compatibility with video filtering by web developer handle encryption with error concealment by mobile developer handle qualitative insights with feedback incorporation by data scientists handle industry partnership opportunity with resource allocation by Grant administrator handle potential for paradigm shift with data pre-processing by institutional Review Board member handle short-term deliverables with a literature review by a philosopher uhoh handle qual quantitative metrics with data visualization by developmental psychologist handle generalizeability with knowledge transfer by mathematician handle economic viability with hyperparameter optimization by Anthropologist wow handle Economic Security with military training by cyber security expert handle biocurity with counterterrorism operations by border control officer handle military Readiness with economic sanctions by chemical security inspector okay handle voltage regulation with anti- islanding control by harmonics mitigation expert okay handle Talent handle Talent Development with conference organization by statistician handle peer review with techn techology transfer by grant writer handle research impact assessment with research Network building by scientific publisher handle math teacher professional development with argumentation skill development by math communication coach handle audio description with Universal Design consultation by inclusive HR specialists handle reasonable accommodations with job placement assistant by plain language expert what is that is that this we'll we'll rather than using the control K in line let's go to the control shift L what is a plain language expert please explain to me with hilarious esoteric who's on first style cool though Quantum pet use Blake handle symbolism with historical research by color symbolism expert handle illuminated printing with thematic development by theologen handle Industrial Revolution critique with illuminated book creation by spiritual Rebellion historian handle poetic language with lyrical composition by psychologist handle cultural impact with ar artistic cross-pollination by poetic Innovation theorist fantastic work a plain language expert is like a word wizard who waves their wand and poof suddenly utiliz becomes used and Implement strategic initiatives terms into do stuff they're the Houdini of bureaucratic jargon escaping from a straight jacket of legal e faster than you can say here to for and wherewith they're the ones who look at sentence like the aforementioned party shall here and after engage in bilateral negotiation Vis A the procurement of goods Andor services and say nah let's just go with they'll talk about buying stuff so remember when you're scratching your head over a government document that reads like it was written by a committee of particularly verbose lawyers just call for the plain language expert they'll swoop in keep fluttering in the breeze of Simplicity ready to transform that wall of text into something your average Joe or Jane can actually understand and if you're still confused well that's the plain truth of it check out the center for plain language okay interesting I'll go to that website wow like interesting why it went there okay all right cool so this method could be improved but that's an amazing semantic simplification handle with buy handle the box I'm sending with Care by using gloves handle this process handle this setting with this recognition by that remember where's respond H but there's so many cool sentences to explore probably other simple sentences that could be written okay well we did generate 3r from the p3f Jason so thanks to those who saw SL will see all finish this with the GitHub push then in the coming weeks pushit in the coming weeks we'll possibly return to the llm theme with the structured calls we will uh possibly return to active inference generative modeling with python Andor Julia with RX and fur so thanks everyone till next time e