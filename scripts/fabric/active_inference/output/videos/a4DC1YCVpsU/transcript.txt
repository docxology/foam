foreign hello and welcome everyone this is active inference guest stream number 55.1 it's August 30th 2023 today we are going to have a presentation followed by a discussion on geometric constraints on human brain function by James Payne and Alex fornito thank you again for joining really looking forward to the presentation and the discussion so please off to YouTube to introduce yourself and continue however you like thank you oh thanks very much Daniel uh my name is Alex vonita I'm based in the school of psychological sciences and internal Institute for brain and mental health at Monash University and I'm here James Penn who is a research fellow working in the team uh and so the idea today was that we were going to talk a little bit about this work I'll begin by providing a bit of a historical and theoretical background and then James will take over and jump into the specifics of what we did and what we found uh we're assuming some basic understanding of Neuroscience and some elements of human brain Imaging and we'll go through a little bit of maths but uh hopefully it'll be enough to give a picture and if there's any questions about it afterwards we'll be happy to try and answer them a key most learning factor for this work is really trying to understand how the structure or anatomy of the brain constrains its function and if you look at a diverse range of systems found throughout nature we know that the structure of the system can strange it's Dynamic so for example the the shape of a racing car will influence its aerodynamics and how fast it can go the folding patterns of a protein will influence the other proteins that it can interact with and quite have quite large effects so here for example we've got an example of the hemoglobin protein in a healthy person and someone with sickle cell anemia and this change in the geometry of the protein leads to a 20-year difference in life expectancy uh and here we've got the molecular structures of diamond and graphite so both of these materials are made of the same atoms they're all purely carbon atoms it's just the bonds between them that are different and that difference is sufficient to create quite A variation in the properties of the material so Diamond being one of the hardest substances on Earth and valued at somewhere between 12 to 90 million dollars per kilo whereas graphite is one of the most brittle and only cost you about twenty dollars per kilo and so this is essentially the reason why we don't propose to people with h2b pencil we use diamond rings instead now the brain is no different we think Anatomy constraints function but there has been a long-standing debate about the specific properties that are the most relevant and how we should best conceptualize them and this can be traced back to the days of ramani kahal and Camilla Golgi two people considered to be some of the founding fathers of modern Neuroscience Golgi developed a technique for staining neurons that allowed you to visualize their structure under the microscope and kahal really perfected that technique and studied the nervous system in extensive detail and really laid down the foundations for we think about the anatomy of the brain to this state now both of these men were recognized for their efforts in 1906 with a Nobel Prize but even at the award ceremony when giving their lectures they were in bitter disagreement so if you actually look at the recordings of their lectures kahal says we applied golgi's method and our observations revealed in my opinion the terminal arrangement of the nerve fibers nerve elements possess reciprocal relationships in contiguity but not in continuity so here is saying that cells are fundamentally discrete elements separated in physical space and that there's a a gap between them at the synapse the synaptic cleft and that's and signaling occurs through this Gap Golgi on the other hand didn't agree he said while I admire the brilliancy of the doctrine which is a worthy product of the high intellect of my illustria Spanish colleague I cannot agree with him on some points of an anatomical nature which are for the theory of fundamental importance I found myself unable to follow the current of opinion because I was confronted by one concrete anatomical fact this was the existence of the formation which I have called the diffuse nerve Network and so for Golgi all the cells were continuous they form one continuous Network there was no point of separation between them and signaling occurred through this continuous Network now ultimately uh the growing body of evidence and you can see it in golgi's statements was starting to favor kahal's model but really it was only resolved in the 1940s with the Advent of electron microscopy where people could actually resolve synapses and saw that they were spatially disjoint [Music] and this ultimately established the neuron Doctrine as the fundamental theory about how the nerve the system is organized at a cellular level and this basic idea that we can divide the brain up into discrete units was then carried through to different scales most famously by corbinian brodman who developed a persolation of the context based on site of architectonic grounds his idea was that different parts of the cortex have different cellular properties and so they Define these discrete areas that are functionally specialized in in some way uh and certainly this has been a very influential idea in Neuroscience ever since but around the same time in fact a couple of years earlier the neurologist Alfred Campbell published his own signal archetectonic map and he agreed that you could identify discrete boundaries largely in primary zones but then in the cortex in between there was a lot more difficult to find sharp outlines or boundaries and he suggested that actually the changes were more gradual or continuous in nature boardman's view became more popular and certainly became sort of the dominant theory in neuroscience even though subsequent attempts to try to replicate it were different and so different anatomists would parcellate the brain in different ways using different boundaries and so on but nonetheless this kind of uh congruence between the discrete model of kahal and discrete model of broadman eventually led to the idea that you know essentially we can think about the brain as a multi-scale network we're at the cellular level we can identify discrete cells that are connected by synapses then we can scale up at the population level the mesoscope mesoscale resolution and identify how population of cells are linked by bundles of axons and then all the way through to the macro scales which is what you sort of see when you look at one of Rodman's Maps you have these broad roughly sub-architectonic areas connected by white matter bundles and in the last two or so decades we've had the measurement techniques for characterizing these networks on a vast scale and there's been a pretty well established pipeline for mapping these networks so the basic idea is that we have the brain we Define we divide it up into these discrete areas and they act as our Network nodes and then for every pair of nodes we measure some aspect of structural or functional connectivity between them functional connectivity being some aspect of coupling in activity and then we can represent that in the form of a connectivity Matrix so each row and column represents a different region and each element tells you about the type and strength of connectivity between areas that can equivalently be represented as a graph and then with that graph representation we can apply all sorts of different analytic tools to understand different aspects about how the network is is connected and organized and this is this basic approach has been used quite extensively to understand how the underlying anatomical properties of the network constrain function this is one of my favorite examples this was a study of two different worms C elegans and pacificus both of their nervous systems and the head have been mapped at the level of each cell in synapse and they're actually identical so they've got the same type of cells the same number of cells it's just the connectivity between them that's different and that's what you see in this network projection here that the topology of the network is different and in this study they showed that changes in the connectivity of just two Hub neurons were sufficient to elicit a difference in the behavior of the animals such that pacificus is a predator of c elegans and here you can see pacificus eating poor C elegans for lunch now we can't lock humans up in a room and see who eats who and try to understand how their Anatomy constraints function in that way but we can do things like use MRI to measure anatomical connectivity and functional connectivity and correlate the two and it's pretty consistent in finding that we generally find there is a correlation between them uh we can run computational models where we have a structural Network we simulate the activity then we apply say a lesion to that Network and look at the effects of the activity and we can show for example that if you leisure in a hub area you have quite a dramatic impact on brain function compared to a theologian a more weakly connected non-hub area or we could use clinical studies we could look at cases where there are naturally arising lesions through a stroke or some other form of brain damage and we can understand the functional impairments that result so for example in this case uh people with lesions to certain types of Hub areas with diffuse connectivity showed much more generalized cognitive impairments than people with lesions to areas with more specific patterns of connectivity so this is great this has been really informative and great for understanding the role of individual brain regions or Connections in brain function but it doesn't really give us a coherent unified perspective about how Dynamics emerge from the underlying structure it's all a little bit piecemeal now if we want to develop such a coherent understanding we can draw some inspiration from different uh the physics and Engineering where typically the structural constraints on the Dynamics of a system are studied by understanding the eigen modes of the system now the arguments of a system are found by solving an eigenvalue problem such as this one so an eigenvector we can think of as something that we measure about a system that doesn't change its direction if it's subjected to some kind of transformation so if that's the case then this equality holds so the idea here is that PSI is our Vector something we measure about the system subjected to some transformation L and uh if PSI is an eigenvector then the transform eigenvector is equal to the eigenvector just scaled by some back value so we can the transformation can scale the vector but it doesn't change its direction and so if that's the case then this scaling Factor Lambda is what we call an eigenvalue and PSI is an eigenvector this kind of equation is applied to a lot of different systems a lot of different contexts but when we're studying the eigen modes of a system typically our L term here is is an operator called the laplacian operator which essentially describes how smoothly some kind of structural property of the system varies through an appropriate spatial embedding so I'll come back a little bit to what that means because we can make different choices for what we use in L and that determines the specific anatomical properties that we prioritize but for now I just want to emphasize that a key property of these eigenvectors is that they're orthogonal and so that we then we can use them as an um a basis set for reconstructing different activity patterns that we might see in the network so I guess the most famous example of a basis set that many people will be familiar with is a Fourier set so for example here we have some one-dimensional signal and we can decompose that signal as a weighted sum of sine and cosine functions of varying frequencies so here you've got the the different functions different frequencies and here you've got some weighting factors and we can reconstruct this signal as awaited some of these functions in a similar way we can extract our eigen modes of the brain based on some particular anatomical property and we end up with these spatial patterns here that are organized again in terms of spatial frequency or the wavelength of fluctuation so here you can see you've got a very low frequency fluctuation moving from Back to Front top to bottom media lateral and then as you move up you get these more high frequency fluctuations and so then we can use these patterns to reconstruct any spatial map that we observe on the brain so it could be a map of brain activity recorded during a particular task it could be say a map of cortical thickness variations or gray matter volume variations it's sufficiently General to allow you to reconstruct any type of map and so we can do that just as a weighted sum so here y represents our map and then we represent that as a weighted sum of our modes with the a coefficients representing the weights and people oh sorry um I should emphasize that that explanation can be a little bit abstract for people who aren't familiar with eigen modes and it is always a bit of a challenge to get an intuition and so you can do what one of the people in the team did and and US chat GPT to explain eigenmodes to a 10 year old and it turns out that it does a pretty good job I was quite happy with this explanation so I thought I'd share so I'll check gbt says of course let's imagine we have a wobbly jiggly ball of jelly when you poke it it Wiggles and shakes right now imagine if you poke the jelly in different spots or with different amounts of force each time you poke it differently the jelly Wiggles and shakes in a different way eigen Moes are like those different ways the jelly Wiggles and shakes when you poke it so essentially seeing this video here the jelly is poke and it wobbles in a particular way if you poke the jelly in a different spot or with a different amount of force you'll trigger a different pattern of vibration and so commonly eigen modes are used in the context of systems that vibrate and the idea is these eigen modes correspond to Preferred patterns of vibration when the system is perturbed and those preferred plans are just dictated by the structural properties of that system we can we can extend it more generally and think about it more as how a system responds to any type of excitation and how an excitation spreads through some connected system and the eigen modes correspond to the preferred patterns of excitation again determined by the physical properties of the system so naturally given everything we've been talking about and these ideas that the brain is a multi-scale network we need to make a choice about how we Define our laplacian what specific anatomical properties are we going to extract our eigen modes from and so a natural choice would be to extract them from brain connectivity right and we can do this quite in a reasonably straightforward way we get some map of the connections in the brain we map connectivity between every pair of nodes after we apply some discretization we Define our discrete nodes we map every pair of connections represent that in the form of a matrix and then we extract this quantity here it's called a graph laplacian it's the details are not so important but that's essentially our L operator here and it describes how smoothly connectivity varies as we move from node to node in the network and when we do that we can several Studies have shown that you can use the eigen modes extracted from this graph laplacian to reconstruct kind of classic functional networks that you record with functional MRI we can reconstruct different patterns of functional connectivity between Pairs of areas you can use it to reconstruct different EG signals and people have even shown that you can make predictions about the pattern of neurodegeneration that you see in different forms of dementia so this has been really fantastic important work and a really important proof of principle that this eigenmode framework can be used to understand how the structure of the system constrains its Dynamics and in each case the interpretation is that these dynamical patterns that we see with fmri or EEG or so on are reflecting excitations of these underlying eigen modes or the resonant modes of the anatomy of the brain this view very much aligns with what we would think of as a classical view of a brain organization that I've just been discussing so following from kahal and broadman's work the idea is that lots of different scales we can divide the brain up into discrete areas they're connected in some way and it's the signaling along these connections between these discrete areas that drives activity but there are reasons to think that particularly at a course of scale so we know at the fundamental cellular scale the network is discrete but at coarser Scales perhaps a different set of approximations might be useful so if you look at dense reconstructions of neuronal tissue so this is say with electron microscopy you find that cortical tissue is extremely dented it's like a really rich thick forest of cells and their processes and as we've talked about the there's been a lot of debate about where you can actually draw boundaries between discrete areas and how valid that and reliable that is outside some kind of classic examples saying in primary cortex and if you look more deeply at the cellular organization of specific regions here on the left we've got the cellular organization and on the right we've got a myelin stain you see you get these deep penetrating fibers that are coming in from the white matter this is what this kind of classic graph approach will pick up because we divide we Define our nodes in the cortex and then we're mapping the connections that pass through the white matter they can also say that there's a lot of connectivity that's moving horizontally or tangential to the geometry of the cortex and so these horizontal connections allow for the continuous spread of activity so rather than actively jumping between discrete nodes it can actually spread as a propagating wave [Music] and you know just to emphasize the some of the limitations of the discrete model uh not long after broadman's work just a couple of decades the renowned physiologist lorento Deno was pretty emphatic about uh his his concerns with the approach he said the only really good site of architectonic pictures are those of Campbell who let me put in capital letters has been the only side of architect honest who has described facts and only facts the German cyto architect honest has mixed facts and theory in such a manner that nobody can tell where facts ends in theories begin so again this is just emphasizing the idea that while we might be able to Define discrete areas at a mesoscopic or macroscopic resolutions in some cases especially around the borders of primary sensory or motor areas but large swathes of Cortex those distinctions become a little bit blurry so an alternative approach has emerged out of neural field Theory so neural field theory has been around for several decades now and this is a different approach to thinking about cortical activity so the basic idea is that instead of dividing the brain into discrete specialized areas or nodes we can treat the cortex as a continuous shape and we actually uninterested in trying to capture our patterns of brain activity propagate through that continuous shape and so this is something that you can see in diverse types of electrophysiological recordings so this for example this video is of the Dynamics of voltage sensitive dyes recorded in in the mouse brain and you can see that you observe these propagating waves of excitation that move continuously through the cortex rather than jumping from region to region as would be implied by a kind of strongly discrete model so a big emphasis in neural field theory is on describing these wave-like propagation patterns and it's been shown in recent theoretical work that if we accept that wave like propagation drives neuronal activity then really the eigen modes that we should be extracting or prioritizing are those that are derived from the geometry of the brain so our eigenvalue becomes this problem here where this operator here is called the LaPlace Beltrami operator and it describes how smoothly the geometry or the shape or the curvature of the brain varies through space and just to briefly explain why that's the case here we've got the wave equation that's used in some forms of neural field Theory lists the divisions that we've been focusing on and so the basic idea is that the firing rate of a given population of neurons B at location R and T is given by the afferent field of incoming population so other populations a so we've got other populations providing this afferent field of activity that determines the firing rate of B and obviously we then need to describe what this afferent field looks like and that's given by this part of the equation here so on the left here this set of terms describes how the field evolves through time we're not going to focus on that today over here which is what we're interested in where we've got how the field is evolving through space and so here we can see our friend the LaPlace Beltrami operator which describes the geometry and here we've got the length scale of axonal connectivity so in this model we make a very simple assumption about connectivity we assume each point is connected to its neighbors in a distance dependent and isotropic way and that distance dependence is roughly exponential so the idea is that areas nearby to a given location are will have a strong influence and that influence declines roughly exponentially as a function of distance and uh that the the speed of that decay is given by this R term here you can see that geometry is firmly embedded in this equation now I should point out this isn't something that's just been plucked out of thin air this is a damped wave equation that has been used for centuries to describe wave Dynamics in all sorts of different media and so from that physics we know very well that the geometry of the system constrains the spatial properties of the wave propagation and you can start from first principles of neuronal biophysics and derive this equation and given all that work we know that the eigen modes of the LaPlace Beltrami operator actually correspond to the standing waves of the Dynamics so what are standing waves so in this simple like example we've got two traveling waves here a blue and a green and as they interact with each other you get these patterns of constructive and destructive interference uh represented by this red line here that cause these very large amplitude fluctuations that are fixed in space right so they're not actually traveling like the original carrier waves they're fixed in space so that's why they're called standing waves and they're a nice example of resonance so these fluctuations in the red in the red Trace are much larger in amplitude than the original carrier waves so it's an example of resonance where we're getting a larger response in the system than the energy that we put in and just to convince you that this is something real here for example we have a pool of water a classic wave system if you apply vibrations at a specific point in in the pool you see these waves that travel out they hit the opposite wall reflect back and start to interact and then you see this the emergence of these standing wave patterns that are fixed in space but show these very large scale amplitude fluctuations uh another classic example is the clubny plate so if you arrange dust particles on a plate and then you apply some vibration at a particular frequency the dust particles will settle into these uh complex patterns uh the pattern is determined by the specific frequency that you apply and specifically where you apply the vibration and the pattern the patterns correspond to the eigen modes of the plane and again those patterns are determined by the physical properties of the plate things like its stiffness its geometry and so on gratuitous but you can extend the idea to three dimensions and you can actually cause the particles to levitate again in this case they're trapped within the nodal lines of sound waves that are being projected in three dimensions and this does have real world consequences so this is a video of the Tacoma Narrows Bridge in the 1940s the engineers didn't pay enough attention to eigen modes and so on this particular day Crosswinds hit the bridge in just the right spots and are just the right frequencies to excite the eigen mode of the bridge so you trigger these resonant responses and create these large-scale amplitude fluctuations that ultimately led to the collapse of the bridge so uh hopefully a background has kind of Illustrated that there's sort of two different views of thinking about uh which anatomical Pro properties of the brain might be more more important in constraining Dynamics so on the one hand we have the classical kind of connectome centric view in which we view the cortex as comprising discrete areas and Dynamics are dominated by node to node transmission uh the connectivity between areas is topologically complex and not homogeneous and we very much think that that's very important and so we prioritize measuring that we don't really directly account for the spatial embedding of the network or its geometry we can look at it secondarily but it's not baked into the model and because we're interested in connectivity that means we need to measure it so from a practical perspective at least if you're dealing with mirror Imaging data you need a T1 weighted image to measure brain anatomy but also diffusion MRI image to be able to measure brain connectivity foreign the other perspective which is a geometrically informed perspective that arises out of neural field Theory views the cortex as a continuous sheet we're not making distinctions between different areas of the cortex we think Dynamics are dominated by propagating waves of excitation especially these mesoscopic and macroscopic scales we approximate connectivity between different points of the cortex as being being homogeneous and distance dependent so we know that there is a strong distance dependent in connectivity it doesn't explain everything so some things are missed but we know it's certainly an important feature so then the question is how far we can get with this approximation and a nice feature of this approach is that we are directly accounting for spatial and geometric effects the physical properties of the brain which are overlooked by the the connectome approach the nice practical benefit of this approach is that because we approximate connectivity in a simple way we don't actually have to measure it we can derive our basis set simply by looking at the geometry of the brain and surrounding it a T1 weighted scan which is is very standard in MRI experiments so hopefully that's uh set the scene for thinking about different anatomical constraints in the brain and which ones we might want to prioritize I'll now hand over to James he'll talk about how he went about testing these different ideas and trying to understand which constraints might be more important for Dynamics all right thank you Alex sir I'm gonna focus more on the things that we found in the paper that we recently published I think a lot of you have the link for it but there's no incentive message if you want to we want us for the the link so basically we start with we're trying to answer and test the theory on which modes of the brain uh could best uh describe activity measured in FMI so we'll Begin by how do we actually measure these modes so uh geometric modes are based on the T1 weighted image which is a standard Imaging tool that people use in the field and you can extract a model of the cortical surface uh here on the right and this there are robust pipelines to do so and you can do that on a population average sense basically you get a group template of the surface or you can do that on an individual basis uh on the other hand connector modes need diffusion MRI and structure MRI because you need to kind of align the two and then we run a cryptography pipeline basically finding connections between regions in the brain uh and then from there you can construct a Vertex level or even a region level connector Matrix basically it's a matrix where each element represents the connection of one region or one vertex to another region or another vertex and you feed these cortical surface or these connector Matrix in the eigenvalue problem equations that Alex has mentioned in the previous slides and then how do we test the performance of these geometric and connector modes basically we focus a lot on FMI data so we uh there are several open access data sets in that are available for example the the popular human connection project which is uh which roughly has about 1200 participants but we focus on 255 participants who are completely unrelated there are no Twins and no siblings and within the human connection project that I said you can for each subject uh they have what we call task evoke data basically these are functional activity was that that was recorded was each participant was performing a particular task and hcp has a suite of seven different tasks in within each task several several different uh uh contrasts within it and then we also analyze resting state data basically State data is where the the participant is just inside the scanner and just not doing anything and you just scan uh brain activity uh through time and you can construct a functional connectivity as well where each element of this Matrix represents how correlated the activity is between two regions we also analyze data from what we call nervo so they say it's an Open Access repository of thousands and thousands of different maps that people have contributed and each map was acquired with distinct experimental protocols and we talk about 10 000 of those from your evolve uh and again uh it's a the level of um heterogeneity in the different tasks uh is quite remarkable in the neurobot so we wanted to make we wanted to um do our analyzes on on quite different tasks to make sure we are capturing something really meaningful so just to remind uh yourselves of what we're going to do next so basically Alex already mentioned this you extract for example the spatial map say that's the task about that and we decomposed that into different sets of logging modes so these patterns could be the geometric modes or they could be the connective nodes and it will be weighted by a coefficient a and the weights represent how each mode is expressed uh for that particular map and you can truncate the number of modes that you can that you want to use and then you can reconstruct back the uh the the data by just taking a linear sum of the coefficient multiplied by the geometric or the connective modes so what did we find by doing these analyzes so first I'm going to show you this uh how the spatial Maps look like in terms of reconstruction so on the left I'm showing you the different tasks of special maps and these are group average maps for the human connection project data set and again these are the seven tasks for that data set and then we ask okay how if we use about 10 modes uh how would this potential map look like and for this result we're focusing on the geometric modes so the Reconstruction looks like this from afar you they look quite they look quite different but if you actually look a bit closely it already captures the kind of the large scale uh core scale patterns that you can see from the data for example this relational map you can clearly see these the emergence of this big pattern now what happens if we incorporate more modes into it so we increase the number of modes to 100 and now you can see that the Reconstruction almost uh looks like the empirical data but there are still subtle differences especially especially in the mobile localized activity for example here in the IRS and if you increase it further you can see that we can better capture those isolated localized patterns uh just by increasing it to 200 modes so you can see that the modes are actually really an efficient basis set for task develop data we do the same for resting state data we increase the number of modes in here and compare the functional connectivity of based from the empirical data and the Reconstruction and we see the same thing that has to increase the number of months to 200 we can connect we can capture the empirical data and you can do this in a more systematic way by calculating how well can we can reconstruct the empirical data just by you know taking the correlation of the empirical and the reconstruction in reconstructed Maps as a function of an increasing number of modes and we see that indeed the Reconstruction accuracy increases as we increase the number of modes and up to 200 we can get about you know 80 85 to 90 accuracy which is quite efficient given that uh we do the analysis on a on a cortical surface with about 30 000 vertices so mathematically the maximum number of modes available to us is about 30 000 and using 200 out of the 30 000 we can already reconstruct the data quite uh efficiently and then we now so we've shown that the modes are quite powerful and efficient in representing uh the data we now test the hypotheses or the the questions that Alex has laid a while ago that are the geometric modes more parsimonious than the other anatomical modes and when I say anatomical mods again we're focusing on the connector modes which is based on uh the connectivity Matrix but we also test another anatomical mode based on uh an EDR rule so an either rule is the exponential distance rule Princess Alex has mentioned a while ago which is that us because the Assumption of near food theory is that the connections are very localized and also uh organized in a distance dependent way spec because specifically uh the connection white changes exponentially as a function of distance so we want to test that uh hypothesis on how dominant that exponential distance effect is set for the the details we just created a synthetic network based on a simple probability of connection following an exponential distance rule with a scaling factor or an exponent in Alpha which we matched from empirical diffusion MRI data and again there's a lot of uh empirical evidence of the existence of this exponential distance rule so it's not just a a hypothetical theoretical kind of assumption we see the effect in mechanics if you follow the wet uh as a function of distance from track tracing data and this is in uh logarithmic scale you see this linear curve which represents an exponential in uh linear coordinates and we see the same with human uh diffusion MRI data that the way changes as a function of distance in an exponential distance way and even in in other species like Mouse rats marmosets and so on so forth so this is a universal property found in a lot of the different species so this exponential distance through connectivity would be uh is actually uh empirically valid so by using these three different uh anatomical properties we can calculate the modes using the equations that Alexis mentioned on Largo and you can get these geometric modes on the left connector modes in middle and the modes from the exponential distance through connectivity on the right and again the modes are arranged in quite a unique way in that the first couple of modes will represent the low spatial frequency or patterns with very long special wavelengths and if you go further down you can get this high spatial frequency or short special wavelength patterns so it's a very uh so the basis set that the modes provide can capture different scales of the data so how do these and anatomical modes compare when we now reconstruct uh the different FMI data that we have so for resting state functional connectivity We compare the three modes Again by measuring the accuracy as a function of the number of modes and you can see that the geometric mode outperform both of the connector and the EDR mounts but you can see that the either modes are quite um close to the geometric modes but so again suggesting that the the fundamental effect that the EDR connectivity uh that's in in you know empirical data so they like it it highlights the importance of this simple but uh important exponential distance through connectivity and we can see the same thing for by reconstructing the different tasks activation maps that we have again I'm showing you here the difference so it's the geometric minus the connector and geometric minor stedia reconstruction accuracies and red means the geometric modes are outperforming the the other anatomical modes so in all the assets that we have the results are quite consistent so again you suggest that the geometric modes uh are more passive values uh than the other anatomic anatomical models that we have and then we we golf it bit further on how do we actually use the concept of these modes uh in analyzing uh for my uh activation Maps so I'll just kind of just want to explain a little bit of what the traditional approach we have in brain mapping research so for example you do an experiment you capture the activation map shown here for a particular task and I'm showing you here the kind of the 1D version of that so the value of the activation versus the vertex in this cortical surface so what traditionally what we do is to uh because we because we want to highlight we want people ask okay if a person does a particular task which regions of the brain are kind of driving those the the behavioral performance that we had when whilst performing a particular task so what people usually do is to threshold these Maps uh and you can set professional barely arbitrary and then you can get these clusters of activity and we we then make a conclusion that these clusters of activity are the ones kind of driving the behavioral uh effects that we see whilst performing a task and people can even go further and you know hone down exactly really really highly localized regions if you increase the threshold but if you go further back uh we started from this whole brain activation map you can clearly see that by thresholding you're actually removing a lot of important you know activity patents uh that are sub threshold but they but they do exist so it's kind of like uh the analogy is you know it's by doing this these thresholding approach you're just looking just at the tip of the iceberg you're ignoring a lot of the important properties of the iceberg that are not seen by the threshold that you sent so what we can do is to use the mode approach to actually look at uh the uh and and kind of look at the properties of all the of activation maps and here on the left I'm showing you here the power of each mode so basically the whites that we obtained from the reconstructions that we had no longer and the figure on the left shows you the results we have on average for the human connection project data set and on the right is for the 10 000 maps from your local so what you can see here actually is most of the power is already is contained within about zero you know about 50 modes and if you remember the modes represent and each mode represents a different wavelength and they are arranged and that the first couple of modes represent these long spatial wavelength uh spatial structure so what this means is that actually in in FMI activation Maps most of the power is is within those long wavelengths kind of suggesting that indeed by even by performing a particular task you you are actually activating these almost whole brain uh yeah yeah so you can see this almost whole brain activity that again you will miss out if you do some thresholding effect and the further emphasize the importance of these long wavelength patterns we did a simple experiment where we tried to remove say the first couple uh long wavelength modes and that's the solid curve that you see in here and by doing so we start removing those long wavelength modes we the Reconstruction accuracy completely drops even by just removing 25 of them but if we just remove the you know the short wavelength modes so starting from the right the effect on the Reconstruction accuracy is not that uh significant so again alluding to the fact that these long wavelength modes are really important uh and they describe uh the important structure found in the activation maps from FMI done so again so we've shown how the modes can explain and and represent spatial activation patterns what happens with the Dynamics and the way we can do this is we go back to the Crux of the neural field Theory which were to be the geometric arguments were based from and neural theory is very generalized you can you know construct different populations of excitatory inhibition neurons and you can even connect the thighs and so on so forth but the important bits to remember is that we feel theory that relies on the idea that activation propagates through space as waves and simplify the the experiment that we want to do because we want to model the activity as a function of time we just focus on the cortex and we simulate the equation based from the wave model and we tune the parameter but if you look at the equation there's there are only two parameters and we fix one of them so basically the model is uh only relying on tuning one free parameter and what we did was to compare that with uh a more sophisticated mirror Mass model so there are mass models rely on the connector so basically you have regions in the brain that they are connected and the connections are based from diffusion MRI and each region will have its own dynamical properties so they evolve through through time so it relies a lot of this on this connection and again local Dynamics but it's important to highlight that this highly sophisticated model has about 19 parameters and we fix about 15 of those but we still need to kind of tune about four uh so in comparison to the weight model again don't wave model only has one and what we did was to how well can it recap recapitulate uh functional connectivity uh data so here I'm showing you an example for the empirical functional connectivity that we have and the resulting model based functional connectivity for both the wave and the mirror Mass models and we can uh kind of quantify how well the the model based functional connectivity results uh stack up with respect to the empirical data in a in in a variety of ways one can look at how well that's the edge FC so basically each element of this Matrix Compares between the empirical and the model based data you can see that both models are you know performing quite similarly we can also look at the average connectivity within each region so basically you're taking the average of a row or a column and you can see that the wave model now outperforms the mirror Mass model by a bit and you can get further because these properties the first two properties are based on static FC basically you you're kind of averaging the effects across time but we also mentioned our two models compare in capturing uh dynamical properties full time and you see that the way model actually performs uh the neural Mass model and so in summary for this it's just to show that the Simplicity of the wave model uh can capture a lot of these properties of functional data again highlighting the the idea that this wave evolving or traveling in in space and time in the brain is probably a good approximation we also simulated uh the effect if we stimulate say the visual cortex so we just ping these beautiful cortex and allow it to the activity to propagate uh through space and time and this will be the propagation starts from the physical cortex and then it goes to the frontal uh uh cortex and I think I want to highlight one observation that we found is that we can see that when we started from the visual cortex the activity starts to separate into two and in The Psychology and Neuroscience literature people operate have actually found this effect and they call it the separation into the dorsal and ventral stream and each stream has important uh cognitive implications but people have uh tried to explain the Separation by capturing the complex layer specific activity in the video quartix but what this simple experiment that we have done has shown that maybe the geometry and the idea of waves propagating could be sufficient in uh obtaining these uh kind of physiological effects um and then we also tried to compare it with how well because it capitulate the visual hierarchy that people have found in primates for for example this work by uh uh in the last uh a couple of years where they uh also did a simulation uh where they stimulated the the beautiful cortex and what they found was if you followed regions along the visual hierarchy in the Maca cortex you see the activity patterns are kind of delayed in a hierarchical way so they follow the same kind of uh relationship as the visual hierarchy so we did the same thing we compared the activity the amplitude of the activity by matching the regions that people found individual hierarchy of the Macar cortex and we we tried to find the regions in the human brain uh and then we see the same effect and then we when we compared it to a typical measure of hierarchy in the new Imaging Space by using the intercortical map which is just the ratio of T1 and T2 we see the affected the time to peak of these activation patterns uh what captures the rack of the intracorical Marine again highlighting that indeed what we're getting is capturing this this hierarchical kind of processing uh uh starting from Individual cortex and think of the last result that I want to highlight is the uh the subcortex because again the brain is just not it's not just the cortex uh so what we did was to also calculate the modes from subcortical regions and what we did was to mask the subcortical regions and perform the same and uh solve the same equation using the LaPlace with primary operator and you can get these Arguments for the thalamus spray item in the hippocampus and we compared that to what we call in the field as functional gradients basically they are representations uh low dimensional representation of racing State FMI data so what we did was to compare the geometric modes for the different subcortical structures and the different functional gradients based on FMI data and you can see that the modes uh uh almost perfect in perfect correspondence with the functional gradients and we see the same effect for the different structures again probably highlighting the idea that the geometric effects that we solve in the cortex are much more dominant in the subcortics that geometry really constraints function um just to tie things together um what are the advantages of this approach that we found first it's a it's a more physical understanding of the relationship between structure and function based on ideas in physics engineering that has been used in the last century the direction modes are only based on T1 rated images so it's very simple to perform and the analysis can be done by anyone with a structural T1 weighted image and hence you can apply it in quite different experimental contexts in both humans other species health and disease and finally to summarize things I hopefully we've shown the geometric modes are indeed more parsimonious than other anatomical modes and this is confirming a lot of the predictions from theoretical uh calculations of near field Theory and highlights the importance of treating the brain as this uh really physical system in correspondence with what we people are doing in physics and engineering uh but it also highlights the idea that the effects that we see in FMI might be dominated by the effect of this simple local and exponential distance for connectivity however uh the the uh the contribution of long-range connections are still there but the uh what we're highlighting is maybe the uh their influence may not be observable with the resolution that we currently have with FMI data so it would be interesting to see and perform these experiments in a much more highly resolved say track tracing data from other species uh that we found that evoked activity is dominated by these long wavelength modes which is pretty much challenges a lot of the traditional approach we have in the new Imaging field where we focus a lot on these focal activations and that traveling waves shaped by geometry are sufficient to explain a lot of a lot of physiological phenomena by you know that they just emerge from the model and we didn't begged all these physiological phenomena into the model uh and finally the geometric constraints seem to be universally uh exist in both cortex and subcortics and that we can only we can use one single approach to study the you know the whole brain uh quite nicely and I just wanted both Alex and I would like to thank all the other co-authors of the work he has been a truly multi-institute collaboration all the Open Access Data set that we have used and if people are interested in doing our analyzes we have written an Open Access uh software package repository in GitHub you can access that in here so people can you know analyze belts in the brain in quite different contexts that they want to do uh and I think that's where we want to end thank you awesome well thank you for the great presentation a lot of places to go first all past to Dean um thank you gentlemen I I I first got into this paper through uh another individual on the active entrance community and I think I was the one that may have pounded the table that we might want to do a a guest stream on this and it's ticked the paper and really brought it to life so thank you very much I really appreciate it especially some of the dynamic images I think it really helps in terms of explaining what you guys were trying to um trying to do your work with in your and your subject matter on so I'll just start with that I have some questions later on but just first of all thank you for uh for a fantastic um explanation thank you well you present this in a neuroscience setting what's a common response or reaction from the introduction I could really tell how careful you were to speak to the totality and the different threads in Neuroscience so after all that set up and all the statistical analysis that's presented where does that put people in terms of their own understanding of the way that they've been doing complementary methodologies or orienting their research questions that way yeah I think um and generally people I mean at least we found that people are quite interested um I guess the approach is a bit different to how a neuroscientist would typically think about the brain but kind of aligns with how say you know a physicist might now Lively start approaching thinking about or modeling the brain and so the work was really trying to bring those to kind of perspectives together um you know I think the reaction is is usually kind of yeah this is this is really interesting um you know then how do I how do I make sense of it or what I do practically um you know there has been I guess there is some people might kind of split split it artificially into this comparison of odd geometry versus connectivity um which is probably not the right way to think about it um it's you know the way we like to think about it is that um you know we're sort of comparing two different models and each of those models makes certain approximations and prioritizes different features um the you know the approach we put forward in this paper emphasizes the role of geometry and it does have connectivity embedded in that model it's just a kind of simplified approximation of connectivity this kind of homogeneous distance dependent kernel um whereas you know typical connectome Centric view will try to capture all the complex connectivity but we'll ignore also the horizontal connectivity um that really is what drives activity spreading through the brain that's completely ignored and so really you know the idea behind this work was to kind of test in a way between these two approaches and you know say which one's approximations were kind of more useful in a sense do you want to add something or I can make a comment there no finish finish this because then I'm going to ask my questions about the cello yeah well the statistics was very clear and and it was very interesting how with two different data sets there was similar curves with also very different number of samples so it was almost like the the some of the statistical distributions were latched onto relatively early and then that like captured the big continent and um a lot of the connections are local this is and this is of course a topic to explore about the molecular and the mechanistic electromagnetic basis and whether this to what extent it represents traveling propagating electrochemical waves and or loading heavily on simply diffuse local connections and and even the the blurry line between those two so it is really like a question about what is being captured because even the EDR with the spread captures a variance component related to local abundance direct fast acting connections in some regions and distance connections maybe over the days digital connections really do matter as as the the jello sets and things change but at the exact time scale that some of these patterns are happening at your work is showing new information and comparison with different ways it's been looked at yeah um I mean I think one of the things that it highlighted well I even probably just you know in my head is we've been focusing a lot on trying to capture the effects of this complex connectivity right and we ignore all these lateral horizontal local you know diffusing uh connections but what the work has now kind of shown it highlighted the kind of maybe the issues that we have with FMI right maybe you know because truly the both of these roles happen probably you know simultaneously right but just the effects that we're seeing in FMI but it's probably not the most efficient way to capture Both Worlds uh or it cannot hung down the specifics of one world over the other uh in the resource that we're getting is that the effects of this you know very localized connectivity probably dominates uh a lot of what we see there FMI uh but time will tell if you know we improve the ways we capture brain activity that we can really kind of particularly focus on the different aspects of the approximations uh to me that's the kind of the beauty of the work it now highlighted these effects into the you know broader audience yeah I think the the FM I mean you know everything that we've presented is really addressing things that we measure with fmri so on pretty coarse spatial and temporal scales there's some theoretical work suggesting that kind of you know the more complex aspects of connectivity that can't be explained by an EDR I play an important role in supporting Dynamic transitions between different brain States um but that would happen on a very rapid scale that could be missed with fmri at least a typically organized fmri experiment and so one thing we're interested in looking at further is trying to pick that apart a little bit and trying to isolate the functional contributions of those more complicated connections foreign can I ask about the metaphor of the the spoon tapping on the on the cello there the metaphorically speaking that seems like it's like an external perturbation on a on something that can respond to that now he'll appreciate I'm I'm asking from a very naive point of view and uncomfortable with it is there any difference then in terms of say something that happens interceptively like something that's simply coming from within system and does that does that show up in the same way as when there's a response to an external stimuli yeah so you know the actual underlying model a key component that we haven't really talked about is that you have uh thalamo cortical loops and there's a driving input from the thalamus that influences the wave activity in the cortex and uh you know they could be sensory thalamic nuclei or they could be interceptive inputs as well and they are would be expected to drive cortical activity in different and especially non-uniform ways um you know really distinguishing between those different types of inputs as far as I'm away hasn't been modeled yet it's all been kind of a a simple level where you treat the cortex homogeneously and you have a single thalamic nucleus I mean some people have started to split them up um but you know that would be that the underlying principle and the model could be extended um in such a way that you could potentially distinguish between interceptive and extra receptive inputs I just want to add for example the visual cortex experiment that we perform it's a really simple perturbation right but it could represent different types of perturbation we just can't you know particularly capture at the moment but it's like an overlying if we perturb it in a certain way this will be the effect that we see uh but yeah you might also know what I was going to ask next thing because that was the direction as well as that visual cortex example so so from the active inference Community one of the things that we're always dealing with is surprise say versus sensory attenuation and then on the third vertices the seeming unawareness prior to the surprised or the attenuated state but still available and so I'm kind of curious when you move away from the visual can you still have these sort of same waves going through the brain because other sensory uptake is causing that same you get a surprising feeling like a sense of weightlessness perhaps right or you're you're an astronaut and that's now something new you become attenuated to what is there I know it kind of stuck with the fmri but it just seems so the possibilities in terms of what you guys are opening up just seems really interesting is that something like the intercepted thing where you can see this now having up new new areas of inquiry I mean yeah so I think there's some really interesting work where um people have looked at um recursive neural Nets uh structured in such a way that you can get wave-like propagation between the elements of the network and have shown that the systems that have that wave like propagation uh it actually facilitates their ability to predict what's happening in the same movie um so it improves their predictive performance uh physiologically people have shown that you know just with simple visual stimulation you get these back to front propagations but there's also front to back propagations which are presumably encoding the predictions and so then the question is uh how do the top down predictions in the bottom-up sensory will get reconciled between the interactions of these waves um you know I think these are kind of really interesting ways board that we're still coming to terms with and we're not we haven't really quite [Music] um made sense of what the what the wires mean for computation I know that Peter Robinson who's on the slide here has written a couple of papers um talking about how these fields can relate to predictions um yeah but yeah I think this is kind of a very new exciting area that um is worth exploring yeah one kind of connection there is like the standing wave that you showed in the physical water pool and so now when we're looking at a solid color visually there's some State and there's some stable non-equilibrium steady state or stable representation or stable population code or all these different things which which may not be um exhaustive or incompatible like at all but there's some standing wave now maybe that is component number 99 just like principle component 99 it's amplitude might be small but there's like some mode that is that's ramping up and its Associated positively or it's ramping down it's Associated negatively and and there's some standing pattern that emits the pelting of new sensory observations and like a Bayesian updating setting it is remaining the same now the more inertia you have on the distribution the more stable it's going to be which is like equivalent to saying the less attention you pay to sensory stimuli the more stable your your priors are going to be it could be a prior about perception it could be a prior about action and there are descending motor patterns as well and all these different modes are being played like in an apartment building and there's like different songs but they're happening in different frequency spatial temporal and frequency bands so that we can tune in to different songs like different radio stations but with more spatial richness it's a total expansion of the palette that recapitulates certain aspects of topology and helps us even identify residuals that are are most apt to be explained that way but it also opens up to like these big waves that get filtered out like by low pass potentially filtering in different data sets so that shorter term relationships can become more apparent but that can be the Ripple on the wave and so end up throwing out a huge amount just of the sheer information contents of Rich dynamical data sets yeah really interesting concept trying to wrap my hair around it uh yes it's it's really cool because you know again we we still don't know what because what we found is that for example in a different task data that we have not all modes are equally excited certain modes are excited in quite different ways and we don't know what yet what these combinations mean truly uh behaviorally cognitively and but yeah we'll we'll keep working on it as far as and see what happens yeah ask one more quick question so so I appreciate the geometry part of it um so does any of this speak also to the the sort of the tunneling effects of the sort of that eigen value or eigen mode eigenvalue Quantum piece where it's you know you could be rotting the surface of this and appreciating that the the parsimonious speaking speak to that surface effect is there anything about this that also helps us understand better how something goes you know from through the wave like quite literally across from one one slope past the crown and on to the other side or is that again something that you guys weren't really spending a lot of time on but I did notice I I pulled up the paper and I noticed on page 11 you were talking about some of the ways that you were analyzing the volumes so that's the context that I was curious about that sort of tunneling piece to go along with how we sort of follow the the patterns on the surface well I'm not quite sure I follow you asking how let me try to let me try to see where it comes as I see it Dean's a Quantum tunneling connoisseur post even and uh with the basis set of the sine wave it's like imposing this kind of oscillatory pattern and then you're you're up waiting or down waiting but is it possible to use a basis set or is it possible to detect modes in your analysis where there's like an effect locally and then there's like a then there's like a tunnel and there's like a region that the wave doesn't appear to pass through um by the way thank you Daniel we're stumped I guess it means on what you mean by tunneling right so like each mode like if you look at the high frequency modes they are quite patchy and so they'll be sort of disjointed areas of high amplitude and low amplitude but they fluctuate in time right like then there's standing waves and so they'll kind of alternate up and down so in a sense it looks like there's coupling over long distances um but um that's just due to the standing wave Dynamics which is just driven by the interference pattern of the traveling rights um so you know I'm not sure if that's kind of what you're getting at but I guess yeah from a perspective of just if you're just looking at the standing wave Dynamics it would look like things in spatially disjoint locations were kind of uh coupled in some way okay it's like one jello it it stays put where you hit it and it stays put one mile away and it oscillates between like a jump rope um or it could be hit somewhere that's also very variable then be like the opposite of a jump rope with one one mode and that's what's captured in the set of functions that are then parameterized so then when you assemble them or when you um superimpose them you you could get like um kind of digitized looking outcome patterns in terms of the real empirical correlations and it's map not territory and it's tempting to interpret these very literally as with many statistical tools one I think as we've discussed like there's there's multiple possible mechanisms and and in your paper and in your work you probably thought of many many mechanisms that lend themselves to like unique empirical predictions but basis set decomposition is used like in SPM which is kind of like the one of the precedents of active inference and and the work by Carl first and others it's using basis sets as well so yeah they used uh they used it everywhere do you have any closing or or near closing like thoughts or where does the work go how do people what data sets are Salient or questions or cognitive phenomena or like what are you excited about for your lab and for the fields your left I mean there's there's a few different uh ways that we're interested in in progressing it um so one is I guess trying to reconcile this uh purely geometric approach that makes a very simple approximation with connectivity with the actual connectivity of the brain and trying to understand if the contributions of these kind of complex connections are not so easily revealed by classic fmri experiment or what are their contributions to Dynamics and is there a way of kind of uh bringing some of that complex connectivity into the into the wave model and trying to get some traction on that question um another aspect is we've done the simplest thing we treat all areas of the cortex is homogeneous but we know that's not the case areas vary in terms of the cell density degree of myelination level of synaptic complexity and density and so on um and so that in a sense could be imagine you could imagine that as changing the effective geometry of the cortex and so we're playing around with how do you introduce the heterogeneity and how does that change the mode structure and uh does that have an impact on your ability to reconstruct Dynamics um we're then also interested in sort of taking this board to leverage these approaches for thinking about different ways in which we might be able to map brain changes in different disorders or or variations across species and so on and so kind of like um you know classical SPM analyzes but making inference at the modal level and seeing if that can provide some useful insights so there's a few different strategies any other comments or thoughts yeah Dean where do you go after this Dean in your own neuroimaging career no stop it I just think it was a very clear picture and I really again I really appreciated the paper itself um but today's presentation sort of brought it to life and made it a lot I know that you guys were really trying to focus on making sure that you got all of your your uh uh all your formalities in in a row but just the way you presented it today made it a lot it made it even more come alive in terms of the the the mechanisms that you use to sort of come up with with a clearer picture but that's what I came up with away with so again thank you very much thank you thank you yeah we'll look forward to seeing the continuation of this trajectory you're always welcome back so thank you both thank you thanks guys see ya bye thank you