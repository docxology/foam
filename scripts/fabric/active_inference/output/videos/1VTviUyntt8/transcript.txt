hello and welcome to the active inference lab this is active inference live stream number 20.0 on april 15 2021 i'm daniel and i am here with blue who will say hello hi i'm blue knight i'm an independent research consultant out of new mexico thanks for being on blue and looking forward to this conversation welcome to the active inference lab everyone we are a participatory online lab that is communicating learning and practicing applied active inference you can find us at the links here on this page this is a recorded and an archived live stream so please provide us with feedback so that we can improve on our work all backgrounds and perspectives are welcome here and we'll be following good video etiquette for live streams 20.0 is a contextualizing stream for the upcoming discussions that we'll have on april 20th and 27th about this paper the emperor's new markov blankets and we'll have some of the authors join us as well so this will be an awesome discussion here we are in number 20.0 and the goal of this discussion as stated is to set the context for the upcoming discussions that we'll have on number 20 and number 20.1 and that is about the paper the emperor's new markov blanket by yella brunberg at all and the link is provided here the video is just an introduction and us kind of working through the paper so that we're ready to interact with authors and really grasp what they're discussing and we'll be going through the usual sections of the paper um any uh just overall thoughts before we sort of lead into it blue just what did you like about it or what drew you to the paper i liked this paper i thought it really provided an overarching view of the markov blanket and its use throughout like historical use and also throughout the the first in context so i thought it was really thorough and gave a good treatment to all of those topics nice agreed so the paper is emperor's new markov blankets and the links provided here the aims of the claims of the paper that's where we're going to start with the aims and the abstract and the roadmap to just see how the authors laid out what they're going to be trying to do so we're going to evaluate their aims and then see whether the claims they make are valid and whether they support their aims that they laid out and they write i'll read the first one blue the aim of the paper is twofold first we want to explain how it has been possible for such an innocuous technical concept as a markov blanket to come to be used in order to settle central debates in the philosophy of biology and cognition so that's the main key aim here is how did we get here how did we get to debating a statistical technical concept like the markov blanket and having people talk about consciousness and emotion and multi-skill systems so how did we get here with the markov blanket and then blue you can go for the second name and what you thought it meant they say we will trace the development of markov blankets starting from their standard application in bayesian networks through the role that they play in variational inference to use to their use in the literature on active inference which is what i had said about the paper that i liked they say we will argue that in the course of this transition a new and largely independent theoretical construct has emerged one that is more closely aligned with the notions of sensory motor loops and agent environment boundaries do you have any thoughts on that daniel it's gonna be the core distinction that we're going to hit probably 50 times is that there's two ways to talk about boundaries maybe the ones that really are there and then the ones that we infer and that's what this paper's about so here we go to the abstract markov blankets have been used to settle disputes central to philosophy of mind and cognition their development from a technical concept in bayesian inference to a central concept within the free energy principle is analyzed so that's the historical component of the paper then there's the sort of distinguishing part of the paper we propose to distinguish between instrumental pearl blankets and realist fristen blankets pearl blankets are substantiated by the empirical literature but can do limited philosophical work first in blankets can do philosophical work but require strong theoretical assumptions both are conflated in the current literature on the free energy principle and then their conclusion is consequently we propose that distinguishing between an instrumental and a realist research program will help clarify the literature good good on to the road map which now has a 55 miles per hour speedway on the left side for the rapid run through they start with introducing bayesian inference and really walk through it in a nice way that we're going to walk through as well and go from kind of the simplest form of bayesian inference to surprisingly nuanced forms that introduce networks like bayesian networks and that's where we get to this concept of a pearl blanket and then it's by tracing the history and the citations and the formalisms around the pearl blanket and the markov blanket that we find out where it intersects with active inference which is where the authors propose that this fristen blanket concept sort of surreptitiously or without being noticed starts getting deployed in a way that's um sort of sometimes one way sometimes the other way but it's actually the looseness around the definition that in their opinion gives rise to uncertainty which is not what we're about here and in section five they really just provide more examples with walkthroughs and graphs and figures that we're going to walk through today with how is the pearl blanket different than the first and blanket sense of the markov blanket and then how does that relate to this key distinction at the end between inference with a model versus inference within a model so kind of like generative models versus generative processes that's going to come back and um it's a great paper so we hope that you listen to these discussions and also read it any thoughts on the road map nope it's going to go fast yes it's a long period yeah so the title of the paper uh is an allusion to the story called the emperor's new clothes so people can read through the way that it's written here but um the emperor's new clothes is a interesting story it's a polycymous story there are many meanings of it so what is the emperor's new clothes about blue in general or what what is it doing here in the title and we can definitely ask the authors but what do you think it's doing here so in my understanding of the emperor's new clothes it's definitely like without reading the screen it's a story about an emperor who wants who goes to like the best you know clothes maker in town gives them all kinds of money and the clothes maker proceeds to make them clothes that are invisible and then when the emperor he sees essentially maybe what he wants to see in the clothes like sees this you know and dresses himself in them and then goes parading throughout the town naked because the clothes are invisible and then the child says hey that guy's naked yeah and then here's what part i had forgotten was although startled the emperor continues the procession walking more proudly than ever so it's like it's not like oh and then he was so embarrassed that he stopped doing it so maybe it's a story we'll keep in mind and we'll ask who are these characters or what do the authors mean by that but also at this sort of general level why why does this paper matter why are we talking about it and studying it and discussing the implications because it's good to be clear when we're talking about science or philosophy and uh an unfortunate reality of science is that it's easy to slip in metaphysical claims into uh so-called facts of the world or even just measurements of the world and it's not good to slip in ungrounded metaphysical claims and then also this realism instrumentalism distinction is something that has been dealt with basically in every field oh is it the model of language you're talking about or are you really talking about language or those kinds of differences between systems as they are and systems as we model them is something that is a nomadic concept so to see it appear in active inference is cool but also it's exciting to be involved with the authors and see how the scientists and the philosophers are actually dealing with this question in a new way at a new time scale because of maybe the way that they're communicating with each other the big questions in the paper like sort of beyond just what they set out to address would be like how is physics related to metaphysics what what can we study about electrons and temperature and mass that would tell us anything about whether a spirit exists or what's really out there beyond plato's cave how is scientific modeling related to reality and then a big question for a lot of us and a lot of people outside of our active inference community is like what does the free energy principle and active inference really say about pragmatic concerns and then totally independently what do they say about philosophical concerns and it'd be awesome if they were 10 out of 10 on both but what is the actual reality of what these frameworks tell us about pragmatic concerns and philosophical questions what big questions resonated with you blue uh the biggest question really that resonated with me i think is is are we you know using the right tools to study the right things so i think that you know when we think about um active inference and cognition and statistics like are these all you know should these all be represented by a markov blanket like is this the right the right thing to study this with i don't know how how unified do we want models and systems to be on that this is sort of the last little general signpost before we plunge into the free energy principle and active inference and everything it's just a little distinction on maps and territories because realism and instrumentalism it sounds really philosophical and there's isms and it sounds like a belief system but it really boils down to this map territory distinction and so the authors wrote in our view the free energy principle literature so whatever it is even if you've never heard of this idea it consistently fails to distinguish between the map a representation of reality and the territory reality itself this slippage becomes most apparent in their treatment of the concept of a markov blanket so if we're ever getting lost in the weeds with fristen and pearl and instrumentalism realism we think like map in territory and then what's really cool about this topic especially in the active inference setting is that two of the papers that are cited in this paper as relevant prior work are mel andrews's paper and also thomas van s and ns hibilito's paper and these were on active inference 14 and 15 and now we're here in number 20 so it's kind of like we're going quickly and we're speaking with a lot of the authors and then also on the left is um a paper that i co-authored with rj and another colleague mikhail and we kind of stepped back even further than active inference and just asked what does it mean to map across systems and we highlighted that sometimes when mapping across systems and using the complexity science approach people use bayesian statistics networks and predictive and counter factual approaches those are kind of like three key ideas in making some systems similar to each other or comparing different systems and those are um citations to the active inference literature because active inference is drawing together a lot of these different domains that might be seen as different like bayesian statistics network science cybernetics ecological psychology i mean there's different words because they're different areas but we're actually coming at it in a new way and that is why we're thinking about maps and territories in a new way because it's not just like cognitive maps yes or no or maps in the city yes or no it's a lot of new things coming together which is why it's good to clarify adding on to that uh is the fields and glaze book paper that we did that um you know mapped the the two spaces right from one to the other like the cat the category theory yes nice the mapping and so and then what if the map is the territory so let's get to fep so for this breakdown every time in reading a paper we get to reintroduce the free energy principle because it's always good to start with sort of a first pass on what it is because this video might be someone's first time hearing about free energy principle and also it's a good opportunity to see how the authors frame free energy principle and then use that as a scaffolding for our understanding and our curiosity instead of us trying to get to the best explanation week after week after week we can develop our understanding week by week but then always be inspired by the way that authors have phrased it in their writing so on the right side with the colors i kind of broke down into like almost haiku or just short sentence a little bit what they were saying and what it comes down to is that the fep is a normative mathematical framework so normative like it says what should happen like evolution by fitness maximization says that it should be maximizing its fitness that's kind of similar it's not saying what you should do but it's saying how systems should be and it's about systems that are self-organizing and how they fit into their niche fep is drawing on physics inspired machine learning approaches and so part of the appeal and the excitement of the free energy principle is that it brings together machine learning and physics and math with also potentially some qualitative dimensions but even without dipping into the qualitative or the aesthetic or the embodied or the inactive at the very least from a control theoretic perspective the free energy principle adds in a lot of features that are absent from other frameworks like network theory alone bayesian alone or predictive systems alone combining those types of approaches in a really interchangeable way with system properties like learning attention and action planning is very powerful active inference is a theory that is a corollary to or it's a compatible implementation of systems that are broadly construed under the free energy principle and then they kind of close the authors do with the recognition of a of a claim that you'll see in a lot of places that if we could have a theory of everything or a multi-scale system then it would be great so that's what motivates people to work on the fep and why a lot of people are excited about it anything to add on that blue okay it would be great i'm excited about it a unifying theory of everything let's get to it let's get to it now we wanna just like you said with are we studying the right systems with the right tools so this is what the fep is and um very um intentionally it appeals to things like control theory and measurement let's take it into the deep end with metaphysics so the author's right the fep has been applied to metaphysical questions so these are very different than action planning learning attention these are going to be related to questions that are metaphysical like what are the boundaries of the mind and the citations are in the paper what are the boundaries of living systems so what's really there ontologically what's the relationship between mind and matter like what is experience all these kinds of philosophical questions about qualia um and even things like is gaia real or is there a scientific uh basis for talking about gaia or sort of earth level awareness or at what level could awareness exist and more we're probably all curious about a lot of questions and it's not like we need to a priori classify them into physics or metaphysics um but that shouldn't make us think there's no distinction the questions that come to our mind we're curious probably about a lot of stuff so we want to be open to questions as they come in especially ones that are framed in new ways and then also be trying to approach them rigorously because as they raise here it's a web of formalisms it's true that it is a web because we're gonna walk through it in the order that the authors laid it out but it is a web of concepts and so even for those who are experienced in the field but especially those who are new to the area or as they call it a layperson not only are there distinctions that are unconventional but their implications are not always obvious like assumptions or axioms or relationships that have maybe very non-obvious conclusions or implications especially when combined and then the two risks here are it might appear to be and actually mathematically unjustified but at the very least appear to be and that might warrant the unintended smuggling in of metaphysical assumptions like i have information theory i can calculate it and here's who's conscious and who's not conscious i would say that's completely unwarranted what do you think good example yeah i think that's i mean that's like the main critique right of of iit so i don't know i think that it's a good example and how can we say who's conscious and who's not when you can't even give consciousness an adequate definition i think i don't know but we're solving unanswerable questions but that's the joy of it cool yep we talked about the consciousness side in some of our other discussions but suffice to say that there's kind of a distinction between the questions on this slide which are related to stochastic systems and action in the niche and then the metaphysics which are things that you could imagine even robots would debate over like who is really a robot like us or whatever they ask so how does the fep relate to active inference they write active inference is a process theory derived from the application of variational inference to the study of biological and cognitive systems and we're not going to read this whole piece but active inference is a process theory so it specifies how processes play out which we're going to go into a lot of detail and it sort of takes something that's initially static and it figures out how to take a bunch of equations just there on the page and actually link them in a way where it helps us think about how systems work in their flow so we take a bunch of equations that relate variables like estimates and action states and sensory states that are all happening at once as analytical equations in the fvp and then active inference is a compatible architecture like a skeleton or a style of model that implements processes compatible with fep what would you say about that i think that you summed it up well uh i mean the authors you have a couple points here that are highlighted so the fundamental imperative of active inference is to minimize free energy so this is the fep the free energy principle um and and then the other point is that uh you know this is also the the question that i had at the beginning are we using the right tools to study these these phenomena right more specifically we can ask what role the pearl blankets might play in active inference so yep we're going to be seeing how this technical concept entered the discussion of metaphysical questions and it's almost like active inference as applied to biological creatures is where we see a lot of it coming into play and yep we talk about active inference throughout so we'll kind of return to it so now let's that's like the modern stuff right fep and active inference let's pull back to base and to bayesian statistics and build up in a new way how we're going to go from simple base to modern base so blue what would you how would you start us off or what do we need to know as we go on this like little base uh several slide journey so like the one sentence or maybe like this the short summary that i give about baze like bayesian statistics versus frequent statistics and frequent to statistics which is like what most people are taught um in school like when you flip a coin the probability of it coming up heads half right 50 percent of the time it comes up half bayesian statistics accounts for the fact that like the previous 12 flips have all been heads right like so what would you if you have flipped a coin and you know it's a fair coin if it's come up heads 12 times in a row like the next time you flip it don't you think it's more likely to come up tails right like so the bayesian accounts for what has happened in the past uh when it's it's not accounted for in frequent statistics at all nice and um just to go through the notation because we are going to be kind of going through the notation as they write it's a recipe for calculating the posterior probability so that's the probability of x given y and x is the hidden state of the world like let's just say that the hidden state of the world is the true temperature um it uh it's actually a hypothesis about the world that's why bay's in bayesian statistics it's like a hypothesis that you're testing and uh the observational data the measurement is y and this is uh posterior two data so like prior and posterior are referring to when new information comes in prior to the new data coming in and then it's updated and then you have a posterior which has been updated by the new data and in very rapid here in this paragraph they make the move from doing inference basing inference on a hidden variable like the temperature of the world into this idea of the model evidence with a normalization that keeps things adding up to one so instead of having like an uncertainty distribution of how the temperature might be in the world and then taking in new data and updating that another way might be um i have two hypotheses it's colder than 20 or it's warmer than 20. and then i can always be judging relatively which one of those is more accurate so even if the temperature distribution is like very gnarly it's possible sometimes to have a simpler thing that you're trying to hypothesize about the world like is it over or under a certain number that helps you guide action and then also when you do this model um comparison you can keep the relative uh basically the the relativation you can keep models being compared relative to one another and that can sum to one so you can do probability type estimates on different model classes even without knowing whether any specific model is likely or unlikely so like in phylogenetics which is an area that blue and i have both worked you can use bayesian statistics to relatively evaluate what the most likely tree is for species but that tree's likelihood might be like super low but that's not what matters it's whether it's more likely than other hypotheses so that's kind of what they write a little bit about here is when you have types of models that are computationally or analytically intractable so there's no closed form solution for the posterior like there's no clean way how you're going to update your model of the phylogenetic tree given the next new genome that's added in it's just not something smooth like signal processing might be so how are you going to deal with that and that's the big challenge so it's kind of this rapid bayesian acceleration from like you're trying to estimate something about the world that's unknown okay well what's unknown is which model is better and then the challenge is we want to update our ongoing estimate of what the best model of the world is but there aren't really update rules for how new data coming in should help us update which model it is like night and day it's clear more light it's likely to be daytime but again think about the phylogenetics or something where as new data comes in it's really hard to know how exactly to update your models so in that uh the phylogenetic analysis if you have new data coming in literally like you want to add a new branch to your phylogenetic tree the the computational way that that's calculated is by switching in and out in and out in and out each branch to see the likelihood of the least likely or the the best evidence for that tree that's existence but it literally makes every single tree and then calculates that which is computationally a really intense um and time-consuming effort so that's why variational base is so neat and swift in comparison yep exactly it's these red and blue on the bottom it's like a continuum of approaches uh before enter variational the continuum being we have some simple cases where we have a closed form solution for exactly how to update the model's evidence as new data comes in and then there's sort of this wild west where you need to use customized schemes and sometimes you have to resort to just extremely costly like almost brute force like swapping or doing the markov chain monte carlo however maybe there's another way which is what brings us to variational base and variational base as the authors write on the bottom the trick of variational base and we're going to come back to the kl divergence but here's the trick up front is consists in letting go of trying to minimize the kl divergence in equation 3 directly shifting the objective to optimizing a different functional which bounds the model evidence so what would you say the variational trick is i mean that's it so if you bound the model evidence then you like so you know that the answer can't be outside of these parameters if you that's like bounding the model evidence then you're not calculating or trying to you know calculate things that are outside of those parameters i would say yep and maybe there's another way to read this equation on three but the underlined red part d sub kl is the kl divergence so it's about the divergence between two different distributions and the double line is like what the two distributions are so that p x given y we saw that back here that's what we want to calculate so even though we're kind of accelerated on base we're still back on equation one doing inference on the world but it's going to look more complex now so we're looking for the difference between that thing that we really want to find out p x given y and then the magical q distribution that we're in control of and then we want the divergence between those two distributions to be zero and distance is always positive there's no negative distance and so we just have to minimize this divergence so that we can get at what we really want and again one part we don't know and it's hard and the other part we're totally in control of so the whole question and trick is going to be can we design a queue so that by reducing the kl divergence on q versus p we're getting out what we truly want so that is kind of what threads the needle between these two approaches the the red being like the elegant and simple and effective and then the blue being like the extremely messy and simulation based variational base is elegant and also it helps us potentially deal with complex underlying distributions cool good okay now here we return in five there's d sub k l between q of what we want to know and p of x given y so it's the same as it was on the previous equation three and that is going to be given another equivalency and it's restated as uh the natural log of p of y minus big l of x so what what do you think about l of x blue or what did you see here um or sorry no worries okay i'm like i'm lost in the map i was just like thinking oh you know there's two lines that's an equal sign here's one line is a minus and here's three lines yeah i was i was lost at the three lines like what why is that an equal sign like this yeah i'm confused at that three triple line thing um i think three lines can mean that it is defined as like it's strictly defined as or but let's find out i don't want to say anything that's incorrect that's what i was thinking of that um i'm like no no i'm i'm opting out in the past yeah but um the uh restatement here is this value that we want to go low low low with the divergence between what we can control and what we can't control we're going to restate it in terms of two different pieces a sort of log uh this is just the likelihood model of the observations so this is just y it's p here p x given y was like the true x given the y observation like the true temperature given the thermometer and here we're just going to have the likelihood of the measurement so this is a lot easier to calculate than x given y because it's not a conditional and then we're going to penalize that by big l of x which is an expectation of q what q thinks is going to be a likely value for x plus a joint distribution of x and y of p not the conditional so it's a little past me y reframing it in each of these nuanced ways helps you do it but i just think of it like mathematical pinball like you gotta like bring some wall down so that you can go up another ramp and do something different but let's definitely ask the authors about it and this the negative is like baffling like i think like the point of when you are getting into the logarithm the logarithmic scale like so that you like eliminate any possibility of a negative and then like they put the negative on the front of it i'm like that's a little strange to me yep and then also it's like the it's like the negative variational free energy and so we push on though um they are able to uh say that basically free energy this is by analogy to the variational free energy they're going to bring that's where they bring in the f they say basically the free energy that you might want to minimize we'll get there in a few equations but the free energy function of x that hidden state of the world like which model is best or what's the real temperature it is the negative of this l because here what l was defined this way and it's almost like we we don't we can separate out l from p at all so here we had like sort of a hybrid with q's and p's and here there's like a p here but now when we get l all alone now we've kind of encapsulated p in a way where it's like all q centric i'm not even sure if that's true so i don't go too down the rabbit hole but now it's framed in a way where we can do our work on cue but um but but but get to where we want to get on p and i think that is the rub that's what the question is about is okay it's a approach and i would love to ask somebody with more variational inference especially actually on this uh i think these are the ones where we were like blue and i were just like okay these are we're going to raise more questions than we uh answer but what does it look like to make the variational version of a model and what do you sit down and do so that you can calculate this or is it all carried out beneath the hood so uh minimizing free energy as defined in this way on the q which is the function that we control the goal is that that will also get us to the right value on p the function we don't control so i have my internal model of temperature and i want to be doing inference on that finding what's the most likely the most free energy minimized internal model of temperature and then if that is attuned properly that should be accurate in terms of the external as well so in my like limited understanding of making a variational model um i think that these models instead of like using values they use distributions right so so in that's the kind of the the key difference i think between um the variational like model construction versus the the like non-variational variety of a bayesian model in my limited understanding nice point that previously we were like looking at passing uh like a number through a function and then when we're going variational we're talking about like passing functions through each other um this one we're not going to go into the technical details but it's about mean field approximations and this is a super interesting topic because a lot of statistical models will assume that there's like a homogeneous field or that a gas is well mixed or that all types of a certain interaction are equally likely to happen amongst all molecules bouncing around but because we're interested in applying free energy principle not just to the burning candle or to a chemical reaction but to active inference agents to cybernetic and goal-oriented agents how does the mean field approximation work like if we want to explain culture is there a mean field approximation for culture or how are we going to apply this to the systems where we know we're kind of extending into analogy land but at the same time maybe reality is really multi-scale so it's not just uh an analogy to say like when chris field talked about quantum and communication at our scale not just as bubbling up from electrons and not just as a metaphor but actually as like a third way that it really was based upon those principles at our scale that's what this makes me think about like do we need are or will there be mean field approximations at a lower level and then we're just experiencing a sort of non-mean field at our level and okay 21 anything else say they're blue so i think like that the the mean field approximation um i i think it's like i don't know it's it limits the interactions between different variables so you're interacting with the density instead of each individual variable interacting with each variable so it's like um it's like a course it's a course grading like having this mean field approximation i think yep and we'll return to it when we look at the um figures related to fristen's paper but yes it's related to partitioning variables and yes now this part i thought was really interesting and kind of like basic statistics so maybe you'll be familiar to some but they're seeing it in a new way that the difference between the different relationships that variables can have and we're seeing it here written out with math but we're actually going to come back to it with figures and so it will potentially be a little bit clearer but there's a few different situations the nicest situation for a statistical inference is when you can cleanly separate inference on the two variables so here it's like p x1 and x2 the joint distribution of x1 and x2 it can be separated very cleanly because they're independent so it's like you flip a coin and you roll a die the way that you get the probability of a head and a 4 is basically you just multiply that probability of head times probability of getting a four and so that's the clean case and sort of almost by analogy that's how i understand variational inference like it just clean the variables cleanly separate so that you can do restricted optimization on subsets of variables in a little bit more principled way but um back to the stats there's often a time where the joint distribution that you care about is conditionally dependent so conditional dependence conditional independence two sides the same coin it's conditionally independent on or conditionally dependent on a third variable x3 and so here we're gonna separate x1 and x2 just like we did above but now we have like x1 conditioned on three and x2 conditioned on three and there's actually all kinds of situations where we're really interested in these interactor variables and so there's there's one reason it might be latent cause estimation like i want to know why is it that some people take this drug and have this side effect and other people don't sometimes you want to know all three factors like how three different nodes of a computer network or genetic network are related so you actually might be interested in how all three of these nodes are linked and then other times the mediator might be useful for like a statistical analysis or like an interaction effect in an anova like okay there's an effect of age and there's an effect of height but is there a height by age interaction so those kinds of questions they're not the that anova questions not in the bayesian framework that's from the frequencies framework but it's an example of when you want to know about interactor variables but it turns out that this is going to facilitate the variational inference because you can like use this hidden variable 3 to shield or separate x1 from x2 and x2 from x1 so that's the the move of pearl and then that's what we're gonna dive into from then on so we we went from basically bazon states bayes on models to variational bays variational bays gives us this free energy minimizing way to work the variational inference contingent on a few assumptions that we would love clarification and education on and that's going to help us separate out in a way that's tractable different parts of the world model that we care about so an easy way to think about this conditional dependence is is if you're like thinking about the probability of mary and mo both eating at the frontier restaurant in albuquerque it's independent of one another right like mary and mo they eat periodically at the frontier restaurant this is like an independent probability that they go there whatever and then they have another friend that they go with so mary and mo go with sally they if sally eats at the frontier restaurant then the probability that mary and mo will be there together because they'll all go together is you know they'll all be there at the same time if sally's there because then they'll all go eat together but they're not independently friends they're only friends they only go as a trio when sally's involved nice our variables just hanging out with each other so let's take it from doing inference on like one variable states and the variational and everything to two variables that's with this joint inference and then here we brought in the third variable let's generalize that beyond three because we're not just interested in x1 and x2 in their relationship or how three influences it we want to be actually open to all graphical relationships and that just means everything you can draw as a network with nodes and edges is graphical or that's a network analysis so they bring in now the notion of a bayesian network beta and it is defined as containing g and p so g is sub defined with vertices uh and edges v and d so g is really like edges and notes so g is the network itself and that's kind of the matrix form the two space form that we're familiar with and then p is as they write a collection of tables containing dependencies between the variables as a set of matrices with structure but it's kind of like g is the social network like who are the people and what are the edges and then p is describing their relationship in a way and uh they also then they write the the tables p uh the graph g is often represented by an adjacency matrix so that's a you know nodes by nodes and then the cells are whether they're connected or not and that's exactly what we were getting at with the two spaces so yeah it is pretty interesting and then the tables p contain the factorization for the joint probability distribution over the variables characterized for the uh directed acyclic graph the dag and so there's an equation that we're going to use to jointly consider like the network nodes and edges g and all the dependencies on the network p and so you can imagine if there was like if you had a matrix of 100 people and these 50 all knew each other like they had dependencies between each other and then these 50 people all knew each other they had dependencies between each other we would want a method that could decompose that matrix into a more factorizable potentially nicer to deal with form okay so here we visually see it and i think that the circles are all meant to be complete but they look like like i was wondering if it was a dashed line or something but i think it's all yeah so here we have a bunch of variables t w y x u and z and then the authors very helpfully go through a few of the kinds of relationships that can link motifs of three variables and so here's w and y and so it's like notice how w and y are unconnected but they both have a dependency towards x so it's like w and y are marginally independent but only conditionally dependent if x is observed so if you didn't see x you wouldn't know that w and y had a dependency but then when you do observe x you can see that oh x is actually being influenced by both of them that's called um the head to head w and z marginally dependent because you could tell that potentially through latent interactor variable x if you had w and z measured you could tell that there was an influence um but you wouldn't know as much about the influence of w on z unless you knew about x and then there's x and u which is kind of like the backwards example of w and y because x and u would be correlated in the real world like you'd be pulling out x's and pulling out u's and they'd be correlated so they're marginally dependent but then if you measured y if you observed y you would make them conditionally independent because you'd be able to correct for y and then as you pulled out corrected x's and u's they would be conditionally independent so the bayesian graphical form allows us to go from that p of t w et cetera et cetera so think about that there's six variables that could be six times six variables to consider like 36 connections but we can factor it into like the function of z given x because that's the only thing that z is conditioned on x is conditioned on w and y use uh u is conditioned on y and then t is an alone variable so we've gotten all six variables into a way that is like a lot sparser it only specifies the parts that we actually need to care about in terms of the dependencies that actually exist so that's kind of the bayes network it's just using network thinking to talk about the really nuanced relationships between sets of variables so this could be like six demographic factors of a person and z could be the health outcome and so then we can use this analysis to do statistical inference just like we would with any other technique anything to add on it blue uh just the final formula down at the bottom really specifies uh like it separates out like b z given x right and so and t is independent of everything so you can really see like the the conditional dependencies down here in this final equation x given w and y and then u given y so yeah it's almost like there's the graph representation then there's the adjacency matrix representation and then here's an equation representation so it's like a rosetta stone if you could have a technique that works on matrices and then you wanted to apply it to a network well then you need to connect networks and matrices but then you could definitely apply it there what about the pearl blanket with this cute picture yeah so the pearl blanket is really um traditionally is described by the set of nodes that shields a variable so in this case variable a that's in the middle from the other nodes in the network so a can't interact with these nodes that are outside of the pearl blanket which is the represented by this circular blanket so a can't interact with these other nodes without going through the nodes that are contained in the circle yep and if you notice it has uh like the ones that are to the sides of a it's because all these kinds of relationships are relevant so even the one that a it does not directly connected to a but it still is included within the blanket that's kind of important to note all right so now we're gonna get to this figure and it's kind of clever how i think the authors did it because they introduced this in figure two uncolored and then we're gonna talk through some fristen simulations and then active inference in figure six and then we're gonna return to this in figure seven with a new color scheme that will help really make their point clear so here they're taking this simple example and they're just giving another example and um here is their their legend the grays are the observables so y is observable y1 y2 we're observing two things about the world measuring two things all the x's are hidden states the arrows are that bayes net directed acyclic graph representation the dashed node is this special node a10 that's like our focal node and then the thick nodes are the blankets around x10 so here just like you had a and it was like its neighborhood was the blanket here we're gonna have the pearl blanket as they write thick lines are used for nodes constituting the pearl blanket for selected node x10 depicted here with a dash border so it's kind of like a legal argument they're like saying you know uh would you agree that this is the appropriate use of the pearl blanket because if you do think that this is a pearl blanket you might find yourself in a trap in figure seven when they show you what this actually represents so it's like okay good this is what a pearl blanket is there's no real dissension this is where we're at with pearl blanket thinking and we've just specified some arbitrary network you know nothing in mind just specified it and then they also um define in 4.1 uh a little bit about how pearl blankets play a role in active inference and it's a super fascinating topic that is something we want to return to with the authors but if you notice that this q distribution that was the one that we were in control of and then that minimization previously we were looking at f of x it was free energy minimization on states hypotheses but here we're also including policies pi sequences of action so now we're doing free energy minimization on policy and so that's what allows us to include the action in the loop with active inference so active inference isn't like just a two-stroke engine where we're going to do inference on states and then action selection in a second step it's actually a loop that integrates action and inference into functions in a co-equal way and that's what one of the special pieces of active inference is as they write um something that classical formulations of variational inference in statistics and machine learning do not consider instead assuming fixed observations or data so you read in the big data set you do the free energy minimization and there's your answer and then if you get new data what do these companies do they re-run the optimization with the new data but this is actually like real time in the loop and it's also taking action okay any thoughts or on figure three do you want to intro it or what yeah so this uh figure i think the papers on the next slide actually the the figure that came out of the um it came out of this first in 2013 paper and there's like a set of figures in this paper that were accepted from that paper and so this is the it's a primordial soup simulation that was done in in the article by firstin and the larger cyan dots represent the location of each particle and then there are three smaller blue dots associated with each particle representing the electrochemical state of the particle so this is like on on how life came to came to kind of be right so that's the the what's going to happen in the simulation so this is just the first and then we go on into the into the next figures from the paper nice so take this one yeah yep yep so the simulation is just like the cyan it's kind of like the nucleus of an atom and then the blue dots the little ones are like electrons floating around okay so just it's it's not trying to be a physics simulation but that's kind of what's happening figure four um here is oh and and they're electrically charged that's the electrochemical part here's what they write um you can take so let's just say each of these cyan dots had a number you know number one through 100 like an agent-based model now we're going to element 1 through 120 i guess you can plot the adjacency matrix a based upon the coupling that is dependencies between the different particles at the final simulation t so you're going to start this simulation let it run out and then okay this one is very closely coupled to that one and this one is closely coupled to that one so number one is talking to four and number fours talking to 22. and then you can take that matrix and you can just put a dot where you saw a dependency so if you saw some sort of behavioral dependency between the two like in adjacency you're gonna add a dot and then you're gonna rearrange the rows and the columns by swapping which preserves the information rearrange them so that they're sort of uh falling out there's actually several there's there's a pattern that falls out we see that there's a broad region of interactions over here and then in the bottom right there's like another kind of sub area of interaction and then on the very bottom right is like a very tight area of interaction where you see a bunch of dots over the 120. so as they write the adjacency matrix is a representation of the electrochemical interactions between particles because it's drawn because the adjacency is on the simulation but can be interpreted as an abstract depiction of a bayesian network and so we're taking the dependencies between these particles as they jostle around and this is what we're trying to do we're trying to almost like factorize it separate nature at the joints you know map in the territory okay there's a border on the map but is there a border on the territory and then um plot it as a matrix and then there's some shading that's going to be suggestive of what role those nodes are hypothesized to be playing so here's what they did just in a little more formal on slide 30. they used spectral well this is i think what frist in 2013 did yeah uh spectral graph theory was used to identify the eight most densely coupled nodes which are defined as the internal states so y eight y dense cup okay right that's the question that's what we're discussing and those are going to be defined as internal states just to skip to the slide those are those blue ones right in the middle here so those are those core states back here given those internal states the markov blanket is then found through tracing the parents children and co-parents of children in the network sounds like a preschool um as an extra interpretive step and that's part of what this discussion is about how interpretive is this like interpretive dance interpretive or like interpreter at the un um the nodes in this mark called blanket can be further separated into sensory and active states the sensory states correspond to the parents of the internal states so that's incoming info not that they birthed the internal states but the sense states are the ones that have an upstream dependency on the internal states and the active states correspond to the children of the internal states and their co-parents so again not that the active states are simply birthed by internal states but that they have downward flowing statistical dependency states that are not internal states or part of the markov blanket are then called external states so we're using this partitioning where first you identify dense couplings then traced out parents and co-parents and children and then everything that's left is external states and so you recolor that simulation from figure three here it is uncolored and now we're gonna recolor it with this new color code where we've identified the blue densely coupled nodes and then the active states and then the um sensory states which are sort of on a frontier with the uh teal states the cyan the external so it's almost like you have the internal you know let's just imagine it's like the nervous system and then it's swaddled in the active state and then on the outside of the sense of the active states or the sensory states and those interface directly with the world so that's kind of the tantalizing nature of this model would be like wow if it really just fell out of a simulation that you can get self-organization like that wouldn't that be cool but what is the issue here blue well i mean it's kind of arbitrary um like so you know they said a third of the of the electrochemical states from the very beginning of the simulation were not did not interact right so it's that establishes this non-equilibrium system um and and i think that uh you know the the issue then comes from assigning these interactions to internal external active and sensory states that may or may not have some kind of dependence on one another yes as they write here the simulation assumes that by viewing the system through the formalism of the markup blanket plus some additional assumptions about the separation of states the ones that we kind of walked through just a second ago you can uncover hidden properties of the target system which is then said to quote instantiate or possess a markov blanket and then this is the map territory the procedure of attributing to the territory which is the actual dynamical system what is a property of the map which is the scientist doing inference on the dependencies and then cutting it at eight nodes and then using this other approach to make the markov blanket it's a property of the map and it's a clear example of the reification fallacy treating something abstract as something concrete without further justification that's not the only way reification works but it's one key piece of it and so in other words it's like you go in with a marcotte blanket hammer and your secondary pipeline for identifying parents and children and then you find it because it's defined for any system you're going to be able to get a markov blanket using that protocol and then look at this have you really discovered something about this dynamical system by separating it into this partition when actually all of the particles are doing the same jostling motion so it's not like we have uh the influencer nodes here these are just densely coupled ones and so um they propose in this same paragraph proposed to distinguish between pearl blankets to refer to the standard epistemic or like statistical use of the markov blankets and first in blankets to refer to this new metaphysical construct and they also give a shout out to martin beale in the paper and so we're kind of coming back to this map territory distinction on the map side we have epistemic pearl blankets bayesian statistics but no philosophical power and then what they're attributing to the territory would be metaphysics and it would be the kinds of things that the fristen blanket is making claims about and i think my question was can we do that action in the loop without metaphysics because it seems like there's two innovations in or differences between the pearl blanket in its sort of normal statistical use and the way frison's using it first he separates sense and action but also he's making metaphysical or ontological claims so i'm just wondering like are the ontological claims separable from taking a control theory perspective on bayesian statistics that's what we would like to find out so then blue you copied this image over what do you like about it or what did you see in it so i just thought it was like a nice pictorial representation as opposed to this primordial soup that gets a little bit hairball of what we have as internal states which were back in the in the christian picture the the central um dark blue most highly connected nodes so we have the internal states and then the external states which are separated from these blanket states and so that's this where this pink dashed line is surrounded that that's labeled with the bees so this is like the fristen blanket contains the active states and the sensory states that may be interacting with each other uh and then this fristen blanket is what separates the internal states from the external states um and they take it in quite a literal sense like the boundary of a cell and and um so forth so separating the the internal from the external is the first and blanket nice and let's connect this to figure four and then the kinds of things that we wanted to discover there looking at this as a graph of bayesian variables it's like active states they influence external states so this is that coupling so it's almost like external states they don't connect to internal states at all that's kind of like missing a corner on the graph so we have nodes everywhere you know there's cells in your hand and there's cells across a wall but how can we separate nature at the joints maybe we could make measurements find the statistical dependencies and then carve those dependencies into densely connected internal states and then incoming states that are upstream and outgoing states that are downstream and then we might have a new way to do bayesian modeling on systems that are on a continuum or as part of a really uh complex process and figure five yep we already had that i guess we put it put it twice and yes 4.3 this is sort of the uh man's search for meaning why and how have marcon blankets been reified to act as parts of the target system how did we get here and uh where this technical idea became reified so people thinking that there's support in the literature saying oh yeah markup blankets it's in the literature there's real measurement support for markow blankets that's reification um of delineating spatial temporal boundaries rather than formal tools intended for scientific representation and statistical analysis when did the map become conflated with the territory because like everyone's familiar how we use linear regression on healthcare data but then no one goes back and says well then you're a linear regression so it's a little bit like if somebody were using markov blankets on health data and then said now you're a markov blanket or is it i'm not saying it's exactly the same but that's the rhetoric of what is being uh put out here it would be like the line delineating the healthy from the sick is a markov blanket it's a line there's actually a line and then they write so again people should read these papers they're fun to think about and there's a lot more that we're not getting to go into in the um zero but they write basically perhaps surprisingly many authors in the field are seemingly not aware of this process of reification and this has led to the conflation of several different kinds of boundaries in the literature markov blankets are characterized alternatively as statistical boundaries causal boundaries spatial boundaries epistemic boundaries and autopoetic boundaries each characterization is treated as somehow equivalent to and interchangeable with the others now it's rare that someone does the grand slam where they totally conflates all of them but then there are papers here and there where oh it's causal and it's spatial and then it's spatial and it's epistemic and it's statistical and it's causal and through this web of formalisms we can get in a tangle to kind of any thoughts about that yeah just that the paper itself contains like many quotes from other papers where they use the markov blanket or the fristen blanket in very much um like a statistical and um instrumentalist sense and then turn around and use it in a very realistic sense so there's many uh like examples of that illustrated through the paper that trace back through the literature good point and those are the parts that we didn't quote in this dot zero but there's many pages so if someone's reading it and they're like wait they don't do that in the literature read the paper because that's where they mention it and this is from the live stream number 15 where we had uh we were discussing the paper of fan s and hippolyto and we introduced this discussion around realism and instrumentalism and what those authors had written was basically realism and instrumentalism concern the models and statistical manipulations that make up the fep whether they are thought to be used and manipulated by the systems under scrutiny independent of scientific inquiry realism the tree falls in the forest does it make a sound realism yes there's a real tree it really did fall it really did make a sound or conversely whether they are thought to be scientific tools wrought by humans in specific socio-cultural environments to study particular systems instrumentalism so that's like well no a sound means somebody has to hear it so you don't know if the tree is real or it really didn't make a sound and the whole question is where does free energy principle is it about what systems are doing realism when we don't look or is it about us modeling systems no matter how they look that's instrumentalism and that brings us to figure six where they show a classic sensory motor loop so it looks like it's an active inference loop and that's where they're going with this but their whole point is that um it although the figure does not use directed edges to signify causal influence it is not strictly a bayesian graph as it depicts cyclic sets of circular dependencies some between pairs and an overall loop compo containing all components now this was quite interesting because first off it points out that yeah octave inference didn't invent the internal external or the action sense idea we're using different models and we're recombining them but there is this cycle right there's also in active inference more of an emphasis on the internal states and the external states as they have their own endogenous dynamics but that could be part of these models too and then it's true that it's not a directed acyclic graph if there are loops local or global loops but what about implementations that have time steps where you can break these loops like if you compute it in this order just a thought like does it really violate how how badly does it violate some of the assumptions of directed acyclic graphs but i don't know any thoughts are good for seven i don't know yeah i don't have the answer for you if i did i mean i don't know that necessarily putting a blanket over the sensation and the action states the sensory in the active states like putting that in a box like does that break the acyclic graph thing i mean i don't know that that necessarily breaks it enough to to make it somehow valid either right like i don't know it is a cycle i think good question so now we return to the figure that we saw before and this is where they now strike so figure two remember it was like surely you agree this is how a pearl blanket would be deployed on this graph now speak now or forever hold your peace and then now it's going to come back to bite some people who may have not expected where it was going to come so before they were highlighting that x10 node and now they're going to color according to fristen's scheme they're going to color the notes so it's colored like figure 5 but on the figure that they introduced earlier with x10 still as a focal note but then they're going to show that if you have a different focal node x9 not only are different nodes included but they're just they're categorized differently which isn't a problem for the pearl blanket because it's like oh if you if you're uh if you measure variable a and b then this one is the child or the parent depending on you know what you measured in that bigger graph and then but if you're going to have a realist interpretation of what these nodes are you're out of luck because one is going to be an active state for one in a sensory state for another and then if you are going to say well it doesn't matter if it's an active state or a sensory state like they're all doing it for each other it's equivalent to the pearl pearl blanket phrasing so what they write is if you're going to have a sensory motor interpretation which is not the only option this suggests that the sensory motor blankets are markup blankets applied under specific set of assumptions and it can't be traced to standard uses of markov blankets in variational inference so basically depending on what your hidden variable of interest is you compute a different blanket around it so that is problematic for realist interpretations because depending on what you're doing inference on you might variously find that the membrane of a cell or a measurement from the membrane of a cell was a sensory state because it was incoming for something else but it could also be an action state because it's outgoing of something else but then it would be internal to another set of things and so if we want to make realist claims or interpretations about blanket states and internal external states that's an issue so is the issue like that we haven't figured figured out how to like nest these models yet i mean i i think that it makes sense that the outgoing is incoming for another agent right in the in the model so that we just haven't figured out the nesting pro properly yet appropriately or like that each nest is its own like blanket state i don't know i agree i'm an optimist as well let's see eight but this is this is where they they really go for it and this one i thought was just very clever and funny so the delayed figure you know with the intermission to convince you lull you now eight so now they're going to go into a graph that oh total coincidence it looks like the left side so here on the right side you know we were talking oh x10 x9 but we never talked about this left one that looks like california but let's look at it now [Laughter] so california exactly um on the left a bayesian network where id and i sub p denote the motor intentions of a doctor and the patient respectively so that's this these ones on the top too h is a medical intervention with a hammer c is a cortical motor column and s are spinal neurons movement is m and then k is a different way that the leg could have been observed to move like somebody could have moved it or gravity could have changed so again m is the movement that's the observable movement this is the abstract bayesian net on the left in a in b is one possible action pattern which is that the the patient goes to the cortical motor command the ip and then h is the medical intervention with a hammer and then that results in no motor behavior but then here you do have um the motor behavior observed but it comes about a different way rather than h the intervention as a co-parent you have k this other way like somebody picking up the leg and moving it in the middle and on the right the same network is partitioned using a naive first and blanket with different choice of internal states c and s respectively so if your internal state is the cortical neurons you're going to think that the uh basically active states are the spinal neurons which is how people talk about it so it's not like this is like a the theory is blown out or anything it's like saying the spinal neurons are the active states of the cortical neurons and then the movement is if your focal node internal is the spinal neurons then the active state is what we would call in realism the real active state so it's kind of like saying again depending on what node you're focused on different nodes are going to be categorized as a sense active internal and external i want to say that's how we've been thinking about it that depending on which side of the line you're on that's going to be internal external but the point is it provides um problems for realist interpretations of any single markov blanket because we have to acknowledge that the markov blankets and especially how the states are classified is conditional so it's like is the bicep an active state or is this an active state it's like well if you're doing inference on this yes but if you're doing inference on that no so it's hard to have a realist interpretation even though there are times where if you define something internally as something that's truly on the inside of something it might be that the active states truly line up with what's on the outside of it but that isn't the full generality of this bayesian network approach and that's like a broken clock is right twice a day and it doesn't actually get as general as it could be this makes me think of like the broken knee like the phantom limb it takes me back to that like what if the you know sensory neurons are activated for the leg to move but there is no leg to move right like then what nice so okay next um one uh they give a little bit of recent history so if twitter's too fast and textbooks are too slow this is the the history speed for you beal pollock and canai 2020 questioned some of the technical assumptions underlying the use of markov blankets by fristen and since then the idea of the fristen blanket being understood as a distinct construct has gained traction in literature and we're actually looking forward to having martin discuss that with us in about two weeks so again it will be really interesting to hear like how did you come to the position where you were getting at these technicalities and critiquing it and where does action fit in where does philosophy fit in where do these other things that fristen is bringing in and um [Music] any anything to say on this this part or only the question that i raised at the beginning where does language begin right like to what to what extent is the the problem or or the issue that's being raised like a function of the language that we're using yes and in this paragraph they make another subtle point that shows why when the language is uncertain there can be a lot of drift underlying they say in a recent paper fristen blankets are formalized in terms of constraints on sparse couplings and then they're identified using read the technical details the non-zero components of the hessians using some other last names and that is taking it the construct according to the authors far away from the pearl blanket origins and so they're saying you wouldn't make that kind of swap in the underlying mechanics unless you were working with the physical domain of what's really there um so that's an interesting point would be cool to hear from the authors here on the next slide is a kind of a closing remark by the authors and this is kind of a meta point and the meta point is actually the relationship between action and inference like of an organism and then scientists modeling their world so it's not the first person who's made that comparison you know you got physical foraging you got information foraging but they're saying basically there's a lot of similarities between perceptual inference and scientific inference both use a previously learned model of the world and set of observations to infer the causal structure of the unobserved outside world and this was like the triple meta is model-based cognitive neuroscience is in a special place it makes models of how animals model their environments a cognitive neuroscientist uses both behavioral and neural data to infer the most likely model that the agent's brain implements there's nothing wrong with this doubling up of modeling relations as long as one is conceptually careful one needs to distinguish between the properties of the environment properties of the agent's model of the environment and properties of a scientist model of the agent modeling its environment and that's the third level and that's why it's unsurprising actually almost in retrospect that fep arose from cognitive neuroscience and neuroimaging with eeg and fmri because it doesn't come from we're going to use physics to find the grand unifying theory it actually came from a we're making measurements about how agents reduce their uncertainty about their model of the world and it's that that gives you the triple loop which i think is like quite interesting about how it's nested well and here we are adding like another layer to the loop like thinking about how like trying to you know criticizing the model with which the scientists are using to model the agents it's just models all the way down yep so what are the implications for cognitive science in humans and this part right here properties of how the scientists model their agent modeling their environment you could replace scientists with researcher or data scientist or machine learning algorithm this really matters what people take into account when they design their algorithms and when they make algorithms about other cognitive agents because that constrains in ways that are sometimes obvious and sometimes not obvious you know if you only had one variable for a user on your website how likely they are to buy something that was your variable you're going to set up a different algorithm so it's the properties of how the scientists models the situation that really matter and um has implications for cognitive science that when we're studying humans and non-humans and non-animals and blue's big question this is actually the big question that the authors bring so and so they asked in the paper if bayesian networks and markov blankets are the right kinds of conceptual tools to delineate the sensory motor boundaries of agents and living organisms so the authors you know brought this up within the paper i thought it was just important to highlight that because i don't know i think like if we're you know if you go out to a scale like if you have an image and you start to you know coarse grain that image you know building representations of the image building representations of the representations of the representations of the representations eventually you can't see the picture anymore at all and the point is to make it easier to understand not to you know make it so blurry that nobody understands it at all i think cool this is what brings them to the distinction of inference with uh wait is that even the right it's uh yeah oh yeah inference width and inference within i was thinking i was getting really you know inference of a model but inference with a model the distinction between the two blanket constructs as they're positing them i'll shrink our little video can then be easily identified once we look at who appears to be performing the inference and what system that inference is performed on so they go through four kinds of networks we're not gonna go through it here but if people are interested in the technicalities here it's really worth thinking about what's the difference between the generative model and the generative process so like i can have a generative model of blue in my head so when she's speaking i'm doing generative inference on her syntax but then that's not the generative process which is the actual underlying person so this is just a nice very um rigorous way to break down when we're doing inference on a model versus inference on a on a process and okay 42 all of this points towards a fundamental dilemma for anyone wanting to use markov blankets to make substantial philosophical claims about biological and cognitive systems which is what we take proponents of free energy principle to be wanting to do so agree or disagree you know if you disagree you can write a paper or you can come on activestream but that's the claim of the authors and so that is what we kind of got excited to learn about and they then come back to this with versus within and they say basically in inference with a model the graphical model is an epistemic tool so that's like i'm going out to the forest with my machete i'm gonna use it as a tool as i go out versus inference within a model the scientist disappears from a scene becoming a mere spectator of the unraveling inference show before their eyes the way that's written makes um the authors sound a little bit um sort of dismissive of that being a likely approach it's almost like well we wouldn't want that to happen or it can't happen so scientists can only do inference with models now the scientist as the body is the inference within a model like the inference is happening within the science body or within the scientists exocortex or within their community but that's very different when you're talking about the real system the scientist at the desk that's the system that is doing inference but inference with a model is the instrumentalist take okay and um this is just a final slide that just gives some closing thoughts and this was interesting because they mentioned that there are there are simulations like the game of life which have been enormously productive in many domains and so basically they say that it might be an interesting way of modeling emergent processes in complex systems but it won't support any metaphysical claims about frist and blankets and then they say we will not pursue this idea any further here but offer it as a more modest perhaps instrumental interpretation that some proponents of the fep and active inference might be inclined to adopt in order to avoid any stronger commitments so that's in some ways where we feel like we're sitting which is we're approaching active inference instrumentally and then we'll see what happens with the other claims but it seems like we can pursue it instrumentally and i guess that's a modest proposal and then they just summarize so overall nice paper relatively good length a lot of figures clear arguments rigorous philosophy and math so it was um good times and like a good coverage of the literature and um you know a trace through the history of the the methods underlying the fep was good do you have any other closing thoughts only that maybe inference within a model is actually possible if you're using a robot that's programmed to do inference right like the inference if the if the or if the action is to do inference if that's how it works then then that's inference within a model possible cool well it will definitely be really interesting to hear from the authors hear from everybody who wants to join on the stream so blue thanks a lot for joining this was a great discussion thanks everyone for watching and we'll see you later bye bye thank you