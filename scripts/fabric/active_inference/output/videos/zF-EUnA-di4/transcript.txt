hello welcome to active inference lab and active inference live stream 17.2 it's march 16th 2021 welcome to the active inference lab everyone we're a participatory online lab that is communicating learning and practicing applied active inference you can find us at our links on this slide this is recorded in an archived live stream so please provide us with feedback so that we can be improving on our work all backgrounds and perspectives are welcome here and we'll be following video etiquette for live streams at this shortened link you'll find our calendar for active inference live streams for 2021 and here we are in the follow up to 17.1 in the same paper and uh definitely recommended to check out 17.0 and 17.1 if you haven't but this will hopefully be a cool discussion either way and you can also see the future live streams cool well today in 17.2 we are going to be just continuing to discuss and learn this really interesting paper and it will be fun to speak with whoever joins or doesn't for this stream and also hopefully to get some questions from the live chat but we're just going to introduce ourselves go over some general questions and i think uh seeing as it's a dot two and we had a lot of the background and dot zero and then we had um chris fields the author come on for dot one let's just think about where we can take this fun discussion okay so here um especially for our first time participants we can introduce ourselves and just warm up so first we can just introduce ourselves i'm daniel i'm in northern california and i'll pass it to stephen hello there i'm stephen i'm in toronto canada and yeah i'm interested in a number of areas that relate to active inference particularly those that can inform community-based development and the way that we make meaning in complex contexts and i'll pass it over to is that alex there dean dean sorry hi um i'm dean uh i don't know how to pass things yet i'm pretty new to this um i'm in calgary so hi steven in toronto and uh i decided to s to step into this because of uh reach out to daniel did on researchgate and a follow-up and then the opportunity to look at last week's 17.1 presentation and for about two hours i was completely absorbed in the conversation and thought this is really interesting so i took the next step and decided that i would try and uh integrate myself more with what's going on here cool well let's maybe learn more about your perspective as we walk through some of these warm-up questions and just go through at whatever pace we want just sort of the topics in the paper as well so the warm-up questions are what is something you're excited about today what's something you liked or remembered about the paper or also the discussion 17.0 or one and what's something you're wondering about or would like to have resolved so maybe since we all listened to it and hopefully those listening will have two what was something about 17.1 that sort of stood out in people's mind or something that changed how they thought about active inference or how they thought about something that wasn't active inference yep stephen yeah well one of the things that was quite interesting was that there are other ways of people looking at the math side of it which some of you know the math itself is normally quite a challenging area to get your head down but to realize there's also some other thoughts happening at some foundational level so that um was interesting i didn't know about that particularly um or to the extent that was happening so that that was particularly one area and that tied into this idea of quantum contextuality which i hadn't heard of actually and really was very interesting dean what do you think um i guess the biggest thing for me was and i and i use terms that may not you you might have to unpack them but one of the things that i was really interested in listening to was the fact that um that pers the perspective piece and how you every time you're observing something the perspective that you hold um you may not be aware of how important that is but the fact that chris sort of brought that out again and again um well that really that really resonated with me because it's something that i've been working with with people for a long time cool so a few thoughts that i had from 17.1 and also what you just said so this quantum contextuality and then the part that was really novel and exciting to me was thinking about quantum not as just simply about electrons and protons and okay you got strong force weak force electrons protons maxwell's you know just throw the regular physics particle physics or something and then it's just equations that have different efficacy over different spatial scales that's one presentation of quantum and so then it's like well if you were that size or there's something about uh the system about that specific system or that size of system that makes it quote quantum and this just expanded the definition of quantum to me to this kind of measurement communication encryption encoding and ultimately also bidirectional meaning and semantic information all the way down so that was a very different way to think about the relationship of like the molecule to the electron orbital it's like it's quantum it's not the way that the electrons would be behaving by themselves but maybe that's not just because they're electrons maybe that's something about structure in general so that was pretty cool and then also you mentioned and chris did dean observation is always coming from a perspective and that was something that we talked a lot about with the projective consciousness model from an earlier discussion and so that was saying yes um you get all these cybernetic functions and all these functional attributes of consciousness from a projective geometry where the observer is at this the center at this actual special point and then things are projecting out in a certain way so that's like kind of physical analog it's geometric and then um stephen you said there was a different sort of math that they were presenting they didn't use projection of geometry this was from like a different branch of the game with the category theory and with these other theories that we just were barely scratching the surface on so that you know what does that mean that those different branches can re-uh integrate in a certain way and then potentially not just through an equation but through a process theory so that was some interesting stuff any other thoughts or i mean really yeah we're just we're just yeah go ahead just now that's some really that's really interesting i'm just letting it sit because it takes this idea of the perspective and this idea that you know the idea that this quantum idea can be much more across scale and he did talk about i think he called it quantum noise or there was the use of noise which then gives a rationale i think for how this quantum processes could permeate through everything even if you don't see quantum transitions in the simple sense like you said with electrons and stuff then there's this this is permeating and that that then comes to that idea of the the the contextuality as well as perspective when we think we take a bit different perspective in a very okay i can see i've moved from here to here and i've taken a perspective but perspective at this kind of phenomenological deep level is kind of happening happening at um um all scales like the the context is changing um beyond what we can take a perspective on if that makes sense except we use the word perspective because that's what we can get a handle on but it's it's changing in so many ways of which some of which we just can't know so i thought that was really interesting um and maybe that's something that our biology is knowing but a deeper level you know it may be these nested levels there's ways of which that sort of knowing is being harvested once for a better term um so yeah thanks the body knowing which is something we hear about and something you just said it's almost like well if the body knows through action like the tendon knows to do this because of its biomechanical properties but that's it's how the knowledge it's not a turing computer it's not doing some trigonometry but it involves angles but it's because of how it's embodied so that's a it's an it's not the knowledge on a hard drive so that's sort of why some of these information science approaches are probably on the cutting edge of what information means because we're having to think about how there is information like in the body of the insect that helps it walk or in the nervous system of the insect there's some pattern generators for example that that's where the knowledge of walking is so it can't do every walking pattern but it is like this attractor for walking and then that's where the knowledge is but it's not all knowledge and it's not a text file or script that is implemented on how to walk or not even really an algorithm so it's kind of like good and also yeah knowing is on the inference side and then what is the other side of that with action [Laughter] so i use sometimes use the frame of of prisms and prismatics and you got energy in and then you got a rainbow on the other side daniel are you kind of talking about seeing both at once like knowing what both are are doing i mean it's going to go through this triangle right but i mean just being aware that what what what we see on one side is not necessarily what we see on the other side and that doesn't make one more important than the other it's what's important is knowing how things are are looking to the person who's got this perspective now okay i'll try to address it yeah i seem to remember shauna saying the word prismatic or chromatic or something about yeah i use that all the time yeah okay it probably has an interesting technical definition so it's interesting just that it's like a vivid sensory representation of all the opportunities all the possibilities all the colors the rainbow and even beyond with the electromagnetic spectrum greetings blue welcome um and then there's like um yes the prism focusing different rays of light or just optics like the rays of light are focusing at the center point and then um that's where the focus is that's where the regime of photons is and then that's what enables the function um greetings blue do you want to say hi and give any um thoughts while i just resize some stuff yeah sure good morning everyone my name is blue knight i am an independent research consultant based out of new mexico and yeah this paper was i don't know it was like really difficult to work through i thought and also really well written for like i'm not like want to sit and read like math lemma this and theorem that and like that's always like not my thing i mean i always find it just difficult to digest i like to do math as problems but not read it as like reading material but i thought that for like the amount of information that was contained in this paper it was like really well written and easy to relate to um i did think that it could have used some additional like practical examples of stuff but then like considering the length of the paper i was like man if they like put practical examples for all of these different things it would have been like a 70 page paper so um those are my thoughts on the paper and it was great having chris here with us uh last week to answer all of our questions and definitely something i um really enjoyed so cool um yeah i wonder if we can keep that question about examples of this in mind as we maybe look through the keywords or look through the roadmap let's just re-acquaint with the paper so this is the information flow in context-dependent hierarchical bayesian inference by fields and glazebrook one of their papers and collaborations together and they basically lay out that there's two goals they're kind of a twin purpose with this paper so one piece is related to what stephen was bringing up earlier with taking this quantum contextuality approach and then generalizing it in a scale-free aka multi-scale way using techniques that are scale free apparently such as two spaces and channel theory although also say like a linear regression is scale free there's no a priori scale for a linear regression it could be over little things it could be over big things so in a way just saying scale free is almost like saying we made it about how the modeler approaches the system so that we didn't get tied down in attributes of the system that we don't want to be um making skill-free and then the second side of this scale-free approach to contextuality is they're going to demonstrate a connection between that and a lot of recent work in bayesian statistics and hierarchical bayesian models which is also where the most direct connection to active inference comes into play because we've also seen hierarchical bayesian models as implementing active inference and then that's being tied to something that's at a different or a higher level of mathematical generality which potentially could allow an active inference model that you make for this specific task if you make it within that framework you might be able to lift it out and put it somewhere totally different like you might be able to use it to describe systems and fit parameters or generate data that's something that not all models can do but there's probably other modeling maneuvers that will be possible and so it's kind of like if you have gaussian assumptions certain things and statistics work really well together like you know certain relationships between multiplying things and adding variances so this is kind of like a higher level statistical um relationship that and i think that has to do with the matu the commuting of the cones or the cocons but who knows um okay on the road map were there any sections that like sprung to mind or anything somebody wants to say on this all right let's go to why it matters and think about the examples so yeah stephen um yeah okay and good points you just made um i think that the um that example that was just given actually about the prism i think it was a good one i think that might even itself be something that could even be a a topic of discussions i think that opens up things but it also uh it gets some other stuff because one thing that's going on here is the the bayesian inference you're kind of inside the the situation that's at play and what i think that if we're going to say why this matters i think it might relate interestingly to a paper that's going to be actually coming up over the next week which talks about um the way that we understand the global workspace or theory of the brain and the idea that we have this phenomenological consciousness which is somehow attuned to the flux of sensory data and then we have what we're actually often modeling which is what we're able to consciously be aware of so this flux that's at the you know which sort of it starts to get into the markovian monism theories of of um fristen this seems to sort of give another way to go from the flux up uh maybe this you know in the way that david bone talks about the um implicit order of nature and um and i got a message from tim as well just through saying about to think that you know we've got this idea of quantum noise and classical noise you know and you know this non-linear dynamical systems are kind of working with what could be mean as noise or changes in noise so um so i think that that part of the that part of the the story is um is sort of important across all of active imprints in a way because at some level there has to be a way to extract meaning from uncertainty and so it seems that this gives some other way into that blue or dean here's a thought okay go ahead dean i'm just going to say that i so back to the perspective thing um so one of the hardest things that when i was working with with people trying to find themselves in in new situations was you you you're either inside of the box or you're outside of it and i like the word that stephen used their extraction because i think that that i think what this work does is it maybe enables that extraction piece a little easier if people know what you're talking about in terms of stepping back we have a tendency to step into things and analyze things from a from an inside out perspective and i think how this how this could potentially work is as a way of of gaining a sense of removal which is actually advantageous at times i mean if you're looking at something that's complex it's it's very difficult sometimes not to get caught up in the in the moment i was speaking just before the live stream started about white water rafting when you're when you're going down the river and you're in a class three uh rapid you're thinking about that you're not thinking about the perspective of being up on the cliff watching the raft go down the river i think this allows people to get outside of that moment i think that's my one of my hopefully why this matters contributions even well just sort of with with that i think in some ways i i agree what you're saying but i would also say what's interesting is maybe it allows you to remove yourself more than we normally can because but also show that actually when you think you're immersed in it you aren't as immersed as you think you are right because there's these other levels of immersion um which are you're beyond your conscious awareness and there's probably even other levels which even beyond your phenomenological and biological systems ability to tap into so there's a maybe it's both ends if that makes sense you go you can go further in if the word in is meant that way and further out if the word out is meant that way so on this why it matters um here's one thought and then anyone else or i could go for a second so stephen when you said extraction um and i know you have a background in chemistry so that's sort of like it's separating into the different fractions so it's it's um not just extracting like you know the lithium from the ore it's actually like we can have a discussion what are the affordances what is on the table what are we just going to just say is our option space for policy and then what are our preferences and what kind of uncertainties are we each bringing to the table from our perspective so it is um not like we're extracting the essence of the conflict and then we're gonna fix the essence or the reduction of the conflict or one dimension of the conflict perceived and then that will propagate through the other aspects of the situation it's kind of like we're gonna come with uncertainty to a minimal model and then if one person has one narrative for the policy and somebody else has a different narrative that's off the table so that is a way where people can bring their different ways of seeing a common model differently like in the quantum measurement case if both people are measuring the quantum particle and they're both fine with it that's one type of experiment steven yeah i like the point you picked up there on extraction it was interesting because uh that that sort of came up so strongly and i think um the other thing that's interesting is the idea even in chemistry is the idea that still you extract something right it's quite thin like but the idea that you're extracting something from noise because in chemistry it's normally like basically you you calculate everything down and then say what is negligible what can you say is beyond concern so you just say it's beyond worries you know it's it's within tolerance so to speak and then you just work within that whereas in this case it's like well all that noise so to speak is what we're extracting the information from it it feels to us like the stuff's out there and we're getting thinness so to speak but we're actually getting signals and supposed extracting enough variational free energy changes in the noise to then perceive it as you know knowledge but it actually it has to start out as fluctuations in i don't know if the word noise is maybe the wrong word but certainly fluctuations in non-linear dynamics so that's that's that changes a lot of things about how we understand knowing the world interesting here's kind of another point on the signal to noise so we're thinking in the shannon information aka shannon disinfo theory nothing against it framework it's about the telegraph and the wire and getting the exact recapitulation of the signal on one end of the wire as the other end of the wire that was the second paragraph of the 1948 paper by shannon we talked about it in the dot zero video he said the question of communication is about perfectly reconstituting a signal and so in that framework if you have if you're doing a chemical synthesis and there's one product you want then you can calculate like the yield of that product and then similarly if there's one thing that you know that you want you know you can calculate really exact statistics like information um and then once you open it up to the semantics um then this the noise has a different perspective just like you are highlighting cure i think there's a lot of richness in what you already said but yes noise is richer than just decay in the copper wire because we're not trying to recapitulate anything in the person's mind it's not a bit wise transfer through speech it's actually like the differences in the way that we speak are conveying meaning so it's not just error from some perceived um pattern of speech it's like just the meaning that the person is conveying through their action so that i think is also something that really matters when we think about differences in how people are going to be learning or communicating or something like that stephen yeah and the the interesting thing is that while to some extent you heat up a liquid or something it expands and you sort of the energy put in shows itself as the work you particularly see say when water freezes but there's this whole question of entropy and how it somehow tied to some rearrangement which is not shown as work in the system you know that you try and heat up ice it hits a point there's something going on there and we can't quite know what it is and it's energy hungry in some instances or energy yielding but um that that process is is beyond our direct perception so you just have to build it in with gibbs free energy and the entropy and enthalpy terms to see what will happen with reactions so that that actually then actually ties into fristen's work um in in actually it's the sort of foundation of his work in a way so i i'm not sure how entropy was named in this paper maybe i don't think that's directly part of this math this is another way to come in without maybe coming in with the word entropy but um it's interesting thanks dean i just again just try to draw from examples when i would talk about this with people and there's a privilege always given over to gap closing like we want to close the gap we want to understand we want to find the signal within the noise and i think what this does is it sort of gives over a certain amount of credibility just a gap respecting just leaving the thingness out of it for a bit so that you can actually take in more information back to what stephen was and what you're both alluding to how do how do we how do we give ourselves um cut ourselves a little bit of slack by saying gap respecting is just as important as gap closing and if we give ourselves that it's a kind of a privilege to do that because it's twice as much effort as just gap closing i think the benefits can be really quite profound nice point thank you so sarah oh stephen do you have anything to add here well just one last point on that is that could then where you start to get into abductive growth based knowing um where is maybe um we're used to because humans have got this capacity for deductive and rapid you know exclusion of what's out there an inductive trying to narrow the gap between us and a goal but when we're growing when we think about sometimes i need to just sit back and heal you know there's certain situations in the world which i can never process psychologically from a i can't close the gap on certain things right i just have to sit back and heal right because they're hard and so that that same piece you're talking about there then starts to tap into well that's the main game in town for organisms yeah the gaming town of closing gaps and is is um is a nice add-on that we have but it isn't the main game and blue so that just brings up to mine's like time as a gap closer right like when you just sit back and heal and and ultimately like time as a gap closer like if you think about like the time value of money and i mean like time is ultimately the thing that will you know close the gap on all prediction and and like we don't really see that in the models or in the math at all um it'd be interesting to see like the temporal dimension and how that plays in or people have thought about that or i mean time like can it flow forward and backward and i think that was something that was brought up maybe in the last live stream that's just interesting yeah nice dean just just one last thing i i i completely agree with you because again the privilege goes on on to time on task instead of task or or task on time instead of just seeing time in and of itself i have this crazy theory that that time is learning not just a way of measuring learning and i don't you can't get there unless you can get off that treadmill so thank you that's a great point and dean what you said about learning as time it's like the difference between kairos and kronos so kronos the chronometer the decimal time and it's about the wall time the clock time and then action is happening in a space of meaning of act it's time for dinner and that's an action affordance and so that is something that's we can bring in the uncultured component whereas the other approach is no the wall time is just simply how it is and we're going to like pro trustees shrink expand use heuristics use coarse graining to get around this sort of fundamental um linearizing from our perspective just at the scale we're at which makes it not scale-free which is why perhaps quantum only applies to certain so-called spatial levels of what we measure steven yeah sorry give me a sec i had it and then i just went for a sec there so let me ask sarah's question because it's really nice point in chat so sarah wrote um could we look at chew space slide and get a broader perspectival view to maximize signal to noise sort of speak so maybe i didn't perfectly read it but i think it was two spaces can we enter into here a little bit and connect that to some of the bigger discussion points and maybe even the other um useful points so stephen you want to give a thought or is there anyone who wants to give a thought on the two space piece here yeah does it this directly i'm not sure exactly how but um this gives a way that um things can transform from one space to another so it gives you that capacity i mean sort of keep it tightness to the the idea of time i mean with and i know this paper is not specific active inference with active influence you know without time you're not able to make inferences from noise so to speak or changes in information content in random fluctuations you only get that because you've got time because then you can tell if there's been a fluctuation so one snapshot can't do that now this seems to maybe give away to okay you've now got a shape of the information space what happens once it has a shape um now but beyond that it's uh i'm not entirely sure yeah um blue anything you'd say on this um topic otherwise i think walking through kind of just the way they laid it out in the definitions could be helpful in some of the examples they gave because like steven you you mentioned this morph ism right and it seemed like there's the true space and that's like a matrix but one that can be various kinds of things it's a matrix but just like we can represent a network with a matrix so we can think about like the space of all the networks all the social networks of five people it's like a five by five matrix and ones and zeros or weighted numbers so that's the matrix representation of the network and then that is one type of meaning of the matrix but also this can describe probability and it can describe programming languages bayesian networks like if each cell had information about a conditional dependence or not so that's like a a chew space is the space of the possible of these things and then this is the part where maybe we'll just say it's beyond the experience on this conversation but the wikipedia has like understood statically it's a relation and then understood dynamically and then it has another definition so it gets interesting has a static or a dynamic interpretation so i think it's yeah unless anyone in the um chat wants to jump in and help or somebody with expertise wants to come on later um how can we connect that to some of these use cases blue or that on anything else go ahead so i think like the um the dynamic aspect of the two space and the the two morphisms is that like you know any um if you have like a set a matrix right so if you have a matrix and it's like any series of transformations that can be done to form a new matrix so that that in my mind is like the dynamism of it all like if i take you know set a and i do this that this that this that in this specific order so again like here here's like the temporal like we're alluding to like time as a variable or time as a gap closer but like the temporal sequence is important because you know if you do you know if you multiply before you subtract or if you get your order of operations wrong it's going to be different right so the temporal order of things is the the morphism to to make the the next set thanks for that another interesting sentence is that um it's like the true transform or the morphism is a pair it kind of comes into existence as two spaces and a mapping between them or a map between them and so that is what ties it really broadly to functions and computation and these sort of transformation transmutation or input output seeming communication seeming processes measurement like processes because it's about sum space and some other space and so when we think about the active inference model and then we have hidden states that inference is being done on and then we have observations and it's almost like there's a matrix that connects the two of them i'm not saying that that's going to be all at this level of two space but it's kind of like there's a mapping where you can run the model from the sense data to the state and do inference or you can generate from the state likely sensory data so that is a bi-directional it's like a two-way bayesian machine because it can take in observations and update expectations of hidden state variables or it can generate so that generative and receptive element of bayesian computation is i think just it's like whatever is the topic that includes that and that network matrix and a few other things that's kind of where this topic can go which is why i think it's a really rich area and that's why the papers are written in 2020 and that's that's yeah stephen and then dean i think this this idea of moving between spaces is also really valuable because as you know i'm very interested in um understanding how we can look at awareness and sort of indigeneity is very much about awareness and a lot of the active infant work work is tends to be at whatness what's this what's that how can we understand what this is understood to do and think about but this when you start to get to this broader um understanding of how we can make meaning um and taking that idea a very broad level is the ability to transform between spaces and engage with spaces and that might extend up to our conscious awareness space but some of these spaces are well below the level of consciousness you know down to the level of cells you know but it's it seems to have and play out the importance of spatial transformation over whatness thank you steven dean yeah what i took away from this was that when we when we discriminate when we separate um this sort of gives you a sense of why we might do that um i think of some of the stuff that we looked at um in some of the work that i did we would ask people to watch something maybe a youtube clip and instead of trying to take all the information in as is is classically recorded through notes we'd ask them to columnize and row in under three headings tools and rules and pools now that was the mnemonic but pools basically where the gradient is what's aggregating and so we'd ask people to classify something and what people found was something could fit into two categories something could be a tool and a rule sometimes it could go across all three it could be a tool and a rule and a pool like there was a way of being able to see um relationship and i think that's what this two spaces does it says we can discriminate we can separate but sometimes things fit into multiple categories and that's that's something we need to be aware of our minds are able to sort of pull apart and then reorganize that's what i took away from that nice very nice dean and i think that's sort of reflected by this cone and potentially even your prism topic because it's like yes there's a unity of c in this case but it is going to be manifest in these different spaces and this is a really informative slide so it's talking again about these pair of two spaces that are related through a transform the transform a to b can't and this is from section or example 2 7 in the paper the transform a to b in this case can be viewed as transporting the information encoded in valid flow formulas from a to b and can thus be thought of informally as a channel from a to b implicitly providing a sense of spatial and or temporal separation between a and b so i thought like there's the maps of meaning and so there's my internal map just so to speak just using it instrumentally and then there's person b and then if we're playing 20 questions it's like okay is the house bigger or smaller than a bread box there's some semantic mapping internal to me and then there's a channel with this with the sense data and then there's a semantic flow related to whether they're going to give me a yes no which is like chris said that's quanta because we're quantizing the response is it bigger or not we're making a measurement of the response now they could be lying or they could be wrong or they could you know we couldn't hear them or something but it's a binary question and then there's a semantic flow and then there's a back and forth potentially otherwise you're talking about different things and so if somebody is thinking maybe i was thinking of a little toy house smaller than a bread box so if you have a different frame of reference then even the communication is not going to work because the holograph is going to be read too differently by the people even with the same information so that's like the separation of cognition across participants in a conversation and then that's happening implicitly through time but then it seems like also things can be just more abstractly described as being separated through time and so something that's separated in time but not in space is like memory which is where this whole discussion of memory comes into play because it's it's a communication through time at that spot like a time capsule it's like 50-year message out you debate whether you're the absolute position of the time capsule is the same but it's like relative to it it's a message through time blue so it's funny that you bring up a time capsule like i've been really thinking about um you know at scale carrying information forward and backward like from you know cells to person to like a group of people and and it's like you know when we what do we carry forward and when we like used to make time capsules like every 10 years i don't know if we still do but then we would dig them up and like you know dig them up every 20 or 30 years or whatever and like what do we put into a time capsule and does that like effectively capture like the culture of the society at that time like a cd or like you know these different things that go into the time capsules like this is actually like what we're carrying forward and sometimes it's like dumb stuff like i don't know it's just funny to think about what goes forward right in time and and why that and like how the selection process works and if it's like a systemic or generalized thing or um i don't know it's just something that i've been thinking about how that is transmitted across time great question and very prescient of course with so much digital information and a potentially fluctuating cost of storage wildly cheap but then wildly expensive and that could lead to some very unfortunate information flows evolution has sort of an answer to that which is like what's passed forward is what is fit to its niche not biggest bench press strongest fittest but fit to the niche adapt skilled to the niche so we don't need to go too semantic on that but i think the term actually does fit and where evolution by natural selection as well as active inference come into play is by formalizing a process theory you kind of step away or at least you can maybe get some distance or some model ability of these complex processes so in evolution the process theory is basically you have heritable variation in phenotype that's found in a population where there's heritable variation in fitness and if those are all linked up in the right way at least locally that's the way that the phenotype and the population moves and so active inference it's similar but kind of like with information just saying okay sense data comes in action goes out from a generative model into the niche back into the sense something happens with the generative model integrates the information engages in policy so it's like if somebody listens to a lecture and they only write the notes of five sentences and then they pass that off the process theory explained why there was an information bottleneck there because we just modeled the situation and we don't need to go into oh it's tragic there was only five sentences or there was more than you know it was five deep sentences though or something like that we just say what it was that was the actual transmission and then that is a starting point for the kinds of value-oriented analyses that you might want to do afterwards dean yeah i'm just curious what other people's thinking is on this because typically between the inference and the model we not necessarily the people here but oftentimes what's parked in between those two things is a plan and what you just described is not a plan so i'm curious what other people think is between the inference and the model i have my ideas but i'm because i'm trying to get to know you folks i'd like to know what you guys think is between the entrance and the model stephen yeah well this is that's the six million dollar question they um i i think that the the the introduction of the quantum approach at certain scales does yield something very plausible and and and chris's work with mike levin would tie into that because he does a lot of work with bioelectrics on cells membranes so i could see that the this question where it's more directly attributed to to quantum fluctuations and what that means you know at the level of the cell and then the bio electrical or the other chemical electrics or the bioelectrics of the membrane and then you the next level that i can kind of see it more plausible is brain waves you know and you've got this overlap then maybe there's some quantum effect but then in between that i i'm it's probably more action is more classical in terms of how you pick things up it's literally like i just keep doing it and in a very rough and ready way i extract some sense of how it is to pick up an apple or something you know and i'm inferring things in a more classical way so there that i think there's a mixture of a classical and not only past partially knowable set of information transfer and maybe some more quantifiable stuff which maybe is i don't know if it gives you more accuracy at that level but um might be more quantum like but i i'm not that's that's my thoughts um okay uh so just to dean the question was what's in between the model and the inference okay is that what you asked yeah so let's just kind of go into that so what by model you mean the actual code as you wrote it on the computer or the actual systems diagram like the model you mean what's on the computer or what's on the paper is that what you mean that's the product of the model and then the inference is um the computation that the model does or is it is the inference how we then look at that model and then decide how we should do policy because yeah it's it's literally in it's it's moment by moment it's that it's the smallest time smallest of time frames relative to the the end the endgame or the end product how do people typically they put a plan in between those two bookends that's how they parameterize and so what i'm curious is what other people think actually is in there because i know we see a plan where we're given a plan but i'm not sure that that's exactly what's going on so i was just curious what other people thought is going on blue so like i'm not sure that i'm also like understanding the questions so there's like the generative model and the predictive model right so there's these two models and so the generative model is like the model that you like have um daniel probably have a better way to say that and then the predictive model is in my mind that's the plan like i predict that if i invest in crypto i will have 10 more money at the end of the year or whatever right like so that's my prediction that's my predictive model that's my my my plan so in my mind those two things are are synonymous but but maybe daniel can can clarify or speak to that in a better way thank you blue um i think i try to just take what you wrote annotated a little bit the internal states is a generative model of the niche and that includes the agent's action in the niche like i can see myself going on a walk every morning that's like a combination of a trajectory of action and affordances and a niche and other regularities and other availabilities shoes or something like that and then there's the actual generative process and the generic process is like the part that is the play and also where cybernetics theories like the quote good regulator theory come into play because the cybernetics is like well you have to be effective you have to have all the variables in your um environment but then we can look at for example alternate understandings of astronomy and there might be evolutionarily adequate different understandings of astronomy that allow individuals to deal with irregularities in their environments for the niche that they're in given their affordances so the gen but the sort of realism take would be that it's the same moon and sun at the chart you know the fibonacci spiral all these things you can do but it's about the narrative of policy under that generative model the niche but it's the same market that it gives me an ability to act in a non a surprised way as opposed to using surprise all which is this kind of metric which i can kind of use both in my retina and my nerves and everything is this kind of general awareness of how much of a variation has been but surprise and you know something can happen to me once and i make big decisions on that and that is sort of basically sitting on top of all this activity sort of need to know as an animal because and and um there's a there's a great presentation on this and i can't at one point in history basically we have to add in who into our environment so up to then it was just like how apart and sometimes things fit multiple categories so how do we explain that with a plan no because that's fluid that's just dependent upon how you're looking at it and sometimes you'll you'll talk to the person beside you and say do you see what i see which then you you've you've already pointed that out a couple of times in this conversation so i'm just trying to figure out what's in there is i think it's more than a plan and i'd hate to default just to that or over reduce just to that because i think that's part of the problem when we're trying to figure this stuff out dean and um blue so definitely there is a who and i think that that really like loops us back around to the point of this uh fields and glaze book paper that there's this intrinsic contextuality and and so you can't really effectively model contextuality unless it's you can remove the intrinsic component right like so when you can when you can remove the the subjective aspect like i mean we had a conversation i don't remember if it was last week or two weeks ago about like at a dinner party like how was the food did you have a good time like or not did you have like how was the food was it fun and so all of this is like you know there's no objective answer to these questions it's going to be different for all the 15 people that were at the dinner party right like some person liked the food some person had fun one person didn't one person you know thought the food was cold or didn't like the dessert or whatever right there's the subjective experience so it's really difficult to separate the who from contextuality nice questions and uh answer stephen yeah this is very this is very important actually what you're saying i mean i think this also ties into this idea of what it means when we do planning and also how we think of planning and start to extrapolate that so generally speaking in the in the everyday sense of planning we have like some sort of shared something in the niche like we have a plan we often make plans if not it's somehow there in some verbal semantic thing which isn't just in my head it is in the niche it's sort of in this semantic niche and but the the idea for instance of how does my body know the plan for getting on a street car right when the doors open right i i know how to do that um and it's not but that kind of plan has to come from somewhere and it's much more there you know i mean so they get all merged together but the um and that maybe is partly in our niche in the way that we have the right sort of shoes on we we set up the design you know because we have some control but then even when you get into other areas of the niche okay i come across a particular cliff in a mountain and i i'm you know i'm not from the modern world so i haven't got all the technology right but you can reinterpret the past right yeah that's uh not within our affordances it's we can only infer on certain things but we have causal agency and actually in the spm textbook there are some integrals that are like from all of the time series together just like sort of matches all the time together and there's other ones that are calculated like up to that moment in a sliding window and then it says that's what makes it causal is we've restricted the analysis to only the previous states that's kind of how mathematically causality is defined as is like well if it's lagged in time or if you slide a window as the arrow of time you know changes but then that's not the same thing as the arrow of time or the experience of time or anything like that so yep but then this local logic slide was just to say that um and to also continue this discussion on contextuality it's the local settings so how can i where does this matter and how does this expand the discussion hopefully lead to more powerful models is um if you're not playing with the local rules then you're not playing the game and so you're going to semantically lose against nature if there's organization in a way that attempts to violate local logic like if there's some equivalence between heat and computation in our current understanding and you design a machine that just violates those rules like you don't plan to dissipate a certain amount of heat given how much computation it's like you're not designing within the rules of the system you're just making a poor computer and so we're talking about communication though and information transfer that's meaningful so what are the local logics for communication what are the local logics that are shared by people who speak the same language versus all languages versus all ages and things like that what's the shared context that lets us communicate what we need or how we should act together what else what would be a fun slide to go to or just topic to go to it mentions ergodicity there that might just be interesting to see his take on that yeah you know blue do you remember but um i feel like arrogancy wasn't we can look actually in the paper itself let's just see if it's used there we go not used in the paper itself but uh we put it in there for some reason partially related to these um kind of what we're talking about now in a way like as you're bringing up it's relevant um of a term but yeah it might be there's a question about it raises that question because it's such a big part of active inference how those two things relate because it seems to be able to get at some of the questions without the need necessarily for ergodicity in the same way but maybe i'm not reading into it um but i've got a feeling that it may not require it because you have these spaces that maybe have inherent ways of obtaining knowledge or information between these different types of you know morphological transformations okay i think here is where we asked it so this is the quote um in the paper um they're talking about contextuality by default and they say the criterion effectively generalizes the intrinsic contextuality of quantum theory so the one that we know of with the wave in the particle and the entanglement spooky action stuff to the case in which other properties of a context e.g the order in which questions are asked also affect the distribution of a variable of interest so it's like 20 questions if you go down one branch first it's going to be like a bifurcation with a question and communication is like a bifurcation whereas in the telegraph in the shannon info theory it's like if a signal is garbled and it doesn't come through it's like it's a lost transmission but semantically it it might ruin the file but at the level of the message it just wasn't transmitted accurately but um so it bifurcates the meaning of the file but from a signal to noise it didn't have a categorical bifurcation maybe only one bit in a million was actually flipped and that was just a stochastic thing but when we think about semantic information flow the order in which the information flows especially in a dialectical or in an ecological context is like the whole topic information flow is improvised or at the very least it's it's engaging so it's not just letters on the page re-capitulated but it's something informational stephen yeah that that that's important and that ties into the idea of um how much there's like with shannon entropy or there's the idea of a signal there's something in the signal and you're losing some of it now with um kristen's work it's the idea but it's it's it's all non-linear and you're you need the action so that you can compare um the um the way that the the signal changes are happening to infer something from the noise so to speak you need the action but in this case it's like there's another way to sort of say there's an inherent something out there so to speak there's sort of something in the signal um it's not just only the action needed which is probably why then this can be applied to bayesian inference and not only active inference because the saying there's something inherent you don't only need the action and you're getting it because of the order in which the questions are asked um and that order actually that's interesting then that that isn't often how i thought of contextuality i just think about contextuality is where am i you know what i mean and what's happening but what order did what happened happen give me something is new for me no yep when are we and when were we there all those questions blue so i have a comment on ergodicity but can you back up to the uh cone cocoon diagram because i think that this is why we brought it up yes so here in this cone cocoon diagram the one on the top right like so so you see this um information channel c right that that relates all these classifiers a1 a2 all the classifiers are linked to this core information channel and that that kind of um doesn't really imply like a a distributed system it applies like a centralized control but um we brought up ergodicity because if if you look down in the second picture here from c to d there's this commuted commutative property that is or i guess it's even in the top picture so it's this the g's right like the commutative um aspect of the cone cocoon um diagram and so i think that that's where where the ergodicity um came into this paper right like the fact that that all uh properties are available to all points in the in the cone cocoon cool and also you know these topics can go expand beyond the narrow and the technical but let's think about a technical definition of sampling ergodicity so not taking on all the um experiential elements per se but a remember is a classifier so it's a two space scarlet letter a that's what's being represented with the and it itself is a classifier because when we were talking about the two spaces there was like it could be the um types of a computer language and then what their descriptions are so this is like cats are small you know horses are big this is my classifier you know big and small and then horse and cat and then just which one's big which one is small so it's a two space informally um and then here is a different true space a2 at a different time maybe it's time point two maybe it's person two maybe it's all the people so here's me a sub k all the k people or all the k moments and whether it's one person through time if you ask the question you get the same quantized response yes the cat is smaller than the horse because cat's small horse big if you always get that response back semantically then you're sampling from ergodicity with respect to that question so there's it's a big topic with like what it means in physics and everything like that but just from a sampling perspective if there's k people in the room and you sample in all 100 of them or every time you sample 70 out of 100 give you an answer that's the sampling ergadicity and then here are c and d which are like two observers and they're kind of co-sampling but they can only see the raw data so they're able to see all just what we were getting at with the top part just like this is like sampling across informally population or through time and then it's ergodic if there is a stationarity there here that is the same scenario but now there's two observers and then if they are related in this very specific way then it opens up a lot of connections semantically between c and d also sarah added in the chat that salience is a time dependent phenomena and uh that's extremely true so everything that we talk about with attention and salience and surprise those are like almost explicitly time-bound processes and even in machine learning when people talk about oh it's a neural network with attention or with recurrence they're kind of talking about a time element but anything that's where it's not just a snapshot that moves state to state but there's something that's captured across time steps and that's called attention sometimes so it's kind of like it's actually a similar way to how it's used in a modeling framework here this was one question that we had in 0 and beyond and hopefully got to ask chris a little bit but like what um are examples or how can we you know what's the next question to ask or what's the next system to explore this way that was one set of questions also if anyone in live chat has any questions we can definitely look at those what else would be interesting i mean there's a few more slides that we haven't looked at that we could kind of explore so maybe one element here is oh yeah go ahead steven sorry well just just once he talked about and maybe this is something he brought up as a as a slightly new advancement he talked about separability separability um as a sort of he positioned that sort of center stage during his slides when he did his introduction um as maybe a way to i don't know think about contextuality um in a more tractable way um yeah i wondered if that was you know was that how did that come up was that something oh that's interesting was that a little bit surprising that he when he did that um yeah great question and point so i just searched in the document there's two spots where it's mentioned they write we have previously shown how inference can be represented using the formalism of this paper employing only the quantum theory of separable systems and the thermodynamics of measurement interactions so there's the citation to fields and glazebrook to explore that more but i think from what we're talking about here's an interesting part that um is related to two spaces it is often the case that two spaces may be separable or other types but let's just focus on the separable element um i.e both separable so it could be separable it's almost like you could have another two space you know which two spaces a through z are separable or not so there's separables equality and then it says separable means all rows are distinct extensional means all columns are distinct so actually the transform that goes between them is probably the transpose the t in r and then if it's separable on columns and you transpose it it's separable on rows so that's like a relationship that's kind of a high level but it's maintained when you transform it back and forth like blue is saying add subtract add subtract you can transpose the matrix back and forth um so separable meaning the rows are distinct so let's just think about the case of the chew space as a descriptor just which was one of the uh ways that they used it so like the types as types of processes kind of so if it's separable it's like they're distinguishable types sometimes that's also called a full rank matrix where it's like every row and column matters uniquely and informationally there's no doubled rows where you could condense the matrix by saying actually there's five of this row and so this or this row is a linear combination of this other row stephen yeah that that um this this is good to bring it back here that because it's uh this is sort of the applications of it and um the separability um i think there's more that can be looked at with this over time i think this is obviously something that's going to be quite appliable and it also relates to you know this idea of self-organization and planned organization so you you know how much are things um uh able to to to infer things because of the um the separability um that in itself um maybe changes what's possible um yeah actually here's a quote we haven't looked at this is really interesting though in working set theoretically so with this sort of set approach to choose basis there's considerable scope for the choice of arguments in the choose space as well as the choice of the corresponding relation r because we get to choose the spaces and the map so we can you know map from various things to various things different ways these and so what kinds of things can we do probabilistic in particular conditional relationships so that's like all of computation and stats bayesian fuzzy type relationships fuzzy logic fuzzy math um spatial observations object identification and merological reasoning this isn't a paper to look into that means parts and holes how they're related to each other and dual process theories of cognition so that's bringing it to the cognitive neuro and to even the neuro scientific numerous examples are discussed in the paper and they are it's um it's a double paper but it's very informative and so all these kinds of things are kind of what is adjacencies for the two space dean and then anyone else dave if you have any thoughts after dean otherwise no worries i just could you go back to that cocoon thing yeah that one there the bottom one it's interesting because when i read looked at that in the paper it took me back to some stuff i did about um that diamond shape and how that symbolically relates to opening up which you mentioned daniel and and self organization which stephen mentioned um we see that when we see a diamond uh designating a high occupancy vehicle lane and the sort of way that that frees you up as long as you meet a minima in terms of the number of people in your in your vehicle and we used to talk about that idea of how these spaces are there even though you may not be necessarily noticing that um yeah that's that's even if we don't formally look at it that way there's all sorts of examples around us of when that's actually occurring so i just thought i'd point that out it may not have necessarily do those kind of associations but again if you're trying to bring this kind of information to people and go well here's an example of where we're actually doing this stuff we may not be aware of it but it's it's going on this that's as soon as i saw that that's what kind of made me smile cool thanks for that association there dave this is not addressing any specific point but gregory bates and a number of times observe the cyberneticians getting stuck by talking about random inputs random inputs he says look stop thinking about random i want you to think about noise we're now going to talk about organization from noise and i think part of the point is noise is more clearly relative to your values and your plans yes very nice and also affordances which are semantic like even years ago when i was learning about shannon information theory i thought i can be symbolically surprised by the characters on a page but if i don't speak the language who's to say whether the information is really there so there has to be something else here that's helping address the situations that are meaningful or not because it's not just about how rare the character is in a world where just one word can mean a lot at the right time in the right context stephen yeah the the idea that you're you're you you need to constrain certain times or separate i mean i suppose in a funny way the car lane i uh example is quite interesting is you know you've got the the movement of traffic and at some point the high occupancy vehicle lane becomes different in terms of what's on it as long as you can enforce a rule oh and you know and communicate it but and enforce it and that that kind of idea that you can create separability otherwise um and maybe that that sort of principle of uh there's some constraints um implicitly out there i suppose on what things are gonna do with each other i suppose um just like the way water behaves in certain contexts at certain scales within our gravitational field but there's also and i'm not sure how if i'm over extrapolating but how biologically you know you know different ways we have to there has to be some point where you have to impose a separability you know you might need to form an organ from cells to be able to do the next thing you know to to create insulin or something it's not just enough to have some insulin cells dotted all around the body you need to have a pancreas you know so there needs to be that constraint you know so that you're in the high occupancy lane and that's what's happening so it's um you're in the high insulin-producing cell type and then at a bigger level you're in the high insulin-producing organ sub-component in the organ and so it's this nesting and there's um uh maybe even an extraction of function using what you were talking about earlier so then sarah wrote in the chat also about the uh definition of the two spaces here saying that this is another way in which the ergodicity is going to come into play because uh sarah writes separable is saying that the event space for a given time frame cannot be compressed i'm not sure if that implies the aggregate matrix itself cannot be compressed reduced in some way and then here this this by extensional collapse so if you can't collapse the rows and you can't collapse the columns and you can transform it and that still is going to be like true it's just like it it's informationally rich then any repetitions in the rows of objects and columns of attributes are factored out and also the reason why attributes are at time is an attribute if you think about the object as existing through time just like you could measure the color every inch of the ruler you could measure the length of the ruler at every measurement in 10 time points in practice this removes unnecessary repetitions in the content of information hence minimizes the amount of processing required by a given algorithm so if you do 100 measurements of exactly one meter because the time was unique that's still 100 measurements so the classical approach would be like well sounds like we got an answer i mean look at the p-value it's one meter but then here when we retain this rich contextuality we actually don't pool even though we were sampling from erodicity of length we don't need to pool all of those measurements together in the same way perhaps and so that is definitely related um sarah's point that this matrix the rows or the columns can be thought of as being temporal so when we think about the matrix having structure on like a top to bottom or left to right way that can represent structure in time like just like you have an eigenvector you could have an eigenvalue through time stephen so if i'm understanding you you could have a relatively um say a small number of uh observation types but build out a space because over time you can still you the time variable gives you the ability to make that into some sort of space some sort of topological space it's not just a space of different measurements of different things it's sort of certain things over time is that right yep here's an example that kind of came to mind um it relates to insect vision so a lot of times people think about insect vision like oh they must see like a bunch of versions of the world but then we think okay well we have two eyes and we see one version of the world so it's probably a little more integrated than buggy putting that aside what's the resolution of the bugs site and it turns out that there's some insects that only have like one omittidia cone so it's like kind of like a one pixel camera it's like almost light dark so you would think and if it were on the wall all it could do is inference light dark in the room but because the insect has a body is a body it can move so even if it's just light dark or gradients of it's getting like a bit string we can think about continuous variables or just zero one and so can a bit string encode information that's rich like yes like sports casting of a sports ball game you say now they're running from the 30 and they're at the 20 there's a person and they're at the 10 and so that's a string but it conveys action and context so they don't need to take the 4k video in order to know whether to run or walk and that's actually really related to carl fristin's woodlice example which he claims is the origins of some of the free energy principle kind of any other um slides we want to go to or we can just look at the last ones otherwise i think it's been a great conversation and it was definitely a educational paper and several weeks like for the lab we're always happy to have new participants such as yourself dean so thanks a lot for joining and yeah this was an interesting set of discussions also thanks a lot sarah for helping on and and blue 4.0 for 17 because that that was kind of like how we started the conversation in a way in a way that helped us structure it because there's a lot to get lost in here blue what do you think and then dean so you're on the markov blanket side can you go back to it yep so i was really thinking about like i have this note in the paper so hold on let me find it so in like you know when we have this markov blanket it's like the things that we're not privy to the information that we like don't necessarily know about right and so we make a decision we have all of the information that we need to make a decision but i was thinking like in a system where the markov blanket is like too big like if there's too many things under the markov blanket that we don't have access to like how does that like impact our um like ability to act within the constraints of the system so like here it's where they talk about the frame problem right like so where um you know you kind of can't solve a problem until it's been solved already until you know how to solve the problem like you can't determine the answer and i think that that's like the the gist of the frame problem feel free to like elaborate or or correct me on that but um you know i think that that's like one of the things that is so difficult about a problem like climate change right like so we can't solve the problem like climate change because we don't know how many factors are potentially influencing like we don't necessarily have the entire context for the climate change situation so like i know what i'm doing i know what my carbon output is and and like i can research the companies that i buy products from etc but like i don't know what all of the other nine billion agents in the world are doing and so like we can't you know make predictions based on our actions right so like is the markov blanket like too big in that situation to be able to solve the problem like because we're not able to see directly the uh outcome of our actions or like even the actions of our group of people that are in our network i was thinking about that interesting dean and then dave um just a couple a couple of things first of all um thank you for being so welcoming i really appreciate that and the second thing is is that [Music] when i watched last week's um broadcast because i watched it on youtube i felt like i was i was a spectator and now that i've been a participant but i've been a participant of a debriefing exercise so i've actually been a participant of something that's been separated out from what originally happened and i think that this paper is the same this is real time what this paper was discussing um so if you want to i don't know if you could find a better example of where that idea of what perspective is and what potentially prismatics are even if we're not talking about them we're still playing by their rules um again thank you for allowing me to be one of the the people in the tile today i just really really appreciate that cool and it's like the paper is the tent pole in some ways because it's actually north star the reference point but we're giving our perspective on it but we shouldn't be disagreeing about what the paper is or says we're looking at the same slides but then the richness is actually everyone's understanding and contribution just wherever it is coming from whenever it's coming from there because what else could that context provide dave yeah i don't want to uh go too far off track but i noticed the paper references donald hoffman and i don't want to do an injustice to the good doctor it may be that um i see him stepping into it when he didn't really with his one video about the interface is anywhere you want it to be it doesn't make any difference the interface is totally arbitrary maybe that's just his billions and billions moment but did donald hoffman go down the rabbit hole a couple of years ago or is he still doing good solid work that i can read and not get my inexpert self thrown down a rabbit hole can't speak to uh the body of work don't know it that much but just i pulled up the citation from the fields in glace brook paper it's a 2015 paper of the interface theory of perception and so the way that they that fields and glazebrook use it in the paper is basically to um actually in a way that's related uh to the interfaces it says equivalently an interface and that's the citation so the markov blanket here is being connected to their approach so it's kind of probably a yes and it probably is great insights about the interface and then it probably does matter where it is or what it is or how it's modeled so yeah nice point though stephen yeah the good good good observation there i mean there's probably a you know there's a reason why chris fields has got involved in active influence because let's be honest as from my understanding of my observations over the last 30 40 years consciousness and physicist physicist physicists have kind of run the show around consciousness and there's been more and more sort of big claims um about uh you know consciousness which is great and um this is seen as um you know and a quant there's a there's a thing called um mindell the mindells do the process orientated psychology and um some good work but i always used to like have a bit of a sigh when quantum got mentioned because i knew that it was going to be like even though i knew physics i just felt and maybe i was wrong but i just felt it was being used in a very trans-personal slightly hand-wavy way but maybe that and now we actually bring it into like it's not all about the physics it's about the biology which is kind of like taking the physicist physics area down a peg or two um although now kristen could say it takes up a peg or two because it's all based on physics it depends which way you want to look at it but um interesting world let's let's put it like um thanks yep in this quote um this is the authors they're saying that this marco blanket concept which is map the interface and all these other ideas like communication channels it's doing a double role in these models which is that it's where free energy is minimized so it's sort of what is going into the function that's getting minimized if you're you might be reducing your water usage but what's going into your actual function that's deciding your policy that's what's getting minimized and then something else might also be affected but what's getting minimized are the blanket states and it is that epistemic barrier that's keeping context what isn't directly measured that information is hidden from the observer so there's probably a bunch of questions about this and a lot to say about it but one big question that i have is um we know from previous papers that one of fristen's innovations was to separate separability perhaps separate the blanket states into outgoing action states in incoming sense states now it's possible that there are certain kinds of models that play nice in the uh sort of undirected bayesian conditional relationship neutral way because it's sort of like a built-in bi-directional road it's sort of like cars going both ways in the same lane but when we really make that separation clear and we really have some states that have an asymmetrical relationship in other states that have an asymmetrical relationship it could be simpler it could be more difficult so there might be new relationships that are enabled by the separation there might be relationships that are um put off for now because it complicates it in a different way so i don't know what those would be but those are just like what could happen when you split the states or maybe nothing happens and it's already been dealt with but yeah and then sarah's uh perpetual slide on the reservoir computing um we had a little oh the next steps were just from their words they had three areas and next steps kind of we'll go through this then we'll kind of give anyone else give a last thought but here's the areas where they're taking it next or where they want to signal for everyone to take it next so one is exploring intrinsic contextuality in humans it's like short and sweet apply it to humans so we're asking about applied active inference about what is the applications this paper they are asking that too they don't need to go into any more detail the second question is about how context switching is implemented neurocognitively so like you're talking to two people and you're bilingual and they say something in one language and the other person says something a different language but semantically you're might not even be aware of that difference it might just be associated with that person's voice or with the situation so how is that happening in the brain or in the body or different animals and then the third question their broader question so this is the real you know that's the specula no the third question is whether that intrinsic contextuality can be detected and characterized at multiple scales in complex systems so this is where it's kind of getting to the collective intelligence or distributed computational systems like what if there were a signal that we thought were uninformative but it were actually reflective of this just immense wisdom or processing power cognitive uh dimension so we might think that we're communicating with all intelligent life when we send out the golden you know phonograph with the etching of the fibonacci sequence or a tetrahedra or our body or something like that but there could be a whole dimension of information that's just at a resolution we're not even perceiving so that would be big of course how would we detect that a priori with minimal scale and system dependent assumptions which are equivalent to throwing out the noise and the signal together in this way of thinking well it would be great to learn more about these topics uh i hope that we can continue to just have experts on have all learners and participants on because it's kind of fun especially when we're talking about stuff like this so um any last yep steven you're muted steven yeah just mention you've got a bit of other you know the next couple of events that are coming up just so that people know if they're interested um that you're going to be talking with um we're going to be doing the other live stream oh yes um let's look at the calendar yep so we will um yep we'll have 18 in the coming two weeks on the predictive global neuronal workspace with ryan smith and christopher white uh hopefully joining for march 23rd and 30th but then also march 18th in two days we'll have demetrius bolas so yeah that will be pretty cool um thanks everyone for participating great discussion so fun times