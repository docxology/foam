[Music] thank you [Music] [Music] hello and welcome everyone this is active live stream number 49.1 welcome to the active inference Institute we're a participatory online Institute that is communicating learning and practicing applied active inference this is a recorded and an archived live stream so please provide feedback so we can improve our work all backgrounds and perspectives are welcome and will be following video etiquette for live streams head over to activeinference.org to learn more about the Institute and how to get involved in projects such as the live streams and others okay we are here in live stream number 49.1 we are having our second discussion on the paper a worked example of the Bayesian mechanics of classical objects in number 49.0 along with Jacob and Ali we did some backgrounds and context and now the gloves come off the curtain comes up uh and we'll begin slash continue our discussion and we're really appreciative Dalton that you've joined today looking forward to how these discussions go so we can begin just by saying hello and anything that we want to explore or discuss today and then we'll just jump right into it so I'm Daniel I'm a researcher in California and I think some of the questions that are really motivating me today is what is mechanical about Bayesian mechanics and how do we take Concepts that have physical interpretations like center of gravity or even some of these more Atomic level terms that were brought into play how do we apply those kinds of terms and ideas to cognitive science and I'll pass to ollie hello I'm Ali I'm an independent researcher from Iran and I can't find enough words to express how excited I am to be here uh actually we talk a lot about uh Dalton's work and how groundbreaking it is and personally I had immersed myself for the past several months in Dalton's paper and for the past couple of months we had fascinating discussions around this particular paper so I'm feeling kind of StarStruck right now and I'm very much looking forward to our discussion and I'll pass it to yacob hello I'm jakub I'm a student in the UK and uh I suppose um also uh very uh very excited to to be here today and to discuss the different implications of Bayesian mechanics and how uh how it's related to other areas in contemporary physics and how that can then be applied to cognitive sciences and Neuroscience awesome so welcome thanks again Dalton feel free to just begin where you'd like and bring us to the paper of course yeah um I guess I'll I'll also introduce uh myself just in case uh there are people in the audience that don't recognize me or uh have a face to a name um I'm Dalton uh I'm a researcher I'm based at um Stony Brook University in New York uh where I spend most of my time in the Department of Mathematics and the department of physics and astronomy I'm also at the verses lab uh where I'm I'm the mathematics and the physics of the free energy principle um so it's it's a pleasure to meet uh all three of you uh and and thank you of course for the kind words um I think we can yeah maybe begin with uh very broad overview of the paper I will say um so one of my um one of the aims of my research program uh is to get a better understanding of the mathematics of um random dynamical systems especially coupled random dynamical systems or um systems that model uh non-equilibria uh phenomena and one of the interesting things to me is the idea that uh within cognitive science or Neuroscience there are some algorithms that have been developed over time that uh I have been built specifically to cope with these kinds of problems um which are problems that we don't know really how to make sense of mathematically even physically um where on the uh back foot um but in uh in Neuroscience then the primary object of study is a um non-equilibrium system it is non-equilibria and understanding non-equilibrium phenomena in the brain and so one supposes that the methods that have been developed over time in this area uh just maybe by trial and error um or at least trial and error by the standards of perhaps a pure mathematician uh may have some insights into maths and physics in the same way that there's a very rich history of physics uh inspiring more advanced mathematics and then mathematics circling back and making physics more rigorous I think there's a great opportunity to do that in biophysical systems and I think the free energy principle is a source of great inspiration along those lines so uh with that meta commentary out of the way um one of the things that I I wanted to do with this paper is to actually drill down on that point uh because I think it's something that uh maybe Gets Lost in Translation if you just read uh kind of traditional active inference papers that are all about modeling cognition I think there is there's something on the other side of the aisle to be said about what do those models of cognition say about modeling systems that are cognitive or what does it say about complex systems that are cognitive like and how can we make sense of those things mathematically so that's that's in some uh sense the motivation for basic mechanics and that goes back to what goes back a long time um it goes back to probably um Carl himself he mentions something like this at a couple of points in the uh 2019 monograph but um it was worth writing a paper specifically with the motivation that uh if we consider what's been written about the free energy principle so far there's a very nice foundation for a better understanding the mathematics and physics of coupled or non-equilibrium sarcastic processes and so that was the the motivation for this particular paper and um in addition to building out the fundamental mathematics in the first few sections uh it's then possible to contextualize all that work with a kind of nice work example of what does this mean for some kind of simple systems how can we actually take this foundational maths and make it algorithmic again and then foreshadowing maybe even greater complexity in in the very last section uh so yes a lot of this goes back to a paper that um I co-authored with a number of other people uh earlier in the summer called on Bayesian mechanics uh where it's it's proposed that you know complex systems have a kind of informational physics about them and that maybe the material physics or the the Maths for these systems um is quite challenging in general but maybe if you map these systems into the informational world you can utilize new techniques and make sense of these kinds of systems uh by approaching it from a different kind of viewpoint that is I think the the strength of basic mechanics as again Carl and others have construed it is it is a way of talking about informational physics or the physics of Bayesian beliefs uh the laws of motion on a statistical manifold various ways of of kind of couching that in more formal language but again that was the motivation for the paper and then uh as that gets developed eventually there's a point where we really get into the trenches and actually try and deploy this in some useful way I think that those are really the the kind of two aims that come together in some sense thank you for the summary well there's many ways to begin and start perhaps we could start with the context that we brought which was thinking about this and you touched on some of these threads as well such as the key literature and some of the history let's continue on in this context setting before we get to the formalisms and the worked examples and talk about the three kinds of theories including what you mean by a theory and then the three non-bayesian mechanics and that'll set us up really well to see where Bayesian mechanics comes into play so this was in that paper just mentioned on Bayesian mechanics a physics of and by beliefs so what are dynamics mechanics and principles and how were you using Theory and why was it so important to be clear about what a theory was and the distinctions amongst these three terms yeah of course um so in in that paper there is this kind of trichotomy that gets introduced uh where we talk uh both about Dynamics and mechanics and principles and and disentangle them in a very particular way um so we we think about Dynamics as a kind of observational thing and it's important to separate that from mechanics because uh complex systems as a science is very interested in Dynamics can I kind of infer the laws of these kinds of systems just by modeling them um using some kind of curve fitting or using some kind of set of canonical models that I know sort of sits uh fits this situation but but at the end of the day yes Dynamics are mostly um about the particular trajectories that a system takes through State space or physical space um and and this is uh conflated sometimes with what I call mechanics in that paper which is um something a little bit different it is the laws from which these trajectories are determined and so um for instance uh dynamical systems people especially in pure maths really like the example of Billiards so you uh you send one Billet ball crashing into another one and and you could um talk about the trajectory that the uh ball takes and and you could write down the equations of motion um for this system and just add up all the forces acting on it and figure out what direction is this uh the ball that got collided with what direction is that going to go into uh with what momentum and all of these things but then figuring out um those figuring out that trajectory once you plug in all of these uh kind of boundary conditions the mass of the ball the angle of the initial contact and and so forth um the way that you can kind of compose all that information together that needs to come from somewhere and that's what we call uh or what I call a mechanical principle and this is not a distinction that is new to literature like I'm not breaking new ground here but I think uh it is one of those things that's not made sufficiently clear in the fep literature uh or at least in the um physical uh the places where it's adjacent to physics so mechanics are about the laws that give you those trajectories so we know that that the force is acting on one or another uh billiard balls some together because of Newton's law of motion that's a mechanical theory if I have F then I get M times a and I can plug in F and I can plug in a and I can get a trajectory but if I abstract away from those particulars I get some kind of law that tells me okay how a trajectories generated in the physical world um abstracting one more step we can then ask okay so where do mechanical theories come from what tells me that I have the right mechanical Theory generating the right Dynamics and this is about um the kinds of very fundamental laws that we know hold everywhere in the universe at a given scale these are principles like conservation of energy and this gives you uh the behavior of collisions or the principle of stationary action which actually gives you back Newton's law so you can now chain these things together and say the you know one ball hits the other one it goes in this direction uh because uh if you sum the forces and you add up all the directions you get a net movement and you can do that because uh these uh Billet balls minimize or at least make stationary uh their action so their motion must follow this particular mechanical law and that's the law that generates these trajectories so the reason why this is mentioned in the Bayesian mechanics papers because these have I think been conflated in the literature previously because you have um the idea of the free energy principle which is a principle it's a thing that gives you back um some kind of generative uh rule for the Dynamics of specific systems and uh that is usually something to do with the motion of internal States on a statistical manifold in the sense of for instance uh Thomas Parr lands to cast and Carl Kristen's article um stochastic thermodynamics Markov blankets and information geometry I think that's the title anyway um so if you if you say okay the the Dynamics of a system whose parameter performs um approximate phase in inference uh minimizes the surprisal then you get approximate base in inference as a law of motion for the Dynamics of some object and this law is usually written as a particular gradient flow relation on uh the space of beliefs so it tells you how do beliefs change as those parameters doing the inference change and then if you if you add in progressively more details okay what do those internal States actually mean in the context of the system what are those beliefs about these are the kind of boundary conditions that give you the trajectories the specific dynamics of the system there's an interesting sense in which these boundary conditions are literal boundary conditions because understanding what's internal and what's external and being inferred is precisely the specification of a Markov blanket so as soon as you actually give the system a very particular partition as soon as you've carve it up in a specific way you start to get a sense of the actual evolution of a system as one might see it in the real world but this is I think separating things out in a formal sense like this is useful because it avoids skipping from step one which is minimize variation of free energy or surprisal and I'm going straight away to this is how um something like an active inference system uh does prediction and action you know there's there are some steps in the middle that hadn't really been filled out if you just go from A to B directly and when you when you begin to talk about the maths and the physics um collapsing things together like that starts to throw away some important details that actually do make a difference in the way that you tell the story Awesome Ali or Jacob anything you want to add in or ask there yeah Jacob um yeah I would maybe ask regarding the kind of laws of motion of Bayesian mechanics you mentioned uh approximate Bayesian inference uh would would that imply that the 3D faces of Bayesian mechanics the mode matching mode tracking and path tracking uh would you say those are also specific Laws of Motion within Bayesian mechanics um you you could say that yeah I think at this point the distinction gets uh very fine and and so there's there is a place to usefully truncate it but yeah these These are three different kinds of approximate Bayesian inference um and so uh they are three different uh kinds of motion under free energy principle minimization um and so this is kind of I guess a middle area between Dynamics and mechanics you've started to specify some things like am I doing approximate Bayesian inference Over States or am I doing it over paths but you're still lacking actual dynamical details about what do those states of paths mean um so this is maybe this is maybe a middle area that that blends the idea of approximate Bayesian inference as a law of motion under surprise minimization and actually getting down to the very bottom of this um pyramid so if I were to put it somewhere into this figure I'd I'd maybe slotted in uh yeah uh yeah that's that's pretty much what I'm imagining is you have approximate Bayesian inference sort of roughly up here and then there are different expressions of that just as there are different expressions of Newton's Laws depending on if you're in fluids or rigid bodies or Celestial mechanics so you can introduce even finer partitions than these three there's many places to go one question is what are these modes about who or what is tracking what and when yeah so this is uh kind of about um the idea being a proxy of Bayesian inference tells you that systems match their parameters in such a way that they perform inference right so when we think about Bayesian inference we can talk about it as simply inferring the parameters of a probability density uh so in the free energy principle um when you get approximate Bayesian inference uh saying okay systems that are coupled synchronize uh certain parameters this is Bayesian inference um and and conversely if you have that synchronization you have Bayesian inference or you have approximate Bayesian inference if you're inferring the parameters of an approximate density which is where you get into the uh factorization of the free energy functional that we uh are familiar with where you have um a variational density matched to a joint density but you can split it into the variational density matched to a conditional density plus an extra surprisal term that uh kind of measures how good that approximation is um so this this descends from that idea that you can deduce what a system is doing um just by saying okay it's performing a proximate Bayesian inference because that allows you to say its parameters are synchronizing to the parameters of the environment or of another system um so that's what we mean when we say uh modes in this case a mode is just a parameter of the distribution and it comes from um some of uh Carl's earlier literature where uh he uses the LaPlace approximation so uh specifically we're matching the we're kind of fitting a gaussian density to some arbitrary probability and then the uh mode of that gaussian is one of the parameters because it tells you okay where is the center of that density and if you also get a sense of where the variance of that density is now suddenly um by fitting those two parameters you can talk about the system because now you can say okay the physical parameters of the system are encoding these parameters of some density uh in in a very natural way this gets you back much of statistical physics because it's all about how does a system reflect these statistics of another system probabilistically how does this look but this is kind of upgraded in Bayesian mechanics to noting that well that inference happens because the physical parameters of the system are matching the physical parameters of the environment and and that's where the probabilities come from that's why we talk about beliefs so when we say modes we're referring to um parameters that are fit for synchronization excellent thank you Jacob um since uh we have the the schema on the on the slide there I uh just wanted to ask where do you think that the G Theory um formulation uh fits into this diagram because with the G Theory there is approximate Bayesian inference but uh it's not necessarily density Over States so is it another uh another node from directly from the Bayesian mechanics yeah um so in this um figure the approximate Bayesian inference Lemma is a very specific thing it that originally goes back to I believe originally it's in a 2012 paper by Carl in in entropy called the free energy principle for biological systems but but um certainly it's a much bigger deal is made uh in the 2019 monograph and and it's it's the approximate Bayesian inference Lemma as he calls it specifically about mode matching approximate base and inference is a bit more General so if you were to kind of slot that in somewhere in here it would maybe be parallel to Bayesian mechanics because just like classical mechanics the law of motion is Newton's laws for basic mechanics the law of motion the thing that generates specific physical Dynamics is approximate Bayesian inference or the the law that when you do have synchronized systems you can write it as variational free energy minimization in virtue of the parameters of the two systems matching up and and that's the parameter that minimizes the distance between a health density and an observed density so approximately inference Lemma is is that result specifically but that's more General the idea of approximate Bayesian inference is more General and probably um someone needs to write down a generalization of the approximate phase in infants Lemma to paths specifically to talk about path tracking but once you have a path that fits the bill as a mode and once you have two systems evolving together tracking each other's modes or each other's paths and if you have a probability density over those paths you can now talk about approximate Bayesian inference in the path setting now where that has to do with G Theory uh so so G Theory the the name and and kind of the vision is actually due to uh Maxwell ramstead a colleague of mine also here in the verses lab and uh he has suggested that um G Theory kind of lies in the intersection between a few different things that fall out of the path-based formalism so if you have um a process of Bayesian inference over paths if you're doing uh path tracking um then there are lots of things that do come out of this uh almost canonically one of them is uh everything that comes along with path integral formulations in quantum mechanics and and this is uh I take advantage of this at various points in the paper at one point I I use it to explain okay why does spacing mechanics actually make sense in the classical world and then later on I use it to relate it to chaos um that's a specific example I think more generally uh path tracking deals with non-stationary systems very well uh because you're allowed to talk about now how does the density uh how does the belief change in time how does the mode of a single belief change over time to make a kind of uh modal path and and what are the marginals if you slice up the density along that path um what do you get so you can talk about non-stationary systems you can talk about systems out of equilibrium this way because you can relate um the uh free energy principle over paths to What's called the principle of Maximum caliber in statistical physics which is all about non-equilibria and uh entry production and non-equilibrium steady States uh so so I think um as as we have written about it um G theory is the uh Duality between path integrals and the fep over paths or The Duality between Max Cal and maximum caliber and and the fep overpaths but it's um I think that's selling it short a little bit because it it's also the thing that brings in all these other uh ideas um and stochastic thermodynamics is a really interesting one as well right also falls out of the path-based formulas and very well also does very well with um non-equilibria um so so G theory is kind of this this larger object that uh makes sense of why that column of Bayesian mechanics actually works uh and and explains a little of the the true power of uh the path tracking as opposed to uh mode tracking why why are we interested in forgetting about States uh and and that's the explanation for that uh or the justification for that uh resides in G Theory which is supposed to explain uh why do all of these things just come out of the path based formalism why does it make sense um and why does the fep overpass lie at the center of a lot of disparate fields which I think is one of the real um very powerful statements uh that that may be possible in the near future is uh is the fep actually canonically the theory of everything in the sense that there are lots of approaches in uh statistical physics and stochastic process theory that Trace back to the fep or the fep uh subsumes or implies or something like this G theory is supposed to kind of plug into that last column uh but but it's somewhat outside the hierarchy in that sense foreign thank you Ali uh well yeah uh I was uh um when I was reading about G Theory uh I thought it somehow relates to uh Rolf Lander's principle which basically says that uh if an observer loses information about a system uh the corresponding entropy in a non-information bearing uh degrees of freedom of the information processing system or its environment is increased uh because uh you know London landar believed that information is physical so he somehow put it in terms of a kind of thermodynamical uh point of view but um how does it fit or can G Theory be viewed through the lens of landor's principle which I think is not a um completely non-controversial Principle as well yeah that's an interesting question I think uh insofar as it does give you some technology to talk about entry production at non-equilibrium steady state so so it does give you a way of saying okay if I'm exchanging with my environment if information is Flowing out and flowing back in then there is some increase in the entropy and with respect to things like control theory this is pretty interesting because it allows you to talk about okay if the system is observing something about its environment if it's constantly um maintaining a steady state so engaging in control then then you can talk about that and tropically and you can talk about the irreversibility of processes even at steady state um and and there are you know there are things that connect to that like um the crooks uh fluctuation theorem or yazinski equality and things of that nature um so so my guess would be uh it it probably covers something like landau's principle in that context um talking about the the energy required to erase a bit of information so is ultimately the energy required to insulate yourself from the environment that that minimizes your surprisal it means the environment does not offer information to you but but that does take energy and and sometimes quite a lot uh so so that's that's probably where that um connects to London's principle is talking about and quantifying um the the kind of cost of maintaining a Markov blanket uh in in probably entropic terms great I think this points towards somewhere we may explore over this multi-scale engagement which is unconventional Computing and low energy Computing for example the often remarked upon energy expenditure of the brain compared to say a neural network operating on traditional computational architectures using many many light bulbs many many calories of energy versus the brain which able uh which is able to carry out some tasks with seemingly low energy expenditure while other tasks it does not seem to be able to perform at all I want to pull back before we go into the three non-bayesian mechanics and ask what is Bayesian what does it mean for something to be Bay Bayesian yeah um in in my mind um Bayesian is about uh inference it's about a particular method of doing inference that gives you a consistent unbiased results and fits in very nicely with the rest of probability Theory uh in the context of Bayesian mechanics it is the idea that uh the physics of material systems or the material physics of complex systems Maps into a physics of beliefs so you can talk about the parameters that are doing approximate Bayesian inference or you can talk about approximate phase and inference you can talk about okay what what are the beliefs parameterized by that mode doing and how does that reflect something about the Dynamics of the system um the reason why this is interesting is not just because it's a different approach to the problem and dealing with um interacting systems and uh systems out of equilibrium uh is an area that does need new approaches because it is a very poorly understood area within mathematics and physics uh it still is it has been for uh some time I think uh but um it's also interesting because uh complex systems are informational so there's there's some sense in which this brings us closer to the metal um so it's not just a new view it is the right New View because complex systems are systems that compute and capture data um they are systems that have memory um so it's it's not as simple as even here's a new way of writing down the Dynamics of random uh or stochastic processes uh based on the parameterization of some action functional that's that's valuable because that's a new thing but it's also uh it fits very nicely into our understanding of complex systems as things that uh have an informational physics understanding the Dynamics of things like the brain is contingent upon understanding what the brain is doing and and the brain is uh capturing and Computing over data it is storing memories it is learning and sensing and inferring so it's it's not just that it's a new view it's really the Right View because it gets to the idea that complex systems do things physically because they are doing something in informational space and and the brain is a wonderful example of that the brain is a coupled random dynamical system it's coupled to its environment so you can talk about this parameterization thing this synchronization thing but it's it's even more insightful than just that because the brain is um doing approximate Bayesian inference so so I suppose it's no coincidence that the synchronization of couple ground and dynamical systems gets you back this idea um because I think that is empirically just based on observations I think that is as close to a physical law as one might be able to get at this stage in complex systems theory is that things that synchronize do perform a proxy base in inference because things that synchronize are things that are controlled systems or computational systems uh so so in that sense it's I think it's right on the mark and and as I said you know it's it's interesting that this goes way back to trying to figure out things about the brain uh it goes way back to to Carl friston's original work on generalized filtering and SPM and and these kinds of algorithms that were designed to make sense of what is the brain doing physically based on what we think it's doing inferentially right the relationship between structural and functional connectivity and the relationship between neural representations and neural firing patterns but it has become something massively more General because it is the right kind of maths to talk about these sorts of systems and that's in turn because these sorts of systems do um this kind of approximate Bayesian inference uh so when when you ask yeah what is babysitting about basic mechanics it is about the relationship between Bayesian beliefs and and Bayesian inference uh and physical parameters representing something about the information available uh to that system uh or the statistics of a system coupled to that system awesome just a few notes before we then go into the non-basing mechanics one is from ecological psychology where many of our terms are drawn from such as affordances people have long pointed to the way that we use language like can you grasp it optimal grasp of ideas and so tangible and peripersonal spatial ways of talking about ideas and cognitive processes and then well what is the first thing you want to know after you get optimal grasp how much does it weigh and you said it has become massively more General well is that in grams or in what so I see this as part of the development of the physicality of cognition in that the ecological psychology brought in relationality and action orientation the pragmatic turn and then now what about those objects if we drop the idea what happens if we drop it from the discussion what happens um and then the second piece is the very interesting historical note about the development of complex systems and about the appropriateness of this kind of a formalism because at the very least standing as extremely on the instrumental Spectrum as we can be we're going to need to bake relationality into our analysis of any system whatever it is that it is doing and then absolutely it may come to be the case that if those systems are also cognitive or understood in terms of informational manifolds then it's a doubly appropriate approach and the kind of double ratcheting of cognition makes it difficult to see how a framework that doesn't have some of these characteristics could be adequate to describe that kind of a relation so great points let us go to the non-bayesian mechanics so the non-basing mechanics are classical statistical and quantum so however you'd like maybe just uh on each of the following three slides just what are classical mechanics statistical mechanics and quantum mechanics uh kind of Steel personing the argument and just what do they explain what will they continue to be useful for and how can we see them as special cases or adjacencies or however you'd like to frame it with respect to basic mechanics sure um yeah so beginning with um classical mechanics I think is probably the um simplest example um you have kind of the physics of very large very slow things large is kind of a relative term large compared to atoms maybe and slow compared to the speed of light but nonetheless um this is a a broad region of physics that describes uh things that don't have relativistic effects uh things where observations commute so it's non-quantum things that are not noisy so there's no probabilities it's not statistical and things that do not require relatives to Corrections so things that are below the speed of light um when you have all four of those ingredients I think I listed four anyway you have classical uh physics uh or at least you have a classical object and the physics of that thing um is classical mechanics uh so this um this arises from uh you may have in the third four limits of other kinds of physics so you want to be uh now infinitely precise um so this is the kind of no noise limit of statistical mechanics it's these slow speeds limit of um special relativity uh and and it's a very interesting um limit of quantum mechanics that I can get into a little bit but it's it begins to get a bit complicated um I I maybe I'll save that for the the third slide um so yes but but uh until then I'll say you you there is a classical limit of quantum mechanics that you take a Quantum field Theory and and you can produce a classical Theory out of that in a relatively well-defined way um and and again I can talk a little about the nuances to that statement there are some but but regardless um classical physics is about um large things really the the interesting thing is that all four of these limits kind of coincide um to some extent when you have a very large uh system so very large systems allow you to use the law of large numbers to kind of sharpen your beliefs about a system so so you can imagine this as placing greater Precision on the measurement of your of your system and and that recreates sort of the the no noise limit because you get more and more precise in your estimate of the Dynamics of the system um many uh body systems with very small objects um are systems where you start to see Quantum Productions so particles uh like atomic particles for instance um you begin to run into uh things a regime where things are small enough that quantum physics becomes relevant um and also uh large systems tend to move pretty slowly that is just a general rule um in in what's called effective field Theory which talks about how one theory is a limit of another theory and in particular it talks about as you increase in scale you get simpler theories so I think we would probably all agree classical physics is a lot simpler than quantum physics and that's because effective field Theory says that um large things uh have simpler physics in in very rigorous uh senses one expression of that is um kind of uh the momentum scale is inverse to the mass scale so larger things generally have lower momentum lower energy very small things whiz around at very fast speeds they have high momentum um so once you once you start to talk about large systems things begin simplifying in such a way that more often than not you run into classical physics as a sufficient description of the scale of observation that you're at uh so so classical physics um that's where it comes from uh it is about um Newton's law uh classical mechanics Newtonian mechanics as you might call it is about Newton's law it says uh that well Newton's three laws I suppose I should say um they say that uh the um every action has an equal and opposite reaction um so this is the idea that things that uh make so contact forces uh have at the classical level an equivalent force in the opposite direction um you can think of this as a kind of uh if you're familiar with them sort of exercise exercises in school um in this area you're often asked to calculate the normal force of something um the normal force is just what pushes up on me when I push down on something else so this is why I don't uh phase through the ground when I stand up is because there is an equal and opposite reaction I'm not only putting a force on the ground but the ground is acting on me and keeping me up um that's that's one of them uh the other one is the very famous f equals n a it says that uh the force acting on a system uh is the mass times the acceleration of the system and likewise you can deduce the acceleration of a system by taking the force acting on it and dividing out the mass um so this this tells you okay how do we generate Dynamics out of some boundary conditions like what is the mass what direction is the force acting in and and classical mechanics comes from a what we call least action principle and there are a number of equivalent ways of writing this um but this generalizes to uh what some people call lagrangian mechanics and that tells you um imagining what are the energies that those forces came from how does the system behave with respect to its energies and and if you talk about stationary action you talk about minimizing energy then you can recover Newton's Laws as a system accelerates along Force gradients and and it doesn't waste energy by going any faster or going any slower it does exactly what it's told to do so it uses precisely the energy budget available to it there's a very nice um well maybe I should say about my own paper but there's a very lengthy exposition of this in the uh physics of and by beliefs paper that we've talked about once already I think it's section two where I run through um why is the analogy the classical mechanics even useful here and it's because of um the stuff that we talked about previously with the very nice dichotomy or trichotomy between principles mechanics and Dynamics um but uh anyway more broadly uh than that classical mechanics is a very good example of a least action principle because it's the idea that the Dynamics of classical things comes from a particular uh scale appropriate limiting um least action principle excellent Ali or Jacob anything to add or we'll move to statistical mechanics okay classical descriptions onto statistical yeah so statistical mechanics is uh a bit of an interesting one statistical mechanics is a lot broader than I think uh one might initially think because at the end of the day it is to some extent just about systems with as you've written here probabilistic degrees of freedom and and that is that covers a lot of things you know you can probability theory is just maths so any way you can use probability Theory to describe um some system you can use statistical mechanics and we know that this is the this generality does exist because you can talk about um Quantum statistical mechanics so you can take the physics of very small very fast things and and use statistical mechanical methods you can use probability Theory and entropy in these things and you can also go all the way up to uh black hole thermodynamics and you can do the same you can talk if it's a black holes of very large things um and but you can still talk about the thermodynamics or statistical mechanics of black holes so it's it's worth saying that um we can talk about the uh no noise limit of a particular kind of statistical mechanics but then we need to be a little bit more precise about what that generates um in this case I'm thinking of classical statistical mechanics so it's the statistical mechanics of um interacting particles or uh systems with microstates that relate to macro states by uh some kind of Gibbs relation and things that have free energy and and in particular Shannon entropy so this is a little bit more of a narrower idea of what statistical mechanics is um just because we we need to constrain ourselves a little bit even to get off the ground so otherwise we'd be covering um way too much but it is the case that if you take statistical descriptions of um ensembles of objects and you become more and more precise and you get rid of the noise then you can reproduce a kind of classical equations of motion um and there are ways of doing that uh one such thing is called mean field Theory so in mean field Theory you get rid of the noise in a system and you just say okay here is the trajectory of the system uh in the same way as we might do with uh classical mechanics um I'm skipping some details there and the analogy is a little bit more nuanced than that but it's it's kind of a useful mental picture I think um and one of the interesting things to note I think is as what you've written here is that there is a principle that's relevant for statistical mechanics um because uh statmac is very general it's very mathematical it requires an equally mathematical principle um and so in a probability Theory we have What's called the maximum entropy principle which is just a way of Designing probability densities around uh inferences that satisfy some mathematical deciderator so they should be consistent they should be unbiased um they should lead back to Bayesian inferences under suitable conditions and and Max and is that thing uh and and we know uh due to well work by uh Jane's but but more recently work by people like Kendall uh also here at Stony Brook that uh and and before him um mathematicians like uh markovichlani all of this is a large body of work that points to the idea that if you maximize entropy you get uh the mechanics of diffusion so you get the mechanical rules that generate mass action like um diffusing particles excellent I just want to ask about one word which was unbiased unbiased mean here um I'm biased I think you can think of it as um avoiding overfitting so one of the things that um you can consider Max and to be is a recipe for doing inference that um maximizes ignorance subject to some um constraints so if you have some known unknowns then you want to incorporate those but if you have unknown unknowns you don't want to risk overfitting for those uh things that that you're not aware of so if you're not aware of something you don't want to falsely incorporate it into your inferences and you could consider this as avoiding overfitting or you could consider it as kind of optimizing for subclasses if you're thinking of probabilistic stuff as a prob of classification then you can think of it as optimizing for subclasses that you don't have information on but um either way uh it is the idea that you you don't want to introduce extraneous information into your inference because that extraneous information biases you in a direction that the data doesn't support uh so so that's that's really the idea behind unbiased and one of the things that Jane Jane's uh did and not only James but also um Shannon uh before him uh who who worked on the probabilistic aspects of this um and then after um James and Shannon um Sharon Johnson who also were uh probability theorists and and worked on Max sent axiomatically um not like James who took it more uh as a as a physical rule for a long time and then got into the probability theory of it um either way all of these people uh are able to justify with with rigorous proofs that maximum entropy is the best way of making unbiased inferences and there's there's lots of it to show on this uh those are are three useful names but there's a lot more due to you know Ariel katicia I already mentioned Ken Dill um Adam giffum lots of people have taken an interest in this area uh rightly so I think awesome we're gonna keep moving to now Quantum and then already many of the seeds that bring us to Bayesian are planted so Quantum what is it how did it come into play in your work yeah um so quantum mechanics is uh I think qualitatively different from classical and statistical physics uh it's about very small things uh or very fast things and and as I was saying effective field Theory tells us these things usually go together um and uh it it talks about kind of when you get things that are not classical well at least it started as when you get things that are not classical what do you need to add to your theory to make the right predictions so quantum mechanics began as a kind of modeling effort um it it grew from what we might call semi-classical physics which is just about Quantum corrections to classical stuff it grew from semi-classical physics to its own genuine branch of physics uh in and around the 20s I suppose the certainly the early 1900s anyway um so one of the things that becomes uh relevant is um probability Theory because uh quantum mechanics you may have heard about Heisenberg uncertainty it's about the fact that measurements do not commute so the order that you do a measurement in matters a consequence of this is that there is always some inherent uncertainty when you measure um so-called conjugate variables which are just things that fit into the theory as non-commuting pairs so you measure two non-commuting pairs there is some uncertainty you can measure one precisely you can't measure both precisely and and moreover there's a trade-off if you measure one with infinite Precision you know absolutely nothing about the other one if you try and play half and half then um you that's what you get you get um kind of a blanket uncertainty about both measurements um so so because of the uh non-commuting of variables and and this is kind of an empirical fact this doesn't come out of nowhere uh but it is one of those things where it just happens to be right because it's so elegant that um it wouldn't make a lot of sense if it weren't much like I guess The Coincidence of synchronization and Bayesian inference in complex systems theory um because uh non-commuting variables gives us all of the rest of quantum mechanics um the the stuff that we really know and love and also is a relatively well-defined way of getting back uh classical physics because all you have to do is take the theory and make things commute and then you get classical physics back um I'm I'm brushing some difficulties under the rug it's as you might imagine it's not that simple and technically it doesn't work but it sort of does uh and and if you're interested I guess um you can look into what's called deformation quantization which is exactly the idea that if you take a classical system and you uh deform it in such a way that things no longer commute then you get that quantum physics but um you you can't really do it the other way around uh there's a bit of subtlety to the other direction nonetheless uh that is one route to making Quantum stuff classical stuff another route is just focusing on the probabilities so because of this inherent uncertainty um Quantum particles they're equations of motion uh have what we call transition amplitudes which gives the probability of moving from one state to another but but again nothing is certain in quantum mechanics if you however uh make it certain mathematically you can go in and just take the no noise limit um more properly you should you should do something called Wick rotation first which just allows that limit to make sense uh although uh well yes yes you should do that first um it you know if you do that you take the kind of no noise limits then you get certain State Transitions and this just gives you back a classical dynamical system that you know where it's going once you have the equations of motion um and and this is the route that I take in the paper because it fits very nicely into the path and typical formulation in a way that kind of just makes things make sense uh and and one of the nice things that I then go on to say is um if you have a parameter sitting inside that path integral then you can make sense of why classical physics comes from the no noise limit by writing it as a basic mechanical problem you can write about synchronization and get back the basic mechanics of classical stuff just by doing this very well-defined procedure like this is something that that already exists in physics and is fairly uncontroversial um so so that's that's what you get in in quantum mechanics it's about small stuff it's it's fundamentally probabilistic um because there is fundamental uncertainty and and again this traces back to empirical facts um I think that that about covers it I don't know if I should have said more or if you uh have other questions that's I think that's uh that's sufficient at this Benchmark for that slide oh it's great Jacob yeah um I realized the paper um dealt mainly with uh Bayesian Mechanics for classical objects but do you see Basin mechanics being applied to non-classical phenomena like Quantum tunneling or or entanglement uh which cannot really be explained in the limit of large numbers and then also uh second question which is kind of on the intersection of quantum mechanics and statistical physics is there any change in the formalism when you introduce the notion of indistinguishability between particles sure um well those are really good questions uh I think yes there is probably an idea of um Quantum tunneling that that could be achieved maybe um because uh Quantum tunneling if if you're a physicist this is something that your um familiar with on the nose if you're a mathematician this is what you would think of as an instantum so in Stanton solutions to the uh equations of motion of a Quantum field Theory uh um tunneling Dynamics and so the idea becomes okay can we describe um instantane Solutions uh using beta mechanics and the the answer is I don't know but it seems like there is it's it should maybe be possible because there is at least an understanding of where points A and B are if not how to get from A to B but that that is something that uh would be interesting to um do more work with and and more generally it would be interesting to think about uh quantum physics through the Bayesian mechanical lens um just because you do get this uh you do recover this classical limit of the path integral and morally path integral quantization should be equivalent to things like deformation quantization and geometric quantization and and other methods even um and well actually one other one is worth saying there's a thing called stochastic quantization which begins from real valued probabilities and then makes Quantum stuff out of that and uh the Bayesian mechanics as it is construed today is very close to stochastic quantization in a few very key senses so one supposes it should be possible and that would be nice um so that's that's the answer to one question is uh should be but I don't know it would be cool as far as um entanglement and other kinds of uh information Theory um I actually don't know very much about this Quantum information theory is something that is relatively new uh and a lot of people kind of in and adjacent to um things like condensed matter Theory are very interested in this uh but I I am behind on the literature I think one of the things that um does kind of lend itself to information theory in general is the fact that basic mechanics has these connections to maxent and Bayesian inference and and these are of course ways of talking about information and information Theory um so so yes my my thought is something like entanglement which has inflammation theoretic undertones uh should also be possible but again I don't know um initially what precisely that would look like there is some um literature out there that has to do with the free energy principle in the context of information to Theory I am thinking of work due to uh Carl uh James claysbrook and Chris Fields they've published a lot of work in this direction um which is also something I'm not totally familiar with uh but it again it seems like a very rich area to eventually pursue Connections in great and then the second question was about indistinguishability of particles FM Ali ah yes okay um yeah uh so so I suppose you're thinking of um passing to these kinds of uh bosonic the field theories where you just pack a whole bunch of um equivalent field States into um your uh your fox face and see uh if you can make that make sense um I think uh you you may notice this when we get into the um supersymmetry uh results is there is a conceptualization that yes things do change when you introduce bosonic looking things um as opposed to fermionic looking things um so it does become important to keep track of the uh statistics of these particles uh because that that recovers um things like uh brst charges relating the two genres of particle and that is what gets uh the the classical chaos in the last section um so there is yes there is a reason to um distinguish between uh the the behavior of the particles in each Theory uh I think the the precise nature of that will become clearer once someone actually uh Knuckles down and does out Bayesian quantum mechanics uh where where we'll be able to couple directly to uh that kind of idea awesome a lot of fun topics uh the tunneling do we have to visit every belief on the way from A to B or as it sometimes can seem are we in one position and then we are in a different cognitive position all different kinds of experimenter experimented questions in cognitive science even potentially uh Collective thought and ways of communication in terms of these formalisms yeah and the instant question is is pretty interesting as well right because uh it it talks about okay if we have a system with uh multiple um classical Minima so if we can if we can say okay you know uh there are multiple optimal Bayesian beliefs and stantons are the uh things that that zip between those Minima so it's it's a qualitatively different uh way of thinking about um dynamical systems it's it's not a single Minima and it's not a single classical trajectory it's multiple Minima and it's almost like phase transitions between the two so certainly that's that's interesting uh from the point of view of physics excuse me from physics uh but but tracing it back to something like cognitive science thinking about okay what are the sort of phase transitions between our uh beliefs um and and can we actually access other phases right do those in Stanton Solutions actually exist and do they describe some kind of zipping between um maybe generative models or perceptury regimes or something of that nature it's very kind of nebulous but um it's it's a provocative question excellent Ali well uh I was in the on the understanding that as we go from classical to statistical and ultimately to Quantum Mechanics the role of information and uncertainty in describing and formulating the Dynamics and mechanics of the physical systems um are becoming becomes more explicit so is it a correct assumption to say that Bayesian mechanics somehow aims to put information back in the game and make it make it equally explicit through all of those mechanics yeah absolutely um I think that's a good way of thinking about it right the reason why basic mechanics is so uh General um much like statistical mechanics is very general is because it's just about information and lots of things have information even at the classical level we just usually neglect it because we don't need to think about it um but it becomes very apparent uh and and this is part of the explanatory power of of doing something like that it becomes very apparent that classical stuff um comes about when that information goes away uh or rather when those probabilities that uncertainty goes away that information becomes uh sort of limitingly large or infinite uh so so what basic mechanics allows you to do is actually keep track of how this information change between these different scales which is one um particular uh payoff that I think makes it very valuable um but not just bridging scales also applying to many different scales because lots of things do have information information is just a mathematical apparatus that we can use to describe lots of things so if that's if that's all that your physics is built on then it it will be by consequence something very general awesome the way the it's coming to me today is in classical mechanics we get uh especially once we understand these limits which classical mechanics is like a point within a broader space of physics or mechanics we get principles of least action and stationarity and laws of large numbers not unlike the central limit theorem in statistics and a lot of the esoteric gaussian statistics in statistical mechanics the probabilistic nature becomes formal for example in the Billiards case in classical mechanics you might want to do statistics across many slightly similar Billiards games and so at that point you could either do the plug and chug frequentive statistics or at some point you're going to want to think a little bit more broadly about the distribution of Billiards and then Quantum especially makes the relationality and the modeler models dialectic formal because just by doing statistics you're already in an area of explicit relationality map territory distinguishing and then Quantum takes that to another level and could it be said that with Bayesian we're even going a layer deeper into the modelers approach to the system [Music] where do you see this yeah so I think so um the idea would be eventually we introduce an actual idea of information um which naturally kind of depends on the Observer or the modeler because information is kind of modeler dependent right information has a context it has uh was contingent on observation so when we start talking about um surprisal and the Dynamics of beliefs and inference all of these are very explicitly putting the modeler back in the situation and and that may be in the very metaphorical sense of a system um synchronizing with its environment it doesn't necessarily have to be a cognitive Observer or a uh a pan psychist kind of modeler I don't really think there's remit for that within the maths uh but the the point is that the maths works with or without those assumptions so so in a sense it's actually agnostic to to that and you can you can conjure an image of uh a modeler that that is pure metaphor um just talking about synchronization uh however the uh the language is pretty instructive and it does uh relate back to the idea that that lots of systems have and can capture information uh maybe in a very trivial not cognitive not conscious like sense but nonetheless uh they do um capture and and uh synchronize to information and therefore they do uh model and they do inference great it's the classical if a tree falls the forest does anyone hear it exactly if a tree falls does it make a noise yeah I mean I I think the answer would be um it depends on what's synchronizing to the tree right if the tree falls on okay this is going to be a pretty Grim example I guess but if a tree falls on some sort of small Woodland Critter then then yes I think the tree definitely fell because the uh the statistics of one thing synchronizing to the other one would say yeah pretty unequivocally um the tree just fell but if you're not there you are not synchronizing to the tree and so that information has uh no meaning to you whatsoever so so it is very much about um as you've written modeler dependent um information in in a very mathematically rigorous way really um powerful and also connects to a lot of qualitative and contemporary ideas so it's really exciting to think about where and how Daisy mechanics can be applied this brings us um as we head into the z-score of plus one downhill on the gaussian of the dot one into the paper itself so we'll pause Ali and Jacob if you have any questions otherwise we're going to go to the roadmap and have some overview notes on the paper and its structure does that sound good all right so pardon the meme but um here's the road map of the paper the sections and subsections so maybe just a general comment what did you include in the paper what did you not include in the paper why did you structure it how you structured it uh yeah absolutely so uh the the structure was kind of meant to reflect um I think an unmet need in the uh literature which is both a single place for all of these results to be reviewed and then uh once that review has been done an application of all those results so organize everything and then use it in a kind of insightful way and and having all the rigorous stuff in the beginning makes the application make sense and having the application makes uh or provides context for all the the very rigorous stuff at the beginning um so to do that uh it's it's kind of split almost down the middle um you have the sections one through four are all the uh foundational stuff and then sections five six and seven are the actual applications uh so I I began with a very brief introduction just uh motivating um precisely this uh here are the questions that we're going to answer here's um how we're going to answer them here's why it even matters um in section two I I just very briefly reviewed classical physics to uh set the stage for some of the stuff that we've we've already discussed um then I uh talk about Bayesian mechanics itself uh and and to be through 2D are fairly long because this sets up all the basic Machinery uh we begin with um I I believe to begin with uh we talk about um what does it mean for Bayesian mechanics to be like uh classical mechanics um what are the the basics of it what is variational free energy what is uh surprisal what is least surprisal um and then in C and D uh these uh basic ideas can be used to figure out okay what does it mean then to minimize surprisal how does that matter to Bayesian inference there's exact beliefs the physics by beliefs is then inverting the story and talking about okay um so we know now that uh systems uh when they minimize their free energy they uh or minimize their surprisal they synchronize um to their environment so you can write this nice story about um parameters can you do it the other way around can you begin from the um no I think I gave them the wrong direction so when when systems synchronize they minimize their free energy so you can read this as Bayesian inference then I ask okay can you do this the other way around can you begin from Bayesian inference and can you get the Dynamics of parameters which is just kind of flipping the story but it involves um a bit of work to to actually make it follow through in the end however it does and and the relationship between the two so I say physics of beliefs because one is taking the motion of parameters and relating to the motion on uh statistical manifolds uh space in inference because it's by beliefs to saying okay if we begin with some information theoretic idea of Bayesian inference do we get back the mechanics of systems carrying those beliefs that relies on some work that I did earlier this year which espoused a kind of Duality between uh the free energy principle and maximum entropy so using that as a kind of Technology you can flip the story and say okay if I start from an inferential principle can I get physical stuff back whereas the fep is I I would think of it more as if I start with physical stuff can I then understand the beliefs they are two sides of the same coin uh and uh on the nose it's a very trivial symmetry between the two of course it takes a lot more work to make it uh formally make sense but in the end it does so that's that's section two um section three uh moves us into the first uh idea of actual results in the papers to say okay so if I have a classical system doing Bayesian inference or approximate based infants uh what does that look like and does it look like the free energy principle um and then conversely if I have an inferential principle uh or if I have an informational physics can I use maxent as the Dual to the fep to get back the physical uh mechanics of this classical object uh and in both cases the answer is yes and at the end of that section I uh give an equation that that does precisely that it takes the idea of mode matching um and says okay here is how probabilities behave when you do mode matching and conversely uh here is how uh modes behave when you minimize the free energy of those probabilities uh so in in section four I then talk about okay does this actually make sense in a physical setting does it tell us anything insightful or is it just a tautology that if you build in a classical mode and then take the limit to the mode then you get classical physics if it's if you phrase it just like that it doesn't seem very remarkable but um for the reasons that I described about uh path integrals and and the classical limit of the path integral it becomes a little bit more subtle and so we can actually derive something kind of interesting uh from the idea that uh classical stuff is the mode of quantum stuff so in the classical limit of quantum mechanics systems that do approximate Bayesian inference exhibit classical physics that's I think that's really the payoff of of that section and so it it kind of justifies the rest of the uh set of questions that I ask because it becomes not just a worked example but it does say something interesting about physics more broadly I think uh now we get into the application section so once that's done um we we cool off a little bit and we just do an example of what does it mean to do mode matching um this is this is simple enough to formulate uh and you can see the in this case the mode so mode matching is about stationary modes and it makes sense to talk about the classical physics of something at rest um now things that are at rest uh don't move so uh synchronization uh in this case is matching a mode to a stationary environment is when a force is not acting on you you don't move and this requires uh very little maths um and at the end uh one of Newton's other laws pops out that objects uh in motion stay in motion objects at rest stay at rest uh so so you get that back from from section five uh from section six you can talk about modes that move well you can talk about um systems that move and and there's actually a finer distinction in there that I um precipitated uh just saying which is in in one case you can talk about um A system that moves towards a mode so A system that tracks a mode but eventually finishes in a stationary place and you can also talk about a system that chases a mode uh so we call this infinite mode tracking or uh what you you could think of this as uh mode chasing you could think of this as a primitive form of path tracking it's just the idea that things that go around in a circle um you can look at it one of two ways you can look at it as an object and the example I use is satellite motion so the classical physics of um celestial bodies say one thing orbiting around another this you can either talk about this as a mode that is being um tracked that is constantly in motion um so you get infinite mode tracking or you can talk about this as path tracking um where the path is the circular path around the object and what we track is just that path and that is what is in 7A so I I say in 6B you can talk about this example as infinite mode tracking but it's kind of ugly it doesn't work very well um so this justifies going to path tracking instead which is a much more elegant picture conceptually it makes a lot more sense and um one of the problems specifically with 6B is that the idea of minimizing the surprisal of a mode uh becomes kind of difficult because uh this system is non-stationary the mode is constantly moving and so the surprise is constantly fluctuating but when you talk about the surprise overpaths it's much easier you can say okay we are actually genuinely minimizing the surprise of paths because we are picking the path of least surprises um one thing that I didn't include in this section which is possibly interesting and uh I don't know one of the nice things about preprints is they are to some extent living documents so I I could come back and add this in um if I was so inclined that in fact I might um is the idea of uh moving centers of mass so path tracking combined with um some kind of moving frame of reference uh the reason why I didn't include this is because the Maths for that is not quite worked out yet but uh since then um uh Lance DeCosta uh and and others uh in a paper that is probably about to be released uh it's it's co-authored between myself Lance DeCosta Carl friston Thomas Parr Conor Heinz and Greg pavliatis so uh all of the big um mathematical Minds behind the last few years of the fep um I think I've named all the names if I forgot anyone then um you'll have to excuse me uh they there's some work in that preprint or their paper that's about to be pre-printed uh that formulates path tracking in the context of moving frames of reference so not just moving modes along a path but also moving paths themselves so one extra kind of layer of generalization is is now you can talk about okay what about when the path that I'm tracking is itself moving uh and and there is probably the Machinery to handle that uh in in this paper that's about to be released uh again it's it's Lance it's Carl it's Greg Thomas Connor and myself uh so keep an eye out for that um because there will be something about uh moving frames of reference in that paper and uh I may decide to go back and add something like if I'm if I'm orbiting a body that is itself in motion so if if the center of mass that I'm orbiting is itself orbiting around something else um what does that look like from the perspective of the thing in orbit uh that that's an interesting case um it's something that I didn't include uh because it was still uh that I think there wasn't an elegant way forward with that now there probably is um but carrying on um 7B is is now um relating the idea of path tracking so the idea of a surprise overpass relating that to the um path integral approach to uh basic mechanics and extracting some insights from what it means to be a path integral and one of the things that one is allowed to do in that context is to then develop a story about classical chaos and I think we have um probably some slides later about that uh that deserves a much longer conversation uh but but the idea of that section is to say Okay so we've done all this arguably pretty trivial stuff um now what about interesting systems like systems that exhibit uh chaos can we actually describe those things using basic mechanics and the answer is we can and it comes out of the pathetical description in the uh nice way that we have gestured at with the name g Theory okay nice thank you Jacob um I was waiting to ask this a bit later on but since you mentioned reference frames um I'm wondering what different sorts of reference frame Bayesian mechanics deals with especially in connection to uh recovering classical mechanics from Bayesian mechanics the way I understand right now reference frame is basically imposed by the markup blanket so when we're talking about the tree the tree branch performing inference over over its environment and being shaken by the the incoming wind that's from the kind of from the reference frame of of the tree how would that be different if we considered a our own reference frame looking at the looking at the tree would that could that still have a formulation within within Bayesian mechanics and also how could this relate to multi-agent systems where we have the classic example that comes to mind is clock synchronization where clocks initial pendulum clocks initially start out of the phase but over time uh go um again in in Phase um I think there's a lot of different ways to partition that system one clock is performing inference over the other is performing inference over the other but there then maybe we can also treat it as a as a coupled system altogether where we consider both at the same time uh so I'm thinking there may might be some equivalent of like a non-inertial reference frame in Bayesian mechanic X versus an inertial one uh given by the markup blanket on that specific system uh so I would be interested to hear your thoughts on that yeah that's uh also a good question um so one of the things that uh you can begin to talk about in this setting is that to some extent the precise placement of a Markov blanket is a bit arbitrary and this is this kind of flexibility is actually a good thing because you do want to be able to Nest blankets within blankets there's reason to believe that that kind of multi-scale um self-organizing well that that multi-scale uh patterning behavior that that multi-scale um separation and and being able to infer not only what my neighbors are doing but being able to infer what the scale above me is doing um there's reason to believe that that is where self-organization comes from another free energy principle and one of the reasons to believe that is um work by uh for instance Mike Levin uh in the context of the uh kind of cognitive nature of developing cells right um cells that are in a kind of soup of things uh how do they know to develop into tissues there must be some kind of notion of nested blankets not only knowing what am I in relation to others but what are we in relation to a larger scale other so uh that that's very important um nesting blankets another really good example of this is in a paper by uh Maxwell um Alec Chance some other people that I don't remember offhand so I apologize called neural and phenotypic representations under the free energy principle and it's exactly the same sort of thing if you have a soup and they know something about themselves and also something about something at a higher level then uh you get self-organization so it's it's not just about um kind of self-organization at the constituent level but it's knowing something about the pattern that one is organizing into uh and and these are two good examples of that there are lots of others uh so so one imagines you know the the arbitrariness of the Markov blanket is important because it allows you to Nest things more generally it allows you to change context and you know the the um context of information is kind of Observer dependent so uh in a way you do want to be able to introduce kind of arbitrary frames and get different kinds of uh context for for a given observation set right you want to be able to reassign self and other and still get approximate Bayesian inference um this is what we would think of as a gauge Theory it's a symmetry at the level of the system that is uh not reflected in the physics of the system by which I mean you can make free changes at the level of the system that don't change the physics of the system so so in this case it's the idea that we can change a reference frame we can change the context of an inference but it shouldn't change the idea that systems do approximate Bayesian inference much in the same way that we can change the way we label coordinates in general relativity but it shouldn't change the idea that gravitation is the curvature of space-time in some suitable sense that has to do with metric tensors that I won't talk too much about um so so something like that is is absolutely I think not only kind of useful but it's absolutely essential um to not only making basic mechanics make sense it would be kind of suspicious if inference just fell apart if you redrew the boundaries um especially given our conversation about the uh scale friendliness of the fep uh it should apply and reapply but also that application and reapplication and contextualizing inferences within inferences is kind of right now what is reflected in the literature when we really think about okay how does self-organization work um in in these situations uh and and how does individuation work in these situations or how are patterns formed um and and I think there's there's lots of work uh in this direction about um reference frames and the contextuality of information outside the ivp as well uh and and I happen to be familiar with very specific literature about this in category Theory uh but I'm sure it's more General than that uh so you can talk about how does uh context shape um an observation so uh yes I think um yeah on the subject of reference frames uh and and synchronization it's important to be able to redraw uh boundaries so take new frames of reference and still get um inference uh in the case of um synchronizing pendulums you can imagine okay maybe the pendulums do inference on each other um or maybe they do inference on the kind of if they're on some sort of table or moving beam maybe they do inference on the beam and they synchronize with the beam and therefore they synchronize with each other that's one frame the other frame is one kind of looking at the looking at the rhythmic motions of the other one and uh and just matching up like that in both cases you get inference um we probably prefer one reference frame or another um but but both are in principle uh mathematically valid even if they tell kind of different physical stories about what's being synchronized to uh and and the example of um half tracking and a moving frame of reference is interesting as well because if you think about um something like the moon orbiting the Earth um you can you can zoom way out and you can look at it as the moon spiraling around the earth as the earth goes around the Sun but you can also um pick a reference frame where the Earth is stationary and the Moon is just orbiting around the Earth um so so this is the relativity of motion right or or if you want to imagine um sitting in a train uh it looks like the outside is moving and you're stationary um so so that would be you know mode matching you're not moving but from the perspective of the outside the train has just gone past uh pretty quickly and you're in the train and so you're moving you know but from your perspective you're not so so the relativity of what is being matched to is an important consideration um for for those reasons just to produce a consistent Theory we have to acknowledge that we can freely assign these inferences um the the important aspect is that we get the same inferences back or at least we get inference you know they might not be the same inferences if you wrote them down they might be in different coordinates so to speak but at the end of the day you should still get Bayesian inference um now I don't remember your second question so you'll have to ask it again um I'm actually not aware if there was a second question but I do have a follow-up question to uh oh of your answer uh since you since you mentioned nested um Markov blankets um I I'm just wondering whether in the formalism of Bayesian mechanics we can also admit a kind of Dynamics on the topological structure of the mark of the blanket itself because in the case of cells forming other layers uh in intuitively it seems to me that it's a kind of discrete way of thinking about how we're adding an extra layer of the Markov blanket and maybe the Markov blanket initially admits uh some uh there are some non-integer uh index connecting to your uh prior work on the weak Mark of blankets and then it evolves over time to to form into uh uh actually statistically significant Markov blanket but perhaps there might be also a way for having just one mark of blanket that evolves through time and that might also change the inferences so uh I'm wondering whether uh mechanics uh whether the Dynamics of particular blankets can also be uh taken into account in the path tracking formulation or any other one within approximate Bayesian inference yeah um so there are a couple of interesting things there um for one thing uh the the idea that um perspective matters the idea that you pick a reference frame and carve up your environment that way um does kind of go back to this question of how do we understand um blankets forming uh in developing cells say and and the idea would be that you know blankets have characteristic scales right the reason why we see um something like a stone in nature and not a lattice of crystalline molecules is because at our level of observation the um the blankets that allow these molecules to be self-organized is um completely meaningless but but what is interesting to our level of observation our kind of canonical reference frame is the stone itself uh the blanket around the stone itself it's the Stone's blanket it's not the blankets that um make the molecules that make the stone so um yeah you know eventually we would want a much more complete theory of individuation that covers not just um dynamical blankets but nested blankets and uh blankets with perspective and um and things of that nature uh the the perspective based idea is is an interesting one to me because it allows you to talk about um things like sparse coupling at certain levels and and if we acknowledge that the Markov blanket is coming to a blanket store in the area exactly if we acknowledge that the blanket is somewhat arbitrary then we're free to say that um any system with enough couplings has a blanket at some scale because uh the kind of multi-scale systems in physics that we're interested in at some scale are sparsely coupled um probably not every scale and um certainly within a blanket there's not sparse coupling given a particular reference frame because given a particular ref given the reference frame of myself looking at the stone looking at the Stone's blanket within that blanket I would want to see the stones molecules cohere in a way that is um not sparsely coupled right otherwise I wouldn't see things but then at the level of the stone it is sparsely coupled so so this kind of arbitrariness um allows us to actually do the carving up in a very interesting way as for a dynamical systems perspectives on um Markov blankets I think this is also possible um I am working on something right now that that takes the whole story about uh physical boundaries and conditional Independence and write it in terms of random variables so you have a whole Suite of possible blanket States and you can look at blankets kind of flickering on and off um or uh blankets that occupy different states over time um this is not nested yet but uh it's it's one step towards that direction where you can think about how the blanket at a higher level turns on or off given the Dynamics of its constituents whether they're cohering or not um so yeah maybe that answers your question this is a great topic to chill on for a few more minutes in our final bit of the dot one there's really a lot here I'll just give a few dots and then Ali happy to hear your perspective as well um you even discussed it as scale friendly but it's almost like a one and a half layer model and that is actually uh preceded by even simple Bayesian hidden state observed variable distinctions expectation maximization just partially observable Bayesian models in general under an interpretation where observables are happening at a given scale of a system of interest and a hidden phenomena or a hidden cause is at a higher level of organization connects these sort of multi-scale systems approach with a self-organization approach and we've talked many times about that lateral and the vertical there's the nest mates interacting laterally and then there's the real or as if Colony level organization another point I think it's really interesting to pull out and explore is you discussed how important it is to be able to redraw blankets and still get inference it made me feel that there has to be some kind of a locally distributed local sense making process such that potentially a vast range of partitionings can also remain valid like you can think of different metaphors there and that potentially the blanket provides exactly that partitioning surprise surprise and then moving towards all these features that had been in the uh spectator seats at the math conference dynamical nested multi-perspective systems and the way that some of these formalisms are pointing towards an integration that's quite far out in some ways yet also may bring an intuitiveness to a lot of the ways of talking about different physical systems including the physics of cognition and as far as nature at the joints perspectives would be one not the only one but one of those joints or sparse connectivities or factorized abilities various ways of thinking about it but multiple entities engaging in a multi-perspectival multi-scale inference question it's like two people looking at the boat they might disagree on how to partition different parts of the boat or the boat from the water but at least their perspectives and their communication interface with each other and their observation inference interfaces with the boat could be specified and so then it could be like my map of me my map of you my map of the boat your map of you your map of me your map of the boat and then there's a conversation with all six of those features instead of us only looking at the boat and you did it one way I did it differently and that's the end of the discussion so I think it's going to open up degrees of freedom in perspective harmonizing that wouldn't be classically understood and that'll be seen as extremely non-linear and unconventional behaviors and it's just yeah we've seen what that is I agree um I'll I'll take this opportunity to point out um there are other people in the uh verces lab who are thinking about that kind of question um how does collaboration and uh information synthesis and um kind of agreement or goal emergence how all these things fit into Bayesian mechanics um so people like Maxwell and uh maholt are thinking about if I write down you know these kinds of problems uh is there a way to talk about agreement as it emerges through um you know Collective discussions or collaboration and it is likely something um like this it's agreeing on a reference rate for our Collective observations and and agreeing on you know not just sense making but it's agreeing on how to make sense of something so there's a kind of two-step process I learned something figured out I tell you you have your own um picture of what this thing looks like we agree on a picture that uh serves Us best we we agree on a best reference frame yes agreeing on the sense made is um deciding what to order after the dish has been cooked does that need to have a conversation about the recipe and so many other things Ali uh well I I believe this whole argument around Mark of blankets and especially the nested Market blanket or the dynamic nature of them uh can potentially be connected to somehow the opposing stances uh one which is the preformism or pre-pormationism the other one is uh the progressive uh differentiation mechanism which uh for the in the preformism uh some people believed that the topology of the whole state space manifold is completely pre-formed and we just don't have enough data to model that accurately modeled the state space accurately but for The Advocates of the progressive differentiation um Viewpoint they on the other hand believe that it literally goes I mean the state space manifold literally goes undergoes um lots of Transformations uh according to uh the I mean some inflection points or some singularities and it's not uh pre-formed at all and the dynamic nature of the state space manifold is something inherent to that it's not because of our lack of enough data to model that so uh I'm not sure how much you agree with that viewpoint but yeah that's something that's yeah I think sure I think the kind of drawing and redrawing of uh Markov blankets um it's probably a point in support of the idea of progressive differentiation because uh at one level um we think of uh drawing and redrawing as developments um or uh oh yes development and and one of the things that drives development is something like Fitness pressure so Fitness uh changes the constraints on what sort of patterns are available to you what are you organized into and and these are not things that we know are priori at the level of the system it may be possible that if you write down a whole kind of a world model of the entire universe from you know the very first uh Point uh in time uh after the big bang or maybe even uh at the instant at which the singularity expanded and you had enough computational power to trace it all through uh that you could get to something like um what is it preformationism um but that that strikes me quite a lot as a kind of um super determinism or determinism argument it sounds a lot like some kind of um argument that you know there is no uncertainty in how you will develop there is just uncertainty in um what you're aware of as to your development um or some kind of hidden variables theory that says there is something mediating the way your state space looks you just don't know it and so you have the illusion of Free Will um so this becomes a bit of a philosophical question um I myself don't really buy into determinism so I I would be tempted to say uh that the Markov blanket story especially Dynamic blankets or however you want to call them are to do with Progressive differentiation as we live our lives we draw and redraw our own blankets as we mesh and individuate ourselves from other systems and the environment and this is something that we are in control of certainly locally in the state space we're in control of it whether there is some hidden variable guiding our own actions uh is something that is I think strictly speaking a different question the nice thing about it is whether it's true or not it doesn't break the locality of the Markov blanket construction so uh we we get this idea of locally Progressive differentiation as a Markov blanket and then when we Zoom way out um it may be a kind of a different story but certainly um yeah locally it works as a this kind of dynamic process well we almost got to the paper this was a awesome discussion so Ali and Jacob if you would like to have any closing remarks uh well I just wanted to say that I truly enjoyed our discussion today and I very much look forward to that too because I have a bunch of questions that I didn't have a chance to ask about some of the sections of the paper so I I just wanted to thank Dalton for his time and uh also for Jacob and Daniel for organizing these uh extremely fruitful and useful uh discussion sessions and live streams so yeah I'm very much looking forward to the next one thank you Jakob yeah uh this was an amazing uh amazing.one thanks thanks a lot uh Dalton for all the great answers and overviews uh of course uh Ollie and Daniel for doing bulk of the work on the on the slides and yeah looking looking forward to the dot two Dalton any last thoughts uh no just uh thank you for having me uh it I did really enjoy it um and and thank you of course for all of the background work that you put in um it's uh as I said it's very flattering uh to see um such detailed uh working through of my work uh so so thank you for that uh and I am looking forward to the next episode excellent well next week us and anyone else who'd like to join just get in touch or submit any questions or topics so thank you fellow see you later okay cheers thank you