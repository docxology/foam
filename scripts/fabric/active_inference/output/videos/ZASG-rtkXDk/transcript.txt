[Music] thank you [Music] [Music] all right welcome it is active live stream number 51.0 this is the background in context first discussion for canonical neural networks perform active inference by isomera at all it's October 26 2022. welcome to the active inference Institute we're a participatory online Institute that is communicating learning and practicing applied active inference you can find us at some of the links on the page this is a recorded in an archived live stream so please provide us with feedback so we can improve our work all backgrounds and perspectives are welcome and will be following video etiquette for solo live streams head to activeinference.org to learn how to get involved with active inference Institute projects today it's the first of several discussions that we'll have on the paper canonical neural networks perform active inference 2022 by takuya isamura hideyaki shimazaki and Carl friston the video is just an introduction to some of the ideas it's not a review or final word there will be an overview of the structure of the paper and then we'll go through many of the key points also just to disclaim there's many many other and better resources to learn about neural networks so I would very much welcome those with a technical understanding of neural networks and or some of the more applied computational or uh otherwise aspects of neural networks it would be awesome to have them on for the dot one and the dot two because it was not an area I was familiar with and so hope that I can hear more from the authors in our coming weeks and others I'm Daniel I'm a researcher in California and this will just be a solo.0 which I guess hasn't happened in a while in the making of this here are some of the generated art prompts Area 51 active inference Area 51 neural network Area 51 active inference ants Area 51 active inference neural network just some interesting images coming out of stable diffusion so as to some big questions that the paper is addressing and that one might be interested in to come to the paper how can artificial neural networks be understood as generic optimization processes and what is the correspondence between neurodynamics and modern statistical inference methods other big questions are uh about the history and next steps of the enmeshment of natural intelligence EG neuroscience and artificial intelligence as well as of course whether to even play into this kind of Distinction at all and have different integrated intelligence Frameworks and one paper where any of the authors or anyone who has uh kind of resonated with this work is recent buys a door at all 2022 towards the Next Generation artificial intelligence catalyzing the neuro AI Revolution and so this is a bunch of authors and so it's interesting just to quote in terms of what some areas of discourse are saying right now which is neuroscience has long been an important driver of progress in artificial intelligence AI we propose that to accelerate progress in AI we must invest in fundamental research in neuro AI so that's one way to bead some of the developments that are happening in the paper we'll discuss uh what does it mean to be particular but generic that's a phrase used in the paper so maybe that's kind of a jumping off point and then how can active inference help us understand the past present and future here of the interface with neural network statistics and neural AI here's the abstract this work considers a class of canonical neural networks comprising rate coding models where a neural activity in plasticity minimize a common cost function and plasticity is modulated with a certain delay we show that such neural networks implicitly perform active inference in learning to minimize the risk associated with future outcomes mathematical analyzes demonstrate that this biological optimization can be cast as maximization of model evidence or equivalently minimization of variational free energy under the well-known form of a partially observed Markov decision process model this equivalence indicates that the delayed modulation of habian plasticity accompanied with adaptation of firing thresholds is the sufficient neuronal substrate to attain Bayes optimal inference and control we corroborated this proposition using numerical analyzes of maze tasks this Theory offers a universal characterization of canonical neural networks in terms of Bayesian belief updating and provides insight into the neuronal mechanism's underlying planning and adaptive behavioral control here is the roadmap I'll be driving on the right side of the road there's an introduction and a table with glossary of different Expressions used then there's the results sections which has a first an overview of equivalence between neural networks and variational Bays active inference formulated using a postdiction of past decisions canonical neural networks perform active inference and numerical simulations so they work on the interface between neural networks and variational Bayesian methods and start with a more theoretical and mathematical backgrounds and then eventually present some maze simulations that are in Matlab then there's a discussion and then the methods section is following the discussion and it has the subsections generative model variational free energy inference in learning neural networks simulations and data analysis and I think that I have kept to the right color codes consistently from here on forward the block quotes are the direct quotes from the paper blue codes quotes are related to perception uh orange for Action complete class theorems and neural networks together in purple and then red is commentary and then the highlighting for red is related to um the variational methods but it's kind of red ish okay the papers canonical neural networks perform active inference by the authors uh listed previously it's in Communications biology from 2022. and the key aims of the paper are laid out well in the first paragraph so that's in black and other colors and uh here the red is just kind of getting into initial conversation with the paper and connecting a little bit more to some previous streams before we go more into the specifics of the paper the sentient behavior of biological organisms is characterized by optimization biological organisms recognize the state of their environment by optimizing internal representations of the external environmental Dynamics generating sensory inputs so that's the sensory recognition model in addition they optimize their behavior for adaptation to the environment thereby increasing their probability of survival and reproduction so that is bringing the entire active and inactive control theory formal theories of action action selections planning and planning as inference all of these action-oriented pragmatic turn type ideas come into play when this action orange aspect is brought in and it is slash must be slash should be Etc oriented towards survival and persistence otherwise we don't see that kind of thing for long over appropriate definitions for thing and log Etc and uh this few sentences that the paper begins with summarizes a common theme in active which is that there's basically two Pathways towards Proficiency in the niche there's changing the mind which is the perceptual and learning and then there's changing the world through action and that kind of integration of inference cognitive inference whether it's perceptual or learning or other and action as enacted is part of the active formulism and shared with other areas this biological self-organization is typically formulated as the minimization of cost functions where in a gradient descent on a cost function furnishes neurodynamics and synaptic plasticity so they are working with a framework where the way that this perception action flow is tractable computationally either just for our current computers so that we can Implement simulations and data fitting or whether more fundamentally like this is the computational context of action they're suggesting there's a way to think of it in terms of a cost function minimization and also note like minimization maximization in a way they're interchangeable because there's just sometimes negative signs that can flip them so it's the same energy and fitness landscape that is being navigated whether you're minimizing to the bottom of the bowl and thinking of action selection that way and inference or whether you're climbing to the top of the hill gradient descent gradient Ascent they're both kind of two sides the same coin um two fundamental issues remain to be established namely so what this is what the paper is saying they're filling the Gap in literature the characterization of the Dynamics of an arbitrary neural network as a generic optimization process and the correspondence between such neurodynamics and statistical inference found in Applied Mathematics machine learning the present work addresses these issues by demonstrating that a class of canonical neural networks of rape coding models is functioning as and thus universally characterized in terms of variational Bayesian inference under a particular but generic form of the generative model this is maybe the only slide that has resources from too far afield from the paper well almost a few more it's just on neural networks the search on a very common Search tool resulted in five plus Million results for what are neural networks and the first one was three blue one Brown from 2017 which is just a nice YouTube video as they very often make with these beautiful Renditions and it's a very great video and there's many many others a neural network is a network or Circuit of biological neurons and that is variously purely computational and or biological map territory stuff and they can be thought of as nodes and edges which are um the firing rates and the connections between the biological neurons being modeled as weights between nodes a positive weight reflects an excitatory connection while negative values mean inhibitory connections and here is data coming in and ending up activating different neurons in this final layer so this is kind of doing inference in a neural net work and then there's an action part okay the paper says variational Bayesian inference offers a unified explanation for inference learning prediction decision making and the evolution of biological form which can be considered over multiple time scales so this returns to the earlier theme of like perception action and persistence within and among generations and the citations that are provided here for this are friston Kilner Harrison 2006 and friston 2010 both very classic active slash fepers just to show one figure from each here's from the first citation with the winged snowflake where if the snowflake ends up being somewhere that's too warm that's not able for it to maintain the structure then it melts melts into a dew Etc and it must be acting as if in one way or another it's staying above that phase boundary that's how it's statistically identified it's how it's autogenetically identified functionally identified and then here is one of the um kind of path setting figures in the first in 2010 paper with a tree of many different areas to connect to and formalisms to represent as including probabilistic neural coding Bayesian brain optimal control and value learning these three and others can be really seen at play in this 2022 paper uh the kind of inference variational Bayesian methods use rest upon a generative model that expresses a hypothesis about the generation of sensory input perception and behavior can then be read as optimizing the evidence for a generative model inherent and sensory exchanges for the environment and that's the integration of perception and action within a single imperative in terms of if only computation and that is described more on this slide which one can pause and read but the rest of the quotes are from the paper uh one e formalism that I had no familiarity with before this paper and Associated readings and conversations with Ali was the complete class theorem so it would be um great for anyone who's familiar with complete class theorem to help a little bit here but here's some interesting things that I came across crucially from the paper as a corollary of the complete class theorem citations 19-21 any neural network minimizing a cost function can be viewed as performing variational Bayesian inference under some prior beliefs here are the citations 19 through 21 from 1947 1981 2013. and uh also found some interesting resources so quoting from this less wrong post linked here Dutch book defines belief as willingness to bet and money pump defines preference as willingness to pay this is in terms of the foundational Arguments for a Bayesian epistemological worldview hope that's correct again it'd be good to hear from anyone who knows more here but in terms of different ways that one can consider the Bayesian proposition which perhaps these are even better to use than referencing any person's last name because the interesting thing will be the different uh lenses that these different framings on Bayesian probabilities are interpreted as just like what a p-value is interpreted as in the frequentist world common obviously like a base Factor interpretation so Dutch book defines belief as willingness to bet and money pump defines preferences willingness to pay in doing so both arguments put the justification of decision Theory into hypothetical exploitation scenarios which are not quite the same as the actual decisions we face if these were the best justifications for consequentialism we could muster I would be somewhat dissatisfied but would likely leave it alone fortunately a better alternative exists the complete class theorem so here's an image from that post able World States observation likelihood maps to the possible observations hashtag a matrix then decision making rule may be probabilistic action selection as inference a possible actions affordances and here we commonly see the loop being closed from actions to World States like through the B Matrix changing how the world changes through time and here these are both going to be mapped to a loss function l a real valued score from taking an action a when the world turned out to be Theta realized Theta so that's quite an interesting framing and there were some other useful posts online and from this uh zhat blog the argument boils down to if you agree with expected utility as your objective then you have to be Bayesian in a nutshell a strategy is inadmissible if there exists another strategy that is as good in all situations and strictly better in at least one if you want your strategy to be admissible it should be equivalent to a Bayes estimator complete complete class theorems only base strategies are admissible and admissible strategies are based so there's probably a lot of interpretations of this but it seems kind of related to Optimal control or base optimal inference perhaps a little bit more keenly so these are some next two slides were contributed by Ali so if you or if anyone familiar in this area wants to come on in the discussion to be great but uh Ali pointed me to this book fundamentals of Bayesian epistemology by title bomb 2022 the table of contents shown here and some challenges and objections to Bayesian epistemology are listed which can be read and then also there's some quite interesting logical structures which can be read here in terms of their premise theorem and conclusion in the areas of arguments for bayesianism being representation theorem argument for probabilism the Dutch book argument for probabilism and the gradational accuracy argument for probabilism so pretty interesting back to the paper they wrote we have previously introduced a reverse engineering approach that identifies a class of biologically plausible cost functions for neural networks citation 22. previous paper of isomura and friston 2020 the paper was reverse engineering neural networks to characterize their cost functions the abstract shown here but this letter considers a class of biologically plausible cost functions for neural networks using generative models based on partially observable Markov decision processes pomdp we show that neural activity and plasticity perform Bayesian inference and learning respectively by maximizing model evidence so this is a precursor paper from 2020 that is cited and foundational for the 2022 paper here's some figures from that paper they have a comparisons among a Markov decision process scheme and a neural network for example a Markov decision process scheme expressed as a Forney Factor graph based on the formulation in friston so here is the Markov decision process as a 40 Factor graph and on the right side is the neural network with the hidden State sensory inputs and neural activity and some figures and concordances and they wrote in this context the neural network can principle be used as a dynamic causal model to estimate threshold constants and implicit priors this reverse engineering speaks to estimating the priors used by real neuronal systems under ideal Bayesian assumptions sometimes referred to as metabasian inference so they're laying out their research agenda and much of the work is going to reference this earlier paper and other work and then there's also some new Integrations and especially the maze simulation in this paper and probably more so let's find out referring to the earlier paper this foundational work identified a class of cost functions for single layer field feed forward neural networks of rate coding models with a sigmoid or logistic activation function we subsequently demonstrated that mathematical equivalence between the class of cost functions for such neural networks and variational free energy under a particular form of the generative model which is similar broadly to what the 22 paper does to this equivalence licenses variational Bayesian inference as a fundamental optimization process that underlies both the Dynamics and function of such neural networks however it remains to be established whether the active inference is an apt explanation for any given neural network that actively exchanges with its environment in this paper we address this inactive or control aspect to complete the formal equivalence of neural network optimization and the free energy principle so this earlier work was not including action and so this paper's key Edition as I understand it hopefully is that they bring action more formally into the model and it'd be interesting to know like what else is that change associated with or what else happens or doesn't um here's some more text about the approach that they're going to take and many of these details are going to be addressed later on here's table one glossary of expressions so these will also be broadly addressed later on maybe it's useful though just to read the first one a canonical neural network in this work the canonical neural network is defined by differential equations of neural activity derived as a reduction of realistic neuron models through some approximations which give a network of rate coding neurons with the sigmoid activation function in particular we consider networks comprising a middle layer that involves recurrent connections and the output layer that provides feedback responses to the environment so some category of neural network architectures or anatomies physiologies whatever with sensory cognitive and action like features in an environment or a generative process so the results section they write an overview of equivalence between neural networks and variational base first we summarize the formal correspondence between neural networks and variational base a biological agent is formulated here as an autonomous system comprising a network of rate coding neurons figure one a so here's a small figure 1A we'll see it larger based upon the assumptions which will be brought up later on in a different folder form the update rule for the ith component of Phi which is the internal States so the cognitive States and the output layer y so middle layer X and output layer y these can be seen as the cognitive and the action selective aspects which are the autonomous States in contrast to the particular states of the active inference entity which is the whole blanket and the cognitive States so including the sensory States but the sensory States can't be directly controlled however action can influence them and so that's what closes the causal Loop and that particular that set of the particular States comprising the autonomous States the update rule for the ith component of Phi is derived as the gradient descent on the cost function so the change in that by sub I is proportional to a derivative on the loss function this determines the Dynamics of neural networks including their activity in plasticity so L common loss function o observations sensory States by internal States comprised in the middle and output layer neural activity that's the rate coding part and synoptic strengths W the parameterization and other free parameters including that they characterize l then there's the output layer activity Y is determining the Network's actions or decisions Delta O X and Y why is the outputting action environment generative process hidden State passing observations to the sensory cognitive octave layers the neural network and that is analogous topologically to the variational Bayesian formulation in figure 1B and so left side gradient descent on a neural network cost function L determines the Dynamics of neural activity and plasticity thus L is sufficient to characterize the neural network and then being shown next to on the right side variational free energy minimization allows an agent to self-organize to encode the hidden states of the external milieu and to make decisions minimizing future risk here variational free energy f is sufficient to characterize the inferences and behaviors of the agent so sentence structure parallelism and these two schemes or approaches being linked and applied is a focus of this area so neural networks are minimizing the cost function l in contrast variational Bayesian inference depicts a process of updating the prior distribution of external States P of theta so the corresponding posterior distribution Q of theta based upon the sequence of observations and we see other familiar terms from discussions on variational days like minimization of surprise and there's some more model details shown here a few points are about choosing the family of distributions that one is doing variational inference with and that allows for the gradient update rules in that family of distributions to be made simpler for example choosing a linear regression with an L2 Norm at the very least you can say that it has a simple decision rule for Being Fit I'm sure there's like also counter arguments and other algorithms that are better and so on but just to say that a simple decision rule in a known family of distributions can often be good enough as an approximation if not more crucially according to the complete class theorem from earlier A dynamical system that minimizes its cost function can be viewed as performing Bayesian inference under some generative model and prior beliefs the complete class theorem goes on to describe it ensures the presence of a generative model that formally corresponds to the above defined neural network characterized by L hence this speaks to the equivalence between the class of neural network cost functions and variational free energy under such a generative model equation one loss function on the time series of observations comma parameters three lines is defined as F the free energy function on the same o Through Time comma parameters so there's a parallel being shown slash defined wherein the internal states of a network Phi encode or parameterize the posterior expectation Theta this mathematical equivalence means that an arbitrary neural network in the class under consideration is implicitly performing active inference through variational free energy minimization and more is written but this is one of many statements that will be made corresponding to correspondences between neural network loss function generative model octave free energy minimization and associated formalisms note that being able to characterize the neural network in terms of maximizing model evidence lends it and explainability in the sense that internal neural network States and parameters encode Bayesian beliefs or expectations about the causes of observations in other words the generative model explains how outcomes were generated however the complete class theorem does not specify the form of a generative model for any given neural network to address this issue in the remainder of the paper we formulate active inference using a particular form of partially observable Markov decision processes pomdp models whose States take binary values so this is one of several simplifications is one way to see it or areas for later generalization figure two in this section we Define a generative model and ensuing variational free energy that corresponds to a class of canonical neural networks that will be considered in the subsequent section the external milieu is expressed as a discrete State space in the form of a pomdp figure two so to make figure two larger there's a lot to probably say about this bigger I'll just note that the caption is informative and some of the highlighted lines it'll be awesome to have the author and other people who's familiar with some of the differences and symmetries between the for example bottom and top above and below the observations and also about the role of time and what these two risks are what is fictive causality here's more details on that pomdp then equation two this is in this section active inference formulated using a postdiction of past decisions so if it was a prediction of future decisions it's this the opposite a postdiction of past decisions hence we Define the generative model as follows p o Delta s gamma data which is the model of observations decisions observations decisions hidden States risk and data uh theta equals a b and c constitutes the set of parameters and more details are provided this is the familiar notation with some slight differences that'll be described and equation two reflects the factorizability and the dimensions and the kind of computational tractability expression so that would be interesting to also learn about like under what conditions can this joint distribution be factorized under what simplifications or constructions the agent is making decisions to minimize a risk function Capital gamma that's on the bottom of figure two evictive causality leading to this gamma coming from dot gamma equation three is shown and to characterize the optimal decisions as minimizing expected risk in our pomdp model we use a victim mapping from the current risk gamma to past decisions that's that retroductive victim causality although this is not the true causality in the real generative process that generates sensory data here we intend to model the manner that an agent subjectively evaluates its previous decisions After experiencing their consequences this fictive causality is expressed in the form of a categorical distribution so it could be other families hypothetically but this equation 3 is describing evictive causality and this interesting sign indicates the element-wise division operator also note throughout the manuscript the overline variable indicates one minus that variable so gamma bar equals one minus Gamma or it can be understood as the complement of a statistical probability probability of a happening and the probability of not a happening in that one way importantly the agent needs to keep selecting good decisions while avoiding bad decisions to this end equation 3 supposes that the agent learns from the failure of decisions by assuming that the bad decisions were sampled from the opposite of the optimal policy mapping some more details and then by convention active inference uses C to denote the prior preference that's how we've seen the C variable in many models as preferences prior preference this work uses C to denote a mapping to determine a decision depending on the previous state herein the prior preference is implicit in the risk function due to construction see does not explicitly appear in the inference thus it is omitted in the following formulations so that's a key point about the notation of the variable C and something kind of maybe interesting to explore equation four variational Bayesian inference refers to the process that optimizes the posterior belief Q of data based on based on the mean field approximation Q of theta is expressed as and here is the factorization representation of the Q of theta variational and another notation note throughout the manuscript bold case variables such as bold S Sub Tau denote the posterior expectations of the corresponding italic case random variables and some more details about the model for example for Simplicity here we suppose that state indecision priors D and E are fixed so one could imagine they don't have to be but for Simplicity they will be here under the above defined generative model and posterior beliefs the ensuring variational free energy is analytically expressed as follows equation five this is a variational free energy f and recall equation one that it is being connected to juxtaposed with Etc the loss function the gradient descent on variational free energy updates the posterior beliefs about hidden States s decisions Delta and parameters Theta the optimal posterior beliefs that minimize variational free energy are obtained as the fixed point of the implicit gradient descent which ensures that change in F with respect to the change in Hidden State through time equals zero and some more definitions all of them are zero that one might be an O but they're all zero and this is saying the ball rolls to the bottom of the hill in this gradient descents and when the rate of change is zero then that is a fixed point a tractor-like dynamic and that can be used as a way to incrementally fit statistical models like the loss function is used to incrementally fit neural networks to explicitly demonstrate the formal correspondence with the cost function for neural networks considered in the next section we further transformed the variational free energy as follows some details using these relationships equation 5 is transformed into the form shown in figure three see the methods section variational free energy for further details in what follows we demonstrate that the internal states of canonical neural networks and code posterior beliefs here's figure three on the top from the caption figure three is the mathematical mathematical equivalence between variational free energy and neural network cost functions depicted by one-to-one correspondence of their components top variational free energy transformed from equation 5 using the Bayes theorem and foreshadowing equation seven using this relationship equation seven is transformed into the form presented at the bottom of the figure so here's F variational free energy and L the neural network cost function and different elements as they're represented here with some resonances and concordance and Beyond which we can explore there being shown to be equivalent and it was in the conversation preparing for this dot zero with Dean where we saw this as some chromosomes in the section canonical neural networks perform active inference in this section we identify the neuronal substrates that correspond to components of the active inference scheme to find above we consider a class of two-layer neural networks with our current Connections in the middle layer figure 1A those are those connections with loops recurrent in the middle layer the modeling of the networks in this section referred to as canonical neural networks is based on the following three assumptions that reflect physiological knowledge one gradient descent on a cost function L determines the updates of neural activity and synoptic weights method section neural networks neural 2 assumption 2 neural activity is updated by the weighted sum of inputs and its fixed point is expressed in a form of the sigmoid or logistic function and assumption 3 a modulatory factor mediates synaptic plasticity in a post-hoc manner they write based upon assumption 2 which is neural activity is updated by the weighted sum of inputs and its fixed point is expressed in the form of a sigmoid or logistic function based on assumption 2 we formulate neural activity in the middle layer and output layer the autonomous States as follows equation six without loss of generality equation 6 can be cast as the gradient descent on cost function l such a cost function can be identified by simply integrating the right hand side of equation 6 with respect to X and Y consistent with previous treatments citations because neural activity and synaptic plasticity minimize the same cost function l the derivatives of L must generate the modulated synaptic plasticity under these constraints reflecting assumptions one through three a class of cost functions is identified as follows equation seven loss function awesome to hear somebody read this directly so there's a firing rate aspect that's related to neural firing in the short term more perceptual aspect of function and there's a slower neurotransmitter neuroglial Factor mediated learning over perhaps a different time scale and with some different features and they're being included as a joint model of inference and here that is being connected to doing inference on action synaptic plasticity in neural networks so synaptic plasticity rules conjugate to the above rate coding model can now be expressed as a gradient descent on the same cost function L according to assumption one equations eight and nine showing that neural networks can integrate those modes of firing rate like and synoptomodulatory like neural networks cost functions and variational free energy based on the above considerations we now establish the formal correspondence between the neural network cost function and variational free energy using under the aforementioned three minimal assumptions we identified the neural network cost function as equation 7. equation 7 can be transformed into the form shown in figure 3 bottomed using sigmoid functions of synaptic strengths so equation 7 loss function transformed into the form shown in figure three bottom uh hence this class of cost functions for canonical neural networks is formally homologous to variational free energy under the particular form of the pomdp generative model defined in the previous section we obtained this result based on analytic derivations without reference to the complete class theorem thereby confirming the proposition of equation one loss function and free energy this in turn suggests that any canonical neural network in this class is implicitly performing active inference table 2 summarizes the correspondence between the quantities of the neural network and their homologs in variational base so two a great concordance table on the left side neural network formation on the right side variational Bayes formulation so just like in figure three we had the two long lines then table two we have rotated 90 degrees and the variables for different parts of these models are laid next to each other so what papers of neural networks can we make active models for is it already done or is there just one script that needs to be done and then conversely what interesting variational Bayesian models have interesting applications or some other value or Information Gain from being cast as neural networks or integrating neural networks into what had previously been only analytical variational Bayesian models as well as the empirical data fitting aspect which is related that's highlighted by the authors so in summary when a neural network minimizes the cost function with respect to its activity and plasticity the network self-organizes to furnish responses that minimize the risk implicit in the cost function this biological optimization is identical to variational free energy minimization under a particular form of the pomdp model hence this equivalence indicates that minimizing the expected risk through variational free energy minimization is an inherent property of canonical neural networks featuring delayed modulation of hemian plasticity okay brief second to view some image memes and take a breath in a stretch on the left side the top panel says every neural network is implicitly performing active inference question mark that's awesome in the middle image meme one simply makes a neural network and it is implicitly performing active inference also question mark and then in the right image meme there are two pieces of paper neural network and implicit performance of active inference corporate needs you to find the differences between this picture and this picture and here is the paper there the same picture so the previous sections have successfully extended The variational Bays meets inference neural network result from the 2020 paper with an action Loop and a loss function only on the autonomous States so that was the conceptual and Technical feature that this paper brought in again it'll be awesome to hear the author describe it more and differently and then in this part of this of the paper they turn from that kind of analytical theoretical towards some numerical simulations in Matlab here we demonstrate the performance of canonical neural networks using maze tasks as an example of a delayed reward task the agent comprised the aforementioned canonical neural networks figure 4A thus it implicitly performs active inference by minimizing variational free energy so now some entity or agent is going to be constructed and numerically simulated to support some of the uh aspects of their model and point towards utility in other settings so here's figure four simulation of neural network solving maze tasks uh in part A there's the architecture of the agent sensory input layer o of t synaptic weights into the middle layer X internal States and the output layer y decision action with risk gamma of t the sensation comes in a neural network then outputs a decision there's some uh task that the entity must perform which is uh to move towards the goal from the start across this lateral maze so one can imagine that if it were just a hallway with no maze features simple strategies would be very overfit but effective like always move simply towards the goal whereas in more complex settings which this is an example of where there's uncertainty as well as many local Optima so one has to sometimes take one or two or three or four or more steps or however many to get closer to the goal and sometimes may not know for example how long those backtracking situations are going to be and all these other complexities for which this maze example is similar symbolum uh symbolic of so maybe there's some some interesting Mythos maze connections and computational and here's some performance measures on the maze task with the neural network entity this way before training the agent moved to a random Direction each step resulting in a failure to reach the goal position right and within the time limit during training the neural network updated synaptic strengths depending on its neural activity and ensuring outcomes I.E risk this this training comprised a cycle of action and learning phases this treatment renders neural activity and adaptive behaviors of the agent highly explainable and manipulatable in terms of the appropriate prior beliefs implicit in firing thresholds for a given task or environment in other words these results suggest that firing thresholds are the neuronal substrates that encode State and decision priors as predicted mathematically big if true furthermore when the updating of parameters is slow across these two now linked domains parameters of the variational Bayesian autonomous State inference and the neural network loss function parameters when the updating of these parameters are slow in relation to the experimental observations the parameters can be estimated through Bayesian inference based on empirically observed neuronal responses see method section data analysis for details using this approach we estimated implicit prior e which is encoded by PSI from sequences of neural activity generated from the synthetic neural networks used in the simulations reported in figure 4. we confirmed that this estimator was a good approximation to the true e so that's also pretty interesting this is showing they don't just lay out this architecture and show that it's possible to fulfill this maze task with the best whatever it's not a classification accuracy imperative alone they're describing that from empirically observed neuronal responses which is to say the experimenter's observation the sequences of neural activity generated from the synthetic neural networks used in that figure numerically so statistically that estimator was a good approximation to the true e figure five a so here's figure five uh estimation of implicit priors enables the prediction of subsequent learning so that's pretty interesting and will be great to hear what each of the axes are and what all the variables mean with this setup in place they did some numerical validation and talked a little bit more about fitting data from this simulation model here's the discussion section so the first paragraph of the discussion biological organisms formulate plans to minimize future risks in this work we captured this characteristic in biologically plausible terms under minimal assumptions we derive simple differential equations that can be plausibly interpreted in terms of a neural network architecture that entails degrees of freedom with respect to certain free parameters EG firing threshold these free parameters play the role of Prior beliefs in variational Bayesian formulation thus the accuracies of inferences and decisions depend upon prior beliefs implicit in neural networks and here's some more stable diffusion and neural network aunt's brain neural network so some more summarization of what they did based on the view of the brain as an agent that performs Bayesian inference neuronal implementations of Bayesian belief updating have been proposed which enables neural networks to store and recall spiking sequences eight learn temporal Dynamics and causal hierarchy nine extract hidden causes 10 solve maze tasks 11 and make plans to control robots 12. so citations 8 through 12 listed here in these approaches the update rules are generally derived from Bayesian cost functions EG variational free energy however the precise relationship between these update rules and the neural activity and plasticity of canonical neural networks has yet to be fully established we identified a one-to-one correspondence between neural network architecture and a specific pomdp implicit in that Network equation 2 speaks to a unique pomdp model consistent with the neural network architecture defined in equation 6. where their correspondences are summarized in table 2. and the figures this means that our scheme can be used to identify the form of the pomdp given an observable circuit structure moreover the free parameters that parameterize equation 6 can be estimated using equation 24. this means that the generative model and ensuring variational free energy can in principle be reconstructed from empirical data this offers a formal characterization of implicit Bayesian models entailed by neural circuits thereby enabling a prediction of subsequent learning so what can be done with this what is this new new what is new here does this second selection fully establish the precise relationship between these update rules and the neural activity and plasticity of canonical neural networks here is a discussion section on hebian plasticity neurotransmitters and glia with a lot of citations listed and here is just one interesting follow-on discussion from the computational aspects neuro cognitive and computational aspects of heavy and plasticity is these modulations have been observed empirically with various neural modulators and neurotransmitters such as dopamine noradrenaline muscarine and Gaba as well as glial factors so here's a picture by Alexandra michaelva cultured astrostites release signaling and growth factors that regulate proper neuronal development so cool glial pick dopamine and reinforcement learning in particular a delayed modulation of synoptic plasticity is well known with dopamine neurons citations 35 through 37. those citations are listed here this speaks to a learning scheme that is conceptually distinct from standard reinforcement learning algorithms such as the temporal difference learning with actor critic models based on state action value functions pre please see the previous work citation 50. for a detailed comparison between active inference and reinforcement learning that is Sajid Bal par and friston active inference demystified and compared from 2021 and that's also active model stream number 2.1 we mathematically demonstrated that such plasticity enhances the association between the pre-post mapping and the future value of the modulatory factor where the latter is cast as a risk function this means that postsynaptic neurons self-organized to react in a manner that minimizes future risk so the neural network had three layers it's the second and the third layer not the initial sensory layer but the second and the third layer the cognitive and the active States which are the autonomous States of the particular States so that's um quite interesting the self-organization of postsynaptic neurons to react in a manner that minimizes future risk crucially this computation corresponds formally to variational Bayesian inference under a particular form of pomdp generative models suggesting that the delayed modulation of habibian plasticity is a realization of active inference and regionally specific projections of neuromodulators may allow each brain region to optimize activity to minimize risk and leverage a hierarchical generative model implicit in cortical and subcortical hierarchies this is reminiscent of theories of neuromodulation and meta learning developed previously citation 52 doya 2002. meta learning and neuromodulation cool our work may be potentially useful when casting these theories in terms of generative models and variational free energy minimization they then return the discussion to the complete class theorem in neural networks so the complete class theorem same citations from before ensures that any neural network whose activity and plasticity minimize the same cost function can be cast as performing Bayesian inference however identifying the implicit generative model that underwrites any canonical neural network is a more delicate problem because the theorem does not specify a form of the generative model for a given canonical neural network which is pretty interesting is that to say that the form of the generative model as modeled is different in what ways from the given canonical neural network the posterior beliefs are largely shaped by prior beliefs making it challenging to identify the generative model by simply observing systemic Dynamics to this end it is necessary to commit to a particular form of the generative model and elucidate how posterior beliefs are encoded or parameterized by the neural network States this work addresses these issues by establishing a reverse engineering approach to identify a generative model implicit in a canonical neural network thereby establishing one-to-one correspondences between their components remarkably a network of rate coding models with sigmoid activation function formally corresponds to a class of pomdp models which provide an analytically tractable example of the present equivalence please refer to the previous paper citation 22 for further discussion so some of the analytical details especially on the inferential side cognitive side Burr captured in the earlier paper this paper goes further into mapping the potentially necessary and sufficient aspects of particular entity which is to say the risk minimizing features of the autonomous states with respect to the entire particular States including sensory States connecting that back of the envelope verbally expressible formulation to some complete class of neural networks so what's outside of the complete class and why and then what groups within the class have special or different features it is remarkable that the proposed equivalence can be leveraged to identify a generative model that an arbitrary neural network implicitly employs this contrasts with naive neural network models that address only the Dynamics of neural activity and plasticity if the generative model differs from the true generative process that generates the sensory input inferences and decisions are biased I.E sub-optimal relative to Bayes optimal inferences and decisions based upon the right sort of beliefs prior beliefs in general the implicit priors may or may not be equal to the true priors thus a generic neural network is typically sub-optimal nevertheless these implicit priors can be optimized by updating free parameters EG threshold factors Phi PSI based on the gradient descent on cost function l by updating the free parameters the network will eventually in principle become Bayes optimal for any given task in essence when the cost function is minimized with respect to neural activity synaptic strengths and any other constants that characterize the cost function the cost function becomes equivalent to variational free energy with the optimal prior beliefs so the cost function for the neural network activity and synaptic strengths underlying the loss function R equivalent to the kind of gradient descent enabled variational free energy minimization under the Bayes optimality scenario from a risk perspective simultaneously the expected risk is minimized because variational free energy is minimized only when the when the Precision of the risk gamma is maximized see method section generative model for further details very interesting they then say the class of neural networks we consider can be viewed as a class of reservoir Networks citation 54 citation 55. here the proposed equivalence could render such Reservoir Networks explainable and may provide the optimal plasticity rules for these networks to minimize future risk by using the formal analogy to variational free energy minimization under the particular form of pomdp models a clear interpretation of reservoir networks remains an important open issue in computational neuroscience in machine learning so from Wikipedia Reservoir Computing is a framework for computation derived from recurrent neural network theory that Maps input signals into higher dimensional computational spaces through the Dynamics of a fixed non-linear system called a reservoir after the input signal is fed into the reservoir which is treated as a block box a simple readout mechanism is trained to read the state of the reservoir and map it to the desired output then there's two key benefits of this approach the first key benefit of this framework is that training is performed only at the readout stage as the reservoir Dynamics are fixed the second is that the computational power of naturally available systems both classical and quantum mechanical can be used to reduce the effective computational cost here's some stable diffusion Reservoir Computing active inference neural network so this would be interesting to discuss and I remember some octave Institute participants who are specifically interested empirical analyzes and hypotheses they write the equivalence between neural network Dynamics and gradient flows on variational free energy is empirically testable using electrophysiological recordings or functional Imaging of brain activity so then another summarization crucially the proposed equivalence guarantees that an arbitrary neural network that minimizes its cost function possibly implemented in biological organisms or neuromorphic Hardware can be cast as performing variational Bayesian inference so to State it a few more times in the final paragraph in summary a class of biologically plausible cost functions for canonical neural networks can be cast as variational free energy formal correspondences exist between priors posteriors and cost functions this means that canonical neural networks that optimize their cost functions implicitly perform active inference this approach enables identification of the implicit generative model and reconstruction of variational free energy that neural networks employ this means that in principle neural activity behavior and learning through plasticity can be predicted under Bayes optimality assumptions there's a Code availability statement the Matlab scripts are available at GitHub in the repo of the first author and it would be awesome or the author or anyone to bring this working Matlab script up and see if we could do some real time active inference then as mentioned earlier from the roadmap the methods are following the discussion I'll just show the equations but not go into any details because there's not time nor familiarity so those who have more of one or the other would be welcome to fill in some dots because this is a really awesome and important paper so I hope that it can be interpreted and critiqued and elaborated on and so on by those with familiarity in both sides of that free energy loss function equation one generative model section many details are provided equation 10 is shown it's a larger unpacking of the generative model section variational free energy many details are provided equation 11 12 13 14 and 15. section inference and learning details are provided equations 16 17 18. then section on neural networks so there's just some interesting writing here so I wanted to highlight that in this section we elaborate the one-to-one correspondences between components of the canonical neural networks and variational Bays via an analytically tractable model so that's the figure three that we've been returning to neurons respond quickly to a continuous stimulus stream with the time scale faster than typical changes in sensory input for instance a peak of spiking neurons in the visual cortex of V1 appears within 50 and 80 milliseconds after a visual stimulation citation 6263 which is substantially faster than the temporal autocorrelation time scale of natural image sequences about 500 milliseconds citation 6465 so that's pretty interesting what is the temporal autocorrelation time scale of natural sequences what time scale do neural firing and neuroplasticity Etc processes actually occur at and when my some type of function at a given time scale be understood to be functional or not thus in other words Downstream of the fact that neurons respond quickly at a time scale faster than typical changes in sensory input we consider the case where the neural activity converges to a fixed Point given a sensory stimulus we note that the present equivalence is derived from the differential equations equation six but not from its fixed point thus the equivalence holds true irrespective of the time constant of neurons to rephrase neural networks with a large time constant normally correspond to Bayesian belief updating with a large time constant which implies an ins insufficient coverage of the posterior beliefs pretty interesting related to learning rates and Bayesian updating rates and all of the nooks and crannies of Bayesian inference and the challenges associated with Dynamic uncertain rugged Fitness and free energy landscapes these optimization challenges which are addressed differently methodologically culturally Etc in the variational Bayesian and in the neural cases they have to deal with time and so all of those different nooks and crannies mentions like catastrophic learning catastrophic forgetting simply memory anticipation attention local Maxima choosing when to play all these higher order questions are connected here does that make it what kind of a problem space now or just what kind of space pretty interesting and equation 19 20 21 22 23. they have some more details on the simulation maybe we could see the simulation go and in the last section data analysis so this is kind of returning to that point about the time constants in Bayesian and neural network systems when the belief updating of implicit priors d and e is slow in relation to experimental observations d and e which are encoded by Phi and PSI can be viewed as being fixed over a short period of time as an analogy to homeostatic plasticity over longer time scales 66. homeostatic plasticity in the developing nervous system 2004. very interesting in light of our recent discussions on allostasis and other topics thus Phi and PSI can be statistically estimated by a conventional Bayesian inference or maximum likelihood estimation given a flat prior based on empirically observed neuronal responses in this case the estimators of Phi and PSI are obtained as follows nice equation number 24 mentioned earlier so that will be definitely one two look into more well I hope you found this a useful and interesting dot zero I'm looking forward to the discussion with the author and again any other Institute participants or those with knowledge or strong feelings to express about neural networks active inference applied active inference computational modeling of perception cognition and action neural networks in the wild AI ethics all these different areas can hopefully have a nice discussion in 51.1 and 0.2 that'll be the last paper streams for 2022 there will still be a few guest streams upcoming so those discussions will close the paper focused prepared live streams for 2022 and yeah if you want to be more involved with live streams whenever you're listening to this join or recommend someone to join or help in any number of other ways just listening and learning is awesome and we also really look forward to those who want to help make some of these connections that are latent and sometimes exposed in these papers and conversations and with a few motivated people who want to connect for example to the neural network communities and those who can facilitate discussions on these topics that would be awesome just using my final thoughts on this dot zero because it's always great to have others also join in the preparation for the dot zero so just wants to add that note on this rare solo stream so thanks again looking forward to talking or seeing you later bye