all right it's February 5th 2024 we're in the first discussion on chapter 6 for cohort 5 so Andrew thank you for facilitating everyone feel free to raise your hand and everything and Andrew go for it sure so chapter six we're beginning part two of the textbook um this is basically yeah it's describing a recipe for Designing active inference models we get as we know from part one uh specifically chapter 4 especially we've already been introduced to partially observable markof decision making processes as a discret Time version of um kind of one of the the sort of Exemplar active inference models that's used um in a variety of Behavioral experiments as well as the continuous models um in continuous time and so this is kind of just getting into more of like how do we actually begin like given in part one we've been introduced to a lot of the main principles and kind of the framework of active inference now we're being introduced to how to actually construct the models ourselves um so let's see yep um yeah the first part we have the introduction uh crucial defined like when designing an active inference model you want to specify your system of interest um for me personally it was easy coming into active inference have big ideas of what to apply active inference to um because of course it can be applied to a variety of living organis organisms or other systems but um really whenever you want to design your own project you do need to specify a system of Interest what is the problem um some other thoughts are like what are the expectations you have of what kind of Behavioral um like emergent behaviors you might see or expect to see versus what ends up happening whenever you put your model together um so really uh one one take on it is to really just start from basic principles like we have part one of the book we know much more about something like how active inference works now start to use that as a tool for yeah kind of shaping your your project or your experiment you want to put together um so you kind of simplify and grow outwards from [Music] there um section 6.2 there's a very nice brief like um designing an active inference model in four steps again and number one immediately it's which system are we are we modeling uh in the context of like statistical marov blankets like how do we Define the the generative model versus the generative process like what what is what is the agent you're trying to model and what what defines it and how do you distinguish it from the environment or the process that's occurring around it in which it is operating um what is the most appropriate form of the model are you looking at for example some you know experiment that invol uh involves I decades um like continuous movements Arc reflexes those kinds of things in which case you might be um going for more of a continuous time model or are you looking at like are you attempting to um model uh an animal or a human uh operating in its environment in which case it might be um it might be making discrete choices um in which case you're looking at more of a a discrete time model or a more than likely a PDP um if the agent's going to be choosing its actions and has a Time Horizon and you know you're including things like expected free energy um not just variational free energy then step three how to set up the generative model choosing what are the appropriate variables where the priors it's whenever you kind of get into the you know the the meat of the of the modeling process like what are all the specifications here we need to make in order to simulate your experiment that you're going for and number four again the same thing but now how do we set up the generative process because in the same way that you have to set up the model you also have to set up the the process in which it's it's operating kind of intera AC in with so 6.3 deeper discussion uh what defines a model what defines the process where do we draw the line um what are the the in internal States the model um what is it inferring about the process what are what are the hidden States it's attempting to infer from the environment around it um because as we know it has no direct it has no direct access right to the environment around it it can only infer um get some nice further discussion in that section thing other things to consider nested blankets um how the organism might use or your agent might use if you're modeling an agent in an environment in which it's moving around or acting like what kinds of objects are in the environment that it might use as potential affordances um moving on to section 6.4 what is the most appropriate form we get a little bit more discussion of things like time scales throughout 6.4 that's a bit more of a lengthy section with subsections in it you want to consider things like temporal depth um they go into more detail in 6.4.3 um in which case yeah so for temporal depth it's like for example you might have a PDP where at the lowest level you'll have for example say you have an agent in its environment at the lowest level it's taking in sensory observations very quick the quickest Pace the quickest time scale and as it's doing that th those sensory observations of course are generating predictions prediction errors as it interacts with the upper layers that might be happening at a at a slower time scale you could have you know nested levels in which case like maybe at a higher level the the agent has various parameters that are being tuned that're then you know descending those predictions are interacting with the ascending signals based on the incoming sensory observations so those are all things to consider and remembering from chapter five you can have yeah multiple time scales operating in the same model some things happen very quick some things happen much slower um and they kind of sink over time um yeah it's a lot of the remaining sections generally get into yeah much of what I've already discussed here we start getting into into the difference between inference and learning um learning tends to happen at at slower time scales um those would be beliefs about parameters as opposed to Hidden States so um what what what do you believe the predictability of a state is for example it gets into things like Precision modulation um yeah wraps up with talking about more detail on defining the generative process and then final section on just a very brief uh mention of how later in the textbook it will get into modelbased Data analysis so they save going into too much detail about okay now you've set up the simulation per chapter six maybe you got some more additional details on how to do that in chapter seven or eight depending on your use case and finally chapter nine data analysis where you actually like how do we interpret these results if you're using um mat lab and SPM like what what do the and you use a standard routine which is freely available from the the software package that priston at all released like what do these graphs mean that we're seeing once we run the simulation um how do we do individual versus group level analysis um so yeah um I feel like that was hopefully a holistic enough starting point for uh for the discussion here um oh thank you Susan um yeah first first time doing this so happy to be here um yeah does anyone have any questions that they're thinking about anything that's maybe come up um like or any particular topics or something they wanted to point to in the textbook a certain page I have a question uh can you hear me yes okay um I wonder if you could talk a little bit about in the process of selecting a model how do you go about deciding what your mark of blanket is going to be so from the modeling perspective can you just elaborate on the mark of blanket Choice uh I'm I'm very curious about that yeah um so maybe a good quick question um like do you have an example of maybe like just any you'd like to look at a particular phenomena or or something that you want to understand better that you might try and make an experiment to try and study um is there anything we could start from there maybe um I guess I'm I'm too stuck in a conceptual space right now and I can't really do that uh but um yeah no sorry let me just say that from a very abstract perspective from my question is what is a node what is an edge in your in the models and where does a mark of blanket come in into the picture and how do you decide on the states that uh on the states that you choose if I understand this correctly about Mark blanket that Define the markco blanket and if I if I'm incorrect in my language the way I'm describing these things let just let me know sure no I I think the all those terms are very relevant no edges nodes we're kind of getting into the Lang of of graphical models um that's many of the models that you know this textbook gets into especially like you know all these nice um figures of the PDP for example those are all you know technically graphical models um so nodes you know I don't know if um I don't know if Daniel it' be possible maybe to pull up one of the years in the in the textbook yeah just mention it and go for it and then maybe yeah which one yeah um they don't have any in this chapter but I know that in the next chapter it gets into pdps so there might be a good just uh find it and then put in the chat and then Ali go for a first pass to magdalen's question yeah go for uh yes so thanks for asking the question because uh I remember asking the exact same question from Maxwell ramstead uh about two years ago uh how can we identify Mark of blankets in modeling processes and uh I remember his his answer was um something to the effect that it's a very non-trivial process and it depends very much on uh the situ ituation of interest and uh on the specificity of um the uh the kind of modeling or the kind of questions you try to answer uh in each modeling scenario uh but uh there was this paper by Ryan Smith Smith at all I think it was from 2023 or um 22 I guess uh towards the end of 2022 uh in which uh they used very creative approach uh to constructing uh a kind of markup blanket uh in order to investigate uh the uh basically uh to model uh the the the function of the heart based on um active inference uh let me pull up the exact title of the paper but I think it's a very instructive example as to about how can we identify uh markup blankets even creatively uh in every modeling scenario because I think it's nothing algorithmic or formulaic about it it requires uh a bit of out of box out of the box thinking and creativity in order to uh to identify suitable uh boundaries in the uh in the state space uh uh of uh the mark of blanket you're trying to um you're trying to construct uh for each modeling scenario so uh I'll put the uh Link in the chat great thank you thank you I I'll try to give another um way in here so figure 4.2 shows some motifs in this basian graph representational format so to your question about the nodes and the edges the nodes like the circles those are variables they could be fixed or they could be variable and and dynamic or not and it could be different types could be a integer it could be a float and so on this is just very schematic and the arrows are like causal relationships that are here directed so then this kind of maps to X like hidden temperature in the room observable on the thermometer here it's like there's two factors that influence the thermometer readings here one latent cause and two observables and here's like something that influences something that influences and so to select to to generate structural hypotheses and to select the different models and evaluate their differences like which ones are just like explaining the most variance but adding more variables always explains more variants so then there's these other constraints that are applied to the model like you want to explain the most variance parimon L like basian information Criterion or you might have a fixed number of variables to work with or all these other situational constraints but because this is a mapping exercise and Markov blankets are just a feature of the map like X being a blanketing state between v and y not carrying any philosophical implication Beyond just its insulating role on the graph which is the map not the territory so there's a lot of techniques to identify and it was very wise if Andrew to start with kind of starting with a specific system of interest um also the general inquiry is really interesting but in practice starting with the specific phenomena or system is like the starting point on iterating on something more specific which helps bring it a little bit more into the Practical like which variables you're realistically going to take into account and which ones are like beyond the current scope of that modeling approach thank you so much and um if you could elaborate on what you just said about the um the in that on that um figure that you were just showing if I don't know if you can put yeah okay so v and y you said are blanketing X um can you give me an example from models that you've worked on or other people where you know tell me what their X look like and what the V how the B and the Y blanketed that X I'll give one short answer then Andrew will look forward to your response so this Motif is very commonly used to constrain the structure of time so this is if x is the present moment this is like saying the past only influences the future through the present this is like the Marian property for time series because in principle if you had 100 time steps in a model you could have like time Step 11 influence time step 21 and try to learn a statistical parameter there but then you'd end up with so many parameters so instead under the maravian simplifying assumption that basically the present kind of like filters through like a bottleneck information bottleneck that simplifies it to only having to learn one parameter which is like the B Matrix thank you than helps a lot yeah and actually Daniel I think this figure 4.2 is is maybe even a better um start for versus what I recommended um just because in addition to trying to describe the the specificities related to Markov blankets maybe just giving um um kind of an ex like a concrete example of the the graph in the upper left corner which the the textbook describes there um it's so we have right so we have um the one impacting with a with an edge pointing towards the node that is the X and then uh the two is like so basically you can see that there's like a causal relationship here going down like one impacts X impacts two impacts Y and in very simplistic terms um so we already know from earlier in the textbook like a core part of a generative model is to have priors which is the one it's our P of X distribution over hidden States your beliefs about X then one impacts what kind of what do you think is going on right now what is the hidden state right now that's the X um that you're inferring or your agent is inferring your model is inferring um and then that has a relationship with two which is your your likelihood Matrix right it's the probability of the incoming sensory observations conditioned upon or given the hidden state that you're Fring so basically with nodes and edges as Daniel heavily covered it's really just trying to figure out like okay what would be the causal relationships between the different things going on in your experiment um and what are those things in the first place what what are the particular hidden States um perhaps you have an example of like um a mouse navigating am maze um the M the Mouse um might be pick taking in new sensory observations for multiple modalities it might be it can see where it's navigating it might like feel certain things it's might might smell certain things how but those are all things that you'd want to consider when constructing a model right so those are all different variables that end up being their own nodes and what you end up building out into what could become a rather complex graphical model um similarly what are the states like maybe the mouse is trying to figure out where it is maybe it's trying to figure out oh what is the source of that smell is it a reward is a well I'm pointing towards this example in particular because we'll see it in in h chapter seven I believe um and also just to just uh I hope you can worry less knowing that chapter 7 and chapter eight we'll get into much more concrete examples of different models as well um and it'll maybe become a little bit easier to kind of tie the knot between all the conceptual considerations and like an actual experiment you'd want to set up but that's I'm just trying to give a little bit more on maybe how you would construct a model and knowing that like yeah we do have to understand graphical models prior to that um it's just a big web of associations right and they all lead to a series of computations and again it's active inference and so the key part of this entire process being um a series of computations in order to minimize free energy thank very helpful appreciate that I have a question about the construction of models um I think my confusion may be that I'm new to this process and it's early on but this is the chapter that um I want to most understand um because I came to active inference with this desire to create a model um for a a longstanding um social science intervention uh my question is um in some when I'm when I first come to a problem you don't always know the variables of interest and so that's part of why you're doing the experiment is that not true in this case yeah it I mean it to actually any anyone I've had a discussion with who's worked on putting together whether it be active inference models or any other model that might relate to another framework and reinforcement learning or doing other kinds of experiments yeah sometimes it can just just be a very iterative process um more often than not you most people yeah they don't know what all the variables are you might have a strong hunch about what they are or you can of course relate them to like domain knowledge and and secondary literature um but more often than not you may want to construct a model that uses what you know or think is highly likely that this is how this works um have a look at the result result look at what's going on if you're able to to run the simulation see what the output is see if it makes any kind of kind of sense um uh I have a social sciences background and so things like causal inference where we're like okay well what are the variables here uh what are the confounding variables here what are we leaving out what are the things that cannot be observed right so so if you start seeing like what you might and it you know what defines an odd observation is very context specific but if you do start seeing odd results it might point to the idea that yeah you might very well be leaving leaving something out and then you may want to also double check the the complexity of your model like say there's something at the lower level um that you've defined everything makes sense it's at this time scale Etc maybe there's a variable that's left been left out at another level um maybe there's something else that's impacting all of this that's been left out that that isn't even occurring at the lower level that you've been focused on it's been at a higher level this whole time um a lot of my explanation there might be might be a little vague but again yeah it's just very context um context sensitive I almost want to say so no thank you that's I'll add a few more notes on this um so in the symbolic Active Space and and an Institute participant JF his Lego robots using a a logical program rather than statistical distributions but the idea is basically the same it's like rather than a causal um graph which is like we're talking about the textbook it's a causal Theory and here he talks a lot about that incremental proposal so you ask are they actual variables or the hypothesized latent they are actually hypothesized so they're in that Ed in their hypothesizing which is abductive inference is so generation of hypothesis and then evaluation of hypothesis so that's been analyzed as kind of like itself an active inference process because which hypotheses to propose and then given the hypotheses which actions to take for their to uniquely resolve and learn those are all questions that can be approached in actim and then just one one last technical note is this relatively recent pre-print with friston at all this talks about a statistical problem called structure learning so here it's in the context of the digit um mnist data set this is a very familiar problem and data set to um look across different handwriting Styles and identify the digits and this work which we could probably discuss more in a future time goes into a lot of detail with the structure learning which is like when you have um you have 11 handwriting Styles should you propose an 11th cluster and then you evaluate whether the 11 cluster model or the 10 cluster model is better explaining the data it's like doing better on that parto optimal front and then like 11 is accepted and then like there's a proposal to basically to increase the number or decrease the number of latent factors and then there's a Criterion for like accepting a rejecting those kinds of model updates and so that's a capacity that's existed for statistical models outside of actim to kind of like adaptively dial up or dial down the dimensionality but it's not a totally solved problem and it's not totally implemented in ACM but in principle um like a system wouldn't need to know the dimensionality of its environment because it might just have a and it doesn't ever need to like it could just like too cold just right too warm and then that doesn't mean that that that it ever needs to like learn the richness of the continuous distribution of the temperature in the room yeah that might be good enough for the air conditioner just to have three states or something right right right right great thank you so much I guess I did want to add um there's a nice paper um for anyone who's more interested in like so social science research or something along those lines has been a very nice um series of papers put out by a researcher um Ryan excuse me Ryan Smith um he's actually we have several live streams of him uh giving a tutorial on active inference with the Institute um and specifically how to construct models in in mat lab for anyone who's who's familiar with that or interested um and I bring that up because he has a this paper um on simulating uh what's called exposure therapy so this is research that's that is intended to um Aid interventions um for psychotherapists like can we simulate for example um a client um who um who is suffering from you know some kind of uh avoidance or anxious um disorder that's stimulated by something say they have a very strong phobia of something um computationally it could be anything it could be a spider it could be you know seeing the car accident a variety of things and I so bringing it up like they had to construct a model of like how do you simulate exposure therapy so we already know we have a client um that we're trying to simulate we want to simulate them going through exposure therapy being exposed to the thing that produces the fear in them um to see like you know this is a safe environment that we're simulating in order to like test things out as opposed to Jumping immediately to Empirical research that you know we there too many ethical considerations to just playing around with showing people things that that trigger them um so when constructing this model they like you have to model here's the agent you have to figure out what defines the agent um in their case the agent uh experiences affect or something like emotion um they compose that as a distribution like what are the emotions they keep it very simple they go with something in Psychology uh referred to as veilance so you have a nice like positive negative scale um there's been a lot of nice work on emotion in general from an active inference perspective that yeah um veilance seems to hold up pretty well in certain context so they go with that um and then you have um you know how does the the agent deem the stimulus that they're being shown in this case let's say the the agent has a fear of the spider um so they might interpret it as dangerous as opposed to safe so now again we have another kind of sliding scale um these are all what could be viewed is like continuous distributions right like they can be viewed as a number that moves into the positive the negative um then you can take those kinds of things view them as variables then put them in the model um in this case we would hope that the agent being exposed to like say a spider that ultimately is safe um again bear with me that it might come off as a silly example but um say it's a fake spider this is exposure therapy you know they're not going to show them real spider um but to get the agent to slowly become more comfortable with being around the spider like we want those parameters those beliefs about how dangerous the spider is to change over time so that also means you have to we're defining the generative process the spider's there it's a safe spider the agent is interacting with it over time as we run more trials we can see how do the AG beliefs begin to change do they change rapidly does the situation become worse are they being exposed to The Spider and it's just freaking them out more they become they're concerned that it's even more dangerous um and I'll quickly I realize I haven't shared the link for that paper so I've just shared that um anyway so without going into too much more detail because it takes some time um but you know if this paper interests you go for it um the whole idea here yeah is to to just you know thinking through what what is a variable what is considered as a variable and a lot of it centers around defining your agent defining the environment or process around them and then trying to find the linkage between you know all the conceptual ideas like I said earlier like affect is that there's plenty of domain knowledge on that in psychology right like you how do you make a one: one ratio between a little node or variable and a graph with you know research that's been done by your you know the field you're working from or interest in like in Psychology how do we make those connections so that we can build out a model from there um yeah and so yeah Daniel's pulled it up there you know there are different ways that people attempt to show their models um this one the notation is certainly different from the textbook but I think it's more explanatory right like we have an agent is being exposed to a safe stimulus or a dangerous stimulus like a like a spider we have their beliefs about its safety or how danger it is um they also have an arousal level like you know you can include things like you know with psychological research and things like that we care a lot about physiological signals is is the agents like heart rate increasing which by the way you'd want to consider that probably to be a continuous variable right um because it's this is happening very quickly over time um whereas belief context safe versus dangerous that could be viewed as discreet we have two options there um so those those are also big concerns like you figure out your variables are they discreet are they continuous do they happen at quick time scales Moment by moment like the agent very quickly is feing feeling their their heart rate change um and yet over time as we run more trials with more exposure therapy sessions um at a slower time scale their beliefs start to change right to ideally a situation where we can find maybe use this model to find some insight into how to improve intervention for for uh people suffering from phobias or anxiety that's generated by a particular stimulus um so yeah that's I hope that that provides some more insight into yeah how to take a lot of this abstract or conceptual material and then relate it more directly to concrete you situations and problems of Interest Daniel thanks this is a great paper to show and I think the figure here shows like this is like the semantic level like not worrying about how big the variable is and so it's kind of like a little template that could be adopted just thinking about this situation of the exposure and then what is the thing that one is modeling and then what other phenomena they do they need to further include like planning is not here and then the bottom is actually the shape of the variables thems the a the b c and d this agent just like the pdps in the generative model and described in model stream one and these are the actual shapes of the variables and even their types ranging from this continuous belief to 2 by tws affordance matrices with context preferences what a flat preference looks like versus a sharp preference it's all kind of syntactically displayed in this um flat L does anyone else have any other thoughts or things that you know they're kind of pondering right now uh regarding this chapter do we have any other questions that have already been maybe asked in theota what do you think are good small experiments to do between the first and the second discussion on chapter 6 given what anyone has experienced or tried we could also look at a notebook like look at an executable code right now like a PDP example or we could talk about what um else could help supplement chapter six I I think let's look at the PM DP example if it's okay okay I'll put the link in the chat but here's pmdp documentation so this is the python package by Connor Hines Alex shance daph Deus Etc um there are several tutorials and Demos in this open- Source package [Music] um the simpler one are tutorial one and two then the t- maze is most like the textbook and the epistemic chaining demonstrates it's kind of like a tze but with like a little bit more of an epistemic or slightly different epistemic components and each of these tutorials very nicely provided by the authors there's like a collab notebook so just going to this and you can you can make a copy right from there um I'll kind of give it back to Andrew to continue and then maybe next week we could prepare to execute something just so that we're not like needing to execute on the fly but suffice to say like these notebooks do work and you see a similar specification AB c d That's what defines the PDP those variables they're representable in terms of this grayscale heat map visualization sometimes um black or white is one or zero like you just have to look at the the the um graphical settings but they describe um how the variables are shaped and and so it can help to just see like okay here's block by block here's all the variables that need to be defined here's what the different slices in the variables are um yes copying and pasting images or screenshots or code blocks into language models is super helpful as they're very Adept at this kind of classical basic code exp uh explanation and these notebooks just go through Define a b c let's see if we can collapse and just look at the sections D so a mapping between hidden States and observations ambiguity Matrix B transition Matrix for the hidden States that's how the hidden states are inferred to change through time in this action dependent way and then policy selections like selecting which slice from B is going to be used in the time Evolution C preference over observations D the prior on the hidden state which kind of kicks off the chain but after d is used once then it's just B and the hid State s unfolding through time so then to specify the agent it's just taking in these exact four variables so adapting active inference in the pmdp setting to like um whatever it is that you're trying to model it does come down to making the right shape a b C and D it's specified like this here is a class object for the game itself so here's like where the rules of the game like the slot machine or whatever it turns out those um like or if it's prisoners dilemma those are parameterized in something like this so it's like we Define the whole agent generative model then the the context the environment that it kind of plays in and then here's the active inference Loop and here's the pseudo code basically for that UDA Loop like observe Orient decide act it's basically like that kind of pseudo code invoking the specific game and the agent and the interface so this is not like what high throughput production actm generative models look like but each of these tutorials are super informative because they do work and they are um um forkable and they do like capture all that's needed and so that can help demystify it a lot it's not like an infinite parameter fishing investigation it's like build ABCD underscore one and then try underscore two like a variant and just try recombining them and it's about building like a portfolio of different abs and C's and D and agents and visualizations and Diagnostics and summary statistics for the simulation and these notebooks go a long long way and until you're using like large data sets or anything like that poab will have enough computational resources Susan thank you wonderful um so guess this um you know in terms of defining an agent um and this kind of is in somewhat inspired by Cheryl's question um in terms of goals roles and context and you what I find rather elusive and intriguing um is you know is the um overall objective of gen you whether that be generative modeling or the generative process is is are we are we seeking certainty or are we seeking insight and and and so in terms of you how I perceive and and quite frankly I'm going to you know do a plug for my Thursday at 11:00 a.m. um uh foraging Insight because what I'm trying to do is is really focus on how how people self-model versus how we're trying to um predict how people are going to react which is different than you know trying to program something so although you know definitely we want to be able to use technology to augment agency this comes down to how do we help people um discover their own agency and affordances within certain parameters um you know how do we how do we translate that into understanding the textbook does that make sense to anyone I really like that distinction Insight versus certainty I've never heard I've never heard that made that way before but that's so clear thank you so much um so I can see a real problem when you enter enter you know an an experiment thinking that you're looking for certainty and you're actually looking for insight I mean I can I can see how one could confuse those things when they're not distinct yeah like the whole risk management industry but to kind of go to equation 2.6 and then pros this really does map to when we're selecting which experiment to design policy to undertake the certainty is is finding observations that align with our expectations preferences sampling the homeostatic body temperature like pursuing certainty about our homeostasis for temperature and then literally the Insight or Information Gain and so and then this Ties on this is a big topic so we won't go into right now but different um scientific epistemologies like does science prove does it disprove oh well they confirmed this in an experiment so they found what they were looking for or they were shocked by this so then what did they expect and then our experiments for falsifying or confirming or neither and how we hold on to beliefs that may not be um you prudent but you know why we why that's a surprise versus um you being able to belief update so you know this really calls into question yeah what is learning I mean you that might be a good good start is is what is learning because is learning consuming information or is it digesting it and taking action on it and learning from the action I me I'll I'll borrow from something Daniel said earlier as is and you might have to reiterate it Daniel but uh um you moving the Pebbles moving the Pebbles that's what matters and until we actually act on the world we're not moving the pedals we're just new we're just uh regurgitating and and uh F into uh uh uh reminition wow wow I actually just shared um I personally coming from like a comput computational Psychiatry um sort of background SL that's my current field of interest and uh I just shared this actually since you mentioned the word rumination there's another paper Elsewhere on um attempting to simulate uh simulate rumination as a kind of cognitive process that can arise based on certain circumstances I I shared this one in particular because it it's it's one of the papers that I've seen so far that best tries to describe um in a more kind of human relatable view uh like what it is to self-model in one's environment because as we know like one of the bases of active inference is free energy principle um an agent needs to have an understanding of what separates itself from its environment in order to maintain itself otherwise it kind of you know however we want to phrase it from a physics point of view it's you know the environment is entropy it's it's you dissipate if you just you know give to everything that's around you you have to breathe in oxygen you have to do a variety of things that maintain what is you versus what is outside of you and so yeah it's it's really crucial um I like this paper because it it describes like a little bit more in depth like for a human being what what might be required or involved in self-modeling how important it is to have a model of oneself um the role of things like sensory attenuation which is another big aspect of active inference like in order to move your arm you need to like be able to briefly put simply you need to forget that your arm is one spot you need to believe that you can move it to the place you want to move it to so what you're doing is you're attenuating or kind of ignoring where it is right now you're in motion you're trying to be in motion right so if you overly believe like you keep that that belief fixed that your arm is in one spot it's going to stay there you have to move it um that becomes really important when self-modeling too in order to operate in the bigger world around you um so so just all these f Minor Details and aspects of self modeling I think it's a fascinating topic though for sure so is is that the paper that um uh Andrea shared is that the [Music] overthinking is that covered in that okay yeah yeah that's thanks for sharing yeah sure it doesn't get into the IT specific topic of interest is depersonalization disorder but I think the first half of it is really Broad and I just you know I think it's a nice introduction to just thinking about self-modeling in general regardless if you're interested in Psychiatry or not cool yeah thank you pros and then Andrew you can kind of end it however you want uh yeah Daniel I have a basic question like I was wondering the pmdp which you showed uh can it also handle hierarchical models yeah it can okay I don't know if there's a tutorial on it but we can ask the authors but we can look through literature and so on but yes of it can okay I was okay thank you thank you I also mention that um the um Daniel just put in the coda there I shared the Ryan Smith tutorials um and while those use Matt lab um a lot of the pmdp stuff is the coding it's based upon um a lot of what goes on uh like basically active inference modeling It generally started with mat lab and SPM which is what Ry Ryan Smith and everyone else covers and then Connor Hines a variety of other researchers put together pmdp much of it being based on um the prior work in that lab and so at least for a verbal explanation of hierarchical modeling uh I believe it's either the second or the third video of the series with Ryan's Smith um if you so I guess that would be like model stream 00 1.3 versus the one that's on the coda there 00 1.1 um just if you want like a more verbal explanation of kind of how that that can work in a more direct coding setting um as a programmer yeah just wanted to mention that and um yeah um I don't know I think we're just about out of time here but um just brief recap this was chapter six or recipe for putting together models uh potentially it it provokes more questions than it answers um but it's it I think it gives a frame it basically brings up all the questions that you need to be concerned with whenever you're putting together a model right what is the agent what defines the process what are the variables are they discret are they continuous how do they work together how do we relate them to domain knowledge um and and actually translate between you know the the language of basing statistics and mechanics with uh you if you're a social scientist or or um an engineer um and so yeah kicks off chap uh part two of the book overall the next chapter we'll get into continuous models and I think that's it might be the case that for a good deal of people here who are interested in modeling it might be the case that you'll be looking at a PDP um like that's what's used most frequently with trying to model like human beings in their environments um animals as well but they're used um they they involve including things like planning a Time Horizon uh they don't have to but um they can and um yeah that's I hopefully it'll give you much more concrete examples of thinking through like how do we translate between a model and what we're actually trying to do here uh hopefully chapter 7even basically will clear up some questions you might have had from from chapter six so thank you awesome work Andrew thank you everybody see you next time thanks everyone bye bye