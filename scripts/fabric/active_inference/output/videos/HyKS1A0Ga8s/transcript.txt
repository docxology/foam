all right hello everyone it's February 1st 2023 and we're in cohort three of the paradol textbook group meeting number two we're having our first discussion on chapter one so would anybody like to just give any opening thoughts or comments anything that they expected preferred enjoyed remembered about chapter one like what was something they were expecting and got or didn't or something that stuck with them about the experience of chapter one you can raise your hand or just go for it how about oh yes please go for it someone or Chance favors the prepared mind my sense was that it gave a kind of overview but um uh it I I spent my time looking at chapter two because it kind of gives us broad overview but you feel the meat is in the the rest of the book so I was bogged down and uh maths of chapter two awesome yes thank you and I'll copy your comment in Jonathan yes rereading taking another look and just letting it play out the first read and then coming back again and again and seeing more each time um and a lot of the formalisms are not in chapter one so there is meat slash nutrition elsewhere but also there's interesting insights within the chapter and I'm sure it sparked people to think about um different things so anyone else feel free to go for it like just any sections of chapter one or any framings that you remembered or you highlighted or that stuck out to you soon Luigi oh thank you foreign motivates or excites people about learning active um they situate the question that active seeks to address as how do living organisms persist while engaging in adaptive exchanges with their environment pretty interesting [Music] um is that the question that people thought active inference was going to seek to address do they think active May address another question as well okay as always just like feel free to raise your hand or write something in the chat or we'll just keep exploring along so I've not come across the neat scruffy's dichotomy so that was a nice perspective let's look at that does anybody want to um summarize the needs and scruffies or give like what did they think need scruffy's means or what was it doing at this part of the book and I I think uh my my take on it um as a so I'm a physicist originally I'm so looking at it from sort of building from the ground up um you know creating unified theories of things where everything is explainable within some framework versus those who try to look at the details and build from the details up to to understand the phenomena that was kind of my my perspective on this all right Ollie and then anyone else yeah well actually I recommend this um essay each time because I really like it um for um in the book Andy Clark and his critics uh there's a beautiful essay by Carl Preston mainly beyond the desert landscape in which he explains in a very beautiful prose the difference between uh low road and the high road and it goes into much further details about the significance of these two approaches and the pros and cons of conservich and also the importance of looking at the same the same phenomena uh call it intelligence sentience or agency or whatever from these two perspectives and what can we glean from looking at it from uh those to perspectives so I highly recommend uh reading this essay which you can find a PDF for the for that essay on resources page as well thanks thank you foreign neat unified imperatives scale-free systems low road gets scruffy there's a lot of last miles in the low road because every generative model is different and they're complementary roads to meet in the middle with octave Kate or anyone else um this is still pertaining to the scruffies and needs I was just it just occurred to me as I was both reading the um introduction and now listening to this how many of us here would be self-described needs and self-described scruffies I'm personally a definitely a need I'm very much gravitating towards an underlying common explanation for everything so which draws me to the active inference as such so I'm just wondering in the group of us where would we fall in that curious awesome very fun question yeah does anybody want to um dox themselves in terms of being a knee or a scruffy or some secret third thing and just share like why that resonates with them and how they might see learning active bolstering how they are or providing some other support blue and then anyone else so definitely a scruffy um and uh you know like I mean I strive towards neat right because I realize that like order is is um sometimes preferable I'm drawn to active inference because I really feel like it's a kind of a creative lens with which to view like everything so it's just another like set of rose-colored glasses that I put on um and like I also paint and do other things and so sometimes like I'll be staring at a person like I wonder how I would represent their nose in charcoal likes it so it just it's like one of those things it's just a pair of glasses that I um put on but I do want to also draw the connection between um what we were talking about yesterday on the book stream so I don't know who's watching that but um we had like you know they're talking about leadership styles and there's like the antagonistic neural network perspective where there are two um like opposing not opposing maybe unifying neural networks one is called the task positive Network and the other is the default mode Network um with the task positive Network being very like oriented at getting things done um it struck me as like a more orderly thing like maybe in in line with like the needs and the direct or default mode Network being more like people-centered and creativity um focused and like it's also like the difference between like right and left brain I mean we hear all these things all the time right um there's like The Logical versus emotional and so so perhaps like it's maybe not neat or scruffy but maybe it's both right I don't know thanks Ali and then anyone else um I also think that this distinction between needs and scruffies uh somehow relates to uh reductionism versus emergentism uh which is pretty hot to date uh nowadays in the philosophy of science so uh well of course we know that science for the most part was uh basically a reductive Endeavor and most scientists um by large are reductivists but nowadays especially from the mid 90s and the Advent of the complexity theories and dynamical systems and so on uh another Viewpoint called emergentism is actually emerging no pun intended and uh but there was always a debate between which one can provide uh the most insightful discussions uh in in each particular situations that nowadays some philosophers uh kind of take the middle ground between those two uh such as the contextual emergentism uh which has been described in this recent book emergence in context and I think active inference kind of maps in my view perfectly to this point of view of contextual emergentism and it's the best of Two Worlds in some sense it's purely reductive Viewpoint and in another sense uh it's it can be described as an emergent as Viewpoint at least the branch of emergentism called weak emergentism great a lot of threads there and fun comments in the chat so Maria I failed to see how one can work with details without some theory behind is it possible with active just anyone give a thought um but I totally agree implicitly always and explicitly often we do need some sort of combination and also it kind of maps just like even a little bit more Loosely like industrial versus farmers market or Boutique and I think in the book um they uh basically say like right before the needs and scruffies okay here's the two perspectives one perspective is that just the incredible diversity of Bio biological systems and neural processes each require a dedicated explanation so we're going to have a journal or a theory or an acronym or an undergraduate major for just serotonergic synapses that's one option every single phenomena is going to have its own farmer's market bespoke scruffy Theory that would lead to the proliferation of fields with little hope for unification the neat perspective is recognizing diverse manifestations but asking whether those phenomena of broadly perception cognition and action from a lens of persistence and adaptation in life whether there might be some coherent explanations that again recognize the diversity of manifestations and then help us understand it Michael and then Jonathan foreign I can't see Michael or Jonathan um go ahead Jonathan I'll follow um just to say that perhaps this sort of dichotomy between um a high road and a low road is kind of a matter of perspective in the sense that active inference itself um you know it's it's it's a description of certain types of systems but there are other types of systems out there and so if one wants to look at a higher level view then in some sense you know active inference and the free energy principle are themselves the low road of some higher level principle um higher level physics principle whatever it is you want very interesting roads all the way up slash down uh Michael yes in this conversation I may be saying that I thought whatever was neat and maybe I'm a scruffy uh the uh I want to jump back for just a second to what is the key question instead of um I I was troubled by that particular phrasing and I I was like what what would I have possibly said and I'll put in the chat but for me the question is how does life interrogate life um uh it it there's this stance between poetry and plumbing and that um there's a lot of this conversation that is a plumbing conversation and a part of the way Consciousness uh makes sense and speaks is poetry and um and that that's one of the things that um that is is the dance here of not not an either or which is a plumbing way of describing something but um uh opposites and paradoxes uh that are both um simultaneously considered and that um that Consciousness supports um an active inference supports a way of both um problem solving and contemplating mystery both concurrently and that this is part of the kind of uh there's something about not just the problem solving but the the the the the being related in a way that is not um agentic if you will that I think is is missing and and and some of this thank you and that that really ties in well with what blue brought up like the task positive network is like the getting things done and the default mode is like the Mind wandering and the receptivity and there's just an oscillation between those two modes in neural systems Nathan welcome and yes please anything you want to add um yeah so I mean you're talking about plumbing and poetry and you just we're talking about tpn DM where we're switching between these two modes of thinking um and before that we're talking about like higher and lower levels of you know thinking about this whole problem so are we making the claim that like active inference is like are are we making the claim that this is like the appropriate layer of abstraction to look at this problem because when we usually look at big problems like this we have to pick a layer of abstraction where we're not losing like a lot of detail and resolution but um by going higher up in abstraction but obviously we don't want to get bogged down by the complexity of adding more detail and resolution very interesting question I guess just one very logistical way to address it is we're reading chapter one that's giving us an overview of the book then we're going to have like a month to talk about the low road to active inference and the high road to active inference and that's gonna bring us to active inference itself so at least rhetorically or pedagogically in terms of how to lay out an argument and or layout an educational approach it seems like the authors do believe that thinking about neats and scruffies and the resolution or the the unification of them not through homogenization but by recognizing those two perspectives that that is an important construct in at the very least understanding and or learning active and then maybe that will bring us to the question of whether it's also the appropriate level of abstraction in application Ali and then anyone else uh actually I don't think we can associate a single level of abstraction to active inference framework because uh as far as I understand it active imprints can equally be applied to multiple levels of abstractions and it's somehow uh non- it's the scale free framework or in other words where multiple scale Frameworks so even if we if we talk about temporal scales or even spatial scales we can apply it onto various various scales and various levels of abstractions so uh yeah it's not it's a much more broader framework than we can associate with some other theories which specifically are a little limited to a particular level of abstraction so that might we can see some of the examples for these different levels of abstractions especially in the second part of the book awesome thanks so um let us turn to some of the questions that people prepared so does anyone see a question that they wrote that they would like to ask and we can explore or we'll go with the ones that people have upvoted but if anybody has like one that they wrote or just want to highlight let's go to it and also it's awesome like I saw a lot of people adding comments on the questions um all right let's just go to the most uploaded one then bring the question down into here so it's just a little more visible okay on page six it refers to active inference as a normative framework there are some evaluative standard against which behavior can be scored which is free energy specifically the minimization of variational version thereof so just to plant the seed but we're gonna come back to it later the two kinds of free energy that we're going to be talking a lot about are variational and expected but we're going to come back to that but for now let's just think about free energy as a unified imperative for perception cognition and action variational is in the present and expected has to do with futures then it refers to planning to achieve distal goals in humans does this definition of normative mean that octave is agnostic about precisely what humans goal that might be one human may wish to save the world another may wish to rule the world both are essentially minimizing free energy I might be mixing up a few Concepts here but the gift is that active models don't predict a socially normative course of action would that be correct to say all right what would anybody like to add on normativity of active what does it mean to say that active is a normative framework does that refer to social norms or what kind of normativity is being described Ali go for it I guess at the most fundamental level uh the normativity admits the agent uh to be persist through time uh so uh one meaning of normativity can be uh seen from the most fundamental requirement of a system or quote-unquote thing to actually exist or persist through time but of course we can apply this concept onto some higher levels of conceptions such as social normativity and so on but yeah again it applies to multiple levels of abstraction thank you Jonathan yeah that that sort of requirement for wanting to persist Through Time feels like an an evolutionary imperative and there are other imperatives into in terms of our sort of homeostatic set points and comfort and and hunger and things like that which then lead to um the thing which has been evolutionarily um uh sort of chosen through time so it feels like the two kind of have a um there's a balance between the two in in terms of hierarchies of scales of time I guess thank you thank you Scott for bringing in that quote so I I often compare active with linear regression because they're both modeling Frameworks that are quantitative and so sometimes it helps to be like okay is this statement true of linear regression and there's things that are true for both octave and linear regression those like are just true of modeling or quantitative models and then there's things that are different between active and linear regression those are like the features that differentiate octave and linear regression so we might say that a linear regression is normatively using this kind of imperative function like to fit the least squares or the L2 Norm and it's just saying this framework is going to use this imperative to draw a straight line through points and kind of by analogy act INF is going to use an imperative turns out it's a free energy functional that we're going to go into in the coming chapters it uses that unified imperative not to draw a straight line through points like a linear regression does but to describe Bayes optimal perception cognition and action so it's doing something similar instead of having like one imperative for perception and then a different imperative for action it's a unified model of perception cognition and action that we can use this one imperative the free energy of a generative model and use that to guide the fine-tuning or the learning of that generative model to return to the social question as we move forward no it is not like uh an ought it's not the is odd this is not an ethical framework just because there's a normative way to fit a linear regression doesn't mean that it tells you what any given culture is going to be happy or upset or benefit from or anything like that there's probably a lot there's other ways to say it but just the short answer is this is correct octave is not in the kernel of active is not describing social normativity in the sense of like peer pressure or like what people will look at you weirdly if you do okay next question living organisms can only maintain their bodily Integrity by exerting adaptive control over the action perception Loop which they frame that adaptive control as the question that active seeks to address do generative models represent and thereby predict bodily integrity or do these models predict the causes of their sensory inputs and Via minimizing the prediction error they achieve maintaining their bodily Integrity without explicitly predicting bodily integrity how to best talk about what a generative model is predicting great questions what does anyone want to add well I think one short answer and then Ali is that generative models fit whatever parameters they have so you could imagine making a generative model where there's like a hidden state that is bodily integrity and then there's observations that help reduce uncertainty about bodily um integrity so in that case we'd say yes the generative model represents bodily Integrity as a hidden state and therefore tries to do inference using that or do these models predict the causes of their sensory input and Via minimizing prediction error they achieve maintaining their bodily integrity that's actually like another way to say something similar which is that the hidden states are the latent causes of sensory observations and so by minimizing the prediction error with respect to observations it is possible to achieve maintenance or homeostasis of those latent States even though they are not they are explicitly predicted or represented but they're not observed Ali anyone else uh well actually an acts of inference uh all the agents or more technically all all the particular systems and all the particles sorry uh do are kind of doing the this kind of inference making tasks in order to self-evidence and actually this task of self-evidencing is the fundamental uh task that an agent needs to undertake in order to uh keep its homeostasis into action or uh doing uh that kind of homeostasis through allostasis because both of those terms are obviously related one of which needs a more active um and more and more active mediation to to undertake the the homeostasis test but in any case uh the the concept of self-evancing exactly refers to this kind of uh Integrity maintaining uh task that any self any inference making agent needs to undertake to persist through time so I think this is the fundamental requirement of any agents modeled in active inference framework awesome thank you and once we start into the subsequent chapters and we look at how preference is used in active inference we'll have some awesome discussions like do we expect homeostatic temperatures or do we prefer them it's like on one hand I prefer it's what I like on the other hand it's what I expect because I wouldn't be surprised to find myself there so how does that play out um ever yes and you hear me okay okay so a good good answer also depends on which level of the hierarchy you are talking um so at the lowest of hierarchy there's sensory stimuli that's are being predicted and the more you move up the more abstract models or predictions are taking place so higher up the hierarchy I could have predictions about bodily Integrity or predictions about my continuing existence Etc and then lower down the hierarchy you could have some physiological variable that's predicted like nociception in the case of pain and then you can have all awesome okay was that is that all yes okay okay yes totally agree um often people talk about like nested models or hierarchical models multi-scale models and that's one of the strengths of taking of at least bringing some neatness into play is like by using a level of neatness that lets us generalize across different cognitive phenomena like what we might just conversationally call low level or high level it allows those models to be composed in an integrated way so in this textbook there's not going to be an emphasis on nested modeling it's going to focus on like the kernel of active inference which is like the single agent at the single level but then there's all of these elaborations which are active areas of research and development um outside of the textbook yes thank you Yana could you clarify low and high level yeah I think that they uh if I think about the cortical hierarchy there's I think six layers uh um and and if I read the literature correctly they talk about different kind of predictions depending on which kind of cortical area you are talking about and and the active inference models are built in a way that's go that's also uh fits uh the anatomy of the brain so they talk about computational Anatomy fitting the active inference models thank you Jonathan and then John Luigi um yeah I think that that's right I think another perspective is is simply that low level is for instance the the pure sensory inputs themselves um we may be making predictions about you know a site that um something that will come to our eyes higher level might be some um sort of more abstract idea of the thing that it is outside in the world that is is giving us the sensory input and so there's a sort of hierarchy of um time scales and physical scales um that we might take in moment to moment and build up a bigger and bigger picture awesome so just to restate that at the engine Luigi the low level this is just one spatial metaphor is that the pure sensory inputs themselves like the low level is where the rubber hits the road and then the higher levels are abstract or synthesized representations about what are giving rise to those sensory data and that is also called a cause in the statistical sense Luigi than ever yeah um I also believe that it really depends on how your generative model is set up I mean a high level can also be a pretty straightforward sensory uh inference so to say between one observation and one hidden State and not something absolutely abstract or at least that's what I saw like I I agree that plastically it has been like those cortical layers or the the lower levels are the most most um low level sensory uh inputs so so to say and the higher levels are the more abstract ones but I do believe that they also uh that the distinction might also not be that strict all right and then effort then there's a few more points to make yeah and this question uh about what is predicted also uh um I think it also has to be seen from this uh instrumentalist and realist discussion uh is it is it the modeler that uh is building an active inference model and tries to infer what the organism at whatever level is predicting uh and and that's what I wonder is um you you also read in the literature A lot of times that they talk um with the terms as if it looks as if the organism is minimizing this or that or predicting this or that so this s if language um also makes me wonder how how do we know what an organism is predicting awesome this instrumentalist and realist and map territory we're going to return to a lot um on I want to bring a few more points on the nested models and then we'll return to the questions since um like nested modeling it's kind of like the active kernel is like one Lego brick with like a bottom and a top part and then like it is very amenable and as soon as we have the Legos we want to stack and put them in lateral and build them but the multi-level Lego structure is predicated on what that one is at least understanding what it is so in live stream 28 on um sandved Smith's paper this is just one example of a nested model with three layers where the quote low level is sensory and then there's a level of attention and meta awareness so there's not just one way to do nested models there's many nested models that one can make but it's an example of how something that is like raw and exteroceptive can be seen as a low level model nested Within other models that are quote higher but again that's just like a that's just like a a cultural visual graphical layout there's no reason why it couldn't be from left to right or top to bottom or inside to out so it's like it's about what it is not just the spatial layout but that's what it is on the six levels of the brain so here's from um live stream 43 which was with Maria um yes there are six anatomical layers in parts of the mammal brain six layers that are defined like histologically like the tissues look different but it's really important to remember that is not the same thing as it's not six nested Legos and we're gonna get to this more when we get to chapter five which is all about um the neuroscience but here are those six layers so this is not six full nested models like here's three full nested models that are truly nested whereas the six histological layers actually are part of an integrated inference scheme it's not six nested models but a lot of times people think oh multi-level models hierarchical Bayesian modeling hierarchical predictive coding architectures six layers in the brain six nested models that's not true but that's a very common um framing so what is the generative model predicting whatever it is set up to predict these are maps not territories okay I think okay great there were some some awesome discourse here so can someone explain to me why the inferential problem is intractable page eight it has to do with the marginal likelihood P of Y in the Bayes theorem so does anyone here who is in this discussion like want to summarize it or what their understanding of what is the tractability issue and how are we going to approach that um yes am I the the sort of example I gave there was that if you see a flash of light you want to know what's the probability that it is a particular thing given that you have you've you've had some observation of the world um but in order to do that you need to sum up um in this case all of the different things that could have given rise to that particular flash of lights and that in itself is in is intractable so there are various terms within the um within the base equation which in order to do it properly in a complex world would mean summing over an infinite number of things that was my my thought there great great so there's a lot of ways to to talk about this but you pointed to that that several pieces are required to go from a stimuli to inference about a causal state of the world like whether it was truly a tiger giving rise to the stimuli or whether it's something different you'd want to know a few things you'd want to know the probability of given that it's a tiger what is the probability it would look like that flash you saw but then also you want to know How likely is that flash from other possible hidden causes and so that is like the probability of The Flash given that it's a tiger or given as a chipmunk given it's all these other things and that can be an open-ended some so thanks for that great answer it is in essence an infinite sum of possible things and you'd have to know the probability to be able to say what you should really think there's there's there's many notes like yeah ever you go for it no um I also found in the book that they say for complex models there maybe many types of hidden states that all need marginalizing out making the problem computationally interactable so I thought you were saying that before but I also found that the a sentence the marginal marginalization operation might require analytically intractable integrals and I I don't understand what that means is it different than the answer you gave before it's it's very related so sometimes um in a discrete setting we are talking about sums like sums you know one two three four five sum over one two three four five in a continuous setting we are talking about integrals so if something is being summed over a discrete range that is analogous to it having an integral over a continuous range and so they're both beset with the same challenges of large um and interacting spaces and then just one kind of note because on a Bayesian and marginalization this is like actually the margins of a piece of paper that's what it's referring to when there's kind of like Actuarial tables back when statistics was done on spreadsheets so it's like if you have states of the world and then observations in in a grid um if each observation mapped onto one hidden state of the world then you would just have like only on the diagonal would you have any numbers we're going to come back to these topics but then you can imagine that you might be interested in marginalizing a given row like summing across that row so saying okay How likely is this across all columns and that's called marginalization so why is it intractable because it might just be requiring computational resources that are unrealistic or implausible okay I think uh it's there was actually the the reason the whole reason for a variational free energy a quantity uh this this marginal likelihood thing is that correct yes it is it is free energy is going to help bound our surprise let's but let's come right to it so this one kind of goes in multiple different uh directions the central imperative is that organisms maintain their existence High Road avoid surprising States how can one explain different self-harms or perceived self-harms this is kind of like the social norms question in that um we're not always going to get a neat answer from a human scale complex nested system where the generative model hasn't been stated this if that makes sense so like given a generative model one could describe how driving off a cliff is the mo that is the generative models most likely course of action like if the generative model is I always drive straight I'm likely to find myself driving straight that generative model may drive off a cliff but to kind of not mention the generative model and just say well how is it possible that surprise is bounded by driving off cliffs is not a full um it's not fully making contact with what the surprise is because surprise is with respect to a generative model so whether it's the extremely complex cases of humans or whether we're talking about something different then surprise and the bounding of surprise through free energy is with respect to a generative model everything is always in respect to generative model there's no surprise minimization free energy minimization outside of a generative model so surprise immunization free energy minimization those are qualities of a generative model just like the um least squares regression the sum of squares is with respect to a linear regression model surprise bounding free energy is with respect to an active inference generative model and once the generative model is specified then one may find different actions as avoiding surprising States including addiction and different states that people have studied that we're going to come to but we need to fill out what generative model we're talking about before applying the imperative Jonathan and then Everett you know within that generative model there are also um the the different desired states that the organism might want to be in and those desired States you know they're they're not normative in the sort of sociological sense we may have different desired States and so for some some people that may be very different from what another person wants and may lead to one of these outcomes thank you and ever yes it's uh this uh example with the suicide it's also related to the high roads where the imperative is to um maintain our existence minimizing uh surprise necessary for survival um so if if I commit suicide and I would violate that core imperative and but we do know that people commit suicide so how can we explain that so this framework um and it also has to do with um if I predict bodily Integrity um but for example I uh someone who experiences chronic pain because that's the best explanation for my prediction error that I have will be an update of the model that says okay now I'm not predicting any bodily Integrity anymore but I have threats to my bodily integrity and with that also then lead to eventually committing suicide or just some some thoughts but I can't make really sense of this um thanks okay just in our final minutes to touch on one or two more all these discussions people can continue to engage and and develop ad resources ask more questions like it doesn't stop here this is like the tip of the iceberg of us wanting to develop the state on these questions because they're things that we're all asking they're things that other people are going to be curious about and we can have great answers and complex discourse and multiple perspectives here um we're just going to do one more and then we'll end two minutes before um the hour and again these are also things we're going to return to in future weeks this is just our first week on chapter one next week we're gonna do another chapter one session and we'll come through more questions the second half of the questions on chapter one and anything else that people add and upvote so just in the last three minutes can someone explain why exploration and exploitation are automatically balanced through policy selection in active inference page 10. what does it mean to say both exploration exploitation are balanced Jana thank you I will save this chat uh in my in my understanding it would be that you only explore as much as necessary to exploit so you want so X exploration is an effort somehow and you want to minimize this to get the maximum of exploitation that's my understanding approximately thanks um one uh very Hands-On uh way to explore this question is in model stream 7.2 from just a few days ago in the video description of model stream 72 there is [Music] um a notebook that can be run in your browser without any more tweaking and it is going to have an agent that has the choice to do a few different things they can play either of two different slot machines one of which is like better than the other or they can get a hint and so um to have an imbalanced strategy would be like to kind of Zone into the first slot machine you go to and stay there to have a overly imbalanced strategy towards um exploration that might look like just getting the hint every time or just kind of moving around really rapidly in the space but not ever like latching on to ones that have high utility and then a balance strategy which there's not just one single answer to this but a balanced strategy in a given situation is an action policy selection it's a strategy or tactics that navigate or manage the tensions of the requirements between exploration exploitation and sometimes that's modeled what's called a multi-armed bandit where there's like a bunch of slot machines you want to win the most money but you don't know how good each of the slot machines are so you got to explore a little bit to find out like how good they are but then you want to spend most of your time on the best ones you want to spend time proportional to how good they are but of course if you only spend time on what you perceive as the best things might be changing and so you might end up not being on the best machine soon so thank you everybody for joining we'll come back next week for the second discussion on chapter one and um please add comments and questions and discourse in the time till then but thanks everybody for the awesome discussion farewell thanks everyone [Music]