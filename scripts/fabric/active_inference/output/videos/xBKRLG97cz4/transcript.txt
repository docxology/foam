hello and welcome everyone it is September 1st 2022. and we are here in model stream number 6.1 we're going to be discussing branching time active inference the theory and its generality we're going to have a presentation followed by a discussion so thank you Ali and Jacob for joining and anyone else to be adding their questions in the live chat without further Ado over to geophilia Champions and thanks so much for joining really appreciate it hello thank you very much for the kind introduction uh and thank you for inviting me to present today I'm very glad I had this opportunity so today I will be speaking about branching time active inference um basically it's really different version of the of the the approach the first reason is Dash passing so second using Belgian filtering and the third one is using believe propagation and allows the model to contain several observations and several item States this works has been realized in collaboration to we've lost Acosta Mike Josh and Hogwart Bowman so first of all I want to speak a bit about the action perception cycle which is a core ID in active inference and the second is the agent which is all of them the environments provide observation to the agent for example an image of the environments and then the agent need to take this input and perform inference on it and the goal of the entrance process is to extract high-level iron states such as the position of black man in X and Y or the position of the ghost or whatever information may be relevant then based on those States we can perform planning and action selection and action selection how it puts the action to perform maybe the action going up which is fed into its environment which produce another observation and this cycle continues until the Trail Ends now that we have the core there is a core idea of Arctic inference which is action perception cycle I will be speaking about active inference in a bit more depth so basically active inference is about an agents which is equips of a model this agent makes as I said observation which are represented here at the bottom of the screen and those observation depends on the island States through the a matrix so that it is a matrix provide a distribution of the observation for each possible Latin States we also have the G Vector which contains the parameter of the prior over the initial item States as well as the B Matrix which explain how the transition of the environment works so basically it explains how given a state and an action we get the new state at time t plus one we as I said uh have an action or here is a policy variable and this action variable or policy depends on the Precision parameter which is called gamma and as we will see influence how stochastic or deterministic the policy of the agents will be so here we see how the prior over action is being defined so it depends as I said on the game parameter and it is and it is defined as a soft Max function of minus the gamma the Precision parameter times the expected free energy and the expected free energy for particular policy is basically a sum of all future time steps so from t plus 1 which is the first time step into the future to uppercase team which is a Time Horizon and for each time step the expected free energy is defined as the expected Cost Plus xiaomi equity the expected cost is the K Divergence between as a predictive post trial or the future observation and the prior preferences but the prior preferences defines which observation the agent want to to observe and this the predictive posterior defines How likely its observation is and so what we want to do is to minimize the Divergence between the distribution so that we actually observe what we learned okay and the second term is about the entropy of the likelihood mapping uh expected under the directional posterior of a state so I'm speaking about directional posterior I will explain what this is in a minute uh that's that's the definition of the expected energy risk plus ambiguity or also called expected cost per solubility so I presented the model here's a more formal definition here we have a joint over all the variable in the model we saw that the policy depends upon the Precision parameter we have a gamma distribution for the Precision for each of the tonsor of parameters so a b and d and we see that s indeed depends on D and that's the observation depends on the state through the a matrix and 10 thing for the transition mapping we have a state which depends on the previous States and the B Matrix as well as the action being performed in the environments okay so now we have the model that what we want to do is given some observation we want to be able to compute posterior beliefs over the lateral variables in a probabilities in probability we call that Computing the posterior distribution and we do that through a process which is called inference we can for example use exact inference which is based on bias theorem so that's a complex the posterior is equal to the likelihood times the prior and then we normalize using the evidence and basically the evidence is just obtained from the numerators by summing out all the Latin variable X the problem is that when X is a continuous random variable as this summation turns into an integral and we may not have analytical solution for this interval so this method the exact inference can become intractable because of this what we do instead when using via snap inference is that maybe this Trooper stereo is very complex but we are going to approximate it using this Q this viational distribution and try to make the Divergence between those two distribution as close as possible so here we have the trooper stereo on your writer and here we have an example of how the directional posterior may be fit to the true posterior in red in the context of active inference the directionality distribution is defined as follows so it is a joint distribution although all the electron variable of the model and we are doing what we call the mean field approximation which means that all the variable within this distribution are assumed to be independent thus there is no more dependency for the pi a b d and Gamma parameters and we do a slight exception where the state still depends on the policy point okay so that's the definition of the violational distribution and now that we have the virational distribution and the generative model we can Define the biational Primitive so the goal of the violational free energy is to make sure that the approximate post child so that our variational distribution remains as close as possible to the super style and it is defined as the scale Divergence between the approximate question and the generative model this via style free energy is also called like the negative evidence lower bound or elbow in machine learning and it decomposes into two intuitive terms so this is the wire style for energy I decompose it into the K Divergence between the approximate and the true posterior this is the term that will make the approximate booster will be as good as possible to the true posterior and here we have as evidence but which is a constant with respect to the viational distribution which we are optimizing for so yeah really the Via Sharp Energy is a proxy for the first term over there okay so what is passing is an inference algorithm basically it is based on what is called The Mark of blankets so let's suppose we want to compute the like the virtual posterior for one specific node in a graphical model what national expressing is about is saying that this node a only depends on its Mark of blankets more specifically it depends on the child of a so here D and C it depends on the balance of a here f and g and also in the co balance of a for example e and B in this picture and what this macro blanket says that's really we only need to know the values of the variable inside the Markov bracket to be able to perform inference over a here is a bit of a bit more formal um view on this question so here we have the optimal virational distribution for one random variable so this could be for example a and the query on the right gives us analytical solution for this uh posterior and we see that it's only depending on the Node itself its parents its children and the cobalance and that's all we need to know um okay so why by saying the message bits comes from the decomposition of this iatical solution into messages which are added together to form the variational posterior here we can see the first message which basically comes from the parents here we can see one message for each chapter and what we do and that all those messages will be added to form the parameter of the approximate plus tribe here's a practical example basically we are trying to perform influence over the random variable y so we want to compute the parameter of um the distribution like the posterior distribution of a y and the way we go about doing this is that we send messages from the parents all the way through the random variable y and same thing for the child and the components and each time we reach the factor node we combine the input messages and forward the results toward y when we have received all the messages we just add them together and this provide us with the parameter of the violational distribution over y so this was buyer's Diamond which is basically the algorithm that we use to perform in France now I will be speaking about multicarage research which is a planning algorithm that we use to look forward into the future and estimate the quality of each product so before to do that I want just to introduce the notion of community index um so here we can see the roots of the tree which is a state at the present time step and then from there we see [Music] um that we have not in the future which are indexed by sequences of indices for example here's a sequence of sequence of size 1 which contains just the action of the index uh one so this is a state which after taking actual one and then here we have the states which when performing action 1 followed by action 2. and this those indices are called multi-index because we are they are composed of several indices which here represents actions okay so now that we have this in mind I can discuss multi-clarative research so the way Multicultural research is structure is in four steps first we have the selection step where we start at the root node and compute the UCT criteria so this is just a real value I can remember for each of the track and then we select the node which actually has the highest velocity value for example maybe it is S1 so the state with which after taking action then from this we can compute the velocity of each children and maybe this node will be the highest value okay once we have reached the left node we can move towards the second phase which is about expanding the the children of this node and for each child what we are going to do is just simulating some rule outs from this node I'm Computing the average expected frequency for this node once we have this there is a fourth base which is about updating the expected finity of the ancestor of uh then that we just expanded as well as a number of visits because we want to explore part of the tree which have not been explored a lot in the past so we need to keep track of how many times each branch has been exploded okay so that was the algorithm for planning and I now have introduced always a background required to discuss the first approach which is branching time active infants with bilational massage person so first we need to define the model it is basically splitted into two parts the first one represents the past and the present and it is basically a partial observable micro decision process which is just offensive word to say that we have observations which depends on State this is with a matrix we have action variables over there and we have States as as I said so electrical machine as I said is adding like it's parameterized by the a matrix the transition as usual is parameterized by the B metric and we also have here the Z Vector which defines a prior over the initial ion States so this is coming from standard artificial and then the novelty is that we are expanding the basically the future well each time so we okay so we have this model then we perform active like um multi-carot research and each time we want to expand the node what we do that we are going to add some parts some bits to the generative model so for example if we want to add this part of the generative volume we are going to add one transition mapping B this will add a random variable uh is here it's like S12 and then we will add the associated observation using the likelihood map so this is how we expand the generative model as we go mathematically this is defined like this so we see here a generative model of all the variable in the model we have the original prior over the parameters like of the models so the A B and G matrices the state at times type zero depends on D each observation depends on the states Associated to it and the a matrix and then we have prior distribution over actions which depends on some data parameters for which we have a division prior thank you okay and then the state as usual depend on the previous state and the previous actions as well as on the B Matrix which defines the transition probabilities so this is upon GP version like so from GP part of the model and this is a tree life structure that it expands as planning is going on so it is a set of all multi-indexes which has been expanded in the model for example if I come back here we see that there are three multi indices that have been expanded so I is equal to the multi index is one the militant says two and the multi-index uh one one okay and now for each of those military index we add to the generality model a transition and likelihood mapping so that's exactly what we are doing for each index in the set of loot index which has been expanded we had in the future so now we need to we need to test this approach in an environment and for now we will be testing it inside a maze environment where we have here is the exit of the maze here the starting position and then the prior preferences of the items will be that the closer we are from the exits the more the happier the audience will be so here we have a distance of zero one one two three four um one feature which is really important is that the prior preferences fly across fours so here we have we have a three and here we have four in terms of distance we don't have like five six seven eight we have four and what this produce is a blue cell and what this blue side blue cell actually is is a local minimum in which the agent can be stuck if it is not careful and the way to avoid this local minimum will be to be able to plan final into the future to see that the rewarding path is actually this one and notes is the one leading to the local minimum so this is basically a challenge that we are adding uh to the task and here what we can see so here is basically an illustration of the tree which is being expanded and here we have the table of results we see that as we increase the number of planning iteration we go from the agent being stuck inside the local minimum so never reaching the limits to an agent which is basically behaving properly on which zero sets 100 of the top next we need to compare how a partial bunch in time active inference to the previous like state of the art which is activated Plus and basically we designed an environment in which for the agent to be able to solve it it has to plan three five and then eight time step into the future for active influence what happened is that it was able to properly solve the two plus task but then what happened is that because the number of policy it has to evaluate into the future grows exponentially with the number of times that it has to plan for the last one which is the biggest crushed with how um environments like with our approach which is the exact same thing and where we increase once again the number of planning iterations we see that the agent becomes able to sort that all the time and does not crash because it is able to explore in a clever fashion the space of all possible possible policy using multi-carot research this was a bit of a non-pherical comparison between bti and active inputs now what I want to do in this slide is to compare them in demo like in terms of implicity classes which is a lot more theoretical so basically here each circle corresponds to a categorical distribution of the states which means that to store one of those Circle we need to store the number of states so so a number of parameters which is equal to the number of State value okay so if we have a state which takes three values we need to store three parameters then for each time step into the future we need to store one more parameters one more categorical when it comes to active inference and we also need to store um one more category called for each possible person so the total complexity class is equal to the number of policies times the number of time steps until the time Horizon times the number of parameters we need to store for each categorical distribution now in the worst case scenario BCI need to store so the first thing to say is that bti does not store every single possible combination it's using the tree structure of the generative model to store only one distribution for the past and present so first time step in the past and present and then it's if we expand all the trade then it's going to ex to store uh the number of action to the power of the timer is on minus G so this is still exponential in terms of course because of this change over there but in practice we never expand the entirety of the trade so what we do is maybe we will expand this this this and this but not the two other so in practice the real complexity class of this algorithm is a linear in the number of expansion that we are making foreign does not require as much storage space as standard occupations now we want I want to speak about the second approach which is based on Bayesian filtering so first what is bias and filtering well benefit is an inference algorithm which starts with just a simple generative model with a state and an observation we actually know which observation we are making and we have we also know what the prior State and the likelihood is and then we can for example use by asteroid to compute the posterior of the states given some observations and we just yeah we just complete it like this once we have a posterior of a state we can use it as an empirical prior so here is our empirical prior and we also know the transition probability that lead us to the next time step so we can use this information as well as the action that we're actually performing in the environment to compute the predictive posterior over the state at time step one given the action that we just made which is u0 and the observation that we made before and the way this is done is just by performing base and prediction as through the like like the transition mapping so averaging out the dimension of s0 and then comes another observation and we can just use our predictive post channel that we got from the previous prediction step to now um over S1 according to this new observation and those two steps of integrating evidence and then prediction um through the transition mapping are going to be iterated as many times as we as we need to so this lead us to the second approach that I want to present today which is branching time active inference with Bayesian filtering so first thing we are not storing any more uh the past the past observation on state because all the information we need is stored within the beliefs over the initial State like the Quran timestamp the state as a strong time step okay so we have an observation attempty we can perform the integration of evidence step to get a belief about this the state at time step T and then we can perform forward prediction for each of the children that we want to expand for example maybe we'll compute this one and then this one and so on and so forth and if multiculties are status to expand this chart then we will just forward prediction as well for this one and expand its Associated observations so that's the main idea so really the only difference here is that we don't even have any more departure observable lack of decision process for the past we only have magnification time step and we are also changing the inference algorithm from violation passing to bazel patreon and here's a more formal definition of the generality model so we can see here the likelihood and prior overstate for the initial downstep here is the example team and then for each uh like for each future State and observation or each routine says that we already are expanded we have the likelihood mapping and the transition mapping Associated to it in terms of performance We compare here bunching time active inference using Biogen filtering to the same algorithm so btai but with various times person and we see that for the same task one of them is performing with an order of magnitude which is about minute scale so around four minutes between four and seven minutes one of the other performers faster between 2 and 11 seconds so this speed up in performance is basically uh made possible by the change of inference algorithm but now what we want to do is to be able to Define more than one observation and state at each time time point so what we are going to do this is by changing once again the insurance algorithm from better than filtering to believe propagation so what is belief propagation basically belief propagation is an algorithm that takes as inputs a function over some State variables and this function we know that it factorizes into a set of n factors which we call f i and the question is how can we compute the marginal distribution like the national over the marginal of this function when we marginalize out all the other random variable except for one SM okay so we want to marginalize the distribution of all that SM and the way I believe propagation is solving this task is basically by passing messages through the computational graph so in the graph we have two kinds of nodes we have Factor nodes which represent factors of the distribution for example F1 and then we have random variable maybe a X1 and we may have several of them so F2 and then X2 okay and maybe we have a transition mapping between the two so this is the second and now what we want to do is to pass some messages through the graph so when it comes to a message from a node X to a factual so that's because we have one more here what we are going to do to compute the output message is just multiply the input messages that comes from the other arrows that you know goes toward this note and we just multiply all of the input message and outputs the result when it comes to a message from for a factor we basically are going to so take the factors for this Associated to this Factor node and multiply it by all the incoming messages so we take all the incoming messages and multiply them by the factual associated with this Factor node and then we marginalize out all the input Dimensions so that the message at the exact same shape as the this one the output as a Target random variables so this is the marginalization and speaking of that we do that for every single messages we can inside of the photograph and then we use those messages to compute the marginal that was the goal of uh of this algorithm and the way we do that is that we just take all the input messages and multiply them together and this gives us the marginal distribution over the specific State we wanted to so this lead us to multimodal on multi-factor branching time activities which is the last approach that we have been developing before to be able to speak a bit more about this approach I had to introduce the notion of temporal styles so the top work slides is just a set of states and observations we have Estates and all observation which so this is a plate rotation which just duplicates a variable all time or as time and then we have those dashed line what those dashed line are doing is just connecting the observation to a subset on the states over there so for example maybe we have an observation one which depends on stage 1 and state two and then maybe we have observation too but this observation 2 only depends on state two so the reason for which it's a dashed line is because we can have a path sparse mapping in uh between the state and observation we don't have to have all the possible connection okay and two slides total product slides can be connected through the transition mapping which is these arrows and this arrows mean is exactly the same but between two time steps so for example this uh the state over there can depend on the state as a previous time step in arbitrary fashion exactly like the observation depends on the an arbitrary subset of the states but this representation is a bit unpractical when it comes to presenting the entire generative model so what we do is that we just represent these top wire size as a square which is called t s t so the top right size attention and the background here here is gray because observation within the top slides are provided they are actually observed while in the future the background will be white uh because the observation are just not observed okay so now let's grab this more compact presentation we can present the generative model so here we see the initial time step and then from there we can expand some neutral plus size exactly when a multicult research has asked us to so we start there maybe we compute the UC Criterion this is a the highest uh the node with the highest Criterion so we are basically asked to expand those children and we can do so by just using the forward prediction for computing the state here and then from the state we use forward prediction once again to predict the future observation Associated to this top one slice foreign variable once again and it is a product of the probability of the temporal size at time T multiplied by all the future time control size okay so all the top right size we have already been expanding during multi-current research each observation depends uh so in the initial type of slide so this is the initial couple of times this observation depends on the subset of the state within this topmost size and because we are at the top of the tree the state at time step T does not depend on anything after that for each popular size in the future we still have the dependency on uh that we still have the fact that the observation depends on the state within the stopwatch slides but we also have the fact that the state in this topic slides depends on the state in the previous like the current top one slides so for example the state within this top right size half balance in inside this top one slice okay so this is the way the generative model is defined now the way we perform instance is using what we call the IP IP algorithm so I stand for inference and P will stand for prediction so this slide is about the inference Tab and the goal is to compute the posterior over the stage within uh the initial like the current template slides given the observations I'm not going to go through this derivation but you can pause the video if you are watching it on YouTube um but yeah so basically we do some derivation and then we obtain this solution which just tell us to take the product over all the electrical mapping with all the players and then use the build propagation to actually marginalize out this function and that's exactly uh what we are going to do we use big propagation within the current timestamp so if I go back here we have some observation here and we use build propagation to compute the state within the initial topographies so this is the each step the ISTEP which is the interest of then we need to perform the p-step each time the multicult research tells us to expand a part of the generality model so once again I'm not going to go through this derivation but basically the ID is to compute the posterior over the state in the next component size given the observation that we made in the current template slides so here we see that balcony once again we have some kind of summation over all the parents of the states in the top five slides that we want to to compute the posterior form and this is the transition mapping that we know and this is a posterior distribution from the previous sample size so basically what we are doing is just doing forward prediction in this case taking the expectation of the transition level we can do this for the stage and pause the observations so to come back to the main picture we first use the ISTEP to compute the posterior over the state and the initial couple of slides so this is the ISTEP and then we can use this those posterior distribution to compute the posterior over the states in the future so maybe the state in this double slides and then we can use once again the key step to compute the distribution of the future observations that correspond to the stop butterflies and we are going to do that to do that or time step like a all top of our slides we want to expand in the future okay and the next thing that we need to Define and last for this approach is the expected free launch so basically is where we are going to Define this is by first grouping all the observation into distant subsets so basically o i is a set of all observations in the top right size index by the muting this ion okay and now we are going to explain once we have grouped those observations into subset the way we Define the expected free energy is just as a sum over all possible uh groups of random variables so each of those will be iterate over those and then into the calendar versions between the prior um the predictive post style process observations so this is the risk term the color version between what will happen and what we want to about and then we will we will compute the ambiguity for each of the observation which is as usual defined as expected entropy of the likelihood mapping so this build equation is probably new for people for for people that have not created paper but we can look at one specific case which makes it more more intuitive and basically the specific case is just when each subset corresponds to one observation in the top five and in this case the expected frenergy for a specific processing so for one specific multi-index is just the risk for the specific observation plus the ambiguity or the specific observation so we still have ambiguity plus risk and now we need um to present like to test those approaches together so compare branching time and second chance with various time in such testing that isn't filtering and the last approach which is based on the propagation the way we are going to do that is by using a variance of these five datasets basically um we represent the the environment as a guide and so we okay in this environment we have three different shapes we have additives us that need to be pulled towards the bottom right corner of the image and we have squares and the squares needs to be pulled on the bottom left corner of the image and because there are way too many positions in X and Y what we do is that we do some form of State aggregation and for the eighth first position in the right left corner um upper left corner if the shape is in one of those eight position we are going to aggregate them into one state with index 0. and for this it will be in index one and then and so on so forth two three four add to 19 for the squares and if it hurts we will just allocate those States um the indices between 20 and 39. and something for instance so what we are doing is basically reducing the state space so that some of those approaches can still do something because they are not powerful enough to solve the entire um State space so here are the results where we compare Financial expressing but Bayesian filtering and the last one which is based on belief propagation research passing we had to use a granularity of 4 which means that the length like the size of the square is like a 4x4 set of like a square so as a cell has a size of four by four and with this setting we were able to solve 96 of the times and the average time for one um for one trial is around five seconds with the base and filtering approach we were able to go down to the granularity of two so this times the cells have a size of two by two and with this I have with this granularity the hydrogen becomes able to solve the task 98 of the time while um but the thing is that because we reduce the size of the granularity we also increase the size of the stage space and this produces an like an increase in computational times uh which means that each trailer now requires around 17 seconds to be executed for the last approach likely we use the fact that we now know the factorization of the likelihood and transition mapping and this allows us to go down all the way to un like only one the range of one that's cool so we are now able to differentiate between every single X and Y position inside the image and with this granularity we can solve the task perfectly and because we can take advantage of the like factorization of the distribution we go a lot faster than all of the previous approaches and we can solve the task in around 2.5 seconds so just I would just want to make one thing uh very clear here because this approach directly was able to model every y position every Exposition every shapes inside like you know shapes uh of the display of environments what is the orientation like possible orientation of the shape and or the scale um so basically each each shape can have different sizes and this scale Dimension represent that so basically this is approach reliable to to deal with around 700 000 configuration of the state space now we have presented the results and show that this approach approaches daily performance like can lead to very good performance but now how do we trade that uh well here I've got a very small uh code example well directly I'm retrieving from the environments the a b c and d matrices the C Matrix symmetrics correspond to the prior preferences of the agent and as I already said several time a corresponds to likelihood a b corresponds to the transition and the is a prior of the initial States and then the way we'll go about creating the bti three agents is just by creating the top wire slides Builder telling him that we have one action which is called a underscore zero and then giving it the number of value that is that this instruction can take then we just add one state for every single state of our system so the X position y position shape scale and orientation and we provide as a second parameter the pack is the parameter of the trial over the state so now within our generative model we have the state of the system then we need to add the observation directly for each of the stage we add one different one observation which depends on this state through a matrix so we provide a matrix and the list of parents over there and this basically we add an observation for each state in the generality model so before last step is just um to add transition so basically for each stage in the system we say what is the B Matrix that need to be used and what are the prime the parents for this text so for example the position in X of the agent depends on the pronunciation in X at the previous previous term time step and the action which is being performed foreign probabilities within the model and the last step before to build the top right size is just to Define our prior preferences and because in the display data set we need to apply our preferences about the X Y and the shape of a blob what we do that we we say here is one factor so this is one of the X subsets of observations and we provide those three Matrix Associated to that then we call the the function build which just returned the top one slice and we create a PCI three map agent which uses the stock price slides and we provide a number of planning iteration we want the algorithm to use as well as the exploration constants that Traders exploration versus exploration expression exploitation and this is a graphical user interface that we have been developing particularly here we can see the initial supplys uh if we were in the software we can click on the standpoint slides and see the different post style over all the the state variable we can also see different information about those as a stopwatch Styles so the number of times have been visited on all this time and then we can use a button on the on the right on the left to basically perform a step-by-step multicarage research so what will happen in the interface is just we are going to add the children and then we will be able to click on those children to explore those parts of the trees so and we have information about the term water slides in the future so that's another tool that you can use to analyze both planning and the beliefs of the agents okay so I'm now um done with presenting the different approach it's now time for me to conclude this presentation so we have seen three different approaches the first is based on bioslamic slash passing and obviously using active entrance and Medical Art research the third one is based on business and the last one is based on the IP algorithm which is a mixture of belief propagation and forward prediction in terms of performance the first so bti vnp was basically slower like less performant than the second one which is once uh less performant than the third one okay but even with this uh increase in terms of performance ability on one approach to the next there are still some tasks that we can solve for example how do we solve image based problem or which is not clear how we can learn the structure of the generative model for now the the modeler has to provide the description of the model but it would be very nice if we could learn it from the data and also for now we have been basically providing the actions for like with useful sequence of actions for example if we go back to the described compartments we could imagine a task where each time we go right it's only pushing the shape one one position on the right and then one more and then one more but what we have been doing to make plan instructable is just by chunking all those actions together and maybe executing like eight action altogether or maybe four action altogether but this has its limitation and it will be really nice if we could run sequences of function like this automatically but that's all I wanted to say here are sugarfrances if you want to to give them up after the presentation and yeah thank you thank you for the presentation indeed use our reactions well very interesting a lot of material and things for us to discuss I'll start with just one general question and then Jacob and Ali looking forward to your questions just for some context how did this team and you come to be working on this problem were you working on active inference and interested in extensions or were you working in a different adjacent area and came to this algorithm okay so maybe one thing that I should have said is that I'm I've been starting like I started a PhD at the University of Kent and um basically whole world and Marek which are two of microbial laboratories on this project are my supervisors so this is how we we came up to to work together just through my PhD and lost to La Costa is a collaborator that I've been working with because I've been doing some presentation at the field which is the Institute of Neuroscience um where California is and that is through a presentation like during a pronunciation you know to me that he was um interested in working with me so this is how I started working with Larson Acosta and um so in time apply background I'm coming from a very computer science like school like follow into coding and then I arrived at um the University of Kent where I started to study about machine learning and this is where I started to gain some experience into reinforcement learning or even active influence and uh that woman was initially and Michael just as well was uh were two of my teachers and robot woman was already interested in active inference and one one day when she acted as a classes I came on scene and saying well I will be interested to a side project and that's how of course everything started and I ended up doing a PhD after that so that's it so basically a bit of both I come from machine learning my address as well uh long story comes from pure mathematics and what come from uh like neuroscience and easy guy which bring in the marketing from subject to the table excellent thank you so I have many more questions but how about ali first with a question yeah uh well first of all thanks a lot for your uh amazing presentation uh I've really learned a lot uh well I'd like to make a couple of comments if I may um and maybe a bunch of questions uh well as you're well aware active inference slash fep research has been going on recently in um basically two distinct paths uh the theoretical work geared mostly toward developing the underlying foundational principles for example the work of uh Dalton sector by development Max with Randstad and colleagues comes to mind and the more application oriented research perhaps not unlike the distinction between theoretical and experimental physics line of researchers uh but I'm not sure if you'd agree with me on this but it seems to me that sadly the application-oriented research and especially the work and the various algorithmic implementations of active imprints has not gained as much recognition as it should at least as compared to the research and theoretical side I mean the amount of related published literature is a previous cares comparatively so in light of this context your line of research seems to me a lot more daring and gains much more significant so I wanted to congratulate on that but uh you see I'm a big fan of unification in science and technology so my first question is about your opinion on the possibility of uh kind of unifying the different unifying the different algorithmic implementations of active imprints as an example you just mentioned the automatic learning is the structure of the generative model as a possible subject for a future and research I'm not sure if you've seen uh with here at all's a very recent paper from a couple of weeks ago namely the learning generative models for active imprints using tensor networks if I'm correct which outlines an interesting physics inspired approach for that task but it doesn't include any citations to any of the branching time active inference the papers probably because they weren't aware of your work at the time of their writing but this works work looks to me as a pretty good candidate for a potential integration with btai in order to overcome some of the limitations you just mentioned uh or another recent example uh that would probably be uh sanish rolls paper deriving time averaged active influence from control principles uh which is an attempt to derive an infinite Horizon um average uh surprise formulation of active inference um so I really liked your comparative overview of the different variants of branching time active imprints especially the Benchmark analyzes and um I know you described a sophisticated active inference in your work as a subset of branching time active interest but regardless of these are specific examples I just mentioned I wanted to ask how do you see the future of btai in terms of its possible unification with the other variants of active inference implementations each with its own pros and cons in order to overcome some of the uh some of their limitations without compromising the advantage messages of each I mean do you see it as a possibility that branching time active imprints will one day subsume all the other approaches somehow in a truly integrated kind of framework so to be honest I don't exactly know I I the only like part of the chapter that I've been exploring is a connection with launching time active inference has been active in France and sophisticated entrance and I haven't been really speak about based on the pronunciation but I can quickly give the idea of uh what my worker has been like what has been the conclusion of this and basically um it is really about how we back propagate um what I call the local spectator energy which is basically as the expected for energy associated with uh one node in the future and so if you back propagate those upward in the trade following um like multi-carot research which basically comes from bandman's equations and all this kind of um literature in reinforcement learning you will fall into you will underprove an approach which is very close to sophisticated imprints basically because sophisticated inference is also taking some inspiration into the benman equations just applying it to the expected free energy instead of just having reward uh if you go downward search that propagates those local costs towards the future then what you are effectively doing is just Computing like the path integral of the expected free energy and so this will be active inference just taking the sum of all future timestart of of the expected friendship as a great so this was sophisticated inference and this will be active influence now concerning the other approaches that you mentioned I haven't been reading um those papers so I consciously State on that um but yeah I believe that punching time actually runs is a very general framework so it may be the case that some of them will be related but more research is not on this this thank you very much great comments Jakob do you have any question yeah um once again thanks a lot for the awesome presentation and definite it definitely explained a lot of uh things that I didn't understand uh on my uh reading through through the original paper uh I'm wondering uh again going back to the question of learning the structure of of the different components of the generative model um in in your paper you mentioned you mentioned uh using um deep neural networks as general function approximators for learning this uh the state space representation and I'm wondering whether you have given some thought of into how neural networks might fit into this Factory graph representation of the generative model and I guess I guess there are perhaps also two ways to look at learning the structure of of these different components one is just the initial step of uh in your slide when you showed the kind of initialization of the model uh getting the A and B tensors the the prior the preferences and and um the prior beliefs kind of replacing that step with uh with deep neural networks to learn the representations but perhaps there's also another another side to um where you could dynamically change the dimensions of these different components as in perhaps the Asian receives an observation that wasn't captured in the likelihood mapping of the a tensor or perhaps it's a multi-agent setting where One agent has affordances the other agent doesn't and a new transition mapping needs to be learned through observations uh so um uh wondering what your thoughts are on this and how you think this might be compatible with branching time active inference okay so what is the Deep learning um area is I think pretty interesting and should be enabling active interns to scale to a more complicated tasks and more recently so this paper is not yet out but I'm working on a deep learning version of active inference so for now there is no branching time inside the picture so there is no more takeout research and the reason is because it's already surprisingly difficult to make it work just for active influence and um basically I've been reviewing some of the paper into Etc and uh and then I provide my own implementation of a deep active entrance but for example I speak I spoke about the display data set and I was not able to make a deep active influence work on these approaches on this on these environments so yeah and I've been doing a presentation as a field about this uh but basically some of the implementation on the internet contain mistakes um and yeah some of the paper also contains some like I mean I'm not sure if possible paper exact mistake that's that I don't understand and um for another zooters I've not been able to to answer my questions um so basically what I'm trying to say that I've been trying to finance deep active inference and surprisingly it's quite difficult to make it work at least on the despite environment so there will be a first paper about analysis analyzing what the Deep neural networks are actually learning and why it is failing on this environment and then um what I wanted to do is try to apply this implementation that I hope is correct um two different tasks uh most especially like the target games and stuff like this and try to find out whether there are some tasks for which the expected freemergy and you know is implementation of the effective inference can actually solve the task and the parameter preliminary result that I have on this um is that there seems to be some tasks or which uh deep active influence is actually performing better than for example dqm which is a benchmark from the reinforcement learning literature and uh yeah that's it's not as a straightforward basket since um when I was it's quite challenging to to implement that was more for large um deep learning aspects I think it's we still need to work quite a lot before to to make something very robust that can beat uh more standard reinforcement learning for like benchmarks and yeah the other opportunities to structural learning I have not been able like I have not researched it for now so we need more time to to think about a more robust answer to your question that's yeah that's basically what I had to say thank you excellence one really striking aspect of the presentation was the analysis of the computational complexity so maybe we could return to this because it's something that we've wondered about and discussed on a few occasions yeah you presented the theoretical complexity classes with a Big O notation and then also discussed some of the Practical aspects of the actual like clock time on a given Hardware wasn't exactly sure what language or um Hardware you ran it on but provided the theoretical complexity class as well as some runtime provisioning so I was curious to hear some thoughts on how does this big O computational complexity analysis shine light on different variants of active inference as well as branchy time active inference and what real computational resources were taxed in the analysis was this a ram overflow that caused the crash that you referenced earlier is it a CPU throttling is it paralyzable does it require temp files like what in theory is happening with a computational complexity and the exponential blow up and then what in practice is going to facilitate this kind of analysis to scale okay so first thing like this complexity analysis was done in terms of the space which is required to store all the parameter of the you know distribution of the states okay so here we are really interested in how much space do I need in order to store all the distribution of the states like all the posterior distribution of the states and but if what happens uh in standard active inference is that the number of policy that's will be available to the agent so let's suppose we have two actions we have one here one here okay action zero action one here at the first time step there are two actions at the second time step that we deformed black policy basically that the agent can um can actually perform it can go for zero zero zero one one zero and one one and this number of classes will basically be multiplied by two each time step uh like for instance on the road right because each time we can now click each of the action again for each of the previous processes and this exponential growth is quite problematic for for example the prior of a policy social member um this definition for the prior of the policies we see that in order to define the prior over the policy we need to confuse the expected free energy for each of those bonuses but we need to do that for an exponential number of them as uh the timer wasn't applying increases so this is the first problem and also this explanationally exponential explosion is not limited to the number of policy because we still remember okay so maybe for this one I need to go um and look at the variational distribution which is used in buyer style inference but we see that the number like the biracial posterior of the states depends on the policy so for each of the policy we need to store a distribution of a state and this is once again a problem because there's an exponential number of policy which means that there is an exponential number of of stereo that we need to store so this is the kind of problem that appears um within um standard Arctic inference the number of policy is growing exponentially and we also need to store the distribution of a state for each time step now where launching time active inference becomes useful is that it uses a structure like there's a graph structure to avoid to have to store every single single possible combination of uh you know time step versus policy and so this those two we see that is growing linearly is because we just keep in memory one distribution for each state in the past and presence and only when it comes uh the current time step do we start imagining what's going to happen in the future and this growth is still exponential like if we add if we had to explore every single possible polar in the future we will still have an exponential growth but because we are using multicarage research basically we are going to only explore a small amount of the tree and this is where the complexity moved from exponential to linear into the with respect to the number of expansion of the model so each time we expand a new branch in this model we need to store one more categorical for this uh future timestamp that's good and so this is how uh like we can move from an exponential [Music] complexity plus into linear one with respect to the number of expansion of the generative model so that was for the capacity class in terms of Hardware it was basically just on my own computer uh some real critical uh GPU used nothing like this just CPU basically very interesting and on the hardware or on the implementation side where do you see packages in python or Julia like Forney lab and the reactive message passing Paradigm being developed or do you see gpus as being relevant like this is the storage consideration what kinds of scaling relationships or in theory and practice how are the operational aspects of the Computing rather than the space requirements computed so the first thing to say is that the space complexity is also linked to the time and you know computational complexity and because for example as I said when I was speaking about the the prior over policy if we have an exponential number of products you need to compute an exponential number of expected free energy on each of those policies so and same thing for when it comes to the posterior when we have to store the Via style posterior and that there is an exponential number of them then we also need to compute them so this will also become extractable in solution and um in terms of implementation I know that's some people have been developing a phone lab in in Julia I've been providing my own implementation in Python um so yeah those are possibilities in terms of uh gpus I guess their usage will be um really useful only if the isographical model allows for parallelization for example one case where the gpus are very useful is for images because each position in the image can generally be processed in parallel so if we had like an alternative model where we had I don't know likelihood mapping purchase 4 pixel next to each others like a patch in the image and we had to compute the all the posterior for all the image then there is a very large potential for parallelization but if for example a message as a dependency on a previous message then there will be um just a part of the GPU which is just waiting for the input message to arrive so there is also um basically limitation on that because some of the analytical solution requires some other messages so there are some dependency throughout the dependency like the the graphical model by the way so using GPU yes but probably in specific generator model for which it's useful such as image based generative model or um so yeah discount if we have something which is very simple then I think it's not going to benefit a lot from gpu's complication excellent thank you [Music] um Ali again or Jakob if you'd like another question or I can ask one yeah I also wanted to ask about the different um the possible future implementations of branching time accident Prince because um Daniel and Jacob knows know that I'm a big Julia fan so I wanted to know if there's a plan to have a jewelry implementation a branching time active inference because I think we already have a C plus plus and python if I'm quite right the first branching time active inference was implemented in C plus plus and the multimodal one in Python so what are the future plans for uh the other other forms implementation of btai so for now I was just planning to just use Python um but I guess it should not be too hard to report it in Julia and just for now I don't have the usage voice um let's share that and also for like future possibility when it comes to punching time active inference I've been starting to work on trying to implement a slant algorithm um so this is a simultaneously location and mapping so that if we create a map of these environments as we navigate through it so this is also like a possibility but within this uh context basically I was going to go exponentially that we can have observation that depends on a very large number of states and therefore what we need to have is more like a conditional probability table which is stored as a tree so it's biologically um you can encourage rules with interconditional probability table for example you have a school that you have okay probability of C given a and b then maybe if a is equal to 1 you want to have a branching on B and then we have 0 1. and maybe this is real points okay nine okay so what this means is that if a is equal to one and B is equal to zero then the probability distribution of a c is going to be 0.1 for the first value on 0.9 inches for the second value and so basically says the idea is to try to not represents the entire table but choose a tree structure to uncut rules about the dynamic of the world and the likelihood function as well and then the challenge is to be able to perform forward prediction from this tree and in France also from the stream and so this is another picture which may be integrated inside um which UI in the future definitely a theme that runs through a lot of these discussions is representing objects as trees and then taking the tree turn or in the forest turn seriously because the tree structure allows us to avoid redundancies and enable some new types of analyzes Jacob do you have a question or I can ask one yeah uh maybe um continuing on the slam thread I'm wondering whether uh you're consider considering the application of Slam to the um image classification problem and perhaps how the image classification problem needs to be reframed to even fit this uh well first of all branching time active inference scheme but overall active inference scheme because um it seems that active imprints overall is much better suited to these kind of continuously evolving problems where the generative process uh changes whenever um the agent takes actions whereas an image classification problem seems to be way more static which uh at least in the in the machine learning scheme it's just input and output and then perhaps uh some um error um that gets back propagated through the network um so I'm wondering how you um how you are thinking about um image image classification with uh active inference and overall just how images can act um as input in in um dynamical environments So yeah thank you for the impression once again um this uh so basically the thing with like image classification is that we don't have this stopwatch structure like you just mentioned which make it quite difficult for an active in France engine to be applied to this in some sense it's a bit like the transition mapping is is like an identity function in some stuff like um yeah it's a bit difficult to think about how you can bring it but yeah because each time step could be one image for example is a classification um but I think active inference is just not really well suited to to something like this for classification I think they are like just classification models like you know whatever resonate or whatever which are much better suited um basically if you had to apply active inference it would have to you have to have to change the structure of the model uh to remove that it is a top wall uh transition and just to have observation and otherwise you will need some kind of dynamic or violence like the Atari games black manuals kind of of a thing or like the despite environments and in this case you can model the temporal dynamics of the environments and so here active influence really helps because you can you know think about action and how they impact the transition and you can have so basically an encoder that will compress the image so you will have technically an image here you will have an encoder networks a bit like in a via channel to encoder that will produce a parameter so the mean and a variance of a distribution of the states and then we will have the decoder over there which produce another image from the latent variable basically and then we will have here like a transition Networks which is also a digital networks which outputs as a mean and variance of a distribution over the state as a next time step and yeah and then here you have another encoder for the future image and another decoder for the the future image as well and these transition networks will have to take into account basically the action as well as the states to predict the next state so that's the kind of architecture you will need to create a deep active inference address and I think it's better suited to Dynamic environments like attack against identities or static environments and this is indeed a lot more complicated to apply it to if I could give a few thoughts on image slam very fascinating point about static analyzes and dynamic analyzes and so what are some ways that we could pseudo dynamicize the image classification task so a few options one of them is navigation amongst large databases of images so potentially choosing informative examples for training in large empirical image databases or frames from video or in a dynamic feedback with prompt engineering for AI generated images so then it makes it into a dynamic question response task that would be using Dynamics at the level across images but still taking in the whole image and one other approach could be building on some of the oculum motor active inference models of attention only taking in a small amount of the image potentially reducing the state space or the computational complexity vastly and then making the Dynamics of some lower level entity related to policy selections on eye movements or attention and then treat that as like the lower level of the slam and the classification what kind of image am I looking at as a higher level of a slam but the policy is being enacted at the level of which parts of the image are being scanned right yeah that's indeed a very nice setting for other ideas which require registration as a task uh but as indeed bring you much more like much better suited to active influence um so very interesting I wanted to also ask about um two modules or functions that various other active proposals have had which are hierarchical nesting of models and learning so how do nesting and learning influence the theoretical and the realized computational complexity so I think like I think you actually can really help but use a computational complexity of an active infants agents um for example one idea would be to so I was speaking about generative model over images uh imagine you had like an image and then so an image can be like it's millions of possible combination rights like not even more than that but probably more than atoms in the universe but what you could do is like a bit by imitating the structure of a convolutional neural networks maybe you can create over patch of pixels a generative world that we extract for example different line patterns so maybe uh horizontal like or diagonal lines or horizontal lines and we will have a first level of your the hierarchy which will extract those informations and then you will have you know pattern of patterns and so on so forth I think you can create this um you know as a categorical distribution but in a VR other model basically it's a very beginning you have pixels and then you have small edges and stuff like this and combination of edges and all the way up basically to to having objects um but this is very complicated like um in terms of implementation we will require to like probably use GPU for the inference process because there will be very large number of patches so we will need to speed up the training but still I think this is a very good way to reduce the state space of the of the agents because if you try to to basically put an image as input of a standard active influence agents you will have to have like yeah like more possible images and numbered or pattern in the universe even probability with small images so hierarchy can really help on that um and so you had another question right other than uh this the second aspect was about learning for example what if we update our priors as the tree continues or we want to consider policies on priors or other types of updating of our different parameters that might be fixed in other settings yeah so one thing to say about um having learnable prayers is that in some cases this could go really wrong so if you don't like okay imagine you have observations and you have States so those are the observations uh or sorry this is the states and this will be the observations so three possible States two possible observations and if you start with a Jewish layer prior which is just fully uniform so maybe the parameters are all one everywhere well what's going to happen is that if you make one of the observation it's just going to give you as much um like the entrance process within her uniform distribution of the states because the weights within the Matrix are basically all one so there's for each observation there is no real like state which will be more likely to to basically generate it which means that the inference process will have a uniform distribution of a state and basically this is a problem because what you will end up having is like a a matrix where maybe some states are more likely but each state is not more likely to generate different observations and so basically there is a failure of learning because it's just not able to like if you happen again so if you remember the way we update the parameters it's just by counting the number of states observation pair that we are being observing and if the state which is observed is already is always like one point like one third for example like it's a uniform distribution then it's going to count one third of the observation for all the state at the same time and we are not able to identify which states has been able to generate this observation because they are all as likely to generate these observations and so what is going to happen that you deviously just cannot learn which states generate which observation is just countings in above time a state has appeared but not you know with respect to observations so this is a Visionary case which shows that adding matrices for example with derivative and stuff like this can fail to ruin the dynamic of the environments and the likelihood of the environment as well so maybe having digital networks can you know avoid this problem uh but yeah it seems that's a real challenge like learning the parameters within electric influence model seems to requires like a human to cross give it a first drafts where the likelihood like that's a cryo is not uniform when it comes to the Jewish flag if the model is to be able to run so this is one of the challenge for learning in active influence it's something we've come across in specifying the state space and what policies are possible and it it's an interesting conversation because it brings us as modelers into engagement with the model and helps clarify where are we setting scaffolds and constraints what information are we what manifolds are we placing that agent into that set it up oh it's rolling downhill within some super local context even if that local context is still enormous in its state space it may still be just the tip of the iceberg in terms of the total model structures and that's not even to say we need to explore the total model structure in practice but in theory it's quite important or we might just be looking where the light is and putting the rabbit in the Hat making these models that play out a certain way maybe even deterministically because they've been kind of told the secret in the beginning um I have one more um question and then and then I'll your jaka so um you juxtaposed and contrasted three different approaches which were variational message passing Bayesian filtering and belief propagation and whether for didactic or pragmatic use where do you see these different approaches as being useful or specialized yeah where are they better or where is one a generalization or a special case of another so for example so the way we structure the model in bias language especially that we keep track of the past and each time we get new observation into the inside of into the future so let me maybe just go here um oh no yeah so okay so invest time is expressing for example we keep the past and this is quite interesting because when you have biochemist passing you can also have backward messages which means that as you get a new observation you will have a network like the state Associated to it and what is going to happen is that you will have a message like this and you will also have message that go backward in times and this those messages will enable you to refine your understanding of what happened in the past so this ability to revisit like or you know update your understanding about the past is something which is quite uh specific to the various time massage passing algorithm and does not appear for example in base and filterings in the Basin filtering setting because we only keep a belief state of of the current random viable and when we expand like when it gets a new observation and a new state Associated to it we are just going to perform prediction to get the posterior and then we are going to get rid of that so we cannot have those badboard messages um to address for your beliefs over past States so we can't really have this kind of counterfeitual abilities now with the belief propagation algorithm that it is very similar in ID to what is done uh with the belief propagate in the belief propagation settings it is just a more scalable approach which enables one to have a different item States and different observation because this ptibf approach was only restricted to one observation and one States and if you have for example the X position neutral applications of text of as a displayed environment then you will need to create one random variable that corresponds to all the combination of those X and Y position so maybe it will be the random viable describing the position and if we had two value for each of the you know for the exposition and the Y position then all the combination will be like or each of the value for one times all the password and and this goes exponentially with a number of variables so let's suppose we are now scalable and that this can variable can take two additional values then the total number of combination of those three random variables will be like eight eight possible combination basically all the X and Y position or h of the two scale possibility maybe scale 1 and scale two and this exponential growth becomes fully magic if you don't have this ability to have several observation and several States because you will have an expansion growth in the number of state and observation you try to model and this is where really Alexa the other approach multi multi-factor and multimodality is really uh useful to scale to more complicated approach with more States and observations excellent are there Jacob any closing questions or thoughts uh well uh you see I came across your work a few months ago and it got me truly excited so much that I read all five of your papers uh is it is the number five rights I mean uh you published yeah five papers up to notes uh because you see more often than not people see active inference and uh the free energy Principle as uh basically speculative uh thinking and Endeavor without so much pragmatic value in the real applications so in my opinion uh your work as I mentioned there's a very welcome addition to this uh nascent yet exponentially uh growing feel uh and I hope to see uh more exciting developments in the future for branching time active inference or possibly the other uh variants you might come up with in the future uh and uh I'll definitely keep following your work from now on exactly thanks so much for your joining us today oh no problem thank you for inviting me I'm really excited I could present here so thank you for the invitation Jacob any final thoughts yeah uh well this has been a really great presentation and discussion uh Ali also uh linked uh your work a couple of months ago and also uh got me very excited for uh for the um future of active inference modeling and it's a it's a topic that we're um discussing uh quite a lot in the in the Institute and um I think that this approach to reducing the computational cost of of uh of perform of Performing um active inference in more and more complex State spaces is probably the best way to go uh to really um reach adoption of of these models in in different in different domains so yeah I'm thank you thank you very much for uh for joining today and uh I look forward to reading that paper on on the Deep active inference deep branching time active interns sure thank you well you're welcome back anytime and we will um certainly be observing thank you sure thank you bye-bye thanks bye perfect yeah great brilliant