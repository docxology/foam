hello everyone welcome to actin flab live stream number 25.2 today is july 13th 2021 and we're going to be talking about this paper the computational boundary of a self developmental bioelectricity drives multicellularity and skill free cognition we are here with the author mike levin we are a participatory online lab that is communicating learning and practicing applied active inference you can find us at the links here on this page this is a recorded and an archived live stream so please provide us with feedback so that we can improve our work all backgrounds and perspectives are welcome here and we will be following good idiot video etiquette for live streams here at the short link you'll find all the live streams that we've done so far and we're going to have a new series of live streams coming up in the next semester so we're going to be jumping off here with the author uh discussing this paper and we will just do a brief round of introductions i am blue knight and i am an independent research consultant based out of new mexico uh yeah my name is sarah davis i'm a master's philosophy student at this point um past engineer and science artist just generally interested in how the world works michael yeah i'm mike levin i'm a professor in the biology department at tufts university i run the allen discovery center at tufts and i'm also a associate faculty at the peace institute at harvard cool so sarah what is something that you're excited to talk about today or something that you'd like to remember about the paper maybe want to give a heads up um the most interesting kind of through line for me in in all of michael's work that i've looked at is this um connection or this um maybe tension i don't know the way the the morphology plays with electricity just um yeah which one's in the driver's seat or some kind of like understanding of how those two work together awesome is there any like burning questions that you have that you want to start off with or otherwise i can just start oh no i feel like that is going to kind of happen down the road that particular focus so please yeah okay so here we are on the paper we're going to be discussing today how do multiple nested scales of individuality work yeah um so i i want to preface this by saying that and maybe maybe this is obvious but i just want to say that all of this is very much a work in progress so i'm going to tell you what i think about these things but uh i certainly am not claiming that this is all worked out or that i'm not going to change my mind at some point or uh you know that that this is not going to develop in some fashion this is under under um you know constant constant work so i think the fundamentals of all this are simply that there are multiple interpenetrating systems at different scales that are all present simultaneously all of which can be profitably looked at as uh as as individuals and so this diagram here sort of it it looks like all it's saying is the the mere sort of fact of um physical structure if you look you see organisms and within that you've got organs and cells so so that's not the you know that's sort of not the whole point of this the point isn't merely that they're arranged this way but that you've got some units and those subunits have themselves subunits all of which are cells and what i mean by them being cells is the central claim of the paper is that they are to some extent so so not not binary but on a continuum of agency they are to some extent goal uh directed uh agents so they're trying to achieve certain themes and so when i say that they're nested all of this simply means that you can have systems where the different parts are all actively trying to achieve various things in their own spaces and we should talk about that that's an important part that developed since this paper was written is this idea of different action spaces that these things are working in um but but they're nested in the sense that i think just because a higher level system acquires a goal or is pursuing a goal that doesn't mean the lower systems aren't doing it and uh all of these things are in fact simultaneously doing their best to pursue various kinds of goals so that's what i meant by multiple nested individuals awesome so is there a total 100 of individuality that gets partitioned and something that i've been really interested in is how is information passed forward and backward across levels like is there some kind of core screening or um like salience like dominates the information to pass forward so how does that kind of information flow work yeah so so the scaling and the relationship between layers is of course one of the most interesting things here so one of the things we are currently trying to do both experimentally and with modeling is to really show some very tight examples because this paper is largely qualitative but we're now trying to show some very specific examples where you where we can we can actually track the scaling so so you have lower level subunits so let's say you have cells that have only local metabolical so all they know how to do is pursue some some energy level in a kind of homeostasis to stay alive and so the question is how do you connect those in a way that is then going to give rise to a larger agent that has much larger scale goals that can be uh working towards a a state of affairs and and to be actually stressed by the failure to reach a state of affairs that is way bigger than any individual cell and so i'm not sure that there's any kind of conservation here in the sense that there's only a total amount that you sort of have to partition it among the levels and and that's all that there is i'm i'm not sure that's yeah i would i would make that claim i think that um the total amount of individuality can change over time and it can rise and fall and in fact the boundaries between the different agents can can grow and shrink that's a that was a significant part of the paper to talk about that um and what there's a couple of there's a couple of interesting things that get passed upwards so to speak um definitely a kind of force graining in the sense that if you are a system whose parts are themselves competent in getting various things done despite changing conditions and and so on they're not just the hard-wired mechanisms but actually competent to pursue specific outcomes despite perturbations what it means is that the larger system is now working in a much easier space in the sense that it's if it doesn't have to micromanage all the micro states that that the individual pieces are doing but it can rely on those components to get there to get their job done then what you're really working in is a much is a much lower dimensional simpler space where problem solving gets easier and just as a simple biological example you know we now know that uh for example in the in the tadpole if you uh if you activate uh a signal that triggers it happens to be a bioelectric signal that that triggers eye formation in another part of the embryo let's say on the tail then all kinds of interesting things will happen it will it will build an eye it will recruit cells that you never directly manipulated so it's a local self-organization process that eye will form even though it's sitting in the middle of muscle instead of in the brain where it where it belongs all these things are going to happen anyway if you're if you're at the larger and by the way those tackles can then see out of that eye even though it's on the tail instead of in the head so if you are a system that um needs to solve some problems in terms of uh i've got some eyes and i need to do this behavior that i'm doing and so on if you don't have to micromanage all of those components and saying each cell of that eye where exactly it's going to go what exactly it's going to attach to and so on if if there is an effector that you have access to an affordance maybe that says build an eye and you as a larger system don't need to know how that's going to happen you can just trust that that is going to happen under a wide range of conditions you have a much simpler space to work in and the problem solving that's one of the things we're doing now is trying to map out some of the different spaces in which all these different agents are actually solving problems and trying to define what that what that means uh so one of the things that that gets that gets passed up is this is is this uh coarse graining because of the lower level competency so that that's i think a key thing and maybe we'll get to talking about what that does for evolution because i think it's massively important nice sarah i don't have a unfortunately they've moved to change the interface so i don't know where the hand is anymore in this but um one question that keeps coming up for me in in all the different um realms of discussion about this is like well in particular with the bioelectricity part you know you you use the word um subroutines when you were talking about you know we we think we're starting to understand the the the whatever combinatorics of of how this works and and and also related to these nested levels and things like this i i just keep wondering if it's your sense from all of this work that you've done that in nature in in in the communication between these levels that there's any amount of abstraction or semantic layer that's needed um for for that to happen uh between uh levels you know and also with the electricity like subroutine implies that there's some kind of semantics um that something has to rest on and i that just keeps coming back to me do you have any sense about that yeah so so a couple of things so one thing about bioelectricity is that um bioelectricity i i think is interesting not because it's in some sense uh you know magical or there's some there's something you know sort of uniquely better about bioelectricity than biomechanical or biochemical um modes of interaction what i think is really interesting about bioelectricity is that that is what is being used and perhaps these other modes too are too we don't know but but bioelectricity for sure is uh being used as the computational medium by which the lower levels um bind together into the higher level cognition so so about the higher systems cognition whatever level it may have so what the bioelectricity allows us to do is to directly peek into that computation and so i think that's why it's interesting um which is no surprise that's exactly when people do neural decoding that's exactly what they hope right is that by tracking the bioelectricity they learn something about the information content of the global system right what is the the animal or the or the human thinking about so it's exactly the same here so that that's what's unique about bioelectricity and i think that uh what evolution discovered very early on is that and and and then it capitalized on that by pivoting it into into neural kinds of systems and we do it in our computational devices and so on is that what evolution found really really early is around the time of bacterial biofilms actually is that electricity is a great way to process information to integrate information across distance and to do computations right now that shouldn't be a surprise to anybody so um i don't know if i would claim that it has uh you know any kind of a formal syntax at these levels or anything like that but what it definitely does do is a kind of when i say subroutine what i'm mostly leaning on is this idea of modularity but not just modularity in form because that's been discussed a lot in evolutionary developmental biology but actually modularity of function so so the key the the thing the thing about a good subroutine is that you're going to when you activate the subroutine you can move along and assume that everything that's necessary to get that job done given whatever local conditions or current events whatever else is happening that subroutine is going to encapsulate everything that's needed to get it done meaning it's it's it's not just it's it's it's the difference basically so for people who code it's the difference between sort of macro substitution where all you're doing is just you know it's a shorthand for a bunch of hardwired steps which is plopping that in i don't think that's the the magic here at all i think what it is is is uh it's a degree of competency in that subroutine to get something accomplished and and that that has really uh really important implications for evolvability and so on and what the bioelectricity allows you to do is to uh basically to have um to have a language in which the system can call up such such circuits with specific behaviors um at different points or at different times that makes it that makes it really really powerful but um the question of whether it has you know any kind of uh formal syntax or anything like that i don't have good evidence for that i don't even mean like a formal syntax it's it's almost like it and and this also you know holds true between these layers of these nested layers of organism or whatever um is is if there's if you have a sense that there's any abstraction there's any abstraction layer needed and i guess you kind of answered it maybe by saying you know that electricity is this medium on which um things communicate or but yeah anyway that it's i don't think it's an easy it's like you know easy to answer question but that's the theme that keeps coming back to me so i i think there's a lot of abstraction in the sense of in and and i don't know if this captures what you're asking but but there's a lot of abstraction in the sense of generalization um in terms of um another way to another way to say is is is is corresponding voltage itself let's just start with that voltage itself is an abstraction for cells because and in fact people will often ask if i say you know there's a bioelectrical signal they say well is it the potassium level is it the sodium level like what you know is it the particular ion channel gene is the voltage or is it the current yeah yeah and in particular with so so the cool thing about bioelectrics is that with that question has been answered and we know we know the answer it's it's neither of those things so so it's a pattern of voltage that is specific for the downstream effects and it doesn't matter how with very rare exceptions it doesn't matter how you got to that voltage so you can use sodium channels you can use potassium channels chloride what ion used all those micro details don't matter at all because what the collective is keying off of is the spatial temporal distribution of voltage and you can get exactly the same results with sodium or potassium or chloride as long as you're you know you're you're driving the right voltage patterns so voltage itself is a really cool abstraction because it means that all the downs the underlying mechanisms are free to diverge in evolution you want to swap out a potassium channel for sodium channel you can do that as long as uh you've got the right of functional properties so that your you know your overall pattern stays and we use that quite often in our regenerative medicine applications with a really convenient um convenient property so so yeah so so the bioelectric code itself is definitely an abstraction over uh what the microstates in terms of specific ions or the specific channel genes that got you there nice stephen did you want to say hello yes hello hello hi there i'm michael thanks for joining us yeah i was curious we had a really interest chris field gave us a really good insight into the quantum contextuality idea of how things could build up from different sort of space states at very small levels and active inference often uses non-equilibrium steady steady-state attractors as kind of a way to look at some sort of statistics between the scales you know there's some sort of flux or um flow that's inferred and i i find it really useful thinking about it with this cone idea that you you bring to the table because it it there's more it's more of an idea of a distinct um swarming going into a structure and some sort of system that might emerge from that which is sometimes lost when it's very much in the math um and i'm curious um whether when you think about these um the bi-electric effects and the same sort of question came up with quantum contextuality maybe is is is there more of a distinct scale at which there's a coherence you know like you've got the cell membrane then you've got a coherence around which the bioelectrics can operate so to speak and then you might have another distinct level at which um the bioelectrics can operate which is maybe more than the more gradated idea of steady state statistical um sort of manifolds so i was wondering what your thoughts are about how and where there's sort of scales at which the bioelectrics become particularly um coherent or if that even happens yeah i mean so so again prefacing this by saying that the the bioelectrics is not an essential part of the story in except in so far as i think morphogenesis and is is a nice example of an unconventional agent within which to uh play with these kind of ideas you know what so so what i would like to do and and this is um a framework that i've been developing recently is to get away from the standard sorts of living creatures that we're used to right so so the products of that one trace of evolution in the in the biosphere on earth and to go beyond that and to look at the space of possible agents the space of possible bodies and the space of possible minds that those bodies will support and think you know think more broadly so in in in doing that um what i think the bioelectrics in morphogenetic well i think that morphogenesis is a nice example of an unconventional agent that lets us see how the framework is to be practically applied right so so people say okay this is all well and good but what what you know what use is it okay let's let's apply it to a specific thing then really no one thinks of as a as a cognitive agent i'm going to show you how all this stuff maps and why it's useful at the bench and it helps do new experiments and so on so if we if we accept that morphogenesis is kind of a test case for and there are many others it's certainly not unique but it's a test case for an unconventional place to find um agency and all of that and to test out how well this theory helps us out then what's cool about bioelectricity is that it actually allows us to tell a very specific mechanistic testable empirically useful story about how the information flow happens and how the levels scale but it's just one you know it's just that that's just happens to be how the morphogenetic um self does things and there are plenty of other interesting you know cells that wouldn't have anything to do with bioelectricity i just want to make that make that clear right the bioelectricity is not so you know some sort of essential um element that's always going to be present whenever we apply these things it's just sort of it's central to this to the to the example case that i've trotted out which is which is morphogenesis now having said that bioelectricity is definitely multi-scale because you have uh you have you have bioelectric dynamics in organelles in a very small scale you have uh the resting potential across the cell membrane which is mainly what what we study but those scale into tissues and you have global electrical fields which are driven by trans epithelial potentials on the scale of tissues and organs which other people like mensau and many other people study and then past that you have whole animal scale like whole body scale uh fields as well so all of these different levels you know exist uh some of them more and some less rely on bioelectricity but um yeah it's it's it's relevant in this particular unconventional agent it's it's relevant to all the scales that we as we know okay that that's really helpful thanks and and would you say that the the cone concept could have extrapolated to other types of multi-scale piston blanket type ideas um and i just wonder what your thoughts on that or whether that just confuses things to try that but um no i don't think it confuses now i should i'll i'll i'll say i'm i'm for sure not i mean i i like uh carl's ideas very much i'm by no means an expert on the map and i'm not gonna pretend that i understand all that but um i i think that the the thing about the thing about these kind of diagrams is they're not to be they're not meant to be unique or exhaustive so with the goal of this originally this this came about um a couple years ago um at a templeton meeting where we were asked to brainstorm ways to define almost a sort of ident space where you're you're able to compare directly really diverse intelligences right so so things where you don't you can't just uh measure all their brains and then see how they you know how they shake out it's it's really really diverse intelligence and so it's what i tried to come up with is uh a scale and and it's all focused around uh the the spatial temporal scale of the goals that any given agent can work towards and and the scale of um states of affairs that can be that can stress out that agent when they're not being met and so on uh as a way to uh pick on something that i think is central to all ages no matter what they're made of no matter how they got here evolve design combinations chimeras whatever wherever they came from and whatever they are what is essential to them and and i picked this this goal directing this but but this is compatible with all kinds of other systems so you could overlay on top of this almost anything else that you thought was critical about being an agent just start adding dimensions you know and and and absolutely right now you can you can just you can this this is compatible with all sorts of things this is not meant to rule out any other anybody else's you know favorite and favorite framework they're saying it captures one slice of what's essential about being a self thanks that's really useful actually can i just one more thing blue i just was i'm actually really interested in this i do a lot of work with community psychology um so there's this challenge of going from the cell there's like the self and then there's society social but the inter-subjective kind of group dynamics is there's a big problem because it's like a big hole because it and and this i find it's really useful because a lot of stuff which talks about how groups they often try to project out into the future as if it's a light beam that you could measure whereas here it's much more you know like it's sitting in the swarming i like to think the bottom of the cone is almost the swarming dynamics that go down into the past you've got the kind of structure of the cell that's emerged and then the system that's able to go into temporal depth in the future in the code and i think that that offers a nice way to think about group dynamics particularly maybe the more di ironically the more challenging group dynamics where there isn't a coherent single narrative so there might be applications there yeah this is this is so super interesting and i should i should say one of the things about the cone and we had a discussion about this yesterday um and pranav das pointed out that my cone compared to minkowski's coin is upside down right it's it's uh and the reason i did it this way was because if you think about um where where any any given agent the only thing the given agent is really certain of at the at the moment is what's going on right now so your future obviously is is uncertain and when you're trying to predict so so let's say you're trying to manage goals and and you're trying to predict you've got some predictive capacity going forward that predictive capacity doesn't get better over time it gets worse over time right you're you're you're sort of exponentially more uncertain about what's going to happen later on so your ability to pursue those goals in the future get smaller and smaller same thing goes back in the past although you could argue that that's linear and not exponential but again what you're doing at any given moment in time is inferring what your past was from the engrams of memory that are available to you they may be a brain they might be a stigmatic a medium that you live in on the you know within if you're in a company colony whatever it's going to be you've got some kind of material in which you leave me in which in which events leave memories they leave traces at any given moment you are reading those traces recalling them and reconstructing what you think the past was that's your only evidence for what the past you know any given moment what actually and so and so you and so and so even going backwards my cone comes down because your ability to um to go backwards in time and be certain of what went on and when what are what are the facts on which you can now build your goal directed strategy going forward become more and more uncertain going back so so that's that's why my you know my cones are are upside down in this in the so to speak because also because there's no particular reason this has to map exactly onto you know minkowski's informalism but but i think it's close that just because that that that your your level of certainty is highest right now right both in space and time and anything when you step away from that it rapidly you know at least for all of us rapidly um get smaller yeah we were really actually talking about this last week in our discussion and we were kind of thinking about this as like an information cone because you have the most information about your environment at this point in space and less information as you go forward and backward in time so do you think that that might be the the correct way to think about it so so that's true it's def that's absolutely true it's definitely also an information point but i want to be clear about this because um this diagram is not a diagram of what you can sense or how far your effectors range this is which this is um the the the what you just said about the information certainty is uh the the consequences of that are that you also have a limited cone in what the diagram really is supposed to show which is the scale of the goals towards which you can work so so because the information is smaller your ability to pursue goals towards you know how far into the future are am i actively you know doing it just it just becomes limited right your your ability to do so so it's sort of a secondary um a consequence of that but but i just want to be clear that this is this is not meant to be fundamentally a picture of the information certainty of sensory capacity of um effector range or anything like that this is this is a diagram in um in gold space nice so one of the other ways i've been thinking about it is kind of like a possibility cone so like as you progress forward into the future we all are left with one possibility and that's like death right so your goal at that moment is death um and similarly in the past like we all come from a single celled like you know fertilization event and so like we all started an event and ended an event and like the maximum possibility is is now so what do you think about that yeah i mean so so that's a really interesting point right and people talk about you know great transitions in uh in in cognition along the continuum and so on and so i think one great cognition of a great transition is the following if you are a creature with a horizon with a with a with a cognitive horizon of you know a half an hour your goldfish or something i don't know if this is factually true but you know you're some you're some sort of um form that has a cognitive horizon of a half an hour right what that means is that all of your uh major goals survival and these other things they're totally achievable right because it is completely plausible that you are going to make it for that half hour that you can project forward if you are a human and your cognitive horizon your your goals are you know i don't know world peace or your buildings you know the larger things you are for the first time perhaps along the earth's lineage anyway you are able to to to uh comprehend goals that you have no chance whatsoever of achieving because you because you because you have a limited lifespan so now that's and that's a that's a really sharp um transition you know kind of an emergent transition because for the first time you are able to undertake goals that you know you are not going to complete guarantee right whereas the fish essence you know maybe you'll get eaten and maybe you won't but it's totally plausible that you you know that you live for the half hour that you can see forward for the very humans have that and so i suspect that this is uh and this is you know sort of way above my opinion to know details about this but but i suspect this drives a lot of um the weird facts about human psychology because you now have this fundamental stressor that other creatures don't have because you're able to foresee all these goals that you are definitely not going to to meet and and that's that's a novel you know sort of um a conflict between the different modules that that doesn't exist doesn't exist for i think for most other creatures yeah that's really interesting you know something that i might be like uniquely human is like this possibility to see past like the cone of our own existence like into the future uh with these like future possibilities or future goal states and also like backwards into the past in like a historical sense so we all like look at history um so i don't know i like thinking about like you know i've just been reading your recent paper this integrating evolutionary developmental thinking into scale free biology this paper with chris fields um and i know like when we spoke yesterday you mentioned you were integrating these ideas maybe into your next paper but in that paper you guys were kind of blurring the boundary really between the processes of evolution and development and you know phylogenetic memory that's contained in dna and results from evolution like transforms into this onto genetic yeah yeah definitely so so there's a couple of really interesting things related to that to evolution that we that we can talk about and that's that's something i'm working on now and this thing should be done then in a couple of weeks and then we'll see um two things number one um one of the things but one of the amazing things about biological hardware that that's given to us by evolution is that it is there's a default way by that i mean cells but they're genomically determined proteins whatever they have uh there's a default and a pretty con robust consistent default outcome right and and so so embryo you know fish embryos make fish and progress make frogs and so on but there's an incredible amount of plasticity there so that those exact same cells genetically wild type so the hardware is all the same are in fact in other types of environments are able to make completely novel um creatures right and so some of this so synthetic synthetic biology and synthetic morphology is already showing this we we you know as our zenobots and things like this and then there will be tons more going forward that what's interest one thing that's interesting about those novel creatures is that you don't have a long history of uh select specific selection and frozen accidents and all this you know phylogenetics to uh lean on when you ask why do they do certain things right so for every normal animal in the in the biosphere you say why is this thing you know green and why does it fly and how come it has these antennas the answer is always the same well because for millions of years the ancestors were selected for this event the fact that we can take those embryos those cells rather cell cells from from from those kind of animals and put them together into a new creature that has goals and behaviors more morphological goals behavioral goals physiological goals that basically appear overnight you know within 24 48 hours they sort of show up um and then the then the question is where did these things come from because what they didn't do was uh to be honed over millions of years by specific selection pressure so so that that's a very interesting to me to me aspect of the plasticity here that it is not you know they the history doesn't necessarily determine them other than the default you know sort of variant and where does that come from and then there's a whole thing which you know i don't know you can tell me if you want to dive deeper into this or not but the whole um the fact that you have multiple layers and that you have competency going down you know sort of all the way down has massive implications for why evolution works so fast right why why actually anything is able to evolve on the on the time scale that we see so i think you know if you're interested we can get into that yeah that's great why don't we uh unpack that okay um yeah let's let's let's talk about that a little bit um imagine imagine two kinds of creatures and uh you've got one kind of creature where the genome has a pretty direct um influence over what the anatomy is going to be it's everything is hardwired in some in some sense and so let's say let's let's let's visualize you've got let's let's say it's a you know it's a frog of some kind and uh and and and there's the genome and it makes a frog and that's what it does and so now now we imagine evolution is sort of searching the space and now there's a mutation and the mutation does two things uh because most mutations do multiple things let's say we got a mutation that there's two things it it moves the eyes off kilter right and it also has some really beneficial uh effect somewhere else you know it helps with some other things most mutations are clear tropics so it's it's um it's a reasonable reasonable conjecture if you're if your animal is uh the hardwired kind the eyes are in the wrong place nothing works you the evolution never gets to explore the positive benefits of this other mutation because the thing's going to be dead you know it's just it's just not a workable animal anymore the fitness is very low it's gone and so most when if you think about these kind of hardwired things it's the same when i when i first you know now 100 years ago when i first heard about how evolutionary algorithms are supposed to work this idea that i've got a system that does something i'm going to start throwing random changes in anybody that's written any code that they are you crazy of course everything's going to get worse not better that's never going to work now imagine imagine a different now of course it works but it takes it takes massive amounts of time and and so and there's all these difficulties about evolving complex things now imagine what we actually have the actual and i'll explain the the biological um example that's when you have you have a tadpole and the temple has to move all of its uh oregon's craniofacial organs around to become a fraud so the jaws have to come out the nostrils move the eyes move forward like everything all this stuff moves around and you could have a hard-wired animal in which every every organ moves in the right direction a particular a distance and that's it right and that that's you that's your hard-wired thing that actually is not what um how animals work so so if we and so what we did a few years ago is we make what we call these picasso tadpoles the idea is you make these tadpoles everything's in the wrong place the eyes are on the back of the head the mouth is off to the side the nostrils are up here like it's just scratched like mr potato everything's scrambled so if it was a hard-wired system then all of these things would move the traditional amount in the traditional direction and everything would be way off because you're starting in the wrong spot instead what happens is that all of these organs move in novel paths and they keep moving and sometimes they overshoot and have to come back but they keep moving until they build a correct frog face and then they stop moving so now that system so so what the genetics actually gives you it doesn't it doesn't somehow give you a hard-wired set of movements what it does do is give you an error minimization scheme that can progressively uh deform the system uh until the error from some sort of set point and we've been studying you know what the set point is we can talk about that uh until the error with from that set point gets to an acceptably low level so what you have here is a competent set of craniofacial organs that are going to move around and and get to where they need to go even if they start off in the wrong position so now look at what happens with evolution right you got your mutation the the eyes and the jaws now are off in the wrong place but now you've got this benefit somewhere else the the thing is the eyes and the jaws are going to get fixed you don't need to worry about that because they're going to they know where they belong they're going to get there even though they start out in the wrong position so that aspect that negative aspect of that mutation gets hidden from selection for a while anyway because um and eventually it'll it'll you know it'll catalyze into into the genome itself but but for a while it gets hidden from selection allowing evolution to explore the benefits of of the other benefits of that mutation so so here's all in summary here's here's what this means the fact that you have competent subunits and they're competent morphologically they're competent physiologically we can talk about what that means the fact that they're all competent means that the uh the fitness landscape is is much less rugged it's much it's much smoother it means that uh your um the effects of mutations are much more linear meaning that you can you can examine each consequence uh independently because the other consequences can be masked by by things you know if by the local environment being off it doesn't matter it'll things still get where they need to go and connect and so on so so it makes it makes the search process way more easier by uh by allowing you to and it gives you patience it means that evolution doesn't have to solve every problem at once you don't have to wait until you find a mutation that gives you a positive impact and leaves the eyes where they need to be you don't need to wait for that if you can you can grab the first mutation you find that gives you the positive impact because the i think will get taken care of because because those subunits are confident so it's what raises the iq of the whole system the search becomes a much much smarter search it has it has some patience it's able to see linearly instead of um sort of highly uh um you know mixed up uh all of the consequences of these mutations and it smooths the fitness landscape so i think when you can count on your uh your components to do some of the heavy lifting you don't have to micromanage all of it uh the evolutionary search gets massively more efficient and now it because it starts to become a little more plausible that we actually see this you know this amazing biosphere actually evolved by a process of random mutation nice so in that same paper you talk about random mutation but then you also describe this kind of modularity of gene groups and the possibility of entire gene families like the hox cluster duplicating and driving the major evolutionary transitions is this a sort of non-random process sort of ergodicity breaking with perhaps like non-linear effects when these entire clusters yeah i i hesitate to say too much because i don't think much is known there that i can say definitively i think that you know this whole issue of random and non-random mutations is very um you know controversial obviously i suspect that there is a notion of mutate of of evolutionary search that's not quite blind so so people often will argue you know either they most people nowadays evolution is completely blind you know it just that makes these mutations whatever happens is not because of any uh directionality in the search space and then and then you know you've got you've got you have people who think that it's directed towards a specific outcome i i think there's a there's a sort of in-between scenario where it's definitely not directed in the sense that you can see far forward in the search space but it doesn't have to be completely blind in that maybe what it has this comes out of some discussions i've had with both chris fields and richard watson that that maybe instead of a point in fitness space what you really have is a little bit of a vector you have almost like a comet trail right and then it gives you a little bit of um a little bit of information about direction about you know and and and and you can imagine i mean i can sort of design in my head an epigenetic system of marking things on the dna that give you a little bit of about information well what was this allele last time right so that you can sort of say well i've been turning i've been turning this knob in this direction and things are going well so maybe i want to turn it some more that kind of thing and this is totally made up i'm not saying that that we know that biology actually does this it's just maybe it doesn't then maybe synthetic biology maybe we implement this on you know just for the first time we engineer it but i think it's possible to make a system that does that and maybe um collections of genes and some of the complex chromatin um epigenetics that go on maybe they're part of that process but this is this is total conjecture at this point so sarah i know you have a question but i'm going to use my moderator's privilege here and just ask do you think that this vector-driven mutation could be perhaps driven by active inference some kind of vector between exploration and exploitation happening yeah and so and so one of the things that that we've we talked about i mean that i'm to write after this next thing is out is is is really on this idea that maybe um the whole evolutionary evolutionary lineage of a particular um of you know particular um the animal plant or whatever it is uh maybe that's the maybe that's an agent as well just stretched out massively over space such that each at any given point in time all of the off all of the existing uh uh um examples of that species are in fact hypotheses about the space right and that what you're doing what that what you're doing is is you're constantly generating genomes as as hypotheses and some of those genomes are you know proven to be some of those hypotheses are proven good and some are not and then the next you know sort of the next set of genomes is not completely random but it's in some way uh part of this part of the um active inference of this giant is sort of you know virtual agent right so i think there's a story to be told like that uh but it's way more hand waving than details at this point awesome thanks sarah yeah my comment is now maybe a little bit stale but i think i'll put it out there anyway just for the sake of making saying something concrete because a lot of this feels a bit abstract like um and i'm hoping i'm even remembering this anecdote right but i remember uh learning that some gene once upon a time um that gave us um an extra writer cone in our eye allowed us better color reception also was the same gene that um shut off our ability to make our own vitamin c and um if that's correct if i'm remembering that correct that's such an interesting example of of yeah of course it's an example of the of the fact that genes do multiple things but but it was kind of like isn't that coincidental you know that that this um that that gene is is doing you know both something for the eye but then also making it so that you can get your own vitamin c you know by by looking at fruit and i just thought that was that that kept coming to me as an example of what you guys were talking about um but it's stale sort of thanks sarah i'm sorry for making your comments still uh stephen yeah sort of following on it's this you have this idea of like um a goal space or a tedeological space in a way that's really interesting and then with that exploit or explore you i wonder if there's a time when there's there's a thought about when things are very directed and of course our western thinking we tend to think about a nice pointed cone um where we go into the future and we because we sculpt the world around us we maybe have like a a distinctive trajectory because we we kind of we're constructing our world more and more which is probably part of our problem to make it the way we want it to be um whereas particularly if you look at indigenous cultures they would have you know a cyclical the more cyclical approach which would go through seven generations or different levels of generations and would be attuning to the environment and i'm kind of curious whether and again this might be where we don't really know but is there a point at which there's generally trying to come back uh or maintain in the allostasis the kind of the cyclical sort of pattern that is where we want to go to and is there a time when it's like okay we're we're branching out now like we've made a jump and we're going to try and inscribe our environment at different scales from the body out to sort of now maintain some new kind of steady state attractor and how that might fit with this yeah i mean i think i i i think you're absolutely right in that some future version of this is going to have to uh be able to deal with goals that are not only not static meaning they're cyclical but also um goals that are themselves you know let's say second order goals like like my goal is it's a derivative my goal is to get better at something it's not a particular level that i'm looking for but i want a particular slope of some variable being you know particular right so something like that so so you're absolutely right i started out with the simplest you know this is sort of the hydrogen atom of this thing so i started out with something very simple that it's homeostatic as in your your goal is a is to achieve a particular region in whatever space you're solving problems and be that morphe space or physiological space your goal is to find that region and sit there and and that of course is not all there is to life obviously that's just the first you know kind of stuff i just did that for simplicity because i want to tackle everything at once and and there needs to be a lot done here before we get to that point um but yeah you're absolutely right your your goal state in that space may not be a point it may be some interesting you know bigger bigger bigger shape you know and this thing and and i just want to i wanted to say something about these gold spaces because i think it's it's it's interesting to to point this out so um one of the in this in this this all came out of a meeting on diverse intelligences and and so one thing i've been thinking about is what what is intelligence and you know what are these agents actually trying to do and okay so so we have lots of examples of problem solving in three-dimensional space right so you've got you know pros and monkeys and everything else and they're running around and trying to solve problems by moving around in three-dimensional space but but all the different um subunits of the of of bodies are solving problems in other kinds of spaces so we talked about amorphous space so if you are an eye in the head of a frog you are working in a space of possible configurations of where you are relative to everything else and you are trying to move and and act in a way that is going to to um to acquire to a particular region of amorphous space that describes that that the correct frog head that's that's where you're trying to land there's also a physiological space so i'll just give you a simple example that's that that we found recently so so um these these flat worms these planaria uh you you take these planaria and you throw them in barium okay so a solution of bearing now uh what happens is the barium is a non-selective potassium channel blocker it it blocks all the potassium channels all the cells freak out their head their heads literally explode right over overnight you know their heads just degenerate they're gone if you take those planaria and you leave them in fresh barium over the next you know 10 20 days what they will do is they will build new heads that are completely barium and sensitive couldn't care less no problem at all they live in barrie which is fine so we we we asked the simple question and not not because the answer has to be this but just because that's the tool that that was available we asked the simple question what is transcriptionally different about barium adapted heads from normal heads right so what genes are different differently expressed in in these in these heads and so what you find out is that out of tens of thousands of genes that these planaria have they managed to regulate a very small number on the order of of a couple dozen that allow them now to do their business despite the fact that potassium is no longer usable for them so now this is incredible because think about the problem that they're solving i you know my head i always visualize like one of those nuclear reactor control rooms with buttons everywhere so each button is a different gene you can you what are you going to do you have a physiological stressor you can't pass potassium everything's everything's going to happen you have some tens of thousands of genes that you could turn on and off the combinatorics are astronomical you don't have time to try them all you don't even have time for gradient descent you don't reproduce fast enough it's not like bacteria where you could say well they're all random and then somebody will survive and repopulate ahead they don't they don't divide that fast so you don't have time for any kind of evolutionary explanation within some small number of days you have to home in on a small number of genes knowing that if you just start randomly flipping them up and down you're going to make things worse long before you make them better you're going to kill everything off you just randomly start so now the other important fact about this is that um planaria never see barium in the wild so so planaria there's no evolutionary history of being good at surviving in barium because they don't see bearing so now to me this is an amazing example of of problem solving in a high dimensional virtual space you've got this you've got this um physiological space and your problem is your your your problem is physiological your effectors are transcriptional largely of course you have physiological effects too but you're trying to walk in this in this space and you have to somehow map it's unbelievable how they do this you somehow have to map your effectors in in transcriptional space to what's happening to you in physiological space and then rapidly get to a a workable uh a workable region so so that that gives you an idea of what of what we're talking about right these spaces can be um transcriptional physiological all you know all all kinds um and and these things and they solve their problems and like and like you pointed out the correct the thing you're trying to achieve may not be a point is certainly not a point and let's face it but it may not even be a static area it may be some sort of i would like to sort of wander in this you know kind of weird loop that's that's my goal right is to you know it's just to wander in some sort of weirdly shaped attractor yeah well we'll get to that this is the just you know first step just just one just also just just just one question following up from that just before sarah um so if i'm right what you're saying is gradient descent because that would have to come so from where you are and slowly keep incrementing you there's somehow some there's some goal states i mean maybe there's some evolutionary history even if it's not barium something like barium but but somehow it's not it's not only going from adjacent possibilities it's it's somehow jumping ahead is that what you're saying so so the first thing i'm saying is that i don't have any idea how it works right so so i do not i am not claiming i have a good a model for what's going on here but but i think you're on to something which is that i think and i think we talked about this a few minutes ago which was um abstraction and generalization i think you're exactly right i think what the system is able to do is is to say okay i don't know what this barium is but i've been terribly depolarized before it was an epileptic you know kind of a thing and this is an awful lot like that so i'm gonna generalize what just happened to this other thing that i do know how to deal with right and i'm going to move in that direction so that's my that's my gut feeling i don't have a solid model for this and that's not been proven in any way um but i have a feeling that you're that that's where the answer is going to be it's going to be that each and that that it's able to do this because it is able to recognize this physiological problem as an instance of a larger class of things for which it does know how to do and i think that when we talk about intelligence for all of these agents what we're really saying is it's your ability to navigate these various spaces uh if efficiently and without getting trapped in local minima that they kill you right being being able to step temporarily you know it's that patience it's that it's that being able to step away from the direct line to your goal to then come around and um and get i have sometimes when i talk about this i have a picture of this there's a fence and there's a couple of dogs on either side of the fence and they're just like you know trying to get at each other right there's a hole in the fence four feet away so they could do it the problem is it temporarily requires you to get away from get further from your goal right so that ability you're trapped in this local local local maximum and um your intelligence is is directly uh sort of proportional to your ability to temporarily get further from your goal in order to actually get into a better position later on part of the iq but i think the other part of the iq is this kind of generalization right and i and i think you're right i think that's probably what is gonna end up explaining nice sarah um man this is great uh i this is this question is probably out of bounds but if you have any thoughts on it then great if not pass um i mean this uh the the cone type diagram and the the agential um helios that it assumes i'm just wondering if you feel like there's any applicability to to non-agential type phenomena like you know complex systems or hurricanes or whatever um because it just when we're talking about abstraction um yeah i'm just wondering if if you have any thoughts about where that could go if anywhere yeah so so the thing i'll say about that and i'm sure this is this is uh not uh you know this is the kind of thing that's um probably uh not not not a lot of people will agree with this bit but this is my view i to say non-agential presupposes that you can draw a binary sharp line right and between things that are agents and things that are not i don't really believe in that i think that's a view that gets us into a lot of trouble by looking at these support looking for these sharp lines i think that all there is is a degree of agency and i'm not sure we are we talked about yesterday whether there's such a thing as zero i i don't actually i'm not even sure there's a zero but but certainly there are there are things that are very very sort of non you know very very low levels of agency and and things that are very high and everything is a smooth continuum so now then so so then then then the question is okay so what do you do with hurricanes and things like this so i drew um and this will be this you know in the next uh in the next paper there's a thing there's a thing that i call um it's an axis of persuadability it's it and it's it's so it's sort of related to um dennis intentional scenes in the following way there's a there's a there's a continuum and for any given system so so my claim is that it's an empirical problem you can't say whether something is or is not an agent lots of people do they'll say well that's not image i think you you can't say that um until you've done the empirical work and the empirical work looks like this all the way the the question is this as an engineer this is very much an engineering perspective as an engineer how much work do you have to do uh what do you need to know about the system and what kind of work do you have to do to be able to control and predict its outcome so i'll just give you a couple of examples all the way on the left you have things that are like mechanical clocks so if you're dealing with a system that's like a mechanical clock you know you can put it on the left of this of this diagram because you are not going to uh reason with it you are not going to train it you're not going to be able to punish it you're not going to be able to rewrite it it's it's you know goal states you have to you have to know how it works and you have to micromanage the hardware and you have to make um uh you have to rewire the the the physics of it to get it to do something else okay then moving on from that you have something like a thermostat and with a thermostat you're also not going to reason or punt it with it or punish it but there is a separate set point and if you want the room to be kept in a different temperature range you don't have to rewire the thermostat you can change the set point so as and this has massive implications for regenerative medicine that we can we can talk about the way you relate to the system is is quite a bit different now after that you might get to systems that have preferences in the sense that you can actually train them meaning you can provide rewards and punishments they will change their behavior because what you're doing is you're relying on them to be a kind of learning system they're able to do associative learning so they associate certain things you've done to them with us you know with things that they did and they will change their behavior so now this means that we can now think of what this means you know humanity has been training animals for i don't know ten thousand years whatever uh with knowing nothing about neuroscience it means that you don't actually have to know what's going on inside your system you don't need that micro level hardware information what you all you need is uh to to know that that animal that that uh system is actually a that it has that level of agency that it's susceptible to this kind of um interaction and how do you know you don't know until you've tried so we have no idea so one of the things we're doing now with charles abramson who's a behaviorist scientist we're right we're actually writing a how-to um manual you know how-to uh paper on if you are given some sort of weird a new synthetic system how do you know where along the and there's actually has a bunch of a bunch of experiments that you do to figure out where you are along this this path so you can go further and and there are other systems where you know nothing about um what's inside and in fact the amount of energy that it takes to manipulate them is tiny because you can you can give them reasons as opposed to causes and you can you can give them information and they will act on this information and do various things this is sophisticated um agents so all that is to say uh the question of where something like a hurricane lands on this on this on the spectrum i think we need to really resist the urge to just make pronouncements you know sort of armchair pronouncements about that and we need to ask a simple question which type of manipulation is that system amenable to and when you find out then you know how much agency it has now give you a simple example of how this works we and other people have done something similar if you think about gene regulatory networks so gene regulatory networks are a quintessential example of a you know dynamical system it's it's deterministic and all that and one of the things we asked is we we we simply said how do we know where on this spectrum it lands let's just try to train it and see what happens and it turns out and this is so we did this computationally and now we're sort of starting to do this at the bench we simply ask the question could gene regulatory networks have associative learning capacity and that means that you could do interesting things you can do pavlov dogs experiment so you have a gene regulatory network you have some uh stimulus that causes it to do something so you have your unconditioned stimulus that causes the response you have this other thing that's a that's a neutral stimulus that normally doesn't do anything uh you pair presentations of the the ucs and them and the neutral stimulus together and after a while what you might find is that now take away the the original unconditioned stimulus and use the neutral stimulus and that's now enough to trigger the response because there's an associative memory that formed in the network right so now we actually tried this in the sense that we we took a bunch of um known gene regulatory networks from the literature we made an algorithm that basically checks for associative learning and lo and behold we found two things we found that there are six different kinds of memories that these things can do including associated memories from any of them and that the biological networks have way more memories than you find in random random networks that you you know you would just randomly concoct so apparently either directly or indirectly selection likes that so that's just an example of uh what you would do under this view with with dynamical systems right that that you would think oh you know these are trouble cases are they agents or aren't they i think that's why we get in trouble because we try to draw a sharp line i think the answer is there's somewhere on the line they could be way over on the left or not and you find out when you figure out what kind of intervention and strategy avails you of the most predictive power with the least amount of effort nice so we talked yesterday kind of about um you know cells that are contiguous and there's like connections and so this this concept of like a shared information making up uh an individual or like what consists like constitutes the boundary you know if if cells are connected via gap junctions and like you talked about how if there's a calcium molecule inside my cell i don't know if it's from from me or from my neighbor because we share this kind of hole between us and so i just wonder if if there's some degree of information sharing or some kind of like proximal like level does it have to be immediately contiguous to you know have that same like cognitive capacity or or like over a longer distance can this also function like for example if i get some kind of like necrotizing flesh in my leg is my toe necessarily gonna know like what's going on with my leg it's gonna take a while for that signal to diffuse over such a long distance so so where is the like the boundary or container space for this kind of information sharing that has to occur to make this cognitive cognitive individual like a whole the whole thing by itself so i don't know if you can say a little bit more about that yeah yeah um the biggest is so so i think so i think one thing that i really need to improve in this whole thing for next time is a better visualization and i frankly don't yet know how to do it because this this way of visualizing it looks very physical it looks like what the cone is is it that the cone is at the edge of the cells that are connected right it sort of gives this idea that what you're measuring is the actual physical boundary of the system and that's not quite what i'm trying to get across because what what and and this is actually let's just think about the cells in in the in the um cancer versus multicellularity right which is a nice example of how this works when you have a bunch of cells and they get together and they're going to build a kidney the um the size of the at least the spatial size of that of of that particular agent is going to be roughly the size of the thing they're working towards it's going to be the size of that kidney right that's the project they're all working on um each individual cell has no idea what a kidney is but the collective intelligence of that group of cells it has a uh a goal that's trying to build my kidney if you try to deviate it from that goal it will do its best to get back and do it anyway um so what you would be measuring there is the uh the size of the of the state that it's trying to achieve not necessarily this you know where the edges of the of the now there's certainly some relationship there because in this particular example what an a as you said what enables the cells to work together is the fact that they're electrically coupled into one and chemically coupled into one giant network so so there's some relationship but it's not quite always the edge right you know what i mean and and the same thing with the individual cells um there's a it's it's there's it's related but it's not exactly the same thing when one cell defect so let's say an oncogene turns on the cell closes all the gap junctions disconnects from its neighbors and now that computational boundary is literally just that one cell again it's not quite at the edge of the cell because if you look at the scale of things the cell is trying to manage it's a little bit bigger than that because it also really cares about um some of the you know the the nutrients the wastes the the con specifics the the prey whatever else is going on right at that edge right so it's not quite at the cell boundary so i i just want to make that clear that this diagram isn't meant to be an anatomical uh the cone isn't meant to be a map exactly on the anatomy it's a cone of the states that the thing is trying to actively manage yeah i think that the cones were inflicted by us though yeah but but you're absolutely right and as soon as you did that i realized that what would be good because that has to be right those two diagrams eventually have to meet right and so there have to be there there has to be a way to so i think i don't know my visual um imagination isn't great i have to think a little bit more about a better way to to kind of represent it but of course you're right those two things have to come together yes stephen yeah i was just so following on from what you were saying is often as well as useful when we think of entities and processes i'm maybe scaling up to more psychological scales but you know we often think about this is this person this is what this entity is diagnosed as and this entity and it's all kind of and and there's a lot more now move towards what's the process but then what kind of processes do we have on that continuum just like we're talking about with the hurricane you know you maybe you've got a static entity like a rock and then you've got your kind of systems some of which could be mechanical like a clock but then you sort of hit structures there's some sort of structure like a i don't know like a skeleton or a network of processes coming together then you get into them which is what i find really interesting with the work you do is you the sort of non-linear swarming dynamics you know and it's sort of um and i was wondering how when you think of th you know you've got a body and i'm a body and i'm trying to work in my space around me so i see things in my environment out there and i can interact to some extent depending on what my available processes afford me in my structures and then there's other stuff inside which to some extent i kind of have to let take care of themselves unless i want to tattoo myself or do some sort of internal mutilation or something i'm curious about how this entity process dynamic going in and out can be thought of yeah um well i want to say a couple of things uh and again this is you know sort of going going kind of far a stream but i think i think it might be relevant um when you say you are this body sort of in the sense that we are talking to the verbal entity there but there are all sorts of other entities there that we're not hearing from that that and so so we know that from split brain patients right we know that um after a commissurotomy the right side of the brain you can communicate with it it'll give you opinions that uh the verbal patient part of the patient doesn't agree with doesn't know anything about right so it's really really interesting um i also think about uh multiple personality you know they call it multiple personality disorder but but but the reality is you know a single a single brain body system apparently can post any number of distinct and how in how i am i'm not a i'm not an expert in this area i don't know how psychologically deep so some of these other personalities go but enough that you can have a conversation certainly enough that you can have a conversation with them which means they're doing better than all of the ai that we've ever produced right and and they uh and in fact i i read once i forget where it was but there was an interesting comment from a a a therapist who was asked to he was he was he was asked to deal with with a multiple personality patient and he was talking about integration and he was you know that the goal of the therapy was going to integrate because of course it's very disruptive for the for the individual and we're gonna we're gonna integrate all of these into one and one of the personalities said to that patient integration you you're gonna kill me right that's what you're talking about i thought you were a doctor what are we talking about here and so you know it was outraged that that there was going to be this integration of you know of of of what at least uh ostensibly uh you've got this entity that certainly passes the turing test and is is not happy about the fact that you're about to integrate it in you know away basically right so that's you know i think that goes back to this idea that we're an interpenetrating set of selves and we tend to only hear from the verbal one so there's all kinds of other ones in there that are competing and and cooperating and everything else and and the other thing i can say about this so that's more questions than the answers i guess but but the the other thing i think that's interesting is that you're you're right in the sense that um the one kind of entity that we have direct experience with which is the verbal you know sort of one that presumably we share is completely ignorant of most of the things that are going on there and so the space that you're working with nicely coarse grains over all kinds of stuff you know your liver function and everything else you don't need to micromanage all this however there are techniques that will add axes to your option space so if you would like to learn to also consciously control your heart rate or your skin temperature or whatever you can do biofeedback there are tools that will enable you to cross that that that boundary and you will now have a new axis in your option space that you never did had before do you want it i don't know there's a good reason why most of these you don't you don't use it's as good to sort of simplify your space but but you know there was a there was an it was a cool experiment where they uh they measured the temperature between a rat's ears and they gave it a reward proportional to the difference in uh in temperature and so rats readily learned to to get their ears to you know i think like five degrees celsius or something different between their ears to get the reward right so now that's amazing for a number of reasons one is that okay now now you've added uh an effector in your space that is is you know kind of this physiological blood flow i don't know how they do it um that you didn't have before the other thing of course is the credit assignment you know here you are you're a rat and you just got some reward and so well let me see why did i get this so well my tail is pointing up and my left you know fingers are clenched and my whiskers are going which of those things actually worries right so so this is we still haven't cracked this in machine learning is how how living things are so good at figuring out what exactly they're being rewarded for small number of trials actually so but you can i think i think you can break through at least to some extent and you know break through and actually even further right so there are claims that certain types of um you know mental practices will have effects on your immune system for example right so you can i think you can go pretty far down right from if you wanted to add these these kinds of things to your option space ah interesting actually just bouncing on that going that's really helpful actually i've not even thought about that but that that different parts of us ties in with there's this big push all the time if you say about integrate integrate integrate and actually scale out because i do a lot of work with multi-service um service providers say in africa or other countries where they're and you tend to find that any type of um transdisciplinary project has the problem about whichever regime of attention or field of practice the voice is in at that time and then then when we talk about integrating but it normally means they dominate and what about configuring so think about this idea of configuring different fields of practice by different ways or different ways of knowing and also ways the other voices is strategic conversations with communities who don't normally get a voice who knows something in the state space beyond what the the actors who've got the job in the agency know and it's this sort of ties in a little bit with what you're talking about here so i think it's quite interesting in the sense of can we conf because in a way the biology isn't trying to integrate it's actually configuring and allowing things to be but it has a way to still know their different teleological spaces and either just let it get on with it or yeah knows where and when to get involved i suppose is is the thing yeah i mean so so so i think i think the the one way of looking at that is to is to ask what are the optimal policies for uh for this binding so so i'll just you know i'll give you an example so in the case of in the case of the um multicellularity we say okay uh individual cells are pretty cool but when they connect via gap junctions into a multi-cellular collective they can do these these marvelous things and they resist cancer and you know and and turning off the connection and becoming met you know um becoming a cancer cell and going metastatic is is bad and so what you would really like to do is is to reconnect these cells back in so the thing is that right that that tightly coupling individual units into a global entity avails you of all kinds of interesting things right so it raises the iq of the whole and gives you all kinds of capabilities fine but one of the things that gets lost when you do that is uh that the larger system now now can dominate the the goals of the lower system and in fact the larger system may have very little uh care for the goals of the welfare of the subunit you know when was the last time you worried about all the skin cells you're shedding right you just you you know you're gonna do what you're gonna do and if you lose some skin cells you know no no no problem um so what that suggests is that blood you know maximum maximizing out this connectivity into some giant borg like uh you know thing is is an and obviously it's been you know it's kind of been attempted on you know on the on the social scale we know how that turns out so you want to uh somewhere in between there there's a there's an optimal policy right where i i hope there may not you know there may be some no-go theorem it's somewhere that says there is no good policy but i hope that somewhere in there there's a good policy that allows us to uh reap the rewards of appropriate kinds of large-scale organization without a sort of blanket collectivism that that completely uh sort of you know wipes out the uh the needs of the of the lower level subunits so that i hope is a is an empirical question that we should we should be looking for what kind of policies give us that that optimize the various things we want to optimize um josh vaughn garden i planned a grant at one point for this human flood this human flourishing um program somewhere that i think it's actually an empirical question can we identify the optimal policies that preserve the needs of the subunits and reap the rewards of becoming a greater whole nice so i learned this word yesterday at gregor it's the occult concept representing a distinct non-physical entity that arises from a collective group of people and i thought it was really cool and and i think of this concept of emergence so like at what level does this collective kind of body form and i don't know if you've read the information theory of individuality paper uh by david krakauer but we really think about you know emergence you know like the emergence causing the formation of the collective entity but then there also has to be like some kind of downward causation at some some point in there like is so is there is this some kind of like critical point like a phase transition that starts to occur or when does that kind of start to happen that that bi-directional information flow yeah for sure i mean i mean th this this in particular is is interesting because i i i thought about this a little while ago that you know especially um people who are interested in this kind of stuff uh you know and you can think about the the really old concept of group karma right this idea that that not only you have your own individual cause and effect that you're causing but but in a strong sense the group of which you are apart has its own right cause and effect that is that is as real as so so that idea and i don't know how many thousands of years old that idea is i think it is an amazing um amazingly prescient because in in western science the the you know collective intelligence right the science of collective intelligence and this idea that right the group can be a you know a swarm of whatever can be an agent on its own is relatively recent right that people started taking that seriously in in science but i think i think that kind of thinking must have been extremely old because there are these traditions that take it very seriously that the group is not just a heap of stuff but it actually has its own agency in the sense that it can even be the subject of blame and reward in the sense of you know the sense of like rewarding punishment karma whatever that that that's a very strong view of group agency that i think we've only said you know scientifically we've only really appreciated recently so i think that's that's that's pretty cool actually random random linguistic thing here that gregor i was thinking about egregious and like egregious in my mind is like out of bounds you know but and yet gregor is or is not that it's the opposite it's almost like a group thing maybe maybe some other somebody else can think about that differently but i thought that was an interesting conflict yeah very interesting so i think about this concept of collective karma a lot um and really kind of whether or not like i have free will in the in the present like in terms of am i just some kind of computation like my like you know just because i've been doing active inference and so am i just my generative model that that like effectively i can't make any decision because of of my model like whatever input i'm getting at that moment i have to decide based on on the the condition of my model at that time and i think about collective karma much in the same way um and whether or not there exists some kind of of agency in the present or or not like if all the things that just made me who i am right now have just led ultimately to to be where i am and and in collective karma too it's like a hurricane that group of people caused that hurricane to happen like they created the causes for the collective karma for the hurricane to come um so i don't know it's it's something that that is really intriguing to me and um you know i don't know if you want to maybe elaborate a little bit more on that yeah yeah and and so and so two thoughts about that uh one one is that this goes back to this idea of of spaces and the different spaces that each of your um each of the subunits is working in one way that and and after after i drew this cone and i realized that it kind of looked like the the the special relativity cone and all that uh some other some other pieces of relativity sort of started started popping into my head and this idea of deforming the space around you right so if you're a mass you deform the space around you which in turn alters your next possible movements and the possible movements of the other masses around you right so by deforming that by your actions you are deforming the possible the possibility space for for your for yourself for things next to you for your components and so on and so one thing that i think happens is that these larger systems deform the action space for their lower systems so that to that so but all they have to do is roll downhill in effect and so if you zoom in so this gets back and i'm going to connect this back to your your point about karma and and action and choices and so on when you zoom in all you see is physics and you see and you say oh well this this is yellow of course that's what it's doing that's all it could do all the gradients are pointing this way that's what it had to do but the reason it can be it can do that is and still get to some global goal is because the higher level system has already deformed that space so i see this and i don't know how i'm going to ever draw this that's a different story but but i see all these different levels as uh deforming their simpler space that they're working in which then changes the option space for their sub units so that they can they don't have to be a smart this is this is sort of bennett's idea of you know progressively dumber robots all the way down that works if each system makes it so that so that the the the lower level systems don't have to do quite as much of the work and there's a stupid example i always go to from from you know from like common everyday life if if if you ever had a friend who tried to stop smoking and they like to smoke at night one of the things they might do is put their car key someone that's really hard to get to why because they know that when they you know at midnight when they want to smoke they're not going to feel like going hunting for the keys and then they could find and then that's that so so what they're doing is you know who are you doing this so you're doing this to your future self right you're deforming the space for your future self in that case consciously and of course we all do things unconsciously too but in that case you're consciously deforming the action space for your future self in order to uh so that you can be on autopilot at that point right you don't have to have the willpower at midnight that i'm gonna not do this it's you've already somebody's already sort of twisted the space for you so that just going to get your keys is just too high of a barrier and then forget it so uh right so so i think i think that that that that deformation of these action spaces is a really important way in which um lower and higher level systems relate the lower level systems simplify the action space for the higher level system because they're competent so the higher level system doesn't need all the dimensions and the higher system bends the space of the lower system to make things easier to get to and that and that goes back to your other point that you that you just made about um in the moment of of of taking actions in the moment that are the consequence of all the pressures that you have set up and other things have set up for you where yeah i see this as those so if we think about will in the sense of you know free will or decision making or whatever i i see this again this like uh four dimensional block where each one of us at any point in time is a slice of it and if you zoom in on that one that that self-lit that exists at that one time slice your your uh free will so to speak is is limited to none because at that moment on the local scale you you are going to do whatever the local forces have arranged that you're going to do right and and this is the one like a simple example is you know can you control what your next thought is going to be you really can't your next thought is going to be whatever it is so at the local at the local level when you zoom in you know there's there's no no useful sense of freedom there however if you zoom out on the long scale what you what is true i think is that you can take actions repeated actions whether they be practice or or you know whatever they're going to be you can take repeated actions that alter your cognitive causal structure so that over time you have made changes and so so no you can't control the next thought you're going to have now but you can control what percentage of your thoughts are negative or whatever whatever it is down down the line right so so to me that question of of choice and and freedom is very much relative to what scale you're asking but if you zoom in to the to the to the lower you know to the to the physics and the sort of short time scale no i don't think there's any useful sense of that but over the long term absolutely because you can make changes both in your environment your own structure that will get you to a different place thanks uh stephen yeah this is really helpful actually to hear it thought about this way and just as we're saying there about this sort of almost transcendental um or the the way we often think of things being excluded egregious as sarah was saying and um when we we need to move beyond um the inner outer you know there's an inner thought process and there's an outer world but the two are linked like we say so with active inference the idea is that i don't necessarily purely have a model of those cones in my head i i i've got an action model for how to draw them i haven't got the whole thing that can be dumped down like a data source but i have a way to do that which sort of ties in and i was one and when you mentioned there about looking at the future one thing that adds that active inference hasn't really done is it talks about say the car keys example is is is the sequence at which something might have to happen to get to the future being disrupted which is kind of that quantum contextuality idea whereas normally in active influence they talk about the niche construction or the niche modification but it's not just about modifying itself it's modifying the trajectories you might take through that niche which that that gives you more near time possibilities for like sculpting what can happen when it can happen so that i think that's quite useful i was wondering how how you see that relationship to niche construction and weather and models being sort of embedded in the world i.e so if systems are really models in the world that we then read or interact with and using our structures how do we how do we link up that kind of cone with the kind of niche construction that's maybe being used in other areas of active imprints yeah i mean so that's that's a very difficult question i can sort of address a small part of it i think at this point and i can j you know i think i think one of the key questions of all of this is to what extent when we look at systems and we see the dimensions with let's just do the third person case first and then we'll talk about that i think the first person case that you're talking about so when we look at a system and we make a map of its its problem solving in some space and its goal directed activity in some space the question is uh is that in any sense objective in the meaning meaning could we um could we make a case that that that model of that space is better or the best or is uh is there an infinity of ways to look at it and in particular how does that relate to now the first person perspective of that that system itself what does the space look like it's it's a little bit like um you know the the the whole um belt thing right where you're sort of in some space what does it look like to you and chris fields made a really nice example uh in our um computational meeting a couple weeks ago where you said imagine imagine a bacterium and there's some sugar gradient that that the bacterium is in and it's you know it wants to have more energy so now one thing we are tempted to do is to draw a space where by rotating its flagella and whatever else this thing is going to move up the gradient but there's something else it can do which is that it can turn on a gene for an enzyme that lets it use a completely different sugar or let it use that sugar better or something else that solves that same problem with an effector that to us is an entirely different space so so so we look at this and we say ah that solution has a problem in um in physical space and it has a solution in transcriptional space if you're a bacterium is there any sense in which those are not part of the same space i mean i have no idea what it's right obviously what it's like to be that bacterium one could make an argument that our dissection of these things has two different spaces is is totally biased because that's where scientists and we like to look at things that to the bacterium both of those are effectors that live together that's kind of a mix it's almost like um you know it's almost like you you can ask about uh some sort of pca right if you're a principal component analysis where you're learning about your world and you're going to end up with a picture of what the axes are that don't necessarily make any sense to us looking at the system right you find you get you get these components that you know these control knobs and we look at what the hell is the you know what is it doing well but but but but to the system those are efficient ways to build an axis and people like um you know robert brittner and don hoffman have these models of these cognitive systems from scratch sort of building these worlds to these virtual spaces for themselves right that you don't actually know what spaces you're in so um i think there's a research agenda there which is can we build some sort of appliance meaning some sort of i don't know machine learning thing or something that will try to extract these in a i'm not going to say unbiased but at least unsupervised manner that can we build an agency detector can we build something that looks at a system and says i tell you what if you assume this axis this axis and this axis then i can paint you a really uh efficient uh search strategy that will allow you to predict what the system is going to do next because we can view this as problem solving in this space right and maybe and maybe it generates a palette of um solutions like that and there's one that's head and shoulders above the others and you say fine that's my scientific theory of what's going on here and and maybe right and maybe that works i don't know so so that's that's that's a research kind of agenda for the future and the other cool thing about that is if you if you do that of course one thing you might want to do is then build a more sophisticated uh synthetic intelligence by sticking that thing basically closing the loop and sticking that that module inside the agent itself and here's why i'm saying that all animals i think uh you know at least past a certain point certainly have agency detectors this is why we love our visual systems love symmetry and so on because you really want to know looking out into the world you really want to know what are the passive elements and what are the other agents that might eat you that you might communicate with that you might convince them to do something else so so we are constantly estimating um you know theory of mind right an agency for all the things we're looking at because because that helps you get around you you need to know if if it's if it's a rock or if it's something that's just going to come eat you no matter what or if it's a con specific that you might actually lie to and or or you don't have a relationship whatever you're going to do some sort of complicated interaction right so we're all we're all trying to gauge that and probably where what what what one of the things that kind of module also does is turn inwards to tell you stories about yourself and the reason we know that exists is because of confabulation so just as a simple example as this is the modern there there are older examples from the brain split brain studies but the modern example there's um there's somebody who's got an electrode and this was an actual experiment that was done he had epilepsy or something and they put an electrode in their brain and in his brain and it didn't happen to land in an area that when you stimulate it it stimulates laughter the person just starts laughing right so so so you're sitting there so this this person is sitting there talking to you know having a serious conversation with the doctor somebody off scene pushes the button person starts laughing the doctor says to him why are you laughing zero percent of the time the answer is geez i don't know that was super weird i was all serious and suddenly my mouth starts laughing that never happens what happens is the person says oh i came up with a funny story and i was just thinking of a funny thing that happened right so what happens is and this has been you know i'm not the first person to point this out that we are massively unaware of lots of stuff that goes on in there and we have a module apparently whose job it is to tell coherent stories about what that all adds up to so not not just turning outwards to see what kind of agents we see out there but actually to look inwards and come up with plausible explanations that no you're not an automaton because somebody pushed a button that's not that that's not a preferred explanation the preferred explanation is you're an agent you come up with funny stories and sometimes they made you laugh that's a better explanation so um so so we have this so so if we had such a thing we could imagine already piece by piece uh starting to put this together into what might be a fairly sophisticated cognitive system that has a bit of metacognition and a bit of uh much like all of us uh sort of faulty access to what it is that we're doing and and all these kind of interesting things nice so i'm going to kind of take it back to this um time space cube because i just really can't wrap my mind around the fact that if you slice up the cube i think about it like a like a confocal z stack so if you have a slice that's the present if i can't change this slice like you know you can take a projection of the confocal image and look at the whole picture if i can't change this one slice how is it that i'm going to change the future right so all the slices up until this point lead me to make this current existing slice and then it do i can i change any point in the future i don't see how that's possible if i can't change the point in the present so are we just like i think about we had shanna dobson and chris fields on and we were talking about express you know compressing and expanding time and space um and just time in all kinds of contexts like is it even a construct or how does it work and like non-archimedean time and all that stuff so i don't know what uh if you want to maybe unpack that a little bit for me because i'm just not kind of seeing the possibility of um of this changing the future without being able to change the present yeah totally possible and so and so for sure i'm not going to try to make the argument that uh we have a um a mature theory of you know free will of that of that kind i don't think we do but um and i think you're absolutely right in that that is in fact a really critical point if if if if your freedom in each slice is zero then many times zero it's still zero right so totally totally true i i think we can make two moves and again this is this is super early i you know i'm not claiming this is in any way gonna survive uh get a careful careful thought into the future um i think we can make two shifts one shift is that i think it's a again and again i'm like a broken record with this stuff but but i think i think that binary um this binary distinction between you have freedom or you do not i think that's wrong so so i think what you have it goes by amounts so so you may have very little you know if you're if you're if you're a mechanical clock you have very little and uh if you're some other type of living thing you may have more and then you may have more than that so then what you have is and this is super super amateurish but but just to kind of visualize what i see is the kind of um addition that you get in calculus where you start with extremely tiny things that are kind of zero but not really and eventually they add up to something right that's how i see it that's how i think that what you have at each point is a teeny tiny amount and if you look close you know basically it's an epsilon that's not worth talking about it's basically you don't have any but it isn't quite zero and over time that mental effort whatever that is that you put into you know working on your free will or on your kindness or whatever you're working on over time it integrates into an area even though you're integrating infinitely thin strips like that's that's the vision that i have in my head that if we just do away with the fact that it's actually zero but i don't think it's actually zero then you can build up something over time and you can and you can magnify and if you know i'll say one more thing which if we're gonna if we're gonna abuse physics like this right which i mean i realize this is all like completely informal and whatever if we're gonna abuse it um i'll make i'll make one more one more analogy if you think about what is the uh what what is a minimal level of agency so so so sometimes people ask me like um well is there a zero on your on your continuum right is there an actual zero like what's the minimum what is the smallest and so i think okay if you're going to pick if you're going to design the absolute minimal piece that still has some non-zero agency what does it need i feel like it needs two things it needs some minimal amount of uh decision making that isn't obviously caused by local causes right it needs at least something that is that reaches outward in terms of space or time or complexity or something that isn't obviously a locally determined um you know necessity that that's one and the second thing it needs is some amount of goal directed activity something that looks like uh a goal directed activity so so once you've said that it seems to me that that individual particles already have this right because because quantum indeterminacy gives you the first one and least action principles give you the second so you've already got that and so now when you so so i think and again this is you know amateurish as far as the physics goes but my gut feeling is that there isn't a zero that you already start with some minimal amount and now you can do one of two things you can see you got these you got these particles you can do one of two things you can you can make a rock out of them so you aggregate them in a in in one way which basically uh gets rid of all those nice properties and it and and it and it ends up having having you know very low agency it doesn't it you know it just it just aggregates all of it in a way that doesn't do anything useful or if you're if you're alive you can uh you can amplify those properties and end up you know further down on the on the continuum so that's kind of my fuzzy story at the moment is that i think we start off at non-zero and then you can either stay there if you don't have the right organization or you can amplify the hell out of it and and get to you know to get to be more agential nice thanks i definitely think that uh non-zero is the right answer so we've got uh maybe like 15 minutes left and um you know i just there's some closing thoughts some room for some last minute questions uh sarah or steven do you have any last minute things you want to ask no my head has sufficiently exploded yeah no i think i think that was a night i mean i think there's a lot to think about because we've covered an awful lot of territory but um i think i think it's it was interesting to see that you're bringing the thingness and um that i know carl fristen talks about that um so i i suppose one last bit would be would you call yourself um a non-dual modest in the way that um carl talks about that idea or is that something a bit different or maybe not even relevant in this context yeah that's that's a good that's a good question so so i hesitate to put a name on it for for two reasons number one um everything that we've talked about so far has been very much from a functional third person perspective so so we haven't really touched the the so-called hard problem of consciousness or what the so in order and the thing is nothing that i've said touches this question of why is it like to be something that's one of these systems right so from that perspective assuming that we believe i mean some people you know will say that that's a non-problem and that there is no such thing and then whatever but i i i'm not 100 convinced of that actually and from so so so there are that i i do think there's a hard problem and i don't have anything that addresses it and so uh i don't know you know what camp that puts me in the other the other thing is that um i have a lot of um sort of uh uh kind of pan psychist sympathies in the following way so i think that if you scale down if you if you so so so what's one reason people don't like pancyth it means that you know it means that you think that rocks they have hopes and dreams like the rest of us okay so that's obviously not what i'm saying the reason people go to that to that extreme is because they've scaled down the structures that are needed for agency but they haven't scaled down the expectation so so that's so yes it's it's silly to to think that rocks and dreams have to that rocks have the same hopes and dreams that we do however if you scale both sides of the equation i'm not at all sure why again if you don't if you if you're not into binary classifications it is conscious or it's not that that i think is definitely wrong so if if phenomenal consciousness is a kind of um continuum too i don't see any reason why there couldn't be a tiny bit of something that's super hard for us to imagine because we're used to a much a much bigger level of perception and consciousness that that isn't associated with a lot of other systems that we normally that you know that the people who normally work in cognitive science would never buy as as as as having consciousness so so so i have a lot of you know kind of sympathies on that front mainly because i don't buy this binary distinction um and we could talk about this actually interesting i don't even i i'll tell you why basically um bioengineering and the kinds of things that are possible now are they they are really dissolving a lot of things that seem to be uh sharp categories before and i'm not even sure at this point that um the distinction between first person and third person knowledge is even sharp and and i'll just i'll just draw you a simple picture and i preface this by saying um i i made a picture of this and i sent it to a um a well-known philosopher and he said it was you know horrible horrible and and uh and uh and not not useful but but we'll see we'll see what you think um imagine that uh you're looking at that there's a brain and there's some electrophysiology being done some electrodes stuck in there and that's it's being processed and you're and you're on the outside you're the scientist you're on the outside you're looking at that data uncontroversially third person right you have no idea what it's like to be that subject you are studying some signals that come off of that line now what we do is we change this we change the scenario a little bit and uh what we do is we take some of those interfaces that you know they have these interfaces for the blind that either go on your tongue or they go sometimes in your retina but basically they turn uh camera signals into something that's directly plugged into your brain with electrodes okay so now we we take that setup and instead of the camera we plug it directly into the electrophysiology apparatus so now what you're receiving is you're receiving a heavily processed signal but it's coming directly from that brain into your brain and what's interesting is that people who use these kind of sensory augmentation devices they will eventually report that it's just like seeing they learn to get around like the electric lollipop is this thing you stick on your tongue and it shocks your tongue in a way that um maps onto the pixels of a camera right and they say oh it's just like seeing it so uh so okay so now you've moved so you know it's like um uh it's it's sort of you know third person but you know it's maybe like 2.5 percent or something and then you can do another experiment you can say well what we're going to do is instead of using all this um like uh heavily electric you know all this electronics and and processing uh in between we're just going to connect the brains and we can and we can do this and the reason we know we can do this is that there are conjoined twins whose brains are in fact connected so that there's no you know sort of sort of clumsy electronic interface in the middle the brains are directly connected and so now you say okay so if i'm now if my brain is now connected to this other person having the experience it's sort of am i is that still third person and then you ask the question yeah but in your own brains of some people say ah that's an aberrant you know that's an aberrant case but in your own brain you've got pieces of the brain that have to talk to each other you're not an indivisible monad of some type right you are a bunch of pieces that also have to talk to each other so the left side has to talk to the right side in fact the front talks to the brain you are anyway pieces of the brain having to talk to each other and somehow that ends up being first person so now what we've just done is built a continuum where you can smoothly and we can fill in anywhere between these two systems i can fill in as as you know sort of finely as you want and you can smoothly move from from first person experience to third person is science because the bioengineering tells you that you can do it so so i'm not even sure that's a you know i'm not sure that's a distinction so i i you know it's hard to say uh anyway that's a long winded answer to your question wow i i was gonna ask one question now i'm gonna ask another one um this makes me think you know like related to core screening related to layers and levels of of uh different organisms like it just what you the kind of example you just laid out you know makes me question whether you can even stratify in that way or whether it makes sense to stratify in that way um but let me go back to um something we didn't cover and and i i heard it on your podcast and um you ended with a question related to moral philosophy um or ethics i guess not even i don't know the distinction there but yeah um i mean when you know if you're coming from the perspective of not believing in a binary uh between you said it better than i did living non-living whatever like agent versus not um and then you're making things like xenobots it's like that kind of if that's if you held those two views um of not believing in the binary then there it seems like there really wouldn't be an ethical question and so i'm wondering where your where your thinking is along that yeah no no i think i think there's definitely an ethical question uh and and i think it's not quite what we think it is but and i'll tell you what it is but let's just let's just take a step back so so long before anybody made xenobots we made humans right the old-fashioned way and so this is like uh you know then it's competence without comprehension right so we have no idea how it worked but for for you know hundreds of thousands of years we made other humans and so we take care of them as best we can most of the time sometimes not really very well you know so so so we already did that then uh we make all sorts of animals in terms of um of food production and other things we make hybrids so we make mules that are animals that never existed before right we make uh we've made new new plants so so so the first thing that's really critical and and often the the reason i'm sort of sensitized to all this is the people always say oh my god you're making xenobots it's a new like let's not let's not forget what we've already been doing right and let's let's be super clear that that this is a massive problem with the with the food industry right long before we get to worrying about zenobots there's all kinds of things that that we need to fix so i just want to be you know i kind of want to be clear that we've already been making animals and in fact other humans for which we sometimes take good responsibility and sometimes we we don't i think i think this is absolutely uh raises an ethical problem and the ethical problem is is the following when we um when we go to uh synthetic biology and and bioengineering kinds of seminars there's usually now a session that's about ethics and the session goes like this somebody will show a brain organoid made of human cells and someone will say oh my god that you shouldn't be doing that and somebody else will say well let's just see how much like a human brain it is and then they and then people spend a couple hours arguing about whether it is or is not enough like a human brain that they need to worry about it and maybe they end up saying it's fine or maybe they end up saying it's not fine but i think the much bigger issue is that whether or not something looks anything like a human brain is a very poor guide to how much you need to worry about it and in the past uh the way that you the way that we would figure out whether or not how much moral responsibility we have for a particular system went roughly like this you would sort of look at it and and if it was um squishy and and and warm and furry you would say yeah and if it was metallic and you know and it came from an assembly line you'd say do what you want no problem right so so two two things used to be a guide and even that we didn't do so well we can't obviously with those principles but but the two things that used to be a guide were where did it come from did it evolve or was it designed and what is it what is it made of and and it was a pr and that was pretty good right you could yeah if because if it was evolved you could look on the sort of the the tree of life and you could say it's a worm we don't need to fill out any forms when we do these experiments or you could say it's a frog i need to fill out a lot of forms before we can do experiments right for that then that's in fact how it works because you have because you know something about that that lineage and you make some sort of guesses about where things are and then if it's an octopus people really don't know what to do and then so on all of that is going completely out the window right so in the next uh in the next i don't know a couple of decades we are going to be surrounded by and this is another thing that i'm writing on the option space of possible creatures we're talking about uh hybrids cyborgs hybrids there's a million different ways to recombine evolved designed living non-living and software agents into new forms that have never existed before so what something looks like is no guide to what the cognition is where it came from meaning if all the design is going to be a bad question because half of the stuff we're building with is now evolved and and so on um all of the things you know it's just a machine versus oh but you know it's a nice mammal all that stuff is going to go out the window so to me the ethical problem is much bigger than just asking about whether something's like a human brain the what we really are going to need is a new ethical system for learning how to deal with agents that look nothing like us and that don't look like anything we've ever seen before and yet are going to have all sorts of cognitive capacities and uh we have to let go of categories like machine like robot like um all these other things that really don't mean anything they never did but before but it was fine in the past it's no longer going to be useful um and that's that's the ethical that's the ethical problem uh so great so i'm gonna go stare at a wall and try to integrate this information uh it was a lot um thank you so much for coming on thank you so much yeah this was really fun yeah great the great great discussion thank you so much thanks thank you bye