[Music] all right hello and welcome everyone to actinflab live stream number 38.1 it's february 16th 2022 welcome to the actin flap we are a participatory online lab that is communicating learning and practicing applied active inference you can find us at the links on this slide this is a recorded and an archived live stream so please provide us with feedback so that we can improve our work all backgrounds and perspectives are welcome and we'll be following video etiquette for live stream just release an unending torrent of emojis if you have to speak or just raise your hand i'm sure that we'll get to it if you're watching live please feel free to write questions in the live chat and we'll have enough time to hang out and discuss during this dot one where we'll be opening into the paper check out activeinference.org for updated information on participating in any of the labs activities i hope you'll find something that resonates with you today in actinf livestream number 38.1 we're going to be learning and discussing this cool paper the evolution of brain architectures for predictive coding and active inference by pazulo parr and fristen from december 2021 and we're just going to enjoy discussing it and opening up any ideas or questions that us here on the panel have or those who are live chatting us and we have some ideas and thoughts prepared a few things that we know that we can go into and also i hope that everyone has brought some other prepared seeds and also of course spontaneously feeling like new things are arising so we'll just start with some introduction and warm-up we can each say hi and then maybe it'd be cool to just also mention like what got you excited about the paper or what made you want to discuss this paper what's something that stayed with you so i'm daniel i'm a researcher in california and i was very excited by the evolutionary focus a lot of my research over the last years has been in evolution in ecology so it's always awesome to see how people are thinking about how active inference free energy principle and evolutionary studies can all be learning from one another and i'll pass to stephen hello i'm stephen silly i'm in toronto um i'm really interested in how this paper connects to my work with spatial meaning making and social topographies because this paper talks about a more biological nascent stage of development rather than some higher order meaning often people think about and i'm really interested in how this sort of grounded bottom up inactive ecological approaches can be thought about as something where we can actually ground a lot of our meaning making and so i'm interested in how this might match with some of that thinking and i will pass this over to dean thanks steven i'm dean i'm in calgary uh what i found interesting about the paper is that given that i've worked with a lot of young learners for a lot of my life i was really it was really interesting to see how this affirmed a lot of the thinking that i was doing when i was trying to get people past the idea that science is only about the biology and the chemistry and the physics that there is a statistical and predictive component to this and those relationships in that in that realm um can build certain sense of what the underlying architecture is so as i said this is this is a lot of this is affirmations and it's kind of it's it's kind of seen as being not part of what is typically addressed as core learning but i think it should be back to you dan cool nice intro let's just start with a big question and then either of you have any reflections on the big question or we'll go over to blank slide and just bring up some questions we have and also it might be good to go over just some of the key points in the paper like what did they actually do in terms of their contribution so the big question or at least one way to phrase something that might bring someone to approach this paper what is the evolutionary neurophysiological basis of cognition and how do complex cognitive phenotypes arise like you don't go from zero to colony in one time step how does it happen that evolution arises from precursor sometimes simpler but also sometimes more complicated precursors steven mentioned like what is the basis for sense making and cognition and sense making are very related and what's been fun over these last weeks and months is we've explored basic or simple or reduced or basal cognition from a variety of perspectives like we talked about the bioelectric components of thinking about basal cognition with mike levin now we're thinking about a slightly different approach to understanding basal cognition which we'll be discussing here and then also we've looked at some of these more complex cognitive phenotypes like mental action counterfactuals deep temporal inference all the abductive logic which we'll get into probably later um how can we use integrative models of perception cognition action and impact like active inference to study this whole continuum and diversity of relatively simpler in our perspective cognition and also relatively more complex cognitive phenotypes and everything in between so yes stephen and then on with it thanks daniel yeah i mean i suppose also what what some of the paradigm impacts of that of taking that all the way through um and one question that might come up which you may or may not have an answer to or thoughts on but um you know mike levin's work with the tediological cones at the different nested levels and how this sort of could be thinking about what kind of um action control potential you know in in these different nested levels might exist um i would be interested to think about how this may um either be able to connect to that i can see it connecting philosophically or whether there's another bridge needed between this modeling and that type of modelling so just something i'll mention great um dean anything to add or perhaps i'm gonna wait till you get to uh figure one okay so we won't go through all of the binary points in the paper that's for the reading of the paper itself nor will we even go over all of the overview which is what the dot zero video 38.0 is for so you know turn back time and watch that one if you haven't or pause the video if you're not watching it live but what this paper does as evidenced by their roadmap is introduce a few basic principles of cognition predictive regulation and control and then also structure learning in generative models that's not how every neurophysiology text is going to begin the building blocks of cognition it's not how every evolutionary neurophysiology text is going to be framing cognition but that's what they do here and that will play into how it's similar and different than other approaches then with those building blocks in hand or on the floor they provide three examples of motifs that ancestral brains may be modeled as having or may have actually had with those three examples in hand it's then possible for them to state a more general way of thinking about the transitions amongst different structures these structures represent brain design as structure learning in generative models that is called an evolutionary algebra and they introduce five operators that can basically either leave unchanged or change the structure of brain design with respect to generative models and each of those are explored in terms of what are the architectural changes that that evolutionary transition is and then what are the functional consequences of that kind of an evolutionary transition then they have some discussions about how sequences or patterns of application of this evolutionary algebra could lead to different evolutionary phenomena so for example increasing temporal depth in the future means that models are increasingly prospective increasing temporal depth in the past is like memory etc and then they close with mapping to a phylogenetic tree and thinking about that evolutionary algebra of state transitions being mapped onto the bifurcating tree structure that's called the phylogenetic tree which shows the relatedness of different life forms um that's the roadmap let's go to the long-awaited figure one and talk about the action perception cycle and predictive regulation and so they're again discussing this in the context of predictive regulation anticipatory regulation cybernetics and control as a basic design principle for the brain so dean what do you see here or what would be cool to think about so what did this follows i think is is the usual pattern when we're trying to uh explain where we're going to go and so you just had a road map up and i think a road map is a way for the people who are reading the road map to find their way what i think what this diagram shows is that in that in the middle of there there's something called a discrepancy and that discrepancy is later going to be given up given a label y um and what i think is really interesting here is there's a there's a flip potentially that can happen here that discrepancy is where what i would describe as a rule factory and rule in the sense that we find patterns that's kind of our place where where as it says the prediction and the observation come together and i believe that that's different than a road map which is find your way i believe that that discrepancy of that rule factory is way binding and i think what we have the potential to do with this paper because of the way that they have sort of presented the information is the words become x eventually become explicated rules which then become action in the phenomenological space that's where it gets really really interesting because i think most of the time when people look at things as a subject they've taken the world and they've collapsed down to words and diagrams and models what this potentially allows us to do is flip that and move from the words back out into the space with a little bit more confidence so yeah that's why i wanted to kind of start here because i think the word discrepancy it's the first time i've seen it in this kind of figure model and i really like it cool yeah it makes me think about uh setting off on the road trip on the mental actions that reflect the paper and there's the road map which is super informative but it is like instructionalism it's saying you're going to go two streets and then take a left turn at the stop sign and then when this happens then you'll do that and if you've seen this then you've gone too far kind of classic instruction type sequences here we have a figuring out because it's visually arranged with some local connectivity that's suggestive of a causal connection through time but by no means is there only one way to read this simultaneous figure and so that allows potentially for more of a figuring out including the figuring out of rules yes it is indeed a little different with discrepancy at the intersection here stephen yeah so this ties in with the lower bound evidence um control approach on of action so you know the idea is that action is what we can tractably approximate um and perception is uh something that we can access but can't and we can try to make more sense of but is is is a harder a harder uh piece of the equation to get together to get a handle on so um i'm wondering if that's i mean how do you feel about that decoration in terms of its its use across other areas of applied active inference so i think it's a it could make things a little bit more digestible for a number of contexts okay i'm thinking about this in the context of recognizing that it's different than other action perception loops that we've seen which is just really important to keep in mind that we're not perceiving something that we're projecting too much because other times the outgoing arrow from the entity is what if this were a markov blanket type diagram which they often are the outgoing arrow would reflect active states and then the statistical dependencies that are outgoing but where is action it's on the bottom right so let's really try to understand why the pieces are placed this way the outgoing feature of the cognitive entity is the prediction and here's observation coming in if this were a markov blanket diagram we'd have the world and then the incoming statistical arrow would be the observation that would be the sensory states so here it's the outgoing prediction of the entity and the incoming sensory data or observation those two are being differentiated to form a discrepancy which is just a qualitative term but it could be then brought a little bit more formally into a prediction error or a little bit even beyond that into like a free energy differential this discrepancy has two arrows coming out of it from the discrepancy is a rising perception and the changing of beliefs does perception always involve changing beliefs and the discrepancy is also giving rise to action so what kind of a thing is discrepancy such that the inputs are prediction and observation and the outputs are perception and action so at the very least this is not the bayesian graph representations that we've seen before or that we'll see in just a few slides with a more traditional interpretation of nodes as random variables and edges as statistical dependencies this is a little bit more like a thought map that then connects to the variational free energy equation which we talked about in number 37 a lot more but just to recall there's the red and the blue lines these two different components of the variational free energy and those are shown again here so check out 37 to learn more about the red and the blue and about variational and expected free energy but for here we're starting with this action prediction discrepancy motif and then connecting it to perception and action as variational free energy minimization stephen i think one thing that's useful with this more nascent representation is this discrepancy can go in different different directions so it can be discrepancy in terms of temporal occurrence when was the prediction predicted to happen when was it observed but it could also be what kind of prediction and what kind of observation or whereabouts was the prediction whereabouts was the observation there's many different um and at different scales you know so there may be that um at the kind of lower levels there's quite a big jump between when i predict the baseball coming to my hand when that prediction was made when that observation occurs and also when that is chained up at different slower bigger steps of the um nested markov blanket sort of sequence so you this idea of discrepancy is uh i suppose is probably the biggest bucket they could find i would imagine at that at that spot and that may be partly why it's there can i just add to that stephen i think one of the things that's interesting is especially after just doing the 37 paper where we were talking about guides to me the timing of this was absolutely immaculate because now all of a sudden we've gone from guiding to almost taking potentially a referee's position on the world which is a whole different thing than than taking the taking up the position of being a guide and that was i mean that that's not nuance that's not subtle that's quite quite an identity shift and we're going to actually get into identity when we look at some of the evolutionary steps later on but i i wanted to slow down on this because i thought this that's not that's not a minor change that's a whole different perspective shift and i think we need to really make note of that because i think it colors a lot of what's to follow what makes you say that we're a referee in this situation discrepancy there's a difference between what what the world is telling us and then how we rule on them so think of any game where you get into an argument with the refs are they wrong are you wrong it doesn't really matter the point is that there's a difference that's when you said differential graphing is maybe one of the ways to be able to make that explicit but that's not how it's typically framed out when we're talking about bayesian or markovian stuff so i think this is i think this is a big move i know it might seem like a tiny one but i think as we go again as we go deeper into this paper it affirms a lot of the stuff that i actually saw when you're trying to go out there and forage and figure so i'm excited to keep going yeah it could be like the observation the the baseball player is running towards the base and the coach is observing and there's this ongoing prediction and observation with no discrepancy because part of the generative model includes the person moving through time and then given the observation and the generative model the coach predicts slash expects and prefers which will come to you again later with the three piece um that the baseball player is safe you rarely see um super animated refusals when a call has gone towards somebody but it's when it has gone against it's violated their fitness that there's a discrepancy with what the referee has called and what the interested coach has called and that is going to lead to some consequences and again we're still not at the bayesian graph level but that's going to be the next figure stephen this can then build on the idea of what's cognitive what what can you have a perspective on so i think what you're saying there with this referee position is as well as the kind of the swarming dynamics and the kind of inactive processes much of which is beyond our ability to sense or integrate what is it once it starts to hit what's the big bucket at the kind of cognition level that still isn't too much of a a um an inflation so in this case here discrepancy there is a sense of being able to distinguish perception and action at some level and find a discrepancy which in some ways i would imagine covers a lot of what cognition would require to be thought of in a cognition way other types of action for instance how we heal or grow maybe um action and perception won't be so separated but this is trying to come up the idea of cognition so maybe that also informs this process cool so section two again was just about the two concepts of predictive regulation and control that's what we saw here predictive and control so it's just conceptually laid out in figure 2 they formalize brain design as structured learning in generative models so here we have a different figure we still have the cognitive entity and the world we add in one layer of absolutely essential active terms which is generative model generative process the generative model is the cognitive entities model of the generative process is the underlying phenomena that gives rise to observations it's the difference between the cognitive model of vision a generative model of vision and the generative process of visual input which is like photons and the sun and all of that so these are very different they're complementary but just so that we're really clear going forward that we're going to be using those in their specific sense not using them like oh well it's a generative model because this is a model of cognition that makes me excited and think of ideas that's not how we're using generative model here so just to be clear on that now we see action as changing the world represented by you and the cognition involves partially action selection policy selection planning as inference but not going to all those details yet which can have some influence on actual unobserved hidden states the world x star x is the cognitive model of that hidden state of the world that is being inferred and y is the observation that then feeds back into the cognitive model so that's what these nodes mean it's about partitioning the cognitive model from the generative process separating the generative model from the generative process and we're starting to see the traditional blanket form with observations having incoming statistical dependencies and actions having outgoing statistical dependencies what else do either of you see in this model yatine hey let's see so let's go back to being a referee for a second the assumption is that you're already attending and most of these models that that we have taken up in the past especially in 37 what they try to focus on is getting from a to b what this is essentially saying is let's add something to that translation right from a to b whatever we're trying to incorporate in this representation let's maybe look at the interpretation part of it now and the recitation part of it so if i'm the umpire and we can all be umpires we don't have to do that just in a baseball game this is incorporating now a certain critical process i was attending and i saw this but then there were 60 000 other people also paying attention and they saw that that's where i think it this is getting really interesting now this is actually bringing it back to sort of i still think it's an instrumental piece but i think now we're going to incorporate some of the reality and is where the sixty thousand wrong or is the one person who yelled out safe wrong that's what i see in this because that you is is definitely embedded in the generative process not the generative model okay thanks dean stephen so the question that comes into mind is where the body is in all of this and i sense that the generative processes the bigger process with the world the generative model um gives a way to access those priors and and to give away the hidden states and the cognitive model generally speaking cognition is thought of more in terms of deductive and inductive reasoning and logic and and it could be that the that there's elements of the abductive that could be held within the kind of body and i suppose there's a question there um that to how and where that is i don't think anyone quite knows the answer to that but uh um that's that's my thought so let's remember that this partitioning is specific to a given instantiation of model-based science just like majeed was talking about so we're not going around and assigning aspects or phenomena of the world into either generative model or generative process so where does the body fit in well with respect to a model of the body being a structurally real thing that gives rise to observations it's a generative process looking at the coin from the other side and thinking of the body as a generative model of its niche doing inference on certain things or acting as if in that sense it's generative model so different kinds of entities are not going to be just assigned simply to one side or the other it's going to come down to what is specifically being discussed there's a few other um not complexifiers but first off just note that the no the notation here is not the same that's used elsewhere so we will move towards better and cleaner or reformatable notation but like x star as a external state and x as an internal state might be clearer for some people it also carries a little bit of a baggage that the hidden state is exactly what is being inferred about the external world like there's a temperature parameter in the brain and then there's a temperature parameter outside in the world as we explore in the representations paper it doesn't necessarily have to be that way there could be in a hidden state internally having to do with movement left or right and then there's a temperature variable outside and then the model the generative model of the cognizer is about movement conditioned on temperature observations but not necessarily simply a thermometer being instantiated in the head so it's like good to look at this graphically and think about what is being connected to what without worrying too much about all of these side questions but this is what they're setting up as the basis of their further discussion which is it's about prediction and control and we can use bayesian graphical approaches to represent that stephen and that inferred state as you mentioned it's uh in some ways that's always slightly hidden from us like how is that what is that mean to be an inferred state in terms of is that the cognition that's coming out of that in some sort of deductive or can it be an effective sense of how well something's going so again it's not directly asked here but accessing that is one of the big problems that happens is how do you access what has been inferred when it's not necessarily something you can access through sort of direct reporting from a subject matter or from a from participant right like another example of that might be somebody who has skilled action with respect to investing but they may not be able to give an estimate for a number that's a certain you know asset is expected to be at because it's not like they're doing the asset price prediction and then doing a strategy the cognitive model may have a very different structure so we explored it in the representations paper but like there would be ways in which therefore that investment decision is not a representation of the actual stock market because it's not the same variable but then the aboutness of the investment decision would be a representation with respect to what was happening in the generative process so those were some of the like side avenues that we've looked at previously but they're all in play at once and so the question is just how to linearly structure to respect the specific contributions that are made here and the insight that can be gleaned without um every single time pulling back to some of these questions but it's great that we have like specific papers and memes and core terms that we can refer to and then carry on with what they actually contribute okay any thoughts on one or two before we get into the structure of the um aloe stat or the homeostat first i guess let's go okay again so we're going to go from this black and white you know dorothy still in kansas mode to some predictive motifs of ancestral brains and the three motifs the red green and blue are homeostasis so returning to a set point allostasis anticipating or approaching a set point in the future which could be a fixed or changing one and then implementing behavioral control not just scalar homeostasis or allostasis on an enteroceptive variable okay citation 20 in the paper chance at all from the future march 22 is where to look for more details on the homeostatic formulation that they're using here but we can see it in terms of their figure three okay so the left side just for reference there's figure two so that we can remember the structure of perception cognition action impact that the authors are working with here and we're gonna connect this black and white figure 2 to figure 3a this is a graphical model graphical in both senses meaning visual like we're perceiving it through computer graphics and graphical meaning like a network so nodes and edges because there's computer graphics that aren't network topologies but this happens to be a computer graphic that we're perceiving visually that also is reflecting a graph in terms of nodes and connected edges it's a generative model for the regulation of a single interceptive variable so here's a and b with the homeostat and c we split out to talk about later but first a and b this generative model includes an enteroceptive thermoreceptor and a belief about body temperature the prior over x which is body temperature is kept fixed and hence it acts as a cybernetic set point any discrepancy between the predictive thermoreceptor activity given beliefs about x so y conditioned on x and the measured y is registered as a prediction error that is canceled out by an autonomic response u for example a thermoregulatory response so hidden state on temperature beliefs about temperature y the thermometer perception and then there's the selection of action so some sort of like vasodilation or thermoregulatory response and then that's going to change the underlying unobserved true temperature but that's not um needing to be shown so any comments on that first part we're looking just at the top half of 3a and connecting x y to um you action can you still hear me because i yeah can you take can you take the cursor now and just reinforce the feedback and the feed forward part of this because the authors spent a bit i don't want it sort of unpacked like they have at the at the figure three unpacking that we have in the bottom of the slide can you just run the cursor over all the examples of feedback and feed forward going on concurrently because i think that's that's really important to see that it's happening in both directions at once let's label everything and then definitely can do that perfect thank you okay so light blue is action these are subtracted so red circles represent expected values of x the red circles are used to make predictions about y these are subtracted to form a prediction error because those lines with the arrows on the end of them are just dependencies they don't really show both the feedback and the feed forward yes agreed like having some rounded edges and other um directed edges let's see whether it's whether they're like kind or not um let's start with action action influences the state of the world which an edge can be drawn to how that changes the state of the thermoreceptor i thought why here was the observation yeah that's the state of the thermoreceptor is the observation okay yeah so action changes the observation the state of the thermoreceptor um which is being contrasted with the belief about temperature yes from there a prediction error is generated it could be zero if there's no difference or it could be higher that can you can you just show with a green some colored line that has an arrow on each end a connection that demonstrates within that diagram the feedback and the feed forward at once is that possible using this diagram let's see it's this representation so a single arrow that a single line that has an arrow at both ends is a different color so we've superimposed it over this but that it shows that there's a feedback feed forward loop going off at the same time okay so here's the temperature information measurement flowing in to contrast with the beliefs and this is it is in general really important to label the edges not just use color coding we'll let it roll for now the information's flowing from the measurement to the belief and then that gives us the prediction error the prediction error is used in the selection of action which then influences future observations now the red circles represent expected values of x i'm actually not sure what exactly the red bottom larger circle is meaning because the prediction error well there has to be some way of representing that discrepancy right so they needed they needed the second ball on the bottom to show difference like between prediction error and expectation i think that's all that's trying to show yeah or another possibility might be that the prior is staying fixed that's actually music yeah priors can also they can be flexible but in this case it's a fixed prior that's because we're talking about homeostasis then the observations are diverging from the prior and the posterior is kind of like the realized perception which is a compromise between the sensory data coming in and the prior and so yes there's a lot of degrees of freedom depending on how parameters are weighted this green line might approximate the red a lot more sharply we'd call that a weaker prior because sensory data updates the posterior to be more like it or it could be the case that having a lot of observations different from your prior don't change it that's a strong prior where sensory data do not change it as much but then here is the prediction error in relationship to x i i don't know we can look at the paper but is mu shown in an equation i don't have it copied out if it is let me look here while you're doing that yeah but that is the perhaps here okay um stephen anything yeah i'm just noting how the effectively the belief on temperature it's it flows through the thermosector down into the to get the expectation and prediction error so it's you know it's it's it's like you've shown there there is a a dynamic going down from the belief through to prediction error being mediated it's like the thermoceptor is kind of like a mediator between belief and [Music] prediction error on what to do for action and another point i the reason why you can't find the mu is because it's not actually pointed to in the description yeah and i remember reading and looking at looking and looking and not being able to find it and then looping back up up paper to go okay so how about feedback feed forward now there are cases where vue is used to describe internal states that may be implicitly how it's being used but it's super important that all variables are defined in a paper i wish they all had a table for every single variable and expression that were used yeah it would make the dot zeros easier but also it would reduce uncertainty um for example is um is this epsilon even described okay steven i mean i suppose in a thermostat in some ways the the internal states um of the bioelectric strip and in some ways it's kind of um it holds the kind of the the way that um the expectations of action can happen because in some ways it dictates the way that um the thermostat will behave it's uh in some sort of ways even if it's kind of a an analog uh process so i'm i'm thinking like where where would the kind of in a thermostat where would um i know this is a homeostat so it's a bit more sophisticated now but extrapolating that out you've you've kind of got a belief and there's a belief of what something is and then there's an expectation of what you can do about it um for instance i my beliefs can go bigger than what i can do in my actions i could have beliefs about temperature which exceeds where i could even exist or where i am able to change it you know it depends on the scenario so there's it's sort of held in in both scenarios in in both the body and the context and the kind of the the the probabilities available okay so for a non-living thermostat it doesn't have a cognitive belief on temperature but there could be something that's computationally like that reflected by like just a digital prior on temperature and again these aren't cognitive personal affective experienced beliefs bayesian belief this is just saying random variable reflecting in a model variable on temperature so even a sincerely held incorrect psychological belief is not the bayesian belief they might coincide at times if it were a parameter but um the belief here being uh the prior it must be adaptive that's the evolutionary twist that actually helps resolve a lot of this because otherwise right the design space of all edges by all nodes and then any variable i mean it's just like saying here's all the words in the dictionary and so evolution helps restrict the discussion to cases that actually do manage to achieve adaptive control dean and this is where that translation from the silhouette of the head to a statistical density is assumed that we're the the person who's following along with this just sees that but it's but you can also see how easy it is to slip into the idea that oh wait a second we've gone from the physical space and we just held onto the physical space when really now we're talking about a statistical density space and again if you're not if you're not really really careful you can see how people can carry forward something but the actual thing that they're talking about has changed that's why the word discrepancy was such a big deal to me because i normally gloss over things but this time it actually i went oh okay so there's going to be some there's going to be some moments here where we're actually talking about different things even though in the continuum we we kind of think that they're talking about the same thing no we're not yep it's um the travails of realism and instrumentalism for biological active inference episode 55 because are these terms are they an example or is this an example of a model being used to discuss a real system but this suffice to say is the architecture of the homeostat it undertakes action to reduce discrepancy relative to a prior held belief fixed in this case about what temperatures are expected slash preferred the dialectic of the first two p's from live stream number 37. this is an expectation and a preference because expectations having to do with survival are as good as preferences for survival over evolutionary time okay this is going to be contrasted with figure 3 b which is the allostat and so we see the same stack of x 1 y 1 light blue dark blue red except there's now a second column next to it and there's some cross connectivity so again the x's are going to be beliefs about so priors on and then these are observations and so they're saying this generative model extends the homeostat by including a second set of exteroceptive variables that correspond to light intensity y2 observations of light and beliefs about sunrise so like beliefs about the generative process so generative model of the generative process furthermore the model includes a predictive relationship between sunrise x2 and body temperature y so again i wish we could label every edge because the edges are meaning different things even at different times like this is a predictive relationship so it's an anticipatory one but then the one about light intensity and the belief about sunrise there would be ways to make that an anticipatory or an anticip or an instantaneous relationship but the result of this sketched architecture is that inferring a sunrise which will only happen with high posterior confidence if the visual observations are consistent so low prediction error inferring a sunrise not quote seeing a sunrise that is not what is happening in the model inferring a sunrise and finding that visual observations are compatible with it can trigger the autonomic response the behavior you of thermoregulation in an anticipatory manner that is before sunlight actually increases body temperature well how would the parameter be set that way because if that were adaptive then other parameter combinations have been weeded out already by evolution so that is where we tuck the thread back into the ball of yarn which is the parameter combinations that are non-adaptive die they dissipate they fail to exist they're not going to be measured as things in the future empirically however you want to take it so like the quote like how does it work it's the same as it was 50 years ago which is it has to do with survival of the persistent stephen and these um these graphs what they're used for as well is they they do show beliefs tied to the observation space that the space available um around the observation uh the you know whatever the sensorium that is available that's what gives the beliefs its scope and then the expectations are tied in here more clearly to action so the errors the errors of the the the the what's important the the the actual um dynamic that's driving action to change something is is is coming out of the prediction area error that's feeding into action i think that's quite important as because you know this is like the proto animal you know this is like the proto kind of piece here that ties into a lot of how we think about knowledge and meaning and i'm not saying that i'm just i'm just extrapolating a lot but i think it does show how beliefs are tied to the type of sensorim that is being used to shape the observation space i think that's quite useful yeah and these are just yeah dean first got i just want to get your gut both you guys opinions about that orange barbell at the bottom of the diagram because talking identity but we're also still talking about dependency we're talking about duplication we're talking about anticipation so that's a lot of stuff packed in one orange barbell what do you think yeah i'm going back to the full caption the red circles represent the expected values of x so if we're interpreting these as the posteriors on x because the expectations the priors are the top blue ones so it wouldn't have to be the red circles and they don't mention the word orange no it's there and it's identity note the lateral modulatory connections in the allostatic network c24 for details and 24 is the graphical brain with first and par and device um so yeah again this is just a sketch model they're not using it to fit any data or even simulate any data and it does relate to what stephen said about the the inter sensory or the intermodal inference which is one could imagine a cognitive model where if sunrise if there's noises that are associated with sunrise then beliefs about sunrise can be a variable with edges coming from different sensory modalities so it gives us a separation of the um organs of sense and internal cognitive modeling stephen yeah it gives a gives a sense of when would something be important to act upon so there's many many things that i could believe i'm seeing or being perceived in terms of this is sunrise or this is um you know this is the type of light coming in this is the nature of the light this is where the the light's coming from there's all sorts of stuff the stuff that's really filtering down is what is important and this is where the affordance is coming what affords me to make some action you know if it was expanding out so there can be lots of things i noticed like i might notice that that there's a line there and i may notice and believe it's orange but i may not act upon it until i take my attention to it and think it's useful as there's many things going on on the page you know so when we're we have beliefs but then there's what's being acted upon out of all of that to then create some sort of change so i think that is also quite useful in this architecture cool i want to can i add to this because i think it's really important um so we're talking about in the in the context of a of a sun coming up but let's let's see whether it still is true and i think it is just to prove a point whether that orange orange barbell still makes sense if we're talking about daniel anticipating 61 year old daniel and stephen anticipating 61 year old stephen and dean anticipating 61 year old dean now i'm much closer to 61 than the two of you but do i need the mark do i need the monte carlo do i need the play out to be able to make that anticipation as long as i have the identity and the parallelism and the backwards and forwards looking dependency that we see between x1 and x2 and y1 and y2 that's what i think is makes this a very interesting way of being able to sort of build on the previous homeostatic example thanks steven yeah i think also this speaks to traditionally we think about the meaning what does this mean what's all the meaning out there as you mentioned all the data the stuff that it could mean to relate all these variables but ultimately um and the bit that is actually what active inference gives us is that barbell is where the meaning comes in it's like the way to know how being 61 is for you dean is for you to imagine what it would be like to make choices and to act in the world as a 61 year old dean not necessarily to go out and look at all the the data so to speak all the beliefs and the things we think about the world but to actually bring that in and and of course you've got a better chance to do that because you're closer to being that kind of dean um so i think that's quite interesting that barbell at the bottom in terms of um pairing together the kind of beliefs about what actions and prediction areas are available and it's more into that meaningful action meaningfulness realm rather than what does it mean what's the data tell us so yeah we might we might get there and i'm not pushing back on what you're saying stephen we might get there but i think for now what we're saying what we're saying is is that in order to get there we have to have more than more than a a single stack of dependencies we have to have a double stack in order to be able to extend the homeostatic nature of how we've evolved to where we are i don't know again i'm not pushing back on you i'm just saying i don't want to jump that i don't want to jump that firing pistol just yet because i think that orange barbell is going to turn into a green arrow and then all hail is going to break loose anyway so we should carry on i don't want to take steven's stuff away but i want i think i want to park it because we're going to go somewhere in a minute i'm hesitant to ascribe too much specif specificity to something that wasn't labeled in the caption doesn't have a clear labeling in the figure either but i think it is already demonstrated that using graphical frameworks and partitionings like we have an active inference we can start to approach some of these questions like how would different kinds of variables be connected how does that relate to future inference on action counterfactuals etc okay so these sections um four five six seven were just laying out the relationship between an evolutionary or physiological function like homeostasis allostasis or simple behavioral control models of things that are core evolutionary features and functions connecting them to the kinds of graphical representations which are like a little bit of a hybrid of a bayesian graph and a factor graph because there's some kind of computations being implied here whereas in a bayesian graph the edges only reflect statistical dependencies whereas we're bringing in a little bit more of like a nuanced type relationship that one could imagine could be unpacked a bit more were to be specified but it's just to show how different graphical models relate to different functions architectural underpinnings whether you think this is the actual architecture or whether it's just an instrumental architecture like a model structure on a given phenomena how do model architectures relate to evolutionary functions where is evolutionary time in this model we started out by asking like how do cognitive phenotypes arise specifically over evolutionary but also over developmental time and that's where we get to one of the main pieces and contributions of the paper which is figure four the five main dimensions of elaboration of generative models introduced in this paper so there's other kinds of changes and ways that this structure could evolve but they're going to focus on these five there's starting with the homeostat does that have to be our starting point maybe not but starting with the homeostat there's the i operation which is identity unchanged there's i plus i which is just a parallel isolated duplication that's like from one photoreceptor to going to two photoreceptors so to speak there's the allostat which is a duplication as well as a cross linking so these are just sketches one could also probably write that one as like a duplication followed by a linking and there's no like change in linking for example here so this is like a few of a taxonomy of operations there's increases in temporal depth within a level of the hierarchy so looking one more unit further in time at a given time scale and then there's hierarchical nesting with an h and the figure is shown like this because these are like the things that can happen to the homeostat and then they can have a second round and so on and so on there's so many other ones that could happen like where is reduction where's loss where's deduplication where's the uncoupling of the allostat reduction of temporal depth reduction of hierarchy so there's a broad space but one of the main contributions of this paper is to connect functionally oriented graphical models of homeostatic and physiological function to the operations that result in the elaboration of simpler model architectures into different architectures steen this is an interesting part i know steven wants to have to say something too but really quickly there's no plus minus multiply and divide there's an operation but there there's no symbolism for that and again that's that keeps it safe on a statistical level i think that's that's a that's a nice tell there i want to again for somebody who's just sort of looking at this for the first time pointing that out it's not there and because it's not present that tells us something to your point about maybe how do we get d duplication yes it's um well i plus i it is like it's it's a suggestive use of the addition operator but we're not adding these just like integers so yes they're kind of like categorical operations that constitute this evolutionary algebra okay stephen anything on figure four yeah i was just saying that i was saying they've set up they've set a a kind of a paradigm from the homeostat and they've taken that through and they've shown that plausibly can carry through to cognition and then like you say there can be other ways but what they've now given is they've given some legs another way to think of the legs that can be attached to that paradigm because this modeling approach while they could have chosen a lot others by taking it there are certain things that your heart baked into that early stage choice making which then makes other paradigms wouldn't fit with it right you know you certain certain even when you go instrumental or realist you know your instrumental models your realist models don't make sense unless you with this unless you take in some of the paradigms that this structuring creates yeah agreed thanks so just maybe think like is this functional model realism like the function of the model is what is being tracked through time and so that there's many other alterations that could occur and then there's the even more granular like parametric changes or changes in connectivity or edge types and then i think uh as you said dean when all hell breaks loose what's interesting here let's look at the allostat in a little bit closer detail okay so previously we looked at the allostat and we were like okay there's an orange bar now the allostat has a green bar it's a green arrow and it's a unidirectional one well this one independence the allostat has the green bar oh it's okay well those are my bad eyes because i saw i saw the little arrow from the blue actually turning i didn't actually see that there was two circles thank you there's my 60 year old eyes for you yeah um okay cool um and so each of these are in quite a different domain um or at least like a different aspect of cognition and these are the transitions that it can engage in so like duplication retains the exact same function but it's a very important step and that's a little bit what i explored in the dot zero with genetic duplications like on the left side here at the screen having a region of the genome duplicate yes one of the duplicate copies can just degenerate that may be like opening up space or creating motifs for other kinds of later evolutionary steps so even this is not like a failure it's just a change there's neo-functionalization where then those two models can start to sub-specify like if you only have one photoreceptor it has to be doing what it's doing but duplicating it then allows one to focus on a different wavelength than the other for example and then there's um sub functionalization which is where initially a composite function a b becomes two like enzymes start to sub-specialize on one of the two functions of the ancestral so this is kind of like a role duplication um okay so duplication is an important event then there's the allostat and multiple things happen with a but we're seeing it as there is a duplication occurring and there's also cross-linking occurring between beliefs in one modality or beliefs about one type of thing influencing observations um or in about another kind of thing as well as this lateral modulatory uh green orange bar um we have and then we have two kinds of expansions into temporal depth a sort of local expansion with the t operation just pushing the model one step deeper and then the h hierarchical nesting operation which brings it to another time scale of analysis dean and this is where i really struggled and that is in when they were at allostat it wasn't just comparative i felt like you had to build in time especially if you were talking about identity but then it was like no we're just going to leave it comparative and then we're going to introduce the oneness of this i mean i understand why they're doing that to try to make it tractable but i don't know how they can say it can be comparative meaning i know the difference between a and b right now but not not sort of address the fact that in order to differentiate into a and b some some amount of time had to had to have been applied to that split so i had i was i was saying you have to go back in time in order to just be able to do a comparison so it's temporal only going forward in time i don't mean all hell broke loose but i mean i i did ask this question you're right like here there's um there's the triggering in an anticipatory manner and so in one view it's like but this is a single time step model so how could that occur because it doesn't have a temporal depth on the other hand again like kind of that those two senses of representation in the structural sense if the model's a single time step model it can't have a representation through deep time ergo it cannot be anticipatory functionally right the other side of the coin would be if it's enough at this time step such that beliefs about sunrise trigger and a response the model can be functionally anticipatory without a temporal depth representation right which is why the representation discussion was very important leading up to this one because we're all over those eight quadrants here because in evolution and this is something that like cognitive psych people talk about and is like are cognition being shaped towards effective which is to say productive slash reproductive success not towards like ultimate truth discovery and so should we be too surprised that our instrumentation which has had a certain objective function is then susceptible to being convinced about things that are not true well i don't i don't socialize with those people so i i don't know i just knew that when i was looking at it i was thinking in real practical terms what what what is built into this in order for it to still make sense and that wasn't necessarily parsed out in the diagram you kind of had to fill that in through your own interpretation of what was going on so thus back to discrepancy that discrepancy thing is going to come up again and again and i'm really glad that they inserted it at the beginning steven i think it's useful here to hear this temple depth and hierarchical depth being sort of spelt out so because i think it sometimes it's a little confusing in other papers quite where it fits so temporal depth and this again might be where some of this ontology work can be useful just to see if that can be kind of consistent but if temporal depth is you know you've got variables for past present and future states but they're operating maybe maybe within the same kind of dynamics and then if you've got different um temple rates operating simultaneously then you get that hierarchical depth and i thought in the past i'd sometimes thought temporal depth would have covered that more hierarchical depth so you know this is interesting to think about whether this might be actually the way that that differentiation is best made differentiation is probably best made with reference to a specific model and this gives us the design language and the grammar and the motifs so if we want to predict 100 years in the future should we have a decade model with 10 year models that's a times depth of 10 decades and then a nested model with a depth of 10 years or but we have a one layer model with a hundred they're very different and it's not to say that one is like more accurate or less and depending on how the exact situation is set up maybe the computational requirements of one or higher are different than the other but that's the discussion to have do we want to have a b transition matrix let's look at a nested model with temporal depth so here we have on the top level of the model s state 2 this is temporal depth happening at the upper level of the model three discrete time points in an upper level that is temporal depth there's also nesting within each um time step there's a cognitive rollout on three time steps this is one type of nested model but there's other nestings that can exist so here we see a depth of two and then at each level of the nesting there's three temporal depth but they're totally different in architecture and in function so it is the interesting discussion like especially when we have to do multi-scale prediction like fermi estimation so if the prediction is within one time scale there isn't necessarily a need to nest but once we get into larger time scales or where there's recurrence over multiple time scales it makes sense to have a nesting model like if we wanted to predict someone's activity over the next seven days it might make sense to have a day model with a nested model inside of that because then within each day there could be parameter setting versus just trying to fit one time series and find the parameters that make that one time series oscillate in a circadian way instead we just need a day model with a very specific kind of simple transition and then a transition at a nested level with a depth that's measured at the hourly or the minute time scale rather than the days and that becomes especially important when doing family based model fitting like variational inference so we're not just like getting all the data points and fitting a spline through them but we actually need to have appropriate model structure otherwise free energy minimization will drive right off the cliff just like we talked about with axel's bacterium so if we want to do free energy minimization and model selection on model structures we can find the best model relatively easily given the families that we've specified but there's no guarantees once we step outside of that spotlight that we're even in the right category structurally and so that's why humans having these design motifs in mind and many many many more helps us not get into what seems to be a global optimization based upon free energy minimization but actually is a very relatively local optimization based upon unimaginative model structured learning stephen yeah thanks that's really helpful and and it also ties into something i've been really thinking about in terms of the modeling itself is these these these scales these steps you know you're talking about the multi-year decades when we're modeling it's like what do we have access to so we tend to ascribe that in terms of what can we externalize what can we use to put something into a model if it's instrumental and then of course there's a question of well what is the realist perspective on that and what is there that's within our conscious awareness of being in the world something that can be reported as an event a story and what time scales are present there when you get into 100 years it's beyond that so then you're saying okay what are you going to extrapolate what sort of temple structure but on the other scale if i'm asking what do i think i expect you to do next or to dean to do next and that might seem intuitive i can have a whole series of temple and nested scales going on which is not even available to me in a in a cognitive conscious way i might have a sense i have a feel for what i think is going on but a lot of my um predictive processing will be happening at rates unavailable to my conscious awareness so that's that also ties in i suppose i'm not saying it's an art sort of adds to the challenge i suppose but it is the challenge of you know how much ends up being what we can get a measure on to put into our model as much as what it is and that's the same challenge in a way that comes even from the realist perspective at some level as an organism what is it that i even can access in some realistic way not saying we can model it or no that could be put into something like this sorry you're going to say something well all i was going to add is that i mean so the paper's talking about how do we how do we use certain math to be able to understand maybe the evolution of of cognition right that's essentially what the paper is trying to give you know point us in that direction so again in order to make this accessible in order to sort of lower the barrier for people who actually want to have this make sense because they don't necessarily spend sums and sums of hours on on trying to figure this stuff out like the authors or maybe even us i'm going to i want to point out something that i think is obvious to us but maybe not so obvious to people who are looking at this and going i have no idea what they're saying i think first of all is that there's a chrono a chronolog chronology which we keep going back to not just at the temporal depth level but so that's relativity math there's an evolutionary aspect to this so that's algebraic math and there's a dependency so there's a statistical math do we have to be poly math in order to be able to feel our way through this and i'm going to go back to what i said at the end of the 37 first carl firsten said you're not gonna be a polymath but you better be at least somewhat comfortable feeling comfortable with the math because there's no one math that's going to get you here it's a blending of all of them and then it's how it how you feel about that that's probably going to be the thing that lowers the the impediment to really being able to use this now in real practical terms going forward so what's the next evolutionary step right it's how you're able to turn this into something so i think that's i think that's one of the great gifts of this paper if you're not afraid of being if you don't consider if you don't want to identify now where you don't duplicate now or you don't allostat now as a polymath maybe maybe that's something we we owe people that want to get into this maybe the british pronunciation of maths helps reflect that there's already a plurality of maths and kirby erner coming more from the synergetic side talks a lot about this actually like how the discourse around math as universal language makes it sound like math is a singular language when actually math is a pluriverse and so maths reflects that a little better better it's not like these are um just sort of slopes on one mountain and that's mount math and it's so high and only a few people get to the top and scale every side this is just like we're using maths yes of all different kinds steven and often that you see a lot of this in the papers that are published around active inference there's often a team of people a group of people where maybe one member has that higher level understanding the math but the other question is is to understand what would it mean to make an observation now that could be a very the mathematician may not be the one what like some of the work with ryan smith's work on the gut you know it was like well they're going to do gut inference well how do you get some tractable source on what's the gut doing so they created some electrode i'm not quite sure how they did it but they had some way of getting sensory information effectively sensory information or effectively some sort of information to put into their model and so knowing how action and observations can flow in and the implications of that i think is also kind of a a big part of of this right and in some cases it may be the trivial part because it's fairly obvious in other parts that may be the biggest barrier to and then that may be the biggest barrier as well often in in organisms right how do you how do you even access plausibly the approximation science which isn't so approximate approximate it's just chaos that is tractable yeah the rate limiting step or impact and improvement in the real world is unlikely to be any single individual's conceptualization of math on a team if it's structured appropriately and for those pushing the frontiers of math their understanding of math is quite literally a rate limiting step for them or maybe it might be something very mundane like time availability but when it comes to thinking about real model based science and translational applications of active inference i think that we're working towards new ways of combining skills and having shared knowledge resources that help make that make sense and using shared language and ontologies narratives formal documents tools on ft because we're doing it on teams and we're online let's just in the last 20 30 minutes go through the final pieces of the paper so that this dot one will have been like a first sweep initial pheromone deposition and then we can return and take some cul-de-sacs etc so section nine explores a little bit how the duplication operation allows for multiple behaviors to arise and that's sort of by analogy to the um the genomic duplications and specializations and all those different routes that can occur here they connected duplication a little bit more directly to the factor graph models in the sense that duplicated motifs have dynamics that are conserved over different sensory motor domains so let's just say that we just had a visual model with the column of visual and then we duplicated it so now we have two photoreceptors with parallel columns and now the photoreceptor in the second one changes into a chemoreceptor because instead of expressing rhodopsin protein it's expressing an olfactory receptor protein there can be a conservation of the dynamics of inference even when the observation has changed but it was a slot for observation and so we went from having like monocular vision to binocular vision to monocular vision and olfactory perception but you can't get there in one jump to just like duplicate and transpose it's not likely to happen in an evolutionary context and we can see the structure of these graphical models as equivalent to being factorized probability distributions which is to say that the sparse connectivity of variables means that we can make parts of the model that can be like fine-tuned independently in a way that can be fit very attractively that's the factor graph that's factorized bayesian inference and we've talked about that in other places but just to here all we need to say is duplication enables like a control c control v copy paste and then let's edit the other version but that can now happen with evolutionary features and functions dean real quick your hand gestures in this section point to the orthogonal orthogonal mesh beginning okay and then point two i'd like to pull that apart a little bit but let's carry on but that's that's what i've took away from this the men the mesh began and in the beginning there was a mesh begins we'll return to that for um dot two yeah okay section 10 talks about temporal depth it's about time and about the endowing of generative models with temporal depth and the way that that supports prospective inference anticipation or retrospective inference which is like memory so here's what the operator looks like we have x sub tau x at a time point and then now there's x tau plus one the next time point or t plus one could be now and then t could be the last moment so um memory i still see figure four um slide 29 okay yeah so the structure of anticipation and of memory are very similar it just depends whether one has the um stream of observations happening on the left side and a prospection or the stream of observations are on the right side and in which case it's retrospection stephen yeah i mean sort of ties in they talk about what the police do it's very hard for someone to lie backwards so you always get them to tell their story backwards because it's a it's very hard for them to to do that because you say if we're creating things retrospectively but playing them forward so to speak it would kind of time without i want to emancipate that i looked up police in the paper i see policies is that policies um it's a great opportunity for my favorite joke but i won't um this section talks about temporal depth okay from whence temporal depth various researchers have speculated that a major driving force for the development of deep temporal models was foraging and there's a lot of interesting empirical and conceptual reasons to think about foraging in terms of temporal and spatial depth of model and that's true in the vertebrates where they're discussing mainly like hippocampus and entorinal system and in the invertebrates that don't have a hippocampus enterorinal system but it's one reason why comparative neuroscience is so important because it prevents us from getting fixed on specific anatomical realizations of given functional attributes of evolutionary systems like if the story of memory is just about some brain region in humans it may be a useful model it's not even to say that it's inaccurate it's not even to say that it's a partial model it just is a model of that whereas if we want to understand a given cognitive function in a broader context we have to pull back somewhere a little bit beyond or in complement to the anatomy because we need the empirical anatomy to have anything specific to be talking about but it isn't just the case that vertebrae anatomy is the way to do active inference uh stephen yeah i think this is really helpful because it it shows that you know the traps you were just mentioning there that people we fall into is like humans have you know the the frontal cortex it's all about this new then what's the new parts of the brain that are there but we don't say that with a formula one car we say well it's just got a primitive engine thing in there and the rest of it's evolved it's like well that's itself different like this and the same with the mark someone's conversation you know the the the evolution of the break what's often dismissed as the primitive parts of the brain they they themselves can have been more sophisticated although they're doing more things but that they they they they may be helped to be doing more than they were as opposed to there's something else um that is doing all the heavy lifting which i think is certainly common a common misconception i think in psychology anyway dean can i read quickly from the paper sure okay the evolution of temporally deep models from simpler models could been realized during evolution via the progressive keyword here partialization of an initially undifferentiated model so a relative sense of an invariance i.e a model that does not distinguish present from past future into a model that features separate latent states for the past present and future this is the part i loved a key drive for this factorization or parcelation parcellation may have been the observation and progressive internalization of the sensory motor sequences sequence sequentially that the animal creates and experiences while acting while acting in other words the self-modeling of one's own sequential behavior patterns c53 for a computational example i didn't open up 53 but again if we want to talk about the polymath piece of this and the fact that our hex cells have to do some partialization it's right there in terms of sort of the the the next layer on top of this as we move up through that evolutionary cycle yeah 53 is stoin of at all the hippocampal formation as a hierarchical generative model supporting generative replay and continual learning there's a ton that could be said about that from like a computational and a neuro anatomical perspective the internalization of the sensory motor sequences relates to the sensory motor detachment that we talked about in the representation paper so if um some motor region in the brain if it's like a marionette and the fingers and then the motor um plant so that motor region is has to be coupled to the activity of that motor region like either in a one directional way or maybe even in a bi-directional way let's just say so that system like as it thinks so it does and vice versa it cannot engage in counter factuals because any direction that the neural system turns the motor system is just simply doing that so it is not able to engage over evolutionary time in bowel adaptive action the ones that do no longer persist it's just it's always what ties it back to reality into like the finite amount of entities on the finite spaceship earth like darwin's famous calculation like if the number of elephants slowly reproducing like they'll cover the earth unless their population levels are kept in check and so um once there's sensory motor detachment so there's some brain region either a motor region or some supplemental area some ancillary area that's able to intervene in that process or somehow play a role that's detached from the motor activity now there can be like a motor planning occurring that opens up the affordance of temporal depth or of counter factuals all these other cognitive functions arising via the sensory motor detachment and so um foraging is an awesome place to look at that for a lot of reasons in different life forms and computational forging and so like just a few of the notes were like what are the real cognitive demands of foraging for different creatures and what about internal foraging like mental foraging and these papers are very good foraging in mind and foraging in semantic fields both very useful because they have to do with the way that um they have some nice maths too but they have to do with how actions that are spatial can have conserved dynamics structurally just like we explored here to mental actions and then we see them come together like with a memory palace or something like that um so foraging is cool it's good to study eleven endowing generative models with hierarchical depth of four's multi-scale inference we kind of addressed that earlier with like the decades and years nested temporal modeling is not the same as just deep temporal modeling and then um and another way to look at that is like how many operations you would need to get to a hundred years well if you're gonna do only temporal depth it's gonna take plus a hundred or ninety nine time steps versus if it's one nesting and then 10 on the higher order than 10 on the lower order it was 21 operations and so then there's shorter sequence of events to achieve a higher performance model assuming that they're appropriate um section 12 uh yeah go ahead just one thing just on on that modeling it's also interesting think about how we think of time because like indigenous approaches tends to be well as a cyclical time right so things in the future will be a repeat of the cycle so the times of uh i thought of in in the cyclic motion of the sort of passing of the day passing of the um and of course we have this we we have this assumption of time stretching out you know so is it that we will uh you know over time is it well what will things be like in four generations and um and if my world or my ecology follows certain cyclical patterns and it's very stable maybe that's quite a good way to think about um you know it's like say plant plant the tree now to help the people in 150 years you know so um it sort of comes back to there's different ways to construct how we think about time [Music] cool so 12 looks into phylogenetic tree of the evolution of generative model so what is a phylogenetic tree and what's the relationship between active inference slash fep and evolution well we'll have more to share in the coming papers as always but how do they address it specifically here in figure five they um map on will root the tree so technically as shown right here it's an unrooted tree there is an implicit rooting here but it's a very interesting feature of phylogenetics that few outside of the field know about that computationally the tree is often inferred in an unrooted fashion like by clustering the ones that are close and finding the relationships etc however that is leaving an ambiguity as to where the root of the tree is so like for example if this is the overall connectivity of the um based upon the phylogenetic inference this is what the tree topology has been inferred to look like and somebody might say well it looks like this one the red one and then the green one below it they are um they're clearly very closely related but actually if the root comes in here then that's not necessarily the case so the rooting of a phylogenetic tree is very important and a tree that's rooted inappropriately or has an inappropriate out group selection is just it's worse than illegible because it's highly legible and it can have a high statistical confidence but it can have an absolutely non-biological topology but assuming that they meant the tree to be rooted here here the branches are where there's going to be different operators occurring including the i identity unchanging one and then the edges reflect like bifurcations expeciation events so here there's an ancestral homeostat and then the lineage leading to orange did not go undergo any changes that were non-conservative on the branch leading to these sister species there was a duplication and then it stayed the same and stayed the same and then the purple node is going to have two duplicated homeostats and so they're just overlying evolutionary algebra the steps that they gave on to the topology of speciation and so that um as they discuss opens up a way to think from this sort of graphical functional perspective which is compatible with active to think about how for example from the species today we could infer some of the schema of the early vertebrate brain or the early prime vein or push it back further what about the common ancestors of the vertebrates and the invertebrates and all these other questions but that's kind of what they lay out here and so these are familiar models to evolutionary biologists like uh phylogenetic ancestral state reconstructions of phenotype which are often even done in a bayesian way like there's an algorithm beast bayesian estimation of ancestral states this is also a bayesian model that allows us to do reconstruction of ancestral states but it's in a very very different way than it's been approached outside of the active world but that's figure 5 and that's where we see the evolutionary algebra the design patterns or the pattern language for structural changes in generative model superimposed on species relatedness and a phylogenetic tree any thoughts on five i tried to convert this and reapply it to my picking of teams in the march madness table and i wasn't able to take philosophic trees and and convert them into winning thousands of dollars on betting on college basketball so despite my best efforts it's it's kind of contained and for what what it represents i mean not to foreshadow too hard but i think live stream number 39 and 40 might constitute march madness and then also here's another um you know for those who watch okay here now we have a little bit of a march madness bracket going don't we here's bracketology that is so fantastic so here we go yep so now we have um now here the root could have been here and then here's like two big species clades like two like this is like vertebrates and invertebrates and then there's some rooted clade so that's like why it's important to root the tree because here it looks like all of these are sister to each other at the exclusion of this one but then if we were to have rooted that tree like here then actually this is a small sister out group to all of these right and so it the rooting and the contextualizing is really important it's just like it's super interesting because it seems like you put in so much data into these phylogenetic models and it seems like literally how could this not converge on a super obvious answer i mean isn't it clear how these ants are related to each other phylogenetically but then there's a little bit of nuance that enters the picture stephen yeah it's curious that the allostatic can recombine with the homeostatic to give a base level temporal it's um like that doesn't it doesn't deflate back to just staying anaesthetic i suppose there would be they just don't show that it could um you could have if it did that i suppose you just wouldn't talk about it you know it's got a the when it goes a then it goes a i goes to ht sorry yeah it's a th yeah so we have a homeostat here we have two homeostats two homeostats and now here we have one homeostat and one allostat in this blue node and so that um but they're just kind of giving general examples like it would have been cool to see um this is where we're talking about um mammals and here's non-mammal vertebrates like here is a specific brain region and also that is in this um chakraborty and jarvis 2015 paper this paper um gets more into the nuances of neuroanatomy and neurogenetics and how like duplication in brain regions can be underpinned by developmental neurogenetic changes and they do link that a little bit more closely like to studying the bird brain and the song and motor system in parrots which is also cool because birdsong has been studied with active so like there could be a nice building upon this work and connecting it to some of the um structure fitting in figure five so it could almost be like you've got yeah you've got parts of the brain which are more allostatic orientated or homostatic orientated and that so in a way by the structuring of that gives some sort of differentiation in terms of how information and control will be carried out yeah totally and like um extending temporal depth within a model it's like a brain region getting a little bigger let's just say not that size is correlated with function in that specific way but then duplicating brain regions is like duplicating laterally or nesting of brain regions it's hierarchical think about how the eyes developed the insect eye it has a relatively simple module but then insect eyes can change in size over evolutionary time very radically from like taking up you know half of the head to being just one photoreceptor or even being lost because they're existing in more of a um duplicable motif whereas the binocular eye system that mammals have it's not as amenable to like just doubling into four eyes or you know splitting into two in the middles or something like that whereas the insect compound eye has like some of those evolutionary affordances um so then understanding like parameter change within a model and then structure learning on populations of models and what are the mutational adjacencies there's so many awesome areas and it's like truly just beginning for evolutionary bio inactive stephen yeah it was really helpful like having someone like yourself who's got that background to go through that's quite helpful because it's a it's a little it's a little bit intimidating actually at first sight seeing this um for me but i and i see the logic what you're saying it's uh it's quite exciting actually seeing that and again one of the things this paper does is it's it's tying threads together so um which seem very distant in in or almost in traditional terms like well i don't like using the word kamikaze but it's a little bit like um yeah it's a bit bit overwhelming often so i think uh it's but but of course that's the beauty of um active is it has that unifying potential um so thanks cool yeah thank you i agree like there's some labeling this is rarely included unless it's a time calibrated phylogenetic tree but like we're looking at the passage of time but that's not even always shown and so um yes dean we'll have our final thoughts can you just go back to that because i i really i didn't prompt you to put that up there but i really like that because this at some point we're going to have to and point to talk about that sort of basal gating part of this and most things that are are are organized as if then cause allergy but you just said it it's then if go or don't go is very dependent on then before we choose to go or don't go right go or don't go is still held open until one of the others decided so another thank you for that because that again that in the point two we should maybe talk a little bit about that cool yeah there's so many ways to think about like this garden of forking paths branching paths how that relates to parameter updating bayesian belief updating and structure learning what about when the structure of a model is a parameter in a nested model so then that sort of blurs the line from the bottom looking up it looks like structure learning but then from the top looking down it looks like parameter fitting right and if only we had like some mathematics to describe that okay any final thoughts or what are we excited about for the dot two next week um well my last thought um is uh yeah i'm excited to keep this going because i think this has got a lot of legs to it um i think one thing that comes to mind as well with all this progressively um increased temporal and hierarchical depth is is maybe where some of the more basic uh elements still have a really useful part to play is is what mark mike levine said about when do we stop like so we've got all these ways where we can start to okay so we've got all these ways that we can think how do we know when to stop and to sit down i mean it may be in the ultimate ways between our tummy maybe that's where the gut is so useful like at the end of the day the brain can go running off and maybe the gut and the heart need to say okay sit down get some food so which i might well i'm gonna get a drink of honey now but uh i'll bid you for well thank you for a great dark time but i'll i'll i'll hear your last thoughts as well dean uh i hate having the last word so you won't have it don't worry you'll have it and i just appreciate what steven just said because i i think that that's a big part in this ability to go from word back into the phenomenological space and i think there are other other brains that we know of now that play a significant role in that not just the one that turns everything into symbols great my last thought is there's no better drink after a foraging trip than honey all right thank you and talk to you later bye bye