hello everyone it is September 30th 2022 and we're in cohort 2 meeting number five we're having our second discussion on the chapter two of the textbook so um we'll jump in shortly to the questions but first just wanted to um highlight a stream that'll be happening later today which is number 49.0 and I'll I'll share in the chat here um or you can find it through the live stream page this is uh with Ali and Jacob who are here and the upcoming two weeks will have Dalton sakti of the devil coming to discuss the paper and this paper is um it's quite an opus and we we had a lot of fun preparing for it all right so we'll go to the questions and I think these are all just great beginning points is there anyone who wants to point to a question that they're interested to begin with or a question that they asked or one that they feel has like a a natural starting point otherwise I can pick one uh Daniel the um the question on thinking between cognition and thinking was one that I put there it was just from the the beginning of the chapter um a little quote um my thinking is first and last and always for the sake of my doing it's just when you read I always get confused between cognition and thinking and knowing and all those sort of uh words and uh their relationships to each other so I was just wondering if we could just sort of clarify that a little bit all right what does anyone think are these terms synonymous or are different things being pointed at with different um terms like this well I would maybe say that thinking could be interpreted as action and no knowing maybe um could be a consequence well knowing could be the specific representation of beliefs in the brain and then cognition is I see that as the kind of uh overarching blanket well thinking is Ali you know actually there are many different angles that we can uh tackle uh the conceptual differences between these three terms I'm going to start from the last term knowing uh well in epistemology the standard definition for knowing is Justified true belief so if we take that as a definition of knowing then we can go to thinking as the act of gaining that justified true belief as Jakob has mentioned some people describe thinking in terms of action and then cognition is a kind of uh a conscious state in which the thinking happens uh I mean if it's not the action of thinking per se it's uh the blank it's the situation or uh the state in which these kind of thinkings and knowings happen but uh obviously the this is a very simplistic uh distinction between them they're very nuanced uh discussions going on in the philosophy of mind uh about the differences between whether uh are there are these three concepts mutually exclusive or they can be related in a kind of hierarchical way to each other so awesome very uh deep answers one other take would be thinking is uh gerund verb it's a process whereas cognition is a noun and just from a sentiment perspective thinking seems to imply like a process and perhaps the experiencer like the subconscious regulation of blood pressure might not be considered thoughtful or thinking whereas especially um as cognitive theories are kind of pervading all areas in a in a type of like pan cognitivism then cognition is a bit more neutral with respect to phenomenology and awareness so one could say a computer is doing a type of cognition the sand pile is doing a type of cognitive process um this membrane is doing cognition it's equalizing the temperature like those can all be described cognitively and especially as we take active inference which is a framework derived in the neurosciences where these terms might have the least space between them but then the question of whether a computer is doing thinking or knowing is perhaps a further afield whereas to say that a computer is doing cognitive process or information processing might be less controversial like extended cognition but then I guess we just don't hear as much about extended thinking or extended knowing but when they're all um in our body you know then these seem to have like the most synonymy my cognition is first and last always for the sake of my doing okay any other like thoughts or comments on this question all right let's kind of can oh yeah Roman I just want to just say it so it sounds as if it's something that's sort of still in a in evolution or in just under discussion is it really still under investigation or attempting to find Clarity in these in this language I mean I like I like that I like that thinking's the verb and that's that's sort of where I was uh the direction that I was was having with thinking that it's a that it's an act uh that's that's my sort of take on it and cognition is more of the overriding blanket um so yeah so thank you for that that's good yeah and um we might be able to find coherence like in our own understandings or within the active inference ontology but the a larger scale historical Arc around these topics as well as like non-english versions of related topics that's probably more like a philosophical or maybe even like theological domain kind of just Trails off but within these terms as used in active inference it may be possible to have a lot more clarity especially around like cognition you know for the purposes of this model we're defining cognition as the information processing between input and output not saying that's the only definition just like if if one is to say that's what I mean by cognition there doesn't need to be um a qualia but then somebody else if their definition of thinking or knowing is going to be related to equalia and not like information processing then that's going to be verging into a different area mm-hmm okay so let's kind of continue on this uh broad an important theme how does active inference fit in with neuroscience does anyone who asked the question or provided some of this answers and discourse want to give a thought okay yeah I asked I asked the question um great this is yes what are we actually doing here are we doing Neuroscience or are we doing machine learning um I think it's some sort of combination of both but when we when we're talking about things do we have a we have some guidance of what we're what we're talking about uh it seems as though the original variation of free energy fits in with the biology there's there's some correspondence with the physical of the brain um related to superficial pyramidal cells or whatever um the expected free energy seems so much like reinforcement learning and quite away from the neuroscience great thanks for the comments and ideas does anyone wanna add or or speak to these faces Ali thank you yeah let's say uh about I mean FTP literature before 2019 uh was mainly concerned with uh the neuroscientific descriptions of the mind uh using this active inference framework but from around 2019 things have changed and a lot of research are going on which try to relate um active inference framework to other areas in physics in economics in even climatology or other kinds of phenomena which can be modeled using fvp slash active inference framework so uh I I'd say that in the currently the active inference framework is just uh is or at least it converges to be a kind of modeling framework or a kind of mathematical structure which would Encompass all can potentially encompass many different modeling Frameworks in it so uh yeah that's the current uh status of the research an active inference it's not solely focused on neuroscientific descriptions of the Mind awesome thanks Jacob yeah I would maybe uh add to the point that Neil mentioned that um sometimes it feels like it's neuroscience and sometimes it feels like it's reinforcement learning I think um I would think more about active inference as a kind of on the on the same level as like thermodynamics and physics where the specific model is not necessarily that important although we are assuming we are in this kind of Bayesian scheme but reinforcement learning has also been applied to modeling uh the role of dopamine in the brain so in a sense we could say if we if we put it in the in that context we could say that reinforcement learning is also related to Neuroscience even though it's uh also used in other contexts so I guess I'd say that active is again this kind of overarching blanket that covers multiple areas um but it's not necessarily one or the other awesome all right I'll add a few more thoughts and then anyone who that's a comment so first this is going to be a slide from later today uh in live stream 49. and it's a Maxwell ramstead tweet thread you know hashtag scholarship in 2022. and Maxwell describes first wave free energy models which didn't have policy per policy selection per se the Dynamics of internal and active States also known as particular States because that's like the moving particle it's like the internal States and the blanket make up the particle and then the autonomous states are the internal States and the action States those are the ones like under Direct Control whereas you can't directly control your sensory States but they're still part of your particle so there was a gradient descent happening on the autonomous States so it was kind of a one-step model and hence couldn't really be said to entertain policy selection counterfactuals planning as inference and so that was like very much a variational free energy framing and that's totally consistent with a wide range of previous Bayesian work on gradient descent variational autoencoders the variational Bayesian methods all of that area second wave models starting around 2012 equipped agents with beliefs about State transitions especially sensory consequences of movement the emphasis on the sensory outcomes of action has been linked by others to perceptual control theory and also Bridges towards embodiment this enables the design of models with proper policy selection that evaluated average free energy expected under each policy then third wave models use recursive expected free energy functional which enables some more advanced uh modeling tools like counterfactuals so that is one angle another angle and and so the the question was spot on with kind of beginning with Neuroscience if we go to Carl friston's Google Scholar page his most cited work and the work that makes him the most cited neuroscientist alive slash ever you'll find although the free energy principle 2010 paper has been cited as like a keystone Fe paper almost all these several tens of thousands are related to methods related to statistical parametric mapping SPM which is arising from the welcome Imaging Center at the University College in London and the Decades of Carl and others work in neuroimaging basic research and the tool development around it so coming out of this framework where they were doing uh time series modeling like dynamical modeling on hidden State inferences on spatial data like you're getting the MRI data but then you're inferring the neural activation that gives rise to this as mediated by like sensor and various sources of stochasticity the generality of that framework especially in light of some philosophical contributions by uh well in in some ways since 2010 since 2005 to 2010 Kristin was already going for this sort of across domain applications of free energy and so um another um kind of related like potentially extremely formally related but just in its scope is like the constructal law by Adrian Bajan and other works like that like looking for patterns across systems um and then as Ali mentions that scope Was Then followed up on with people working towards specific applications in different areas and then now that there's been such developments with the software packages and mathematical advances and and formalisms that's where we see the encompassing of a lot of different modeling Frameworks this is a great question too how should we be thinking of active inferences relationship with the way we think the brain actually works chapter 5 is going to be um about that it's going to be focusing on specific neural systems like the spinal reflex arc and also like um uh cortical processing and there's some there's going to be a lot of fun discussions on that because there's kind of like a map territory issue like if you use a linear regression on the brain no one thinks the brain is a linear aggression but if you use octave inference on the brain what is it that makes people think that something is being done with the map that isn't just a neural model like in SPM no one said well the brain's a statistic parametric map because we use the SPM package yet it can feel like people are using an active inference model and the claims that they derive are this is the brain doing active inference but isn't that kind of like using the SPM package and then saying that the brain is doing SPM so these are really important questions one other note would be the um the structure of Neuroscience in terms of interacting and nested information processing units is a natural fit for how active inference enables modeling of interactions and nesting of information processing units any other thoughts or questions on this area all right yeah yeah thanks thanks uh for clearing that up I'm looking forward to chapter five then oh awesome yeah all right let's look at we so these look like there's some surprise related questions and then we have some questions on free energy Okay so are the conditions in conditional probabilities so regarding the conditions in conditional probabilities are they mostly subjective objective or something else we may have explored it last week um models in their construction are prior dependent even in figure 2.1 requires are necessarily multi-perspectival is there anything anyone wants to like add the the conditions are conditioned upon by the modeler this is kind of like a map territory distinction like in the writing of the expression the vertical line means that the modeler's conditioning the first part upon the second part and then the question of in the Real Worlds whether something is conditioned upon is kind of the difference between the map and the territory but is there any other like area to explore here okay what are some examples of the difference between natural psychological surprise and Bayesian surprise okay so let's think about those two surprise definitions the first notion of surprise and they're both going to be measured in information theoretic units the first type of surprise is just the word Surprise by itself and it is how surprising a given observation is so if the classroom height is four feet plus or minus one you're going to be minimally surprised with four feet observations and you're going to get more and more surprised as the observations get further from four that is what is described in this column this takes in an observation and then it contrasts that observations difference with respect to the parameterization of whatever family of distribution is being modeled and then that tells you how surprising any given observation is given how a distribution is set the second notion of surprise is Bayesian surprise and that's referring not to how surprising a data point is but how far that data point updates the distribution so depending on how fixed you are in your priors you could imagine a super surprising data point with zero Bayesian surprise because it doesn't move the distribution at all but it was super surprising and then conversely you can imagine a data point that's not too surprising but it updates the priors to fit it exactly now the question asks about natural or psychological surprise so that is connecting to kind of a experiential or psychological question how would anyone relate these formal concepts of surprise and Bayesian surprise to um natural or psychological surprise Ali foreign interesting example that I think can illuminate the distinction between these two kind of surprises um is the Monty Hall problem uh because you see uh the result of uh I mean when we solve the Monty Hall problem the result is very surprising psychologically but not in a probabilistically or Bayesian terms so you see in Montreal problems actually is a very famous puzzle I'm not sure if everybody is familiar with that that I'm going to briefly sketch sketch it out suppose that we have three doors uh behind one of which is a prize so and uh the moderator of the competition opens up a non-surprised non-price door and asks us if we want to change our initial choice of which door we want to open so our intuition says that uh regardless of uh before the opening that door and the after the opening opening the door our choice would be just one half of the probability of being a the price behind one of those doors but uh if we look at it in terms of the Bayesian uh Bayesian inference or Bayesian probability uh we can see that it's not actually one half but it's one-third so we would have a month much a double we can double our chances of winning if we change our choice after the moderator opens uh that non-price door but this is actually a very surprising conclusion into I mean in the sense of psychologically surprising and it has even uh confused uh some of the most greatest math some of the greatest mathematicians for example didn't accept this but finally after some uh after seeing some computer simulations of this problem uh he finally uh well accepted this result but the point here is uh to Define surprise in terms of its uh Bayesian inference is just a kind of mathematical uh the price or it's a kind of probabilistic concept and it doesn't necessarily Maps uh Isis isomorphically or one to one to our psychological surprise yeah awesome and this is going to come up again and again in the textbook and in our work in active inference like there'll be a variance parameter and they'll say this is the anxiety parameter well is that one in the same you know does that parameter value translate and um it's it's a very general issue in parametric cognitive modeling and also about interpretability of parameterized models but it's an important one so um one could imagine some ways in a situation specific way to address this like if you have participants in an experiment uh you're you're making a parametric cognitive model of they're looking at the screen and stuff and so you're able to calculate given what you believe their cognitive parameters to be the surprise and the Bayesian surprise of different stimuli and then you could ask them just purely emotionally how surprising would you say that was and then you could do some sort of correlation between the self-reported psychological surprise and the values that you inferred but one can already see that there's like some complexity there for example around the enculturation of the communication or understanding of what psychological surprise is so on the pro side this is a very tangible and accessible experience that people basically get what does it mean to be surprised you know you open the box and it's not what you thought how does that relate to Technical and formal definitions sometimes it's clear sometimes it's a little unclear all right and one more surprise related question all right table two one why does gaussian surprise not contain a variance parameter why a pi product why not surprise perhaps equals natural log of the normal distribution of the mean of the um the data point observed mu commonly used for the mean and sigma commonly used for the variance um I think there's a few ways to explore this Pi is also sometimes used as a variance parameter so this can be seen as like and it's multiplied I don't think this is pi as like a um it's not a big pie it's not a multiplicative um product like this Sigma is a big Sigma and so it's a sum over dot dot dot whereas a lowercase Sigma smaller font is used as like a parameter so I believe that the parameterization that the the notation that they're using for the gaussian someone please correct if this is not true mu is the mean of the gaussian Pi is the variance it's Precision yes yeah and so by using the pie it alludes to the p and so this is a Precision weighted difference between the observation and the parametric mean so we do have both of the parameters of the gaussian if the observation is the mean then it's going to be minimally surprising as the the residual the difference between the observation and the mean increases then it gets um more surprising is there more to add on this I what I I was expecting to see uh any quote where there's there's a normal uh the normal normal function is e to the minus x minus mu over Sigma squared whatever oh I would have thought the surprise was the negative log probability of that which actually might come out as x minus mu I'm talking through to the answer yeah X to x minus mu over variance which is x minus mu times Precision isn't it so yeah now that makes sense okay just to just to um ask or clarify does it have to do with the fact that the surprise um fancy eye fancy J whatever however you want to look at it um fans uh is in a natural logged scale so we don't see a natural log or anything in the representation because we're already in that space yeah yeah uh I think me trying to explain myself I answered the question there I think I think it's because it's yeah you're taking the log of an exponent so it just yeah and with pi now being Precision that will make sense awesome that's great yeah cool okay now let's move to talking about the generative model and then at the end we'll explore what expected and variational free energy are with respect to generative models so are these ideas about the fit between the internal generative model and observations which is variational free energy that's equation 2.5 and expected free energy that's 2.6 applicable to States other than ordinary waking States so Altered States of cognition or Consciousness such as sleep dreams sensory deprivation seemingly disembodied States sometimes sensation doesn't seem to play a large role in experience there's probably a whole host of ways to go here foreign so one of them is that the modeling of a generative model as being continually engaged in perception cognition action is applicable whether the input is boring or what or not just one note another one is while sensory deprivation it doesn't mean your senses are off it just means that the novelty or the diversity of stimuli is reduced or deprived but you're still having observations like the camera if it's on is still getting observations even when the lens cover is on there might be boring or not informative but um in the sense that we're talking about observations one cannot be deprived of observations without having that sense just removed um okay sleep in dreams if the modeler chose to do it that way then I don't see any reason why not and um sometimes primary sensation may not seem to play a large role in experience however it's actually Altered States Of Consciousness that people have used to explore the role of the generative model in perception so an example of that might be the Albus paper by Adam saffron there's there's this one image it's like it's like very funny um [Music] it's going to start with a person um like doing a cup of tea and then they're going to start talking to aliens maybe it's in a later paper by um saffron uh so okay so here's different brain regions and the person's like okay I'm seeing the Apple here's an affordance these brain regions are being activated in a certain way and then I look down at my foot there's my foot and then that was the that's the medium or that's the threshold dose of a of a psychotropic something then in the in the medium dose activation patterns are altering the vividness and the association amongst different ideas um and then in the extreme doses this is like there's like um different patterns of linking that are leading to experiences that on one hand somebody could say Well they're they're lifted from the sensory observations but another way to put it is the ongoing flow of sensory observations is being um integrated and processed differently it's leading to a different self-organized harmonic mode in the language of saffron such that the perception the experience which is what we have is different and one like little piece of lore around the Albus is Carhart Harris who's a psychedelics researcher in friston wrote this paper Rebus relaxed beliefs under psychedelics just relax and then Adam followed with this paper Albus it's like well it's not simply relaxed beliefs in fact in the hierarchical predictive processing architecture some beliefs might be strengthened like top-down priors might be strengthened in their impact and that's why the priors might be seen like in a in a static field you still like there might be ways in which actually top-down beliefs are sharpened and that's why sounds could be heard from water bubbling or images could be seen in the static or in the tea leaves so it's not just like relaxed beliefs simply it just more generally altered and that sets up perfectly to go through equation two five and two six and this related question all right so we're going to look at equation 2.5 and 2.6 and explore how tractable they are let's recall equation 2 5 and 2 6. so first as always thanks for the Epic work to the people who who added derivations and the natural language descriptions okay so what is happening in equation 2.5 what variables are coming into the picture and how are they being processed what is this F describing what's the situation where f is Big what's the situation where f is low does anyone want to give a thought first also in these descriptions the letters are connected to the ontology terms so just a few that are important to know is X are the hidden States why are the observations that's one important one um another important one is that P and Q are two distributions Q is like the posterior updated distribution [Music] does anyone want to add anything on two five or two six or like um we can start to think about what it's actually doing or calculating okay so some pieces to note variational free energy is not prospective it's dealing with the real-time flow of data a single data point in the presence and then how that data points can be evaluated with respect to the current parameterization of that data point so this is like a function f variational free energy and it's going to be bringing two arguments in those two arguments like the two things that we need to combine which they happen to be functions Q is a function and so f is called a functional because it's like a function of a function so what we need to know to calculate key to calculate f is um this variational distribution and the incoming data point um one other thing to keep in mind before we jump into it is we talk about like minimizing free energy but with a negative sign minimizing and maximizing are the same so um we can just think about as minimizing or maximizing as just like a relativization procedure and it turns out that in this minimization framework free energy minimization expected free energy minimization um are like the less surprising ones which are going to be understood to be the better ones or more preferable because they're more consistent with being that kind of a thing those are going to have lower values okay now just some of the like um sub functions fancy e is an expectation of so we talked about it previously but this is not like a future expectation like expected Returns on investments this is like the expectation of a gaussian with a mean of four and a variance of one the expectation is four so this is like an average of some other distribution in contrast H is an entropy function the entropy is taking in a distribution and then um it is calculating how dispersed that distribution is how disordered that distribution is Ln is the natural log so that's a logarithm and then the only other kind of like wrapper here is this KL Divergence and so KL Divergence we talked about it last time as well the two lines are like the two distributions that the KL Divergence is contrasting okay so if we're taking expectations then the higher the value the higher the expectation is this is just like the average height in the classroom expectation of the height of the class higher expectation higher internally goes to higher here for entropy more dispersed is higher entropy for natural log it's a transformation of a number but they're monotonically related so as the number gets bigger the natural log gets bigger too it slows down in how fast it gets bigger but a bigger number on the number line is always going to have a higher natural log just keep in mind that there's like a minus sign so it's actually like the other the other way and then lastly the KL Divergence if these two distributions are the same their Divergence is zero and when the distributions are increasingly different this KL term becomes bigger okay anyone want to add a comment in here yes Ali and then Giuseppe uh yeah I just wanted to mention that uh for I mean for the expected or a variation of free energy and the expected free energy uh computations are not that costly but uh when we come to uh Computing uh the priors over over all the uh policies up to a specific time Horizon uh that would increase the complexity I mean it has an exponential complexity class so that's why some people have experimented with um proposing some alternative implementations for active inference for example one of which is branching in time active inference which reduces this complexity significantly or the work by Baron millage and so on uh but yes I mean the expected free energy or the variation of free energy uh I mean they're not costly per uh by themselves but um when the policy comes along uh that's a different story yeah just one quick note and then Giuseppe um the variational framework is attractability increasing move from the outset we have a factorized model so it's not like every variable influences every variable and what variational inference does is it actually uses specific optimizable families of distributions that are set by the modeler and takes into account the sparsity of the variables how they're related and it turns out that that's actually um for what it is a very tractable approach then within this variational inference framework the F variational free energy is going to be like far more computable because all it's doing is taking in one data point and then comparing it with the priors basically whereas expected free energy is conditioned upon counterfactual policies and so that requires enumerating policies of a given time Horizon and then evaluating them relative to each other and so while each given consideration is not that computationally challenging as Ali mentions the space of possible policies can be vast so if one has like four affordances like four you can go up down left right and you want to consider a Time Horizon of two you have 16 policies of time step length too but if you wanted to consider policies of time step length 100 you would have of course an exponentially increasing number of possible ways to look and that's what motivates um not just the variational approach which like does kind of as well as we can within a given policy but also tree search and selection strategies not unlike chess playing computers in the 80s where it was like well we can't just consider every Branch but if we prune a branch just because there's one move that doesn't look awesome we're going to be doing just local optimization and so it's always this balance with using generative models to explore branches more comprehensively and deeply but not prune them preemptively in case there's like you know a sacrifice of a pawn and then it gets you a castle so you don't want to discard that move but as those get more and more sparse will you sacrifice upon in 200 moves later you get the castle it's hard to imagine just from information Theory perspective how that needle in the haystack is going to be found Giuseppe um yes now just just a couple of um of details for the people that are not too too versed mathematically that the in the in the equation 2.5 uh one thing to to highlight is that the expectation of what is in in square brackets is always expectation with respect to a specific probability which is in this case the the approximate posterior QX so it's a kind of a if you want a weighted average but with the weights provided by that specific probability so it's an integral but and and also that entropy is basically the the average surprise awesome very nice Point entropy is average surprise or we can say it's the expectation of surprise um yes yes yeah so and and this is kind of where we start to see some of these um like make it fit well but don't fit too well if we can bound you can say I have what I believe to be the just all things considered the best model because I'm expecting 10 plus or minus one and so even though not every single poll is 10 so I'm getting a non-zero surprise as I'm pulling you know 9.5 10.5 10.3 9.8 but my model of 10 with an expected surprise I wouldn't change a thing about it that's where variational free energy can get you Jacob provided some derivations that connect the first line to the second line so that's one interesting thing to explore and a really nice move here that's highlighted is um using some of the the definitions of the operations of natural logs to separate them as basically like a a sum of logs and for logs adding them is multiplication and subtracting them is division um so that's why like Ln of Q of x minus Ln of P of X can be written as Ln of Q over p and then this the expectation of the natural log of a distribution divided by another distribution is the definition of the KL Divergence so that's where the KL comes from actually um so that's one really nice piece to um think about and then with how line one gets to line three one can also Trace how the variables are kind of being like split and recombined and each of these formalizations are going to have like a slightly different advantage in certain situations like entropy you have a term that's only dependent upon the hidden State expected surprise here you have a term with evidence that's only dependent upon the information coming in so this can be seen as actually like um a constant with respect to your optimization of beliefs about hidden States and so that can even simplify some optimizations further um equation six kind of rhymes with equation 2.5 the partitionings are different but you'll find that the operations which are used are analogous we see expectations over belief distributions we see KL divergences and we see entropy terms we also notice that the function or the functional G is over policies because the arguments that are being taken into account for expected free energy have to be the policies and beliefs about those policies like their consequence on sensory um outcomes and that's why almost everywhere you see it's conditioning on policy so it's like there's four options we're going to calculate a few things and and this will return to it so um but one of the key pieces is that pragmatic value like kind of the the imperative of pragmatism is not the maximization of a reward which is common in reward maximization and reinforcement learning but rather it's um going to be about the reduction of difference between preferences and observations all right well thanks for this meeting that was the end of chapter two in the next two weeks we're going to be heading into chapter three that's going to be the high road to active inference so chapter two started with like the Bayes theorem and the frog jumping out of the hand here we're going to introduce Markov blanket formalism and talk about some imperatives of surprise minimization and the principle of least action and a few other things so thank you everybody see you soon thank you Daniel