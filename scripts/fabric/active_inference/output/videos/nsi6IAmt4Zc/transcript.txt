right greetings everyone Thanks for joining we're on eight eight in our second discussion on chapter four so one question was uh brought up that will definitely come to but is there just anything else that anyone else wants to add about for any just reflection or any question that's kind of surfacing that we want to add to the stack all right let's go to the message passing okay so in message passing is there a decay of information as the distance between the variable X and individual Markov blanket constituents increases is implementation of information Decay and message passing an option for model implementation who wants to give a a first thought on that or any any other kind of curiosity around it um so would it I'm not sure if I'm understanding it very well other than intuitively but would it I mean would it be the case that uh like information Decay wouldn't necessarily um I suppose makes sense here given the the models they're already working uh in in terms of like time steps and so you're already kind of um you know you're you're recomputing uh your your gradients and your posteriors and so on in every given time step such that um you know the idea of some kind of uh holistic piece of information that's being carried uh from time step to time step doesn't quite making sense that is each time step involves an entire set of like recalculations does that make any kind of sense yeah um so just to start with one uncertainty is I'm I'm not exactly sure about message passing in the continuous versus discrete time setting um again hopefully something that we we can unpack and talk to Magnus kudal at all since I know that he's an expert on the continuous time um setting but any other thoughts on this or I'll I'll try to give uh an answer Ollie uh yeah just one quick note about message passing is I mean before going into the details of how exactly message passing happens in active inference framework uh it's probably worth noting that uh it's inversely proportion proportional to the robustness of any uh self-organized self-organization systems because you see uh if we consider an agent and uh it's um I mean peripheral um systems or peripheral um let's say limbs as a kind of central like fully centralized system uh in which uh I mean the message passing happens uh almost uh in a fully centralized way from uh the brain or I don't know the central processing unit onto the limbs then this system would not be as robust as the system in which uh this kind of message passing is is distributed among um among the elements of the system so I think that's one of the reasons why we see uh signal Decay or I mean the loss of information as we go up to the hierarchy and uh I mean the more we go up to the hierarchy the less precise the information becomes uh but in order to have more and more precise information we need to somehow acknowledge a kind of autonomy onto the peripheral um nervous system as opposed to a central nervous system so uh that's one of the ways uh I mean in humans and nervous system is organized in which this kind of distribution of uh agency I mean autonomous agency is distributed among both peripheral system and the central system so [Music] um and coming back to active inference framework um I also believe in this framework it beautifully captures this kind of hierarchical model because obviously as we move farther away from the peripheral elements of any system the elements which have direct access to the direct access but closer access to environment then the the accumulation of probabilistic Errors becomes larger and larger and that's why um in order to have a reliable information we need to discretize these kinds of information at some point without uh necessarily having to take it into account every single bit of information that we receive so uh on the lower levels of the uh I mean when we're dealing with the lower level systems we mostly deal with continuous time models which allow for more precise kind of formulation of message passing but as we go up to the central nervous system and concede discretized elements of organizations such as cognition emotion and so on or decision making this process becomes uh much more discretized so that's basically the idea behind the Hybrid models of active inference in which we can incorporate both continuous time and discrete time elements into a single system that's awesome thank you ollie Alexi I wonder if I can ask you Ali to clarify so uh let's imagine that I'm a shark right and if I go up the hierarchy of beliefs then perhaps the most uh firm of course green belief is that I Will Survive one step down from that is that I can breathe in water right so if as the message comes up in the hierarchy I don't need as many details like um because these are not going to change if they change they die is that kind of what you're saying that exactly no exactly yes because as you said as we go up to the hierarchy where we'll need a much much less detail and we just need to take into account uh I mean the general gist of the information we get in order to survive or I don't know achieve a goal or something but obviously um if if we want to I mean take into account every single detail of every Endeavor will need much a more precise channels for information passing and if I made one more quick question in chapter five they make a point to say that uh um ascending messages which are prediction errors are usually higher frequency than descending messages I mean they declare it but I didn't exactly see where they take it from and so I was trying to uh they Illustrated with a cortical column and I was thinking that you know in indeed this is very interesting research that we have top-down messages that are you know better written or something like that and and uh they govern the gamma Which is higher frequency could you talk a little bit about why prediction errors and ascending messages are higher frequency non-linear functions okay uh I mean on this question I can only take a guess because uh I don't honestly know the exact answer but uh I believe the reason that the ascending information is uh I mean um they're on a higher frequency level than um I mean the descending information is because again coming back to this hybrid model of continuous time and discrete time ascending information kind of deals with um let's say a continuous discretization of information and that's why as we go up uh in the hierarchy and the hierarchy will need to have a much more uh I mean a much higher frequency for the information gain because we need to uh I mean we need to construct those discrete information uh as quickly as possible and based on those discrete elements of our information we can then infer any necessary prediction any necessary information about the error that we get or any other kinds of manipulation or optimization uh we need to take into account and I believe this kind of bi-directionality uh Maps quite uh well on adaptive resonance Theory grossberg's adaptive resonance Theory because in that theory as well this uh kind of bi-directionality between the ascending information and descending information comes in a kind of resonance and um they adjust their frequency as to become the resonance uh fully cyclic passage for information both going up and going down so that's why I believe in this kind of framework also it's necessary to take into account different rates of frequency for both ascending information and descending information in order to allow for this kind of resonance to happen between um those two lanes this this is awesome it's a lot of a lot of great information um I'll just try to add a few pieces because I think there's different aspects here um so first I'll let you pointed to the the topology of message passing messages are being passed on the topology of the variables so how the how the variables are connected is how the messages are being passed sounds kind of circular but that's the whole reason why this box discusses basically the markup blanket which is just describing any given node is going to be surrounded by a blanket for that no there's an absolute tag on a given node so it can't be said just singularly this node is an internal state or a blanket state only with respect to the whole partition but that's why two message passing strategies um are being described directly alongside the Marco blanket so a lot of times we see that particular partition inactive inference or just more broadly we see a Bayesian graph and how the variables are connected and this is going to be an implementational or operational procedure that's gonna compute what it's going to turn the crank one gear for a given topology of connectivity um so this point about the robustness is similar to to the robustness of a distributed system I mean if you have a fabric with only local connections then it may take some time to propagate or percolate with the information but on the other hand there's not a single note of failure and all these other um features um message passing graphs can include discrete and continuous time and continuous State spaces like all of these different variants that we've been discussing play nicely together chapter eight comes back with a hybrid model and livestream 46 on the folks psychology where in the periphery it's more like continuous sensation and action and then as you um get towards like the cognitive decision-making States you're dealing with discretization um okay uh another point is about like the computational tractability so there are um works like this one from 2019 with uh par at all where let's learn more about the technical details but basically there's a few different flavors of this message passing implementation that are also kind of hinted at in the um in the Box but suffice to say that like for a given topology of a Bayesian graph which might be describing a cybernetic system active agent or it could just be any other Bayesian graph this isn't about perception and action specifically but on any base graph you can basically Define an implementational procedural pseudo code for how to just bring it that much closer towards harmonization where if it's kind of the ball is already at the bottom of the bowl it's not going to go anywhere but then if it's not at the bottom of the bowl from like a variational inference perspective it will go there and there's a procedure for doing that that's that's tractable um why is the frequency higher on ascending messages than than descending so first these kinds of phenomena constitute empirical evidence for hierarchical predictive processing architectures but but the framework doesn't depend on these phenomena being the case for our real nervous systems but but they're always nice to find and there's a few ways to go here um one connections with the Nyquist frequency so this is um if you're going to be sampling from Vinyl from analog then that's a smooth curve that's the continuous time that's like the motor perception that's the peripheral nervous system that's the record that's like a clock with a smooth moving minute hand and then you're going to have it it translate to digitization like you're digitizing the record um so if if um we're get if there are top down predictions like about the hour in the clock uh metaphor we could have ascending predictions about minutes and descending predictions about hours happening every uh clock cycle there's no reason why you wouldn't do that but at the same time you can you can bake in this structural understanding that hours are top down and slower which is consistent with more broadly in nested modeling nested outer layers um deeper however you want to think about it like they are slower and bigger so you only need to send down that hour uh expectation more infrequently and then just lastly like signal decay um if you have a a Markov chain so just think really um simply about some uh just just without bringing action too much into it think about just the perceptual part here so just like the music listening example um that I think is in in um so here here we are this is a partially observable Markov process happening through time emitting an observation so it could be the temperature changing in the room Through Time but we're not intervening so no action yet um imagine if B was if B worth the identity Matrix like all ones on the diagonal you would just be carrying s forward with perfect fidelity but if B were like 0.7 on the diagonal and then point one on the off diagonal which is like what the case that it wasn't a music example then you can if you set up a hundred of those runs next to each other it'd be like the signal was kind of like blurring by 10 um each time so the signal it it depends on like if there's a degradation of a signal as it's being passed here it's being passed in time if it's being passed noiselessly then the signal propagates um more distantly in space and or time whereas if um the the insulation around a node is such that it it um blurs half the information upon its immediate exit then that's like then that information like that perturbation the base graph um it just dampens more rapidly Ali uh thanks staff connection to Nyquist frequency was really insightful and helpful but uh to add at your point here I also believe that if uh if there wasn't any gradation of frequency uh between those two Paths of information passing I believe uh something like an aliasing effect would happen uh if if the brain or any uh kind of agent uh wanted to reconstruct the information from the input system and then produce the necessary output system because um I mean it's necessary to somehow uh distinguish between the kinds of uh I mean the frequency of incoming information as opposed to the uh the frequency of the constructed information uh in order to evade these kinds of aliasing type effects which obviously would be undesirable yeah cool and also ties to the um ultimately the audio visual roots of predictive processing it was not generated to describe or explain biological phenomena it it arose in the 70s 20 years before round Ballard 1999 in the context of Maximum information compression for Audio Visual and then the the other um sort of connection back to the more like bodily maybe a book that that some of you are are more familiar than than I but the body has a head it's kind of like a exploratory narrative um biology physiology book but but of course the title is the provocation about the body's Supremacy in I guess what we would say action inference Alexi yeah I wanted to reflect on what you and Ali said um about the Nyquist frequency and also that going back to please forgive me ascending messages uh uh prediction errors higher frequency if we take this uh evolutionary kind of thought that uh you know the higher in the hierarchy I go the more difficult it is to update the prediction they're more well entrenched right so let's imagine that I'm a rat but I have an inborn phobia of cats in a one strand of cat hair you know because it's freezing but if I'm in the environment where there's mortal danger like a trap and the only Escape Route smells like cats then I have to update that very firm prediction to get out so it takes high energy which in like Planck's equation means high frequency to update the high level predictions I know it's very speculative but what do you think about that yeah I think there's a few ways that that you could model that um like we let's just say we we have a um we have an aversion to cat smell um like it's a negative value in C or it's a lower value in the C Vector just to be clear like we're talking about some sensory Vector um and there's in our generative model we have some value that just is called cat smell and we prefer it to be lower um well if there are two paths on the maze then to take the path with the cat smell it it has to have pragmatic or epistemic value so if we have a ten to one um aversion to the cat smell but then the expected free energy of the cat path is greater than ten to one then you could think about that as like the circumstances um reflected by the epistemic or the pragmatic value of a course of action but the circumstances would lead to um selection against that um there's probably other ways that it could be explored um one would yeah but um yeah higher or so and and uh there may or may not be these kind of it may or may not be in option like I'm thinking about trying to try and just like trying to see two colors as indifferent when you can clearly see them as different or something like that like you're gonna butt up against some fundamental like the wavelength of light or like maybe there's a sound that maybe you know some sounds are maybe culturally aversive or not or Pleasant but maybe there's also just a volume or some type of sound that that it's like yeah probably you can't can't but then again if that was the only path to escape a burning building then that kind of stuff would happen so then I think it you gotta zoom out beyond the single dimensional generative model and then consider more holistic generative model like we have ten to one preference against cat but we have a hundred to one preference for blood glucose so then right there you've constructed a generative model that enables you to make risky decisions thank you that's very very useful yeah yeah it's uh and in the end it's it's not about the rat that's the territory it's about the generative model so different modelers May construct different generative models that display certain kinds of um Behavior or not so we have the portfolio of models and then we ask well what experiment is going to help us update our attention to these different models and someone has one where there's only you know cat smell yes or no somebody else has no a little bit and a lot somebody else treats it like a continuous variable none of those are the true map but but we have all the maps on the table and then that allows us to design the experiments but for the circumstances that would differentiate the unique predictions and explanations from those Maps really it also reminds me of Terence Deacon's uh nest of conceptions of information so instead of representing these kinds of relation hierarchical relations as a higher order or lower level uh lower order processing and information he represents them as three nested kinds of information in which the Shannon information is would be the most basic one and then referential information which is um uh he also refers to as aboutness information uh incorporates a kind of medium susceptibility to any error and it is an emergent information rising from those Channel information and ultimately we come to significant information or in other words information about usefulness which would which is what actually dictates how the survival of the species uh ultimately is determined uh I mean through the evolution and so on and it it incorporates a kind of the connection or association between uh the reference of that usefulness information and the teledynamic requirements of this species is what dictates what would happen in the significant information or in terms of fep uh the minimization of free energy nice that's that's awesome yeah information is like one of the most overloaded terms or just loaded terms but um Shannon 1948 studying signal Transmission in the telegraph Networks so it has to do with that pure Morse code level of being able to distinguish like a signal from noise and and then projecting all that down to the Shannon entropy and then to the extent that a signal can be detected from noise which is about the Observer not the um the system in itself already then there's this like semantic or symbolic information but symbolic or semantic information if we're gonna um continue with this evolutionary line like okay so here are the photons we can pick out the signal in the photons a signal and photons it looks like it's yellow and red is that a good caterpillar to eat so one has to go beyond the kind of Shannon information if you just had the entropy Channel entropy of different natural settings as a bird that's still um two structured jumps away from like should I go for this caterpillar or not but a lot of times this is taught as information Theory kind of the beginning and the end of information Theory when this is the syntactic information and then the semantic but the the the abstract semantic is still not the actionable information um let's say someone has added the key things how you define the markup blanket uh I mean yeah but we're not playing with the definition of what a Markov blanket is maybe this could be rephrased as the key thing is around which node you choose to highlight as your system of Interest call it internal States and then the Markov blanket is trivially defined around it I.E there's a partition between whatever or there's no partition well again if they if you're using a plural there is a partition between them that's what makes you think that they're two different things and everything under the or there's no partition and everything out of the blankets conditionally dependent well the fact that you have modeled a blanket or a partition at a given scale doesn't preclude there from being as they say message passing within the same blanket because blankets are not something fundamental it's like saying um could messages be passed inside of California yeah but but then also you could go to the county level and there could be messages between the counties or between the cities or you know between the agricultural objects within the the region I've not seen this with love if somebody putting references I'm not sure exactly which exact reference but more broadly nested um Markov blankets could look to the kind of Earth Systems modeling or our uh variational Eco Evo Devo paper nested markup blankets they're having message passing within and across and the kind of like lateral same type of thing same scale message passing and then now that you're you know you you passed all the messages amongst the states and now we're in California and then you pass all the messages amongst the counties and then but I don't have a specific reference where that is is written out but yeah what an interesting question and and message passing is so cool because like it really connects like this but what if this was just an abstraction and there wasn't any procedure known for how to compute it then you'd have kind of like the blueprint of a building but it'd be awesome if you could build it but in fact this is the blueprint and the blueprint can basically be rendered or operationalized into a procedure so that is is a super super strong connection and also one that's not unique to active inference um although i i as far as I know um the the 2017 this paper I I believe is far more General so somebody can you know add more here but basically um here's the continuous and the discrete representations and uh in this paper and some or some other one from this era like they showed that every base graph has a Forney Factor representation and then previously it had been shown that every 40 graph had a message passing implementation so in this paper or some other one um like it kind of connected all the pieces up and said yeah now there is a message passing procedure on arbitrary Bayesian graphs again that doesn't have to be about even a perception Action System I'm I think it just made the general case um some message passing is definitely important and also it's another example of like uh perhaps even a difference in practice between uh like deep learning reinforcement learning machine learning Ai and active inference to the extent that the distinctions can be drawn um in uh just to highlight because there's of course multiple differences that we've talked about but a lot of the work in Ai and ml goes into like figuring out the implementational detail like kind of getting um getting in there with the specifics of the model whereas once something is stated as a base graph then it's kind of like standard methods like you don't need to intervene in how your source code is compiled and so similarly that the message passing step kind of compiles it into a procedure but you don't need to step in to to fine-tune how the blueprint goes to the construction which I believe is a great advantage anyone want to want to go to a specific question or we'll just try to look there's so many questions on on chapter four so anyone can just like bring up one or or some topic that they thought was cool in the chapter um actually I did want to briefly just kind of harken back very quickly to something that Ali brought up earlier um which is uh adaptive resonance Theory and uh maybe how it relates to the asymmetrical frequencies found in message passing um and I know in chapter five where we start discussing kind of uh or we start seeing more discussion of uh like neurobiological correlates and things like that um you know there are these references to um um non-linear functions being involved in the competition for dictionaries such that what is it a ascending messages tend to be much higher in frequency or faster than um descending messages I mean are all of these things kind of kind of related uh you know as far as message passing goes I'm rather into things like fmri and EEG analysis and so I I kind of have a personal interest in uh the asymmetrical frequencies question um if all of that tracks yeah well I think that the uh Sensor Fusion neuroimaging world is is where a lot of these statistical methods can be traced um by virtue of the SPM Origins and here this um live stream was um excellently prepared for by Ali uh Professor grossberg was one of the uh relatively small fraction of guests who prefer full cited referenced questions before joining but also he prepared excellent answers and there was a great discussions um about the compatibility or or reconcilability of of Arts fep active everything Lexi yeah I'm just grateful for your question again going back to it and I have the same interests but um you know come to come join us on August 23rd if you can on uh the cash Theory paper I mean I think I'll try to talk about how the higher the frequency of the EEG the higher the common good of Sinai entropy the higher the level of keraticity and there's much evidence kind of converging on that stuff today on Twitter of all places uh Earl Miller from MIT was talking about uh better frequencies uh governing uh the exchange between medial prefrontal cortex and right hippocampus for spatial uh work in memory so it that does seem to kind of not only be theoretical but also confirmed empirically that we have kind of uh control signals are slower think about the brain you know uh subcritical neurons are firing one at one tenth of a frequency of cortical neurons and subcortical neurons and brain stem are arousing the cortex they are kind of the blood that and the energy the arousal generalized arousal comes you know that way uh and another thing I wanted to mention is about the prioritization uh of sort of um Mark Songs talks in his book about how uh working memory is a very small space like seven chunks of information plus minus two and when we feel something it has to get into work in memory otherwise you know we have to be conscious of an intense feeling and ordinarily for example we don't like urinate or defecate in public this is embarrassing so we hold it we inhibit the wish but when people go through like public execution or hanging that wish is completely released because there is a higher priority there's an existential catastrophic threat and that this sort of uh fear of social embarrassment is completely deprioritized so it does suggest that we need a very high energy signal to kind of overcome very well entrenched predictions so it's a vast topic and I'm highly interested in it so uh if you're interested maybe we can talk and collaborate cool cool thank you and again to connect that to the Terence deacons like a high energy signal are we talking about an informative signal because an informative signal could just be one zero one zero one zero one zero cleanly or something like that are are we talking about like a powerful like meaningful you know like the just some some cultural Landmark that has a specific aboutness but isn't situationally relevant now the high energy is is happening at this higher cognitive level might even be be um uh uh subtle signal informationally or it might even be a subtle signal symbolically or semantically but that's the whole thing like early warning systems and like you know just the movement of of a shadow or the Rope coiled up on the ground might convey extreme actionable information [Music] whereas there might be something in a different quadrant that's like very clear but not um survival relevance exactly I mean I think that if you go into like ecological evolutionary goal of mammals to survive and reproduce then okay so survive means eat and don't get killed and so uh sexual functioning and uh gastrointestinal functioning is disabled when we are in a state of acute fear acute fear takes precedent because if I'm dead it doesn't matter you know I will not be able to reproduce so my first job is to there's a prioritization happening and that's going to be an intense single that just you know uh occupies the entire mind and just casts everything else out right um yeah that I mean a lot of these um whether we approach it from like a circulatory system or like a more abstract information like a lot of these um patterns are are explained or predicted or or so-called paradoxes are are um kind of shown to be otherwise one's like yeah you can't have Max blood flow to every region at the same time like if you if you could do that then you would just have some higher level of allocation to do so yeah when you're running your gastrointestinal tract slows down like there's just a shunting of resources and there's a shunting of attention as well so it it doesn't make sense to um have a system where equal maximal attention is being deployed it it it's just not viable but we can describe it so that's like why the the active motifs and and all these like like Concepts these are our grammar or or ontology that gives us the expressivity that we need to do the modeling but um so we can describe systems that yeah maybe there is a system that pays equal attention to all of its 10 ideas but or not or you know it it doesn't have any ability an organism that doesn't have the ability to shunt um or redirects uh blood flow or attention or does it doesn't have the ability to do sensory attenuation or something I mean you can build it okay a lot of these questions are about um specific um like variables we may have come to this one last week why is the marginal likelihood called marginal does anyone um know this or have a thought yeah I'll leave go for it it's a Remnant to the statistical Theory because um you see when we sum the probabilities of a of a given event uh in in a tabular form uh the the ultimate sum would be written in the margin of the table so that's where this marginal probability term comes from perfect yeah what a great what a great term it's in the margin of the spreadsheet when they summed across um kind of collapsing on one thing conditioning on one thing happening you can collapse across the other dimension on the spreadsheet and then it's in the margin um yeah so so many questions um another another kind of uh uh clear one uh belief updating about policies two update beliefs about policies we find the posterior that minimizes the free energy does a posterior at time T become a prior at time t plus one yes it does so like d we we call that variable in the generative model the prior because it gets the whole chain rolling but you could also think of this as just like kind of being like a starting position on this unfolding sequence so here's a temperature in the room and we're just going to say well our data or our modeling started at midnight and it was um 30 degrees we're just going to inherit 30 degrees if it was a precise prior or you could say we're going to start the chained by pulling from a prior distribution so we're going to start the chain with 30 plus or minus 10. and then we're just going to let it play on and then in that situation you know with respect to the presence moment S Sub t um this is a posterior with respect to what just happened but it's a prior for what is about to happen so just like Marco blanket is not kind of absolute it's about which variable you're talking about also prior and posterior are relative to the incoming observation so one after you've updated the posterior it's not like you just stop then that updated value for the hidden state becomes the the the prior for the next incoming piece of of sensory data a lot of equations that I hope we can unpack and develop in in math group and and otherwise um and and like annotate richly and make sure that for all the equations that we have those um descriptions and yeah chapter fours a big one I mean there's a lot to it and brings up a lot of big topics that was our second discussion on it we are close to the end we'll go into chapter five next also I remember thank you Lexi Bronwyn I think you some discussions that we had one of the specific um message passing neurobiology in the setting of chapter five so how should we prepare ourselves yeah that was a while ago yeah it's a tricky subject I've been listening and thinking um through today I just get I've just gone back to um equation 2.6 um because I got a bit confused um but it was just about um you know message passing in the relationship to uh the reduction of free energy and expected free energy but I'm still thinking about it so I might discuss it next week if I come up with something but I think it's um it's very complex and then you've got the hierarchical thing happening but but one question I had was that over a synapse there's sort of two functions one is a facilitation one's an inhibitory process and I think we don't consider the inhibitory process our ability to inhibit very much it's sort about all about action that um yeah I have to think about all that but that's um I mean in this yeah in that in that equation you've got all of your um all of what you were talking about taking risk um you know that that thing about the cat the cat smell example but within that selection of policy for the reducing expected free energy um you want the one with the least expected free energy but you're also balancing up other factors in terms of the the three nests I think the three nested thing was really interesting because it gave you that that that hierarchy of Habitual responses as opposed to um considered ones and you know higher referential or significant um evolutionary considerations but underneath it is this is this equation I think the relationships between these things in that in that moment when someone makes a decision so yeah it's quite a complex thing that the brain does really that's my thoughts very basic but that's where I sit so anyway whatever I've been doing other things lately so I'm a little bit um I lost and I haven't had a good look re-look at chapter four that I will between now and next time awesome yeah a lot of ways to go there this um functional this this um can apply to a nested system it's just all kind of abstracted there and again this is kind of like that blueprints view message passing helps us get there with the how so it's kind of like the low road which is where this equation comes from chapter two yeah this it's it's like it's explained the how and then the message passing is like the how on the how and then also like what you said about um you know one one uh world view is like the central uh operator Central Governor is kind of being like spurred into action it's all about like excitatory signaling from the outside um or um it having to stimulate a passive exterior through like um you know carrot and stick or just stimulus in general um and then that reminds me of Tom froze um with his guest stream on the eruption which is like yeah what if it's like there's there's just this like seething activity and then what's happening is like inhibition and and breaking and then like in those spaces that are opened up through inhibitions and breaks things unfold so it's not like the decision making was was like well you know shining the laser on where to go it's like no there's there's more than enough energy to go around mental energy and it's just about um knowing when Once inhibit went to break yeah absolutely I think I have a problem the problem is a season that's knowing when to inhibit and that's that's from the work that I do really is a strong point um of of inhibition as a very important part of decision making an action in the world just how we behave really I mean you know if you look at the basis of a synapse if you're in facilitating or inhibiting and that's the balance between those two in terms of message passing but nobody talks about inhibition very often nice yeah yeah great I mean in in the um number go up world is good more reward is better stimulate reward reward is stimulating you know sugar is good all that versus in the predictive processing at least we open the discussion to to both hands uh of up and down and um stimulate and inhibit or maybe neither stimulate nor inhibit just different yeah so it's it we have all the axes we need and and that's why chapter six exists because so much of the challenge is like what building do you want to build so if we said okay well from this we can optimize it super tractably it's not going to be an issue but what is it what is that model going to be and how are you going to iterate on that in a real setting which brings the whole um understanding into action and earlier um yeah this was just the last paragraph of of uh the book active inference is not something that can be learned purely in theory no it's the action people keep forgetting about the action the two are entwined you can't separate any of it uh so yeah awesome yeah well fun fun discussion thanks Andrew for for highlighting the message passing um angle and it's going to be a perfect lead-in to um chapter five where we will revisit message passing again from this like nervous system ankle yeah right okay thank you until next time thank you thanks everyone so much fine bye