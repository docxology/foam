hello and welcome this is active guest stream 64.1 it's November 29th 2023 we're here with Elliot Murphy returning guest and we'll be talking about this paper rose a neurocomputational architecture for syntax so for introduction and describing how today's stream's going to go Elliot thank you for joining to you all right thanks so much Daniel uh yeah I work at the uh UT Health in Houston in Texas in an epilepsy uh monitoring unit where we use interc cranial um recordings to maap language in patients with epilepsy and but today I want to present something a little bit more theoretical a little bit more kind of philosophical almost um this is a new paper that's just come out in the Journal of neural Linguistics and I thought it' be good for me um just to kind of walk through the paper step by step uh give some motivation give some description destion give some kind of outline of of the general kind of framing for the paper so the framework for this paper is trying to propose a general model for how to research language using inter cranial recordings um it's basically kind of move Beyond research that comes from other kinds of extracranial Imaging methods um and it's trying to really figure out what is the most appropriate level of description in terms of neural complexity for specific aspects of language so there's many different parts of language as We Know uh language has words it has sounds you know it has you can read language you can you can sign it you can construct meaning um you can do all sorts of things but the real kind of question for me is um at what level of neural complexity um and therefore at what level of appropriate recording resolution based on what tools you have available uh is going to be uh providing you with the most reliable signatures of particular levels of of structure so um uh in this model ter the rose model I invoke representations operations structures and encoding and I'll introduce them step by step um and so for the purposes of of this kind of introduction um I'm just going to kind of outline what those General kind of Frameworks are but to begin um the most kind of basic assumption that we have about language in terms of like the finding some Linguistics so the study of language like the scientific study of language one of the really basic introductions that you find in every introductory textbook is that um linguists have kind of arrived at the conclusion that the human mind brain applies a set of rules to recursively combine linguistic units into larger objects which deres an unbounded array of hierarchically structured Expressions uh with humans INF fairing sentence meaning based on syntactic configuration now that's a lot of jargon but essentially what that means is when you um hear a linear sequence of words like uh you know we watched a movie with Jim kry you can pass that not simply as like beads on a string you can pass it in two ways depending on how you chunk the individual phrases together and how you establish relations between the different elements so for example you know we watched the movie with McCary can mean that you watched um you know Eternal Sunshine of spot's mind or it can mean that you're sat there next to Jim Carrey watching you know uh the new Napoleon film for example so there's there's kind of ambiguity there but the ambiguity arises due to structural configurations so that that's kind of how you uh rearrange the sentences kind of in your head internally and that is obviously a process that's independent immediately from sensory motor either Transformations or experience or speech or sound or orthography so these are very abstract processes and they're clearly mental processes they're not processes of the visual system they're not processes of the auditory system they're clearly uh hod mental computations so what that phrase unbounded array of hierarchic excted Expressions means is it just means that humans have this generative capacity and people like car Kristen and chsky talk about generativity quite a lot what basically means is the ability to just do exactly what I'm doing right now use a finite set of elements so lexical items or you know memorize words and then recombine them again again again in really novel combinations such that you can say sentences that have you know never been said before in you know the totality of human existence um but which are immediately assigned a meaning you don't have to think too hard about what meanings are usually unless you're reading you know finegan weight um for example so uh typically this is a reflective process so it's automatic it's quick uh the brain resolves this uh very well um without much effort without much entic cost as well and so the question is how does the brain do this um so you know uh additional point to make here is that this capacity for hierarchical occasion has also been linked to human specific cognitive superiority so that's a more General background here so people like Stander how and what will they've long stressed that this facility for constructing hierarchically organized uh linguistic structures um is really potentially a human specific function and that's a very long and and you know uh it's a long and difficult topic to get to get into so I'll put it to one side but it's an interesting topic to to explore the possibility that this whatever this process is it might in fact be unique to humans um so in the theoretical domain U turning to neurobiology an emerging consensus in Neuroscience is that complex behavior and cognition rely on coordinated interactions between brain regions with phase synchronization being a major candidate for a mechanism implementing this coordination by gating information Transmission in the brain and but unlike for models of attention and working memory there's currently an absence of hillory phase coding in models of natural language so what does that mean uh so in uh the neurobiology of attention and working memory there's been a lot of really exciting accounts by people like El Miller O enen uh and a lot of other people uh trying to explore the relationship between neural synchronization metrics and some kind of isomorphic kind of relationship to some property of an either an endogenous computation like a working memory process or some kind of property of the environment that you're kind of you know passing in real time and but in language the best we have just to boil it down very very generally the best we have at the moment in language is basically what called cartographic models so that's kind of localizationist models in the brain so we have a decent idea thanks to the really brilliant work by people like Greg Hickock and Willam matchin and Anga friederich and ning and David poel and really an you know a really incredible roster of people from the last few decades who very carefully maed out which specific brain regions seem to be sensitive to different types of of linguistic structure so lexicality meaning you know the meaning of a word um syntax the the generation of a sentence structure or phrase structure semantics the meaning of words phology and so on but what we really have right now is just a kind of map so we have a map of the brain that you can pull up on Google and you can Google you know language syntax brain and you'll get a decent uh you know rough architecture of which parts of the brain seem to be sensitive to different parts of language but the the main reason why I wrote this paper is because that's of essential you know mapping out the terrain is obviously essential but the next step and people from working memory Vision attention they they did this you know a while ago the next step is therefore to transition to a kind of how question which is which neural mechanisms are involved in language so rather than simply saying these are the brain regions involved we have to then say okay these are the brain regions but what is the brain doing right like what operations are is it's performing at what level of neural complexity um is it sensitive so just because this part of the brain is sensitive we don't really know in what way it's sensitive like how is what what what type of neural processes is it actually recruiting to yield that sensitivity and what does that sensitivity really look like outside of B fluctuations or you know High gamma amplitude increases and and other kind of typical measurements so that's in the theoretical domain in the empirical domain invasive interc cranial recordings have recently mapped out some of the feature space associated with how much phological information can be transmitted by different neural mechanisms and some citations they you to look at but within the domains of syntax and semantics there's been less clear progress and the reason for that is pretty obvious and phology sound auditory processing you know the kind of finite feature space involved in opticor processes uh that's a very non-trivial you know field to explore but it has been mapped out very clearly because the you know processes are kind of less abstract more well agreed upon uh more transparent they involve more clear uh sensory motor Transformations and things that you can detect very clearly with very nice clear signatures in uh in different types of neural States state space State space or in fact different regions of the brain um and these are also things that you can distri disrupt very easily so it's very easy to disrupt phological processing we know we know which parts of the brains uh which parts of Cortex is disrupted but it's less clear how you specifically disrupt things like syntax and sematics you can knock out you know language comprehension in general just all of language comprehension you can knock out and disrupt um certain aspects of working memory performance but when it comes to knocking out you know disrupting the brain's ability to specifically process syntactic or semantic information that's been very difficult and there's only been a few papers on that which I site in this paper over the last couple years but it's been it's very difficult to really try and you know provide causal information causal evidence to try and really stimulate I stimulate the brain in the o or to find you know uh lesion patients who've had a stroke and who exhibit extremely specific Niche you know deficits around this aspect of syntax or or semantics so that's that's kind of the obstacle that we have right the obstacle we have is that we have this very strange uh potentially human specific seemingly very simple you know process of just building hierarchical structures but it's very difficult to isolate um from all these other things going on because as soon as you build a sentence structure as soon as you build a phrase or a sentence you are also doing glow of other things you are also using your attention you're also using working memory you're also saying things or reading things or engaging your eyes or your ears so that's you know it really is very difficult to isolate it um so anyway that's that's that's the problem that we have so I'll just skip this part to the next section here so um I'm just going to read through some of this text and and maybe try and unpack it a little bit more um but the past decade has seen the emergence of low frequency phase coherence as a feasible index of hierarchical syntactic structure will so what that means is that if you read these papers um there's low frequency oscillations in the brain that can be detected using Meg or scal Peg and they basically show little fluctuations little little Peaks um uh aligned with certain moments and periods of or Windows of structure building I'm just thinking of more metaphors little little islands of structure that come along when you pass a sentence in real time whenever that moment of structure building occures you seem to get this low frequency peak in activity in the brain um it tends to be around you know classical language cortex like left left inferior frontal cortex or temporal cortex but the the actual spatial temporal isolation is still a little bit ify we still don't really know quite frankly um so so that's the kind of you know background for that aspect of language at the same time though recent work has also examined local cortical processing using interc cranial recordings so this is these are recordings inside the brain and and what they do is they often Focus instead on high frequency power they can detect low frequency power absolutely but most of the analyses and novel findings within the interrenal space have prioritized looking into high frequency research and for the simple reason that that's do in real way that you can get hope you recordings um so this works exposes signatures of syntax um in in other kind of areas outside of low frequency Dynamics so there's a big question here how these two distinct recording scales low frequency you know Dynamics and high frequency Dynamics could be combined in a coherent model of natural language syntax and quot computation but has been addressed yet so that's kind of one of the arguments that I try and build here um so yeah neural oscillations are effectively like I mentioned they reflect synchronized fluctuations in neuronal excitability and are typically grouped by frequency mainly for convenience but you know not always there are in fact some uh there seems to be something else going on um common rhythms are often termed Delta Theta Alpha Beta and then gamma um and uh broadly speaking high frequency activity reflects local neuronal processing whereas lower frequency activity reflects uh Regional synchronization so high FR activity you get that local cortical computation in a specific brain region this brain region is doing something as opposed to low FR activity which is often more widespread and it's all it's more to do with the coordination of regional synchronization so the low frequencies say okay it's time for you guys to all come online at this particular time to uh you know engage your Spike activity in this particular uh time period but over a larger portion of tissue typically it's over much much much larger areas of the brain um and then there's a bunch of other kind of computational differences seemingly as well between these lower bands so for example Alpha is very often implicated in cortical disinhibition it kind of helps to shield and protect um ongoing representations from you know Decay and transformation and then Theta oscillations often implicated in hippocampus have been involved in learning in memory there's a big literature on that don't need to go into the details but essentially there's a whole you know panoply of low frequency rhythms and they seem to be sensitive to different cogni processes or at least know recruited or they seem to index a bunch of lower order processes potentially okay um so one way to kind of introduce this is through a model that I proposed in my book in 2020 um in this model again using invoking low frequency power the combinatorial power of language is indexed via various cilory interactions like forms of cross frequency coupling which is U basically when the the phase of a lower frequency Rhythm kind of coordinates and dictates the firing of a high frequency Rhythm so you kind of get a potential facilitation of what's called multiplexing or kind of packaging representations in one order and then sending them Downstream and kind of re re re accessing them from in a different part of the brain um so in this book of mine um there's a bunch of kind of literature that's reviewed to motivate the idea that Delta Theta phase amp2 coupling constructs multiple sets of syntactic and semantic features so you get this initial low frequency phase interaction between Delta and and Theta and this occurs when the phase of Delta is synchronized with the amplitude of theta and Delta represents superordinate syntactic categories whereas Theta represents feature bundles generated via electrical access what does that mean it means that these Theta oscillations um there something called the gamma coupling famous um in memory research and navigation uh theet gamma coupling and in fact there's some really nice work published yesterday I think by oans and looking at how ATT tension might be also implemented through Alpha Gamma coupling but the basic idea is that you have individual sets of features that are you know basic mental representations like things responsible for you know animacy plurality uh basic conceptual categories they seem to be triggered by high fance activity and then they're coordinated and packaged into a single kind of Chunk by Theta so you have a single low frequency Theta wave and within that single wave you get a bunch of individual you know five six seven or eight how however many you can kind of squeeze and fit in uh and there's kind of tradeoff between Fidelity and uh the kind of number of um gamma oscillations you can package inside a Peter cycle um but so that packaging of theeta with gamma helps you to kind of coordinate and unify uh an individual representation in the you know attention and visual spaces that's been referred to as uh you know coordinated visual attention when you kind of your visual SE your visual uh uh system is kind of attuning to particular properties in the environment um in the language space I'm kind of invok can get to unify different individual features that compose into alal item so alal item is just a fancy word for for a word so something like you know W talk yeah you bed I'm just thinking of random words all of these random words are obviously composed of individual features conceptual features right so a bed is inanimate it's h you know has a particular geometry it has a particular function a purpose a design and so on and all these different conceptual features compose into what we mean by a bed whenever you think of a bed or a chair or a mirror um or you know Whole Foods it could be anything it's simple anything from simple to complex you have a a constellation of conceptual features that are being composed somehow and and the idea here is that these low frequency Theta oscillations are there to coordinate the firings of those individual features which is why you get a lot of lexicality effects being found in for example the theer range and then what you do is in this model you get those Theta bundles of flexible features and you embed them further so you Nest them again and what you do when you Nest them again within a Delta rhythm is that the Delta Rhythm then takes over from the individual exal items and it composes a syntactic identity so a structure a structural identity so for example it's been you know well studied in linguistics that when you uh put two items together two words together you get a kind of symmetry breaking operation where one of the items kind of determines the category of the phrase so for example um if you say a red boat um a red boat is a boat that is red um a red boat is not a a red likee quality that has you know boatlike features for example um so there's a kind of immediate asymmetry and you get that all over the place if you say John ran John ran does not mean that there's a special kind of John who is exhibiting a running feature it means that there's an event of running and John was its agent right so there's always an immediate kind of asymmetry in language and that's you people like the H others have kind of speculated that one of the interesting things about language is that unlike music and Mathematics that kind of allow symmetry in their structures um language doesn't really like symmetry as soon as you get symmetry in language the language system tries to break it somehow um because there has to be some kind of uh categorizer for you to identify What's called the label or the category of of the phrase for you to get a a single unified syntactic representation so in other words whenever you get two words being combined together one of them always wins and one of them is the loser um and that's how you build syntactic structures you get a kind of uh categorization process so just to kind of recap you have Delta beta and gamma the Delta assigns or it somehow derives or it facilitates the syntactic inference of what the category is and the reason who knows right I'll try and explain some potential reasons here um ultimately it's unknown but we do know that in the empirical domain we get a lot of these syntax signatures being found in the Delta range so Delta seems to care about chunking on some level maybe not syntactic specific chunk chunking but I think it's possible um for reasons cited in the paper so Delta and then and train then packages within one of its waves multiple Theta rhythms uh and the reason why is because the same mechanism that you invoke when you get Theta chemic bling so it's a series of nesting you know nesting and and nesting and nesting and you know the whole Rose architecture uh in this paper is basically trying to construct uh what some people might think of as rather crude but I think rather empirically motivating in fact um isomorphic relationship between structure and neural kind of signal complexity right uh it's it's common for people to think well you know the brain is very complicated language is very complicated it surely can't be the case that a particular level of linguistic structure Maps directly onto a particular resolution of for example illary phase coding um I think there's good empirical evidence to actually assume that um and not everything uh takes place at the lower course grain level at the spike level for example or even inally I think it's a it's unlikely that all these complex processes from making inferences about you know whether or not red or boat wins and becomes the categorizer of the adjective phrase is all taking place at the intra or intracellular level um at the kind of global you know the kind of stuff that you can detect using uh single unit recordings for example and I think something more Global and uh you know interactive is happening and that's why you kind of need to invoke some kind of phase code because the phase code you only get that once you transition to more Global synchronization metrics of of the kind found with low frequency Dynamics that's the whole point of low frequency synchronization so I think that's kind of the kind of basic natural progression that you find here at least in the way that I motivated it in using the the literature that I review in the book and kind of is recapitulated here to a certain extent okay so then um we return to something called phase resetting so phase resetting um alongside concurrent um encoding and storage of the products of this these generated objects um permits a facility for recursive sell self cor and so that's kind of where you get the recursive mechanism of language you you're consistently renesting objects into this more complex Delta Rhythm um you know chunking out more and more and more low frequency um uh complexes essentially and just on the side we also know that um from empirical work by people in my lab and in the as well that um you get a bunch of different Dynamics alongside this so for example we know that beta rhythms and other types of um gamma rhythms are involved in all sorts of different types of um processes like um conceptual storage and maintenance of a particular structure in memory um so there's a very kind of complex interplay here between different rhythms and it's not intuitive it's not easy to to grasp on F you know I realize I'm not potentially not doing the best job of explaining it because there's a lot of things that unpack as soon as you move to another kind of concept you have to unpack it to a certain extent but the basic idea is that there's a number of interacting uh low frequency rhythms that then dictate the firing rate and coordination of these faster rhythms and the faster rhythms kind of are responsible for the more um the kind of smaller more Atomic features like individual electrical items and the slower rhythms are responsible for the more complex larger structures like syntactic identities and syntactic workspaces and things that you construct so the kind of output I guess the output of the syntactic generative engine is found at the lower frequency end whereas the input the kind of stuff that you need to provide to the system to um get any syntactic structure building done in the first place like for example lexical features you need at least to access some features before you can combine them in order to combine something you need to have something to combine those individual properties are hosted by The High Frequency oscillations essentially okay um and then finally um traveling oscillations are also going to be relevant here so these are essentially these low frequencies that I mentioned except they exhibit a particular directionality they migrate in Phase coherence across the brain uh and what that means is they coordinate the spiking of uh neural clusters across the brain across fixed points so they kind of move from one part of the brain into another part and as they do so as they uh the phase of the low frequency is uh shifted across a particular path they then um trigger particular um spiking profiles of these uh neurons that they that they that that they travel across so it's a coordination process and it's also of course given the nature of a migration path that naturally leads to the conclusion that um as is often commonly known different parts of the brain are is are innately sensitive to particular representational features of the environment particular conceptual features things like faces you know places um orthographic information um emotions and things like that um there's a very big difference for example between you know inferior parial cortex and anterior temp cortex in terms of which conceptual features they seem to be sensitive to so if you get that traveling profile you got that low frequency um um you know uh uh phase code moving across a particular extended path then that immediately gets you essentially for free it gives you um for free the uh mechanism of activating distinct conceptual um representations during that process um so I think you know there's a a lot of other things to say here but traveling waves have been implicated in a number of kind of behavior relevant and processes in humans and also nonhumans um and they seem to support brain connectivity and function more generally um so yeah that's kind of the background for for the traveling wave mechanism um and then finally one final thing to say here um I mentioned the Delta Theta and Gamma complex there's also been some interesting work outside of language looking at um Delta gamma FAL comcs so that's kind of skipping out the middleman and simply involving this low frequency Delta complex um uh being face coupled with the amplitude of high frequency gamma oscillations and what that seems to be involved in is featural combinatorics in general so for example it's been involved in fluid intelligence so when you have to just uh perform a particular task or solve a problem immediately and call upon various cognitive representations from different core knowledge systems in your mind lots of different you know aspects of intelligence you have to kind of recruit here and there you don't necessarily have to in fact you don't at all construct a hierarchical structure you don't constru construct a hierarchical recursive representation you just combine things together into a set into a conglomerate to help you solve a particular puzzle so that's what fluid intelligence is all about um you also get that with um certain early stages in phrase composition in scalp so people like Andre Martin and Jonathan Brennan have done some nice work showing this um so what that tells you is that there's you know in language and also non language you can combine features for all sorts of reasons um when you comb and if you if if you need to do that Delta gamma coupling seems to be sufficient and it seems to be a very efficient way of doing that now if you want to con construct an unbounded array of you know hierarchically structured Expressions I as I mentioned earlier that might not be sufficient and so the empirical argument I'm making here is that um Delta gamma coupling will not be sufficient for the kind of Rich um syntactic you know phenomena that are often documented in you know standard textbooks for example so anything beyond a basic phrase unit I suppose anything with longdistance relations or dependencies and things like that or in fact anything beyond a single phrasal structure will probably need to be um call upon on all these other mechanisms that I mentioned earlier the more kind of richly layered uh levels of low frequency interactions so um so Delta gamma is fine for you know featural combinatorics but it doesn't seem to be sufficient again that's an empirical claim could be wrong about that but it doesn't seem to be sufficient based on the literature for the more kind of complex structures of the kind that we uh that we all know and love in the Linguistics World um okay and then we can also make some interesting claims here that I've made with my colleague Antonio bonitz braco in in in Seville in Spain um all these aspects of Hilary Dynamics obviously result from somewhere they don't come from nowhere they result from genetic guidance um and some recent workers provided a list of candidate genes for this particular guidance so we have a particular phase code and neural code for syntax but it's got to come from somewhere unless you're you know well I'm not going to name any names but unless you're the kind of person who's so in love with um you know deep learning and um large language large language models that you you think that it's all just some kind of EP phenomenal domain General learning process but if you don't believe that then there's got to be some some kind of genetic structure for language and so we've mapped a bunch of these potential genes um using a bunch of different techniques um to uh particular uh particular functions um but that's a very much an ongoing kind of far off project it's just the very beginnings of trying to map out the kind of genetics of the neural code for language but at least it's a coherent project right it's a legitimate coherent project although rather nent too to be fair okay um so um just to background this discussion a little bit more I realized we're already quite far in so I'll just kind of skip ahead a little bit um one of the most important questions in the new neurolog syntax is essentially you know what type of neural activity uh low frequeny activity High frequeny activity Spike rate can track very long or very brief phrases so my basic answer which I've already essentially given to you is associating roughly the respective scales of recording and neural organization with particular levels of linguistic complexity so low low frequency gets you structures high frequency gets you operations and Spike individual uh Spike trains give you uh basic representations okay so this section here is slightly less important for art purposes so I'll just skip over it but essentially my claim in this section of the paper section three is just to kind of um review uh existing models of um language in the brain neurobiology of syntax and particular and just to show that they essentially tick U many of these boxes but not necessarily all of them so certain models emphasize the r or the O but they don't talk about the s or the E uh or in fact in my own book I talk about the the O and s but I don't really talk about r e at all in fact um other work talk talk about um potentially a combination of all these features but don't provide a particular mechanistic um relationship between how they uh how these features relate so for example you can talk about the neurobiology of R and O and S and E but even if you have that you still need to have some way of causally relating them which is the kind of final section of this paper which is how you get so for example you know I mentioned that the representations the r unit is hosted at the SP level and the E the E unit encoding is represented in low frequency traveling waves but how the hell do you connect those two things right how do you directly what mechanism do you coordinate them so we know there's some recent work showing that in fact traveling waves can in fact directly um uh uh coordinate Spike lfp coupling that's that's a very promising work there to kind of unify all these features together but you got to have a mechanism to do that so you got to have a separate mechanism in between RN o o and and SN it doesn't just come for fre um okay so a lot of these previous models are very promising from a cartographic perspective they really do help us understand which parts of the brain are involved in different aspects of syntax or semantic um but in terms of um providing the how question right like which neural mechanisms exactly are involved that's typically lacking uh the best candidate you have is definitely the work of Stander ha he's done some really nice work showing that um signature syntax might be in places that most most people have not really thought about um especially at the the lower lower order level in individual Spike spiking activity or cellular barcodes and so on um that's very promising and it's something that I invoke in this paper in fact as well um okay so just to introduce this a little bit further um these four components of rows RSC enter into every syntactic phenomenon everything as soon as you get a syntactic structure you need to have at least all of these things um okay so in terms of representations I Define them just like any old uh mental representation essentially um they are an instruction to provide a particular conceptual feature um they are composed of features determining constraints on operations as well and that's a really important Point by the way I do want to stress that um it's well known in linguistics that um you know words have things like selectional restrictions so a verb will often cooccur or will need to ur with a certain other word um you can't just put words in any order that you like um so you know words are kind of like uh you know magnets they're kind of try and attached to certain other words and often that's independent of statistics by the way there's some good work by Andre Martin and Sophie slats on the relationship between statistics of language and structure in language and they're not the same thing at all they often correlate and they often Aid each other in various ways in very intricate ways but they're not the same thing at all and you can't simply derive all possible structured in language just from the frequency but you know frequency properties of words and the Bagram and trigram frequency right um you need something else you need kind of structural information um so the fact this is kind of a maybe a SLE point but the fact that um individual representations do in fact have selectional and agreement and movement constraints already tells you that there's got to be some kind of relationship between or dependency between the nature of how we neurally represent these representations and how they then transition into the oper ation stage right the O stage there's got to be an initial dependency um so some of these features can be maybe a little bit Baro um but you know linguists often talk about things like demonstrative noun plural and so on um these are of course human defined you know the way that our conceptual systems work we've tried to Define these things using these terms um are these cognitively plausable or neurologically posable uh maybe not but there's at least some kind of atomic unit that's being involved here a unit just call it X right so this feature X and Y they are being composed into particular uh configurations so maybe these terms these English language terms are just a convenience a kind of placeholder for what these conceptual features really are so to speak but I I think that language is slightly misleading for a reason that people like chsky and David poble have talked about and a lot of these things really just come down to the kind of classic Marian levels you know David Mar's three levels of computation algorithm and implementation um all of these things are totally kosher and legitimate at the computational level and so therefore it's it's doesn't really we don't really have to abandon them necessarily just because um we can't find a you know what some what looks like a noun feature in the brain that's you know a lot of this involves kind of category errors I think so which is why I try and break it down into more Atomic stages um so syntax builds structure through um recursive applications of merge like I said you have this basic merge operation which I haven't introduced yet I realized but it's basically just a binary set formation with some kind of categorization so you form a set um you just put two things together and then you categorize it you give a category um you know a n phrase or a B phrase or something like that and there's much more to be said there but that's essentially the basic property of language just uh building sets set formation um okay so this is the outline of the model um at the r level as I mentioned you get single unit encoding of conceptual features and what call formal semantic formal syntactic features and these are basically features that I won't bother going into but there are certain features um like q andf and other things that are uh other features that are interpretable or uninterpretable things that are uh features that only enter into syntactic relationships and don't have any other a role they don't have any any other role in providing instructions to phology or um anything else um but so the the these features um involve uh a what's called a cellular barcode for distinct features that compose into syntactic objects coherently Bound by this High gam activity o so the O stage is is the later stage uh and it also involves Vector codes this is invoking a lot of uh work from John Hopkins University and people like stand again the r level also involves Vector codes for ensembles neural ensembles cellular ensembles hosting features common to objects represented at o and which are ultimately coordinated by the S level the low frequency level um at the O level high gamma activity so this high high gamma activity is like I said it's neural activity that is around you know 60 to 150 200 HZ amplitude in the brain uh these this High gamma sentr motor Transformations um so things like high gam activity provides access to cotor Transformations and they transform these Central motor um representations like you know Sight and Sound and and orthography and so on things that you read things that you are exposed to they transform them into lexes objects um and if you're interested in the particular Regional involvement there's a list there um and then they are they they are therefore accessible as I mentioned earlier they're accessible to Delta or Theta phase locking so I mentioned the the Theta gamma coupling where the phase of theta dictates the amplitude and the firing rate of the high frequency oscillations so though you know you only get that once you have high gamma activity um because that's the that's the sufficiently uh you know kind of correct resolution the optimal resolution it seems which the brain likes to coordinate uh longdistance relationships um and provide you know transfer information from one part of the brain to to the other essentially um so this level can implement the semantic composition of language specific Concepts that coordinate the firing of our units so that this this higham level has also been implicated in basic semantic composition so in a paper of mine the I've looked at the composition of basic adjective n structures using interanal recordings and high gam activity seems to be sensitive to this basic aspect of semantic composition not necessarily syntactic composition uh but certainly semantic composition it could also be involved in syntactic composition um but certainly semantic composition um uh syntactic composition again would necessarily involve the S level your s for structure okay and then of course the high Gamera um activity itself also activates these ensembles that I mentioned at the r level that are composed of distinct units hosting this barcode or vector code for the finite list of units that compose into the feature bundles that you get when whenever you access an individual WID every given WID is literally just a linear list of these features that you kind of trigger whenever you access it um and again you know all of this stuff is only talking about the syntax semantic side the the side of phology and sound and gesture and orthography and all the rest of it that's a separate issue that's a totally separate issue um I'm only talking about interpretation comprehension you know planning thinking that kind of thing I'm just talking about internalization here okay turning to the S level um as I mentioned this is a low frequency neural program for generating uh structural inferences over the O level um so Delta Theta phase amp coupling as I mentioned uh gives you categorial inferences that allow you to modulate the representations of these feature bundles so the Delta can coordinate the theeta gamma complex and it has some say in the sequencing and the triggering and the the kind of um like I said yeah basically the triggering of these features and how they are accessed um basically the readout what what's term the readout right and then finally e the encoding phase um this is what I mentioned earlier with the traveling waves where you get the local and Global workspaces for bottom up lexical memory and top- down hierarchical memory um traveling waves Implement Delta Theta coupling for hierarchical memory whereas the theeta gamma coupling gives you the kind of bottom up lexical memory it's kind of linearized memory just for lexical features whereas the hierarchical memory the the memory about um hierarchical relationships in a structure so so you know abstract relations in a Tre structure uh independent of any linear order or independent of any Sentry motor Transformations triggered by gam the kind of there's separability between the structural inferences made and the uh lower level Cent motor operations that you get and are accessed by by gam and then as I mentioned earlier as well uh Alpha power can be involved in this in the shielding of this of this process um an increase in Alpha power towards the end of sentences is often indicative of like some kind of uh you know acral of semantic attention or semantic working memory or something like that um so I think that's potentially related to this issue too um and then finally beta power also codes for syntactic predictions there been some interesting work um looking at how beta power seems to be be sensitive to um successful or um unsuccessful but basically triggered or not triggered syntactic predict predictions or at least anticipation of building a syntactic phrase or you're about to you know you've been exposed to certain words and now you're about to generate a structural inference or you predicting a specific syntactic item beta power seems to be involved in the indexing of that sensitivity um but notice something interesting here right that's beta power the this whole no this whole notion of prediction and anticipation that is a separate process from the core structure building inferential process involved in that's been You exhibited by Delta and Theta and has already been empirically documented by in Delta and theeta so again again this is a kind of neurobiological support for the separation of kind of you know predictive algorithms predictive processing and uh you know more kind of oldfashioned traditional uh structural uh inferences that are made by the brain so you know just to unpack that a little bit more it would be a problem for me it would be a problem for a lot of people if all of these processes anticipation prediction you know cordination um attention um and also syntactic structural inferences were all indexed and all coordinated in this delter and or fet rythm that would be a problem because how the hell do you separate them out right it's very difficult to think about that um you know if that were to be true then we would probably have to abandon the notion that we can construct a coherent oscillatory phase code for language it might be impossible you just have to just give up on it and look elsewhere but the fact that we can in fact find the separability I think speaks to this potential um which is why I wrote this paper because I think you know I think there's some good um some good potential here okay and then this figure down here um if I can maybe just zoom in a little bit potentially um this just depicts um exactly what I mentioned uh in varable form in visual form so the representation level uh again these individual features here correspond to individual cells sensitive maybe not selective but sensitive to each of these features the question of selectivity basis sensitivity that's purely empirical um I I enjoy you know philosophy and and and theorizing as much as anybody else but these questions are at this stage purely empirical it's it's possible that there are certain cells that are selective or you know sensitive to all these features but at least that's that's the framework there's a particular so infrastructure that facilitates these U representational accessing essentially um when it comes to operation again I need to be careful with the term operation because I maybe this is the one that I haven't explained well enough so I should maybe spend a minute just explaining this um there's the brain you know carries out phological operations it carries out semantic operations it carries out syntactic operations it carries out all sorts of operations in the context of rows I want I'm focusing on how it carries out the co the the the combination the initial set formation process involved in in in merge so the early stage of merge essentially the O versus S kind of captures the distinction between mge and labeling essentially um the distinction between set formation just building you know putting two units together um and then transferring it into a category so I guess what I'm trying to say is the categorization process will not be found at the O level at the high gamma level you might see some category sensitivity in high gamma you might see um different gamma um profiles for you know verb phraser versus noun phrases and in fact we've already found that people like Andrea Maro has published papers on this so we know that um there's a syntactic or semantic sensitivity at the O Level again the difference between verb phrase and noun phrase is not just syntactic it's also semantic right that's the problem big issue here of trying to separate syntax from semantics is that whenever you modulate syntax you also modulate semantics and whenever you modulate lexos semantic content you also therefore modify everything else syntax and semantics so that's an issue and there you know we're trying to well we are in fact uh you know running some designs at the moment to try and experimentally tease those apart but for the for this purposes um the current for the current purposes the term operation is referred to unifying um different semantic different lexal and semantic features together essentially into a coherent unit into a set and then once you've got that set represented in gamma then you turn to the structural level and the structural level is more higher order more complex more Global more interactive and therefore more low frequency right that's the kind of goal that's the kind of framework here um and then finally finally um the encoding level I mentioned very briefly maybe a little bit too briefly the two types of memories that you get in language there's been some really good work by people like David AER uh Queen Mary and um a bunch of other people uh who've kind of explored the uh different types of syntactic workspaces or linguistic workspaces like when you comprehend a sentence you don't just have a single um well you might in fact have a single workspace it's possible but it's also possible that you read it out into different separable workspaces that that responsible sensitive to different types of memory um representations so it's often been implied by people like William matchin I think very legitimately that inferior frontal cortex is really um involved in syntactic working memory um specifically we don't know exactly what features of syntax but C certain typ certain types of um syntactic information are held there and maintained there in shortterm memory um but so uh for Lex memory I'm invoking the gam coupling and then as I mentioned briefly for the hierarchical memory I'm involved I'm evoking Delta Theta coupling and then unifying the both of them or connecting the two was this other form of processing that I mentioned earlier the Delta um gamma coupling right so the Delta gamma coupling as I mentioned is just involved in uh basic uh domain General very domain General uh combinatorics just combining two different representations from different parts of the mind um but nevertheless you'll see the relationship between you know Delta and gamma uh between both of them now when it comes to the the spao temporal dynamics of this process the actual kind of um you know how this is implemented in in the brain in terms of which networks uh which white matter Pathways and so on that's a purely empirical question but we do know enough from the Meg from the scalp literature from the inter cranial literature that these codes are legitimate codes to be implemented across some portions of of Cortex um I have a bunch of speculations empirically supported uh also in terms of which parts of the brain these particular encoding workspaces are going to be found and going to be documented um but that's at least this is the general abstract schema if you like this is the kind of very general um schema and the reason why I've emphasize that is because as I mentioned earlier every other paper in um neural Linguistics focusing on syntax is almost entirely uh cartographic it's almost entirely localizationist in terms of let's figure out if it's you know is it if is it PT you know is it ventral temporal um they're the kind of questions that are framed by most of these models in the literature and though essential that's not my concern here right my concern here is yes localization but let's try and focus on which particular abstract neural code is going to be generalizable enough across different part parts of the brain and also by the way small Point here um also generalizable across cases of plasticity um you know I'm involved in a neur neuros case today we know the brain is highly plastic when you reect certain portions of tissue recruited or not in language you get fairly rapid organization over the over the over a period of weeks and months sometimes years um but that tells you immediately and in fact there's some also really fascinating work in can congenitally uh blind people and or de blind I think too um showing that uh portions of their um uh yeah in the congen blind there's portions of oxital Cortex that come online and are sensitive to syntax so because you know these people are not using their acceptor cortex for vision they don't need it uh they end up uh recruiting it for other other purposes to sometimes linguistic purposes so that's why I think focus on a more abstract code is more important maybe not more important maybe that's maybe that's unfair but I think it's potentially just as important if not more important than trying to figure out the kind of cartographic landscape um but for how language is implemented uh also by the way another small point which is maybe not not so small these days um this is also very important if we care about things like brain computer interface devices so uh you know neurot Technologies um so there's a bunch of uh what's called BCI brain computer interface devices that you implant in patients brains uh to help them uh with either their epilepsy or to help them uh with speech processing you get quic patients who who lose their speech um and there's some other efforts recently to try and help people with you know all sorts of language deficits by using neural implants um there's a you know a factory not too far away from me north in Austin and uh there's there's places you know owned by Elon Musk as you know uh who's who owns neuralink these guys are trying to do something similar but you know that's a speech when it comes to using it uh designing a brain computer interface for things like syntax or semantics I think we're going to need to pay attention to these aspects these questions to do with the neural code rather than just the region because if you're going to have somebody who has a syntactic deficit or a itic deficit and you're going to try and help them get their language faculty back it's no good just knowing which part of the brain is going to be recruited for their language function with a BCI device you need to coordinate particular uh stimulation profiles and particular ways to coordinate and Trigger and suppress brain activity and so in order to do that you got to have the right parameter space and to figure out the parameter space you therefore need to have a question of neural code involved almost definitely a phase code uh some kind of high frequency or low frequency B code so all of these questions that I'm that I'm asking right now don't just have kind of theoretical you know basic science academic implications obviously that's my interest that's that's my main concern here but they will also definitely have kind of you know implications for patient treatment um in the BCI Space Mo moving forward okay right then let's let's move on let's skip past some of this um I've it's getting on to uh almost an hour now so I'll skip through um the next few sections are just outlining representation operation structure and encoding so I'll just pick out some of the most um important moments from here um but again this section number five just defines redefines again maybe exhaustively um the what I mean by representation some example features um and in fact what um these gamma oscillations and high frequency oscillations might be indexing more generally in terms of their cognitive scope and their computational kind of facility um this is just a little brief definition of the kind of scales that are relevant to the different levels so we have single unit activity multi-unit activity uh the envelope of Spike and the lfp these are different aspects of new organization and recording resolution that will be relevant to the different components of rows and that kind of that kind of just outlines the the scope of of of inquiry here um this was something that I put in to satisfy make it clear that you know I'm talking about representation in this sense and not that sense um basic units again I'm just talking about what these basic units are um and then I'm turning here to concerns about um how to distinguish it from things like operations um okay and then oh yeah so this is an important paragraph I think um so this recent work by Nelson FAL discovered preferential activity for um content words function words in the anterior temporal Lo this is single unit recordings again I should I should stress sorry um so that already begins to tell you that at the single unit level at the C Level different parts of the brain I mentioned ATL already in this case ATL does seem to be sensitive to lexical Type U again that could be due to other reasons in this case they looked at it independent of we length and we position uh the big confound areas where frequency but you know there's there's some other kind of indication here that potentially something to do with lax of ality uh is driving this difference this sensitivity um okay um and then more generally um what water term concept cells that preferentially activate for stimuli that occupy a certain position in some category axis uh seem to support a declarative seem to support declar information what does that mean it just means that there's a really some really nice work by Bal um uh showing that there's a kind of feature space um in uh primate and also human um bral tempor cortex that is sensitive to a a kind of axis of animacy so whether or not an an object is animate or inanimate um like a chicken versus a laptop there's some things that are kind of in between and vague and then whether or not a surface is spiky or stubby so kind of you know uh like this or spiky so kind of kind of a Kiki Boer kind of situation for for linguists so that's kind of a nice conceptual um geometry that you have going on and there's different cells concept cells that preferentially activate for stimuli that occupy a space within that axis um so that tells you very nicely that at the unit level we have a potential neural code for this very you know generic but also all-encompassing um object space um this is Doris s laab the barel paper um so you know the kind of um promise the promise that this gives us for linguistic features I think is quite interesting because linguist have spent a long time uh you know reminding us that um the uh feature space in uh linguistic semantics can also occupy something like anime in anime um and then some other a bunch of other abstract concrete kind of feature spaces too um so I think it's very reasonable to to expect and to predict uh at the unit level a similar kind of you know conceptual geometry uh taking place in a different part of the brain uh potentially posterior temporal cortex potentially inferior frontal cortex you know who knows we don't know until we until we explore but um I think that's that kind of you know reinforces the uh the uh the definition of the um of the r level um that I'm defining here okay uh right then okay so this this next section here mapping from artto this gets the the very tricky issue that I mentioned at the beginning so at the beginning of the paper I you know Lampoon and criticize all the the people for not doing this so hopefully I do it you know a decent job otherwise I will embarrass myself a little bit um but the kind of motivation here is that we don't just need a definition of what R and O looks like in the brain we need a way to relate R to O we need a way to feed the information at the r level the unit level all the way up to the O level um so I mentioned just a quick a quick reminder R is a single unit you know Spike train activity um the O level is high gam activity right so they're kind of slightly more um uh easy to detect using inter standard inter cranial measures for example okay so how can we relate these these ideas the o to the R so in this section um I kind of um propos that the relations between multi-unit activity and population signals hold the answer okay uh so I might just have to focus on this for a little bit oh this is only a short section very short section that's that's good okay this will be quick then so um local field potentials reflect the uh the common synaptic synaptic activity of a population of neighboring neurons um and spikes are shorttime high frequency content signals reflecting individual cellular activity right so individual cells neural synchronization can be evinced one of my favorite words there they can be evinced by temporally relating spiking activity to the background oscillations of lfps um and this relationship has been documented across multiple brain regions and cognitive functions so this Spike phase coupling has functional consequences and there's some examples to if you want to if you want to consult okay so that's the coupling between um the lfp and the actual Spike the individual Spike so that's kind of an analogous right if you think about it that's analogous to what I mentioned earlier in the low frequency space right I mentioned the Delta Theta coupling and the uh you know the Delta gamma coupling Etc this lfp phase coupling is essentially the same thing just at a small scale right so it's kind of nesting all the way down um so lfps are a highly effective means of exposing what what state a given cortical region is in since they capture General Dynamics not specific to any individual cell and this is really a really cool Point actually about lfps they actually host uh you know uh types of information that are not detected at the spike level so that's a very kind of an important point there um and also of course you know there are cells I don't Spike to right um so in the same way that there's likely much information available at the lfp level that's not represented at the unit level um like Dynamics and amas properties exist that can only be detected at the level of su activity over a mil of neurons so too is expected to be the case that there are aspects of qual computation that are only represented at the interactional global stale scale even at the state scale like you know hidden marov um scale kind of um Auto Progressive hidden marov models and so on you can kind of generate these more abstract State spaces across networks of brains uh networks of brons sorry um and I think that will also be relevant at some point too in the future but maybe I'll get to that at some point later um and and this and that information is not represented at the lfp or Spike level so that that basic finding empirical finding is another core motivation for the rose model right the fact that you do find this um dissociable level of um information representation across these scales already tells you it already tells you that there's very likely to be this scale of computational complexity um at the linguistic and nonlinguistic level too okay and like I said it's a basic pres presupposition of rows but it's also a presupposition of other major Frameworks in ctive Neuroscience right not not just me I'm not the one to kind of you know propose this um so an example I candidate here is working memory which seems to involve discontinuous bouts of spiking activity as opposed to steady state neural Dynamics right so often it was initially believed that working memory in order to maintain something in working memory there's got to be some kind of direct intuitively direct neural correlate which looks like it's maintaining or staying at a stable level or you know amplitude uh uh steady state or increase over time Etc turns out not to be the case um okay so relating R to O is far from trivial yes that is absolutely correct um consider how communication through coherence has typically been assumed to reflect pH synchronization between oscillators recent workers offered an alternative mechanism through which coherence is the consequence of Comm communication and emerges because spiking activity in ascending area causes post synaptic Potentials in the same but Al also other areas that makes things more complicated um so these authors identified um afer and synaptic inputs rather than spiking entrainment as the principal determinant of coherence opening up new directions for framing the relation between units and coherence so lfp coherence appears to be determined by two factors coherence due to the direct contribution of afference synaptic inputs and coherence between the sender lfp and the sum population spiking connectivity in the receiver so therefore coherence therefore depends on connectivity strength and oscillation power and does not need purely oscillatory coupling or Spike phase locking in a receiver and then fav complexities arise here I mentioned some examples um from our neighboring field too but I'll kind of skip over that it's an interesting topic um but still you know successfully relating the two fundamental signals um in the section Spike and lb can provide is with a comprehensive explanation regarding the neurobiological cognition um and since many signals picked up by the lfp will also very likely be able to be found at the unit level care must be taken to map out assembly level effects from single unit responses and that's kind of an empirical caution um so this kind of section is very I think it's very honest I think it's very upfront about the limitations and potential um you know counterveiling Trends in the literature that provide some obstacles to this grounding but nevertheless I think um even if these things you know are true there's still the possib defer multiple types of phase codes multiple types of neural codes within the same space um being involved in different types of cognitive operations or across different code knowledge systems um and of course you know given that we know that um human syntax is in fact a potentially species defining property I think it's you know care must be taken to really separate out the separate out from these constellation of domain General neural mechanisms which might be relevant but might also not be relevant right it's again that that's you have to kind of weigh up the the likelihood of a domain General versus non-domain General process being relevant for your concern and again you don't know until you know you don't know until you um do the Empirical research um but I think you know the purpose of this subsection is to kind of open up the space of you know possible alternative mechanisms okay I'm going to skip over this section this is just discusses gain field mechanisms I've written a few papers about this uh it's a very interesting topic uh just kind of grounding the kind of lower level accounts of why you know what it is what it is we know already about um uh what the computational properties of uh individual cells might in fact be and that might sound a bit abstract but there's some really good work by uh W tum of fit and Randy gallol and uh a bunch of people that I cite here um just exploring the potential computational kind of uh you know uh kind of classical touring level architecture you know chumsky hierarchy kind of computational um you know facility that these individual Souls might have uh in terms of the uh operational power okay and then this this subsection here just introduces um a kind of a more classical distinction between sharing tonian and hot fian views that's basically just um a distinction that focuses on um the transformation of signals by nodes in a point BYO architecture viewing cognition as the result of patterns of no to node connections uh as opposed to viewing representational spaces um through which computation is considered to be the transform between spaces um so it's kind of a more different ways of viewing um populations and units the relationship between units and their population Dynamics um and I kind of speculate that's you know um evolutionary older brain areas might be explained better be sharing tonian accounts whereas more recently evolved structures in hint language right uh might not be so that's a potential uh Avenue that could also direct a way of uh exploring the kind of empirical space be on this and then when it comes to the operation space I've already mentioned much of this stuff I'm invoking high gamma activity um I am talking about the uh different oh yeah well there's different dimensions to gam right gamma is a not just a unified uh you know construct either neurochemically or genetically in fact it's a very complex structure indeed across species across brain regions you get physiological gamma responses in subcortical structures you get kind of higher order cognitive um responses in in cortex gamma itself is just you know lit is a range um but it's a very a complex manifold um so I kind of this section kind of takes care to to break down what I mean by gamma um you a lot of papers in the Neurology of language just kind of invoke you know gamma oscillations um or particular arbitrarily cut off uh you know range uh band range this section tries to take a little bit of care to just unpack the different types of gamma different types of um aspects of gamma in terms of their sensitivity to different aspects of um representational complexity um so lower versus high gamma you know Broadband narrow narrow band gamma Etc um if you're interested in that that's this is a good section for you to consult um okay so turning to scripture this again kind of reviews some of the things I mentioned earlier to do with the fact that you know every linguistic structure is sensitive uh to some aspect of lexical and sematic information like cohere into some uh some kind of phrasal or sentence structure uh there's a phrase by alaran there's no escape from syntax um that is absolutely true you know everywhere you look in language every time every kind of phenomenon semantic pragmatic even phological there's often a very uh direct impact of syntactic information in terms of the coordination and the instructions and the influence it has on the on these other levels um syntactic structure really is the most kind of fundamental level of of language that has uh influences a bunch of different domains um I've already introduced merge so I'll just kind of skip over this this is just a kind of more SE theoretic classical definition of what we mean by featural combination of the kind involved in language and of the kind involved in the kind of work that I mentioned earlier um and of the kind involved in the uh the high frequency gamma and Theta dynamics that I mentioned earlier too so Mage is basically the most fundamental operation in language it's it's the basic property of language as chumsky calls it um okay uh again from a more philosophical perspective I always found it interesting that even though this is a very rudimentary set formation operation if you think about the cognitive consequences as people like pet hag have in a very nice paper um the computational system of language seems to be related to neural signals integrating perception and action and providing humans with uh novel modes of planning and interpretation where by electrical units and unification processes like merge provide an imaginary space that transcends the influence of direct perception action Cycles that's a really key point there because of course we know that um one of the um real benefits of language and potentially why it was evolutionarily selected for uh is because it allows us to plan interpret think you know consider personal responsibilities uh you know consider our own future our past and so on um construct a notion of um um you know one's past and and where you've been conr Nar so to speak right so we know that other other animals have memories but maybe none of them have a past right maybe maybe only humans have a have a past it's kind of a unique kind of concept um that involves some kind of a different epistemological transition and a linguistic translation too right it's a it's a fundamentally linguistic notion same with the self right the concept of self you know who I am and who you are I are you and so on uh the the the existence of the the pronoun system language for example all of these things are extremely cognitively rich and semantically very important Concepts they're not just there to facilitate communication they're not just there to facilitate information transmission they really are part of the mental uh architecture that we have as as human beings so I think it's an important point that H go makes there the fact that this really is the center of the kind of cognitive neurosciences okay um excuse me this section just introduces um uh syntactic features what we mean by particular syntactic feature I mentioned electrical features quite a lot um but this section kind of just briefly touches on syntax specific features um and it also reviews some recent work looking at um the role of endogenous oscillations in neural computation I mentioned some of the stuff earlier to do with low frequency sensitivity and entrainment to particular moments of syntactic structure building this section here just kind of unpacks some of that more uh exhaustively and give some more recent um references there um so this section kind of just reviews that literature um skipping through this part here um and again just kind of to recapitulate what I mentioned earlier um the role of low frequencies in indexing super lexical structural inferences is very well empirically supported so the previous two pages that I just scroll past they really kind of propos um summarize a lot of literature suggesting that lower frequencies indexing superal lexical so stuff above the individual Word level it really is pretty undeniable at this stage I think um okay and then we turn to the more issues of timing so you know uh what is the precise timing of syntactic um information processing this paragraph here just kind of breaks down some of the particular periods of sensitivity that have been already documented and how it is compatible and maps on to the predicted time Cod dictated by The High Frequency rhythms right so it's no good me just saying oh Delta is involved in syntax and you know gamma in you know semantics or whatever you really need to have a motivated time course in real time like a real- Time passing constraint on how these um high frequency oscillations can embed themselves and be entrained uh and phase locked to these um these these higher pre these lower frequency rhythms and so I kind of just break down the time course of activity here um and it's all kosher it's all you know empirically motivated it's all kind of aligned with what we know about both about Delta and about the intermediary frequencies too okay and then this section turns to again the mapping process that I mentioned um the mapping from the o to S structure so this kind of invokes again a separable mechanism um I'll just scroll look to the top here just a another quick refresher so we had um phase amp cou as I mentioned right so this is Spike phase coupling mapping R to O mapping o to S is Phase amplitude coupling so that's the kind of classical process that I mentioned earlier to do with Theta gamma and Delta um gamma coupling because I get you directly to the higher order structural inference okay so that is a this section is just a short review of the phase amp cing Dynamics in this particular process and also talks a little bit about some other kind of extracranial um excuse me recording measurements that have kind of uh unveiled this in other kinds of domains uh this section here dissociating structure from meaning this is very much for the linguists this is kind of trying to figure out um how we can carefully account for signals that are specific to the semantics of a phrase versus signals that are maybe spec maybe not specific but certainly sensitive to the syntax of a phrase that's a very tricky issue you have to kind of basically uh design an experiment or stimuli that is getting participants to you know pay attention to structural inferences and syntactic information and syntactic acceptability and not pay too much attention to other kind of features but also the stimuli itself have to be carefully weighted across um you know words that uh preferentially engage uh syntactic information over and above conceptual information or conceptual semantic information versus words that very much do trigger um heavy semantic content so that involves a lot of you know careful kind of empirical consideration um our lab is currently carrying out you know some research into that into that space um as are some other labs too um but it's basically a an appeal for focusing more laser like on these you know ways to dissociate syntactic from syntactic syntactic from semantic processing um using empirical uh you know novel kind of experimental for paradigms because a lot of the paradigms that are used at the moment have a big problem which is they don't really carefully separate out moments of syntax from moments of semantics so it's very difficult to kind of you know realistically um and you know kind of confidently make it clear that a given brain signal or a given response is really being driven by either syntax or semantics okay um in terms of uh skip over this no I didn't okay and then this um outlines the the mapping from the S to e levels and it talks a little bit more about some of Stander um and uh other people's work into Vector codes for uh population Dynamics um to do with what level of um representation we might find individual syntactic features at um and again I I transition slowly here to talking about traveling waves how the kind of the more kind of static code that I've presented so far in terms of just you know a Delta a Theta a gamma how that static code might be transfigured into something more you know cognitively and neurochemically plausible in terms of the what we know about the transformation of U information across white mat tracts and across and how different um portions of Cortex cortical cortical cortico cortical information is kind of transferred in real time across different portions of the cortical mantle it's not just like stationary um okay so I guess what I'm kind of calling for here and as I call for in the next section is a more kind of spatial temporally Dynamic uh model or code for language essentially excuse me so all of this section essentially needs it kind of calls upon the notion that you need to map on a um an important you know important findings from the psych linguistic domain in terms of the timing of language the kind of um you know uh when we know that language is coming involved which periods of activity are going to be important and the actual neural architecture that's kind of a very tricky question how you map on those those so for example you know if a psych linguist says okay we know that when people using eye tracking or using scalp Erp responses we know that the period of 300 to 400 milliseconds is when most people kind of detect semantic violation effects we really then have to say okay if that's the case does that time period at the behavioral level map on to moments of uh you know uh neural activity also at that level or maybe potentially the neural response comes on a little bit earlier before it's detected the scalp level or maybe at the single unit level it's even earlier or vice versa or maybe there's a kind of top down uh effect whereby um some kind of intermediary misos scale um you know neural signal can be detected first before the spiking information is it it you know there's different hypotheses that arise here um in terms of their directionality and cause relation between the r to e e levels um in this in the Rose paper I make it you know very clear what my empirical predictions are but you know other alternative ways to to modify the rose model could be in terms of the directionality from different levels right so for different linguistic Scriptures it could be the case that some of the more misos scale levels in fact influence the coordination of spiking rather than the spiking information being read out at kind of high order levels uh which then which then facilitate the inferences being made um the fun ality is very clear in the paper but it's kind of open it's very much open for empirical uh you know resolution essentially okay so in this figure figure two uh figure one is the basic kind of you know components of the model figure two is the basic mechanisms of the model so this just goes into some more technical details that I won't go into uh to do with the actual nature of Spike gy coupling what the kind of mathematical foundations of it are um and how you can you know map that on uh to uh a kind of classic IAL kind of low frequency response um and how how these different signals could be coordinated um in real time okay and then turning to the encoding section as I mentioned earlier um you know we we know that the human mind needs different workspaces for different aspects of cognition um so the big question is does language share a workspace with other kind of you know nonlinguistic uh uh processes is there a specialized uh unique workspace for linguistic information it's possible um I think it's likely in fact which is why I have it in my paper um so in fact we know that um there are some non-human primates that can uh execute very primitive um uh combination and processes like potentially even more flal composition just combining two uh calls you know like Prime vocal calls together into a basic primitive um unit um can they then do it again and again and again can they do they have the workspace that allow a facilitation of storing this one unit and then creating a new structure and then you know assigning that whole complex an identity that is independent from its discrete Parts which is what mge is all about in language H they don't seem to be able to do that so that tells you I think quite reliably that we do need some kind of notion of um human specific syntactic workspace which is what the whole encoding level is meant to be in row and okay so so this section kind of just plays out a little toy example um of what how to derive a particular structure and what the whole um uh process would look like going from R to O uh to e so I think this is important for me to kind of outline since the part of the paper where I kind of really do give a concrete example so let's consider the sentence uh old men walk slowly uh during the compion of the first two words the uh Delta gamma combinatorial code coordinates the feature bundling of the atomic data structures hosted by alen men so Olden men have various features um at a minimum this involves posterior Superior tempal sulcus low frequency activity coupled with neighboring uh posterior Temple cortex but also cross cortical sites responsible for the specific feature types in question so I've already mentioned places like ATL and ifg and then I also mentioned uh feta gamma coupling uh this maintains in shortterm memory I mentioned the electrical memory Booker before the gamma coupling maintains in short-term memory the relevant units via High activity um obv oh in a linear sequence so this is worked by David po too the Theta gamma coupling is a linear feature clocking mechanism that tells you these are the set of features features 1 to five 1 to 7 and you're going to access them and triggle them and read them out in a given sequence so that's the kind of linear lexical memory stuff it doesn't give you the hierarchical uh syntactic relational component that is independent of order that comes later okay um at the transition between men and walk so word two and word three the superordinate Delta Theta code maintains the categorial identity of the object so you know old men is obviously um men that are old right as I mentioned it's not an Old Quality that happens to be men um so that's a noun phrase when you get to Old Men walk you relabel the object and it's no longer a noun phrase right you have to recategorize the syntax um it's not a verb phrase It's old men doing something it's an event structure so things like event structures and uh you know quantificational structures and all the rest of it they involve very specific unique semantics and that are informed and provided by and configured by the syntactic category so that's why I mentioned that you know there's no escape from syntax right the syntactic category feeds the semantic information okay so when you get to the the Theo walk the superordinate uh Delta Theta code maintains the categorial identity of the object in this case the negotiation between a multi-unit noun phrase and a more complex verb phrase is hosting old men so during the same period the lexical memory code again if you remember the lexical memory code is the theet gamma the electrical memory code increases its number of fet and nested chunks due to the occurrence of walk right so old men walk is in terms of the theam code all the theam code sees is another word when when you get to war all the fic code sees is a third word that's it it just sees okay another word's coming another word another word and it just simply chunks those features together uh using the feature clocking mechanism that I mentioned um but that's not what the what the Delta complex sees right that se something else so the superordinate Delta Theta code maintains the identity um and in this negotiation between uh and in this case the negotiation between a multiunit phrase and a more complex phas right during the same period the initial lexical memory code increases number of p and Trunks due to the G work the same transition occurs from walk and slowly with the exception that while the electrical memory code still increases in Clic strength um that's the measurement of pack relations between the the gamma right High pack relations uh the hierarchical memory code would decrease closer to but not identical its pre- Baseline due to the um adjunction relation not demanding a revision of the hierarchical memory representation so what the hell does that mean um so when you get to Old Men walk you change the uh syntactic um category it's a verb phrase so that that involves a activity at the Delta Theta level when you got old men walk slowly the word slowly does not change the syntax the word it's still a verb phrase so old men walk slowly is a verb phrase old men walk is also a verb phrase so slowly changes the gxo semantic information so you keep getting that Theta gamma hack increase but you get either a steady state or a decrease again I predict the decrease of the um Delta Theta pack relationship because all you're doing is maintaining the same syntactic identity you don't need to change the syntax same same syntax again I talked about syntax feeding semantics if you think about it for a second um old men walks slowly is still uh involves old men it could be old men walk quickly old men walk you know um lethargically um whatever uh it's still the same thing so the fact that old men work slowly doesn't change the fact that it's still old men whereas with old men walk that does change the fact about old men so when we get to Old Men we have certain facts we know about old men when we get to Old Men walk that changes things we know that it's old men walking when we get to Old Men walk slowly it's that's a modification structure it's called an adjunct the adun structure or you know adverb or prep prepositional phrase anything like that simply it doesn't it adjoins so that only involves um basic set formation it doesn't involve a re relabeling of the category itself because the category is still the same um so that and this gets into some theoretical syntax ideas that are not important here but the basic idea is that you just get an an uh you know enhancement of lexico semantic information but the syntax is identical so that's why you get this kind of wave of old men walk and then slowly and this is you know I mentioned some of the Delta Peaks before this kind of stimuli old men work slowly is what has allowed researchers to figure out that you get those low frequency Peaks at the third word old men walk slowly because that's that's the period where you really change the syntax H and it turns it into you know a kind of sentence I guess a kind of full sentential structure um with a propositional identity uh you know truth evaluable evaluability it can be true it can be false uh you can you can afford all sorts of different epistemic Jud judgements to it um that's that's the whole kind of um you know you kind of get a a whole complex of instructions being sent to conceptual systems at that stage okay so the transfer of relevant Leal information from Cate you know categorization or labeling that I mentioned would take place via interactions between these two neural codes right so separable codes um I speculate here potentially the Theta Theta um phase phas coupling or phase locking of the uh Theta Gam workspace and the uh Delta Theta workspace um Theta driven Dynamics effectively constitute the handoff of information after electricity has been established by lower level RN o processes transitioning from encoding electrical memory to to multiobject memory and direct testing of these Dynamics specifically with respect to syntactic workspace instruction has currently not been undertaken although much work has been carried out demonstrating increased theam coupling in human hippocampus during Mo formation as well as enhanced frontal Theta to posterior gamma coupling alongside the recent discovery of a rapid neocortical Thea Network mechanism for flexible information and coding and uh familiar operations from left corner MIM list grammar can be appropriately par slated onto these r o and S levels that's a bunch of jargon uh but the linguist will will appreciate what I'm talking about there I hope um but future work should still you know treat this issue of precise passing models with more care intact than I have demonstrated here in this initial architectural proposal so what I'm trying to say there is that um you know I mentioned Mars computational implementational and uh uh algorithmic level in the middle I've talked a lot about computation and implementation I've only spoken a little about about the algorithm the thing connecting the wet wear the kind of biological you know uh stuff you can touch and see with the kind of uh more abstract algorithm in between the computation um and that's the that's the domain of what's called cych Linguistics so the field of psyching istics has a bunch of different passing architectures for how humans pass sentences there's rival models uh lot of them have different uh you know predictions for how um human beings pass different types of weird sentences in real time um that's I have my own favorite candidate I've I've mentioned left corner minute passes um that's kind of my own uh you know favorite account for all sorts of empirical and theoretical reasons um but it's an open question and in fact later I kind of discuss the possibility that different parts of the brain might Implement slightly different passing models um so you know the posterior temporal cortex might be a good place to find a minus grammar but the uh you know inferior Pari cortex or the inferior frontal jarus might be an excellent place to find a different kind of paring model and I I cite a bunch of examples in the paper somewhere in here I think um but that's again an question but it's also kind of a more I think it's a more pluralistic way of kind of viewing language in the brain you know it's not just like you know minim passing grammars explain everything and the entire brain is you know a in concordance with the predictions of minimal grammas it might be a kind of more uh a different kind of constellation of of of pares that we need um but still nevertheless with the basic primitive uh you know computational architecture being uh infected by moments of merge and labeling and kind of more traditional basic assumptions from G grammar okay uh this this moment just uh yeah this period just turns a little bit more towards traveling waves um and a little bit more to do with FM research kind of building the paper more to what we already know from the extracranial world um this section talks about uh syntactic memory as being a phase synchronization over successive Cycles so this invokes a bunch of interesting work and consults some models from um the uh uh the world of uh the neurobiology of oscillations more generally in terms of phase Dynamics and cross coupling and all the rest of it just to kind of situate what the model might look like in a more kind of mathematically rigorous fature space um the section on symbolic computation uh turns a little bit more to um what we already know about um uh in fact I think I should I should review this very quickly because this this this again comes back to the issue of domain story so um Rion directions in the neurobiology of navigation and memory are relevant to the conception of e um so hipocampal cortical sequence replay and encoding is not constrained to Simply repeat past experience rather this process is informed by an internal model of the world generating representations of inferred entities not necessarily encountered physically again this is one of the reasons why I I work with people like Carl Kristen because I think this whole notion of uh you know building a gender model of one's environment the interplay of action and perception cycles and so on that's really a fundamental you know negotiating uh a building block of of what language gives us of what what the role of language really is in the human mind it's really about interplaying these two different um uh divides of of of the human brain uh so this active generative capacity motivates the authors to propose that Replay in the brain instantiates a form of compositional computation so a given replay sequence constitutes a set of entities strung together into a compound whereby each entity is bound to a representation of its compound role determining its function as part of the whole this establishes a clear separation with respect to composability between entity and role or what's called syntax and sematics right the en in the role so while roles encoded by hipocampal cical interactions can certainly be spatial they can also be non-spatial and even nonspatial and non- ukian potentially involving arbitrary roles such as a ve or what we would call right uh some kind of event anchor so the entity role bindings currently explored empirically in humans are limited to things like which position and which sequence but if other roles like if then else can be encoded in a similar way then replay May form a viable candidate um for a neurophysiological mechanism implementing symbolic computation so this compositional nature of Replay is implemented via our friend Thea gamma coupling um mirroring closely the present assumptions of lexical feature sequencing and basic semantic compositionality being complemented via the same Dynamics and high gam activity and there's a nice paper recently by Nina kazanina and dve poel that explore very similar Notions they kind of argue that a lot of the neural mechanisms already known to be found in hippocampus could be used for symbolic language of thought in language uh language of thought meaning the kind of classical fodorian notion um so you know a lot of the a lot of what's already known outside of language about the neurobiological infrastructure for things like navigation could be utilized and exploited by the language system in order to achieve its goals of um composable functions compositionality and basic structure building so that's again once again it's an empirical question these are all empirical questions but I think the you know the purpose of this paper which is a purely theoretical paper is to kind of negotiate through this terrain and see which candidates are more feasible more likely Etc and I think this this candidate in particular I'm not the only one who thinks this is a very you know viable candidate for grounding some of the initial again the stress is initial for me it's initial it's it's just that initial phase of uh the early phase of merge the basic set formation process the theic gam stage potentially not the uh you know human specific structure building stuff that I mentioned earlier to do with the structural inferences um that involve uh other mechanisms that I mentioned but at least in some aspects of language electrical search electrical access uh you know morphologic morphologically complex word binding and so on it's likely that these things are potentially use as well okay um and then in terms of so memory transfer this is a an important um concept that's been raised recently by working by bring at Arland and El Miller um this is just this section just very briefly reviews um how we might transfer memories across cortex which kind of might look a little bit like transferring syntactic structures into workspace or transferring um stored items into a separate kind of consolidation or monitoring workspace um there's some kind of potential for for research in this domain and then turning to Alpha Beta Dynamics this is an interesting topic U that I mentioned briefly earlier to do with how the you know the the the role of these oscillations that are outside the main code space that I've already mentioned right I've already mentioned I've delimited my code space what about the uh the role of Alpha and beta I mentioned it briefly but it's a it's kind of a quite an important role given that they are quite dominant that they're very prominently found in um inter cranial and and extracranial Research into language so um just focusing on syntactic memory there's a recent paper G Cel which supports a role for beta in syntactic identity just being sensitive to the identity of of a sentence the type of category that you afford it uh these authors investigated speech memory representations using interanal recordings in the left paryan cortex during delayed sentence reproduction in patients undergoing awake tumor surgery uh based on the memory performance of patients they found that the phase of front temporal beta represents sentence identity in working memory uh the notion of sentential identity presupposes a labeled or categorized structure like a verb phrase uh seemingly represented partially by front to temporal beta and converging with other literature beta may represent aspects of the global cognitive set going Beyond syntax specific information to include conceptual and statistical information again I I mentioned the role of beta in syntactic anticipation syntactic prediction the kind of statistics of language and I think that that has an important role to play here again um inter Cranium recordings by y truly um of auditory language comprehension also implicate frontal uh Alpha and beta power in phrase prediction and anticipation they kind of Mark the moment of potential anticipation of of a licensed phrase uh another paper found that both uh Theta and Gamma are sensitive to syllable rate but only bet power is modulated by comprehension rates so comprehension obviously implies you know semantics and syntax rather than just syllables um and over the past decade in fact a little bit longer than that over the past 15 years or so there's been a debate about whether beta power effects during sentence comprehension reflect syntactic computations or instead reflect maintenance or set updating um and to Briefly summarize the most current results it appears that the latter maintenance hypothesis is most well supported um so I'm therefore going to you know put further discussion of this to one side um but the basic role of it in in maintenance in terms of just you know continuing aiding with the assisting in some way of maintaining the set of uh Genera and sustained cognitive representations not necessarily being sensitive to the properties of this set not being sensitive to the particular syntactic Identity or the category of the syntax so even the category of the semantics or the features of the semantics but at least being involved in coordinating neural resources available neural resources to help with the sustaining of that memory in work in in in a current space again this is very domain general not specific to language which is why I think it's you know you don't you find fewer of the um language specific syntax semantics sensitivities um even though it's in comprehension as I mentioned comprehension means everything it's just like you know processing a sentence means loads of things it doesn't mean specifically syntax specifically language specific stuff it just means you know when you when you when you process a sentence you do all sorts of things um so I think it's most likely that it's involved in these kind of more domain general maintenance processes um and then in parietal cortex Alpha enhancement seems to index syntactic working memory demands uh much like the regulation of gamma by Alpha in control and attention mechanisms that I mentioned earlier varial cortex may play an important role in memory and complexity such as low frequency rhythms originating in lateral or medial partic cortex regulate the activity of gamma encoded operations in lateral temporal cortex and single unit or assembly encoded are in medial temporal or inferior cortex that's a more kind of specific proposal um and another like likely site of syntactic working memory uh is in PR frontal sulcus for reasons cited in this paragraph it's very heavily involved in all sorts of interesting uh semantic integration processes um and and then yes as as I mentioned um the kind of bringing this model to a kind of conclusion um these assumptions take place all within the context of the of the traveling wave framework right so lower frequencies migrating across the cortex particularly being relevant to cases of um maintenance and storage so traditional standing waves lead to periods when all neurons in the network are turned off whereas traveling waves can ensure that sub portions of a network remain consistently active Direct compatible uh with the Mosaic like architecture of posterior Temple cortex in semantic integration I won't explain that further but it's basically the idea that you know within these um small regions of Cortex like posterior tempor cortex there's a very interesting Patchwork of activity of little satellites of um sensitivity to different aspects of language even though they're all generally sensitive to language um within them there's kind of more specialized regions um which is not unlike what you find in brenal Temple cortex for things like face and place and uh other kinds of uh shape perception uh kind of ventral visual oipal cortex being having a kind of tapestry of um you know a cellular a cell specific sensitivity to different representational features um so where exactly the the waves travel to during phrase composition is again my favorite phrase this is purely an empirical question uh but some candidate regions have been suggested work right that's kind of where where we stand at the moment that's where the field is at the very moment um so figure three here is the basic processes of the Rose model um this kind of just gives a general outline of how Rose is hypothesized to be implemented across the front of temporal language Network um and at the bottom there's a representation of the various frequency interactions proposed to implement pH F building so you have representations category specific information being encoded in spikes with operations you have Broadband gamma activity um initially I hypothesize and PS s based on the in cranial work that we've done but it could be anywhere it could be in PG could also be in portions of ifg depending on the category potentially of the of the phrase uh the the type of structure you're generating that's an open question very much open um in terms of structure we have the low frequency neural program driven by a temporal cortex and then for encoding we have these traveling waves that spatially migrate structure so this I also think that both you know given what we know about the speed of traveling waves I think it's possible that um a lot of this stuff feres um up dorsal or vental Pathways across anterior posterior to anterior temporal cortex um and from posterior to anterior um frontal cortex given the time scales of sensitivity that we know exist there okay this final section of the paper talks about causal evidence um which is increasingly becoming very important these days in Neuroscience as we've exhaustively mapped correlational activity of loads of different linguistic processes but we haven't really got a good sense of which parts of the brain are actually essential for language so when you get regions X Y and Z being activated you know region X might be causally involved whereas region Y and Z regions Y and Z might just be activated or you know recruited or implicated but not actually essential for for the function so this section is kind of charts out some of the um ways of exploring that empirically through cortical stimulation mapping in the o or in the AMU using TMS for example um or joint TMS Meg studies that that's a possibility there's also as a way you can think of kind of uh providing different portions of causal evidence for these these models um and these paragraphs here just kind of just review um mostly nonlinguistic but also some language research um into how people have used these methods to disrupt language in particular parts of the brain um there's some more interesting research disrupting particular phase codes um trying to particular trying to modulate either uh hypo or hyper exite and particular osor Dynamics or pack Dynamics in different parts of the brain now that's a really good way to directly test the causal involvement of a phase code more generally because if you can hyper excite a Theta Rhythm or hyp excite a gamma Rhythm then that can really screw up your potential your facilitation of the coordination of these electrical features and your your attention and working memory and all the rest of it so that's a great way to kind of causally test um not just a brain regions involvement but also a particular brain like how a brain regions involed okay um this section is much more philosophical um if you guys play Elden ring you might get the reference in this in this in this section um but the the point of this section is kind of evaluate the the rose model to kind of situate it in a large context uh to relate it to existing models um uh in the uh uh interrenal space and extracranial space too um so some of the important periods um in this paper um so I've already mentioned this paragraph I think to do with how the how different parts of the brain might be sensitive to different passes so I'll skip that bit um this paragraph here just outlines how the very basic philosophy in row is that uh misos scale neural organization can be useful for brain function and that high frequency gamma oscillations report mechanisms and underlying communication channels of neural computation so neural oscillations organize cortical activity to produce computation uh and Rose Builds an architecture for syntax that presupposes this um some exciting prospects for testing rows come in the form of multi- Channel recordings with broad cical access using B micro electr arrays etc etc um and I just cite some more technical examples there for people in the field um and then let's see what else do we have here um yeah I've already mentioned the inside out outside it well actually I haven't mentioned that I've mentioned Mars framework um but just very briefly I think my model is um incompatible with a bunch of recent ideas to do with um encouraging people to explore the brain from inside out so I'll just read this paragraph and then maybe try and digest it a little bit because it's it's it's probably the most important philosophical kind of grounding here so brain models informed by computational concerns will continue to be needed in neurosciences yes that is true in particular as we approach the Advent of widespread availability of single unit recordings and again one of the anxieties I have with this paper is that as you know linguists get their hands on sophisticated neural recording measures we really need to be careful and quite conservative in knowing what we can say with each of these measures so if you give every Ling linguist on the planet access to single unit recordings and the human brain you're going to get a lot of papers making claims about um as I satti Satur here neonian existential closing neurons or um you know specific very Niche kind of um saor types responsible for all sorts of baroke and complicated and not very cognitively plausible linguistic constructs so I really wanted to in this paper boil it down you know decompose language into its primitive components decompose at the computational level and decompose at the representational level that kind of goes back to the 1980s kind of classical framework of the computational representational theory of Mind where you have a series of fixed representations units and fixed computations or things that you can do with those units this kind of actions and objects right that's a basic metaphysical human distinction between things and processes actions uh objects and all the rest of right nouns and verbs um computations representations um so I really wanted to make it clear that um you know next time you find yourself with uh access to a single unit you know uh data set you need to kind of have sufficiently decomposed these levels to make it kind of neurochemically and neurobiologically plausible rather than talking about the kind of more holtin stuff that I that I mentioned earlier um so it's kind of more it it's more of a cautionary tale I guess um because I you know other fields have gone this before right um so for example um you know grid cells right it's it's over the last decade grid cells in um inal and Par cample cortex were initially implicated in um spatial navigation then it turns out they're involved in auditory navigation and then they're involved in conceptual navigation it so in other words they they end up just being involved in navigation full stop just all types of navigation um and I think a similar kind of transition might happen with when we get um an increasing number of Publications about language in single units you'll get a lot of people initially saying oh well you know these these units these specific cell types are involved in X then it turns out they're also involved in Y and Z and and will ultimately end up being forced to propose a more generic account for these things which is why in in in my paper I I try and you know focus it um I try and appeal to as much generosity as I can there's there's always going to be some domain specificity because obiously language has domain specific representations and apparently domain specific computations so we will need some notion of domain specificity on some level but the only question is like where are you going to find that okay I'm rambling a little bit so I'll just I'll continue um so this outsid in perspective has been critiqued recently um uh duu um Baki um advocates for an an Insider perspective on building neural models of cognition and considers the classical Marian framework a purely outside imp perspective yet Mah himself stressed that the three levels should be investigated in parallel not necessarily prioritizing any given level so this is a balancing app there right uh too much outside in and you're going to get these neonian neurons too much inside out and you're going to be told that Linguistics departments need to shut down right so regardless of your own philosophical bent I think single unit and other types of interanal recordings are plainly the most direct and reliable means to further test and refine rows in particular given recent independent assessments and critiques of bold activ but you know the basic message here is that um a purely Insider perspective is when people will say well what's called Data driven science or datadriven Neuroscience right where you say well let's just um do a bunch of sophisticated statistical analyses on our single unit data and see what kind of emerges um let's just see that let's just hope that language will just arise somehow without any ideological presuppositions or any kind of biases first of all it's impossible I think for any human being to do that even if they tell themselves they're doing it you're always going to be delivering some biases you're always going to be bringing some philosophy of science or philosophy of mind to the table whether or not you like it or not um on the other hand you have the completely um outsid imp perspective which I'm also very much against so the outside in perspective would say let's you know everything that everything that linguist say is Bible um all these theories of D movement and Pie piping and all the rest of it they are literally what the brain cares about and we have to find that in the brain we have to keep our fixed theories of high Ro cognition and just look at the brain and expect the brain to care about everything we care about we expect the brain to be sensitive to all the stuff that we as linguists care about and the problem of science is that you know there's always a negotiation going on there's always a kind of deal that needs to be made um so you know one of our former presidents talked about the art of the deal in this case the art of the deal in this case is figuring out uh how much um Linguistics you need to to hold on to and stay true to and how much you need to let go of and how much you need to say the brain doesn't care about this you know it only cares about this but not that H my own so my own feeling is that the brain excuse me the brain does genuinely care about some aspects of language domain specific or or otherwise namely the representational feature types and also this business of marriage and labeling that I mentioned the basic computations I think the brain does genuinely care about that it probably doesn't care about all the other stuff that link talk about um but it can be characterized at some kind of more EP epiphenomenal level I guess as some kind of Imaging phenomenon we can talk about the philosophical details you know in other kind of uh Frameworks if you like but that's the kind of I think way to go about I think it's much too harsh and arrogant to just completely abandon all of the insights of contemporary Linguistics just because we have sophisticated Neuroscience I think some holding on to some insights from Linguistics will be essential to direct and test and you know refine our data driven science too um so I think what Baki talks about in his book is I think misleading and kind of a you know unhelpful Division I think it's not I don't like to talk about inside out or outside in I think it's kind of just you have a balancing act between both right it's you have to just negotiate when it's appropriate to use computational levels and when it's appropriate to use implementational level theories um okay so that takes care of that um I'll skip over this bit here um yes so this this this gets into what I mentioned I I mentioned this maybe a little bit briefly um but it's very common to object to these kinds of proposals of the kind I mentioned in Rose as a kind of crude form of direct mapping right or isomorphism and I'm so some people listening to me right now might think well you're kind of a hypocrite because you're doing exactly what you're critiquing Baki we're doing right I'm complaining that Baki is just no sorry I'm complaining that these outside in people are just imposing their linguistic theory on the brain and I'm saying you shouldn't do that at the same time though the whole point of the Rose model is to directly map on what different types of linguistic structure onto the brain so a complete niist or you know might say well the brain really doesn't care about any of these structures the brain really doesn't care about um Atomic features lecal items feature bundles phrases uh you know sets of sets of sets and all the rest of it now that might indeed be true that's totally possible um I think it's unlikely given that the um you know um the specific responses that we've seen at different levels of linguistic complexity the kind of sociable scales of sensitivity you can see at different neuro complexity scales that I mentioned here um but so you know the rose model is essentially invoking a direct mapping in some way a kind of onetoone um correspondence between a scale of linguistic complex X and a neural mechanism Y and you kind of you know you you find you follow that all the way up until you get to the um ultim the highest level of nesting that you get with the Delta Theta complex all the way down to the AL PE cing that I mentioned earlier right okay um so some people might say that's a problem uh Rose continues this crude tradition haha and by establishing an even more explicit isomorphism between system level complexity and syntactic complexity so for example cells and Sy actic features versus global coherence and phas structure on the other hand um alternative accounts that build syntactic operations into neural systems of diverging levels of structural complexity have not been forthcoming by the way so if they do forth come then we can test them as well um but would also naturally be required to establish any kind of adversarial collaborations and experimental testing of the models um so through this it would be possible to pit different candidate neural mechanism for syntax against one another and compare effect sizes across studies to see which mechan Mech ISM either from Rose or some other model best explains real time direct political effects of language processing so that's a nice way to directly test the rose model but I also want to emphasize here that as far as I know the the rose model is the only model of syntax um n neurobiological model of syntax that takes seriously this whole notion of the fact that the brain genuinely exhibits distinct levels of neural complexity organization and scales of complexity and also take seriously the fact that not all neural recording meeses just measure the same thing right um single units up to Utah up to SGS up to EOG up to Meg up to scal Peg um these are very different beasts and they record very different things um it's easy and convenient and maybe comforting just to say well the kind of signal that we see in scalp RP responses and delta waves are probably just some kind of summated you know phase reset of whatever's going on at the spike level um on on some level of description that's true however it doesn't help with building model of syntax in the brain that's just kind of dismissal so my appeal here is to kind of ground it more concretely in different levels of analysis and so far you know all the other models of syntax in the brain as I've said are localizationist as opposed to kind of algorithmic or that's why the the subtitle of this paper is a neurocomputational architecture because it's a neurocomputational architecture and it is very much an architecture there's within the row architecture you can imagine three or four or five you know very different specific theories of or models from the architecture so you know it's very much an architecture and within this paper I propose my own specific theories at each level but the AR the scale of the architecture scaling from the spike yeah Spike of PE coupling up to pack up to traveling waves that's the architecture but so within the architecture you could maybe reframe some of these things as long as the the mechanistic relations between R to O to S to e are maintained that's the kind of General framework here um and then going back to metaphysics for a moment um Rose is also sympathetic to recent moves in philosophy of biology to view a range of biological constructs as processes rather than objects Rose is built entirely from neurocomputational mechanisms that are already known to Subs of clusters of generic perceptual and cognitive operations right I'm not invoking any new neural mechanisms I'm not I'm not proposing a new kind of you know microt tribal quantum you know computational mechanism to explain all this I'm being very very conservative and just using literally stuff that's been published in the most you know high impact serious scientific journals uh which which been has been afforded textbook level treatments at every level so all of these mechanisms have been given serious textbook treatment the only difference here is that I'm migrating some of these concerns over to the linguistic domain um for with with various different motivations across the levels um um okay and then turning slightly further um so yeah another nice Point here made in the nature neuro paper by Nina kazanina and Alexandra Tano and current theor is that model hierarchal stri building via low frequency Dynamics correlates some neural measure with attributes of a hierarchical syntactic structure and thus concern the outcome of syntactic structure construction so this is a critique of those Meg and EG studies that show this low frequency Delta entrainment or Peak response at moments of syntax it's a very legitimate critique but by initiating certain syntactic structure building at the cellular R level and accounting for how these output um how these output low frequeny responses at the SN levels the rose architecture goes beyond these other accounts that are more closely tied to the output of structure building so and again even in the Rose architecture this is correct that the uh these low frequency Delta speaks are indeed the output of the structure building I'm not denying that I'm not saying they're the input you know they're not some kind of intermediary response kazina and tabana are completely correct they do they do reflect some kind of um readout the final stage of the syntactic structure building process um to kind of wrap up or even monitoring stage and for me it's part of the um structure to encoding phase and but at least the early stages of syntax at the RN levels are definitely at this this kind of Spike level and High gam activity level okay um yes and then again open questions remain about how to ground this in more neurochemically explicit models I haven't talked much about neurochemistry uh some of my earlier papers in 2015 2016 tried to take neurochemical Frameworks much more seriously and I have more of a like mathematically rigorous framework into uh negotiating particular low frequency Dynamics and but in this paper I'm just kind of leaving that to one side for now because the paper's already you know way too long u and I'm just focusing on the kind of Architectural Components that's something to be focused on at a later stage okay um yes yes yes okay so turning to the conclusion um you know I've mentioned a few times that this the rose architecture really does come in response to the absence of phase coding models in language there's been a lot of phase coding responses um or phase weighted um you know entrainment and low responses empirically documented they've been empirically documented but in terms of the actual theoretical you know summary that's kind of been lacking so that's my main motivation um and many researchers who have kept the Frameworks emerging purely from extrenal you know Meg derived event related fields or scal related potentials or fmri responses Etc these guys have begun to to lose Hope they've begun to lose hope in in the prospect of of of finding syntax in the brain so for example Lena pinin who's probably you know the world's most respected neurobiologist of syntax uh she's written that the Neuroscience of language field has long assumed that our brains build syntactic structure during language processing today it's reasonable to question this assumption and she's you know she's totally right and uh motivated to say that because she's summarizing research from extra mostly extal stuff like Meg and FM and she's definitely right that if you just focus on that research it seems pretty hopeless um I think the lack of space tempal the lack of high spatial temperal resolution in these methods explains the absence and that's kind of one of the implications of this paper um this paper is essentially indirectly critiquing that that field so so pilin you know reasonably speculates that based on the evidence reviewed in her article something like merge might not be an obvious neural operation um or alternatively it might not be found in presently exploded neur signals um in fact she has this nice distinction between um syntax as knowledge and semantics is process where in um you know neural recordings across all methodologies finding signatures of semantics is very easy because semantics is very energetically costly um the number of words and possible Concepts you can combine at any given moment is really kind of astonishing you know the number of different feature spaces you can talk you can you can talk about green horses made from licorice that ride to Mars next Tuesday you can talk about all sorts of surreal St right so semantics is very um unpredictable um it it it calls upon a wide range of cross qual representational features what about syntax syntax is very different because syntax is is syntax is just merge that's it you just build you just you put two things together and then you label it so that's it that there's no diff there's no novelty there every time you you you build a phrase you do it in the same way way you build a you build a phrased architecture you label it you stack it into a workspace you label that you ship it off uh to an interpretation and procedure um that's it that that's all of syntax and you do it again and again and again uh you don't have a different merge process on Tuesday as you did on Friday but semantics is like I said there's a big difference here between the space of semantics and the space of syntax the space of syntax is just this merge this one operation so it's no surpris that it's been very difficult for scientists to find neural signatures of of of syntax syntax specific responses because it's like we do it so reflexively and so trivially and we've been doing it you know since infancy maybe even before infancy um depending on which language acquisition theorist you believe in um whereas semantics were constantly changing it you know it it takes years and years and years for us to really build our our full repertoire of developed semantics which syntax once you've built a phrase you've built a phrase that's it You' you've got all the syntax the only thing that you can go beyond that is you know kind of performance aspects like how complex a sentence you can construct right can you read Shakespeare can you read Joyce you know can you read David Foster Wallace these that's that's a very different question but that's a question about performance it's a question about like working memory attention you know all those sorts of things when it come the actual basic component of syntax is just m so I think pinin is right that you know maybe she's not I don't think she's right that you know meres knowledge and semantics is process I think they're both process and they're also both knowledge too um but in terms of why it's been difficult for people to find a signal reliably that it's because that's all the rest to syntax whereas of semantics you're going to get a very reliable uh very serious uh neural energetic cost involved in in processing sentences so and in fact in our lab in our interanal recordings for our epilepsy patients all the response all the most reliable responses you see are clearly with uh you know meaningful sentences as opposed to um you know semantically impoverished sentences that have a good syntax because it's it's just difficult to really disentangle those things um but that leads to into some some other questions that I won't get into because that's that'll take us to a different topic um but so you know I guess I've tried to what I've tried to do with this paper is that with rose I think I've at least provided some candidate neuros signals and they do exist there's plenty of candid neur signals some very good ones um and that can you can be readily investigated in this manner so um yeah I think that kind of settles that issue at least for me um so under rows there's basically no sense to be made out of claims that syntax lies in one specific brain region I talked about psts before being the real sight of the initial phase of Mage but in order to get to structural inferences and then transferring up to a workspace that's a global um phenomenon it involves uh most likely uh you know posterior temporal inferior frontal coordination there's a nice paper in pnas uh by Oscar wner who's in our lab a postto in our lab who showed very convincingly that um building a coherent sentence structure involves the coordination of overlapping spal temporally overlapping but distinct uh clusters in both posterior temporal and inferior frontal cortex so it's not just you know ifg versus PT it's kind of like okay they're both involved but to what extent um some issues are a bit trickier to discuss because you have to kind of relate this to the legion literature which kind of more reliably uh implicates posterior temporal cortex strongly and for my money if I were just to you know contradict myself just a little bit um I think the language region is essentially posterior Superior Temple Circus I think psts is basically the language region with other things coming online later due to um either coupling or functional functional coupling in coordination with psts psgs will always be involved it's always the Hub and these other regions like ifg and ATL are involved and called upon for performance reasons or to or reasons to do with a downstage readout and interpretation well psgs is the language region um for me at least um so that's kind of the seat uh of the Rose localizationist Approach at least but then the rest of the neural code spreads far beyond that as I mentioned um I only read one sentence of that paragraph before before waffling um but I think I pretty much already said that in many ways um okay and then yeah we can think about testability and all sorts of different ways too uh to do with separate out the category of the phrase versus the semantics of the phrase that's something to think about yeah um okay and then in terms of um the general roles in shaping information processing the currently identified frequency specific mechanisms seem to align with an emerging consensus in the field that slow frequencies control input sampling Alpha and beta gate information flow and high frequency activity is controlled by slow rhythms that's a very general kind of neurocomputational you know framework that's been explored in in the cognitive neurosciences um and then moving beyond this a newly emerging focus on brain criticality and how this concept might relate to brain rhythms provides exciting revenues for future work in theoretical neur Linguistics so that's a cool concept too um and in fact there's some really good work um exploring how in some of my early papers I talked about uh what's called globularity which is this concept of um the fact that the human brain is uniquely um almost spherical relative to other primates it's not completely spherical obviously um but a lot of cognitive abnormalities come with a brain shape reorganization um and the fact that the human brain is kind of more globular than our ancestors has been used to motivate a lot by a lot of serious anthropologists and also neurobiologist ologists uh this idea that the human brain is kind of uniquely efficiently wired in some way to facilitate cross cortical and also subcortical um information integration um so I think there's something to be said there to do with um you know an evolutionary change in brain shape globular brain shape would have naturally facilitated different paths for these traveling waves to move across right um different patches of Cortex can can communicate with each other and in fact we know from work by people like L falky that the basic computational kind of uh contribution of language is to provide a kind of universal currency for different um conceptual domains to talk to each other excuse me so language is basically giving you you know you have then your number sense your sense of morality your sense of intuitive physics intuitive geometry uh intuitive botony know what there's all sorts of different domains in the psychology literature concerning how human beings have been inative modules for understanding reality and constructing a g to model of the world um language seems to uniquely allow us to conduct transactions between these domains whereas in non-human primates they may not be encapsulated exactly but they are much more kind of atomized um the modules you know nonhuman primates have most of these modules for sure no doubt maybe all of them but they don't have a way of um conducting transactions between them whereas of humans we can talk about you know um a large number of you know funny green colorful heavy balloons or whatever right we can combine different conceptual categories together and number sense morality you know um uh different geometrical constructions emotional constructions we can use language to access all of these different cognitive constructions now even more interestingly there's some you know it the if you look at the kind of syntax of natural language there's been some really interesting work by people at qu University and and other university showing that if you take the list of human semantic Concepts and the list of human kind of you know electrical items and features there's a lot of overlap in terms of like uh event structure and agent um uh uh processes and and and features but there's also some nonoverlap so there's certain um uh concern the certain Notions like worry or concern for example that are not morphologically marked in any language whereas things like you know trustfulness or or or belief and uh you know things like that are are marked in by by by words and language so there are certain um conceptual features that are very readily found across to the world's languages and have certain morphological inflections for or or features for but there are also certain epistemic Notions or Notions pertaining to knowledge and truth and so on um that are not readily morphologically marked so that suggests that there are certain parts of the brain certain critical modules that the language system does connect with and does functionally speak to and interact with but there are other cognitive or perceptual modules that it does not speak to that it's more isolated wrong so that's kind of a potential way to kind of think about ways to relate the kind of neurobiological infrastructure with the kind of Behavioral linguistic kind of phenomenon okay um so yeah and then just to conclude the more kind of philosophical foundations of Rose um are also in line with research documenting a rich array of in capacities utilized during language acquisition in the unit which can distinguish distinct phones detect word boundaries lay words and so on um I'm kind of really invoking a very rich kind of array of um innate capacities so uh currently due to the lack of consensus regarding how to ground syntatic comor anality in the brain researchers enjoy many degrees of freedom When selecting from their preferred linguistic Theory processing Theory the algorithm and neurological framework the implementational framework um so I hope that Rose basically allows us to um you know fairly constraint this landscape to narrow the space of likely candidate neuro mechanisms for syntactic stru building it's really all about figuring out what are the what are the most likely mechanisms that we're going to find um natural language syntax in the brain which parts of the brain are going to be sensitive to it and which really index that process on some level um so yeah I think I guess I should probably leave it there and conclude it but um yeah that's pretty much the whole model thank you for the massively informative overview and the research agenda do you want to stay happy to stay for a bit longer for sure yeah yeah happy to chat all right well there's so many places to join for people who are watching live maybe we'll have a few minutes to ask question wow yeah if you have any questions or comments or thoughts I mean I I can I can I can sit here all day and just talk forever about this stuff but I probably shouldn't all right I have uh a handful let's do some short answers and just some general because on the evidence and on the specific brain regions and specific time scales you've made that abundantly clear so going to ask some alternate questions so okay how do we study these densely woven cognitive phenomena without how do we hold that tension without just resorting simply only always to holism or reductionism you kind of talked about that with the inside out and outside in views but how can we approach a different cognitive system maybe not the human brain and language where even the relationships amongst the different phenomena might be themselves not known um okay I see you mean so if there's some kind of you mean a human specific cognitive process that is not language and yeah if you want pull out a different thing or study a different system what kind of account are we looking for how are we going to know we're on the path that's not being just massively misleading and so on no no that's a good question um so I think I think so the rose architecture I think is is partially applicable to lots of different cognitive domains I think for attention and working memory uh you know face perception Al faction they all involve something at the r to O Level the coordination of Spike timing and the um the realization of some kind of centry motor Transformations at the Broadband gamma level the the thing where we take over is really at the S level where you get the uh particular type of low frequency coordination that seems to be specific for language but it's you know language is not the only thing that recruits um you know uh low frequency um illary phase codes to conduct the orchestra of you know representations that need to be externalized or interpreted um so I think the it it's it's transferable in many ways the real um testable uh issue will be to do with whether or not these um you know whether or not I'm correct that these different levels of linguistic scripture are found only at these levels or maybe they're found across all of them um so for example if effects of syntax specific responses can be found truly at the r the O the S and the E scales that I've mentioned that muddies the waters because it means that um the you know the brain at every scale across all areas cares about the most Niche specific issues in in syntax we might have to turn ultimately to um State space architectures u which I suspect will be used to supplement rows at least at the at the um the uh the s&amp; levels I think in terms of you'll have like um different um abtract States being coordinated across Network nodes um rather than the kind of which is you know similar to what I mentioned to with traveling wave just a more kind of global interactional process but for a very different mathematical grounding it'll have a very different mathematical grounding um so but I think um I don't know I'm not sure if I'm answering your question well but I I think I think in terms of transferring it to to other domains that are that could be explored um it's really about um you know trying to find trying to find a prediction of like I will I need to use a particular methodology I need to use a particular experimental Paradigm to find effects that should only be found at this particular neural resolution and in this respect it's no different from the rest of the cognitive Sciences because in working memory and attention and navigation that's exactly what these guys have done for decades uh Linguistics as usual is you know the last person to the party um we are usually linguists are usually the last in COG Neuroscience to kind of you know pick up the developing tools in the in the field and apply them um so and that's fine you know there's nothing wrong with that it turn I think the reason is because human language is the most complex cognitive process that we have it requires a lot of the weeds to be sorted out before we have to figure out how working memory Works how attention Works how Vision Works before we can even worry about language um because all of them kind of presuppose and and require that right at some level so I think it's natural for language to be saved until last right save the best of last for sure no doubt um but I think it's also it makes it um it's also the case that neural linguists have not always taken the lessons that previous Fields have learned as seriously and we often end up making the same mistakes so when we got scal scal pegs for the first time or or fmri we made a lot of the same mistakes um that the uh memory guys did or the navigation guys did um and I think my own fear you know in writing this paper is that the reason why I wrote this is mainly because you know I see it in the last few months I say in the last year or so um ctive neuroscientists getting their hands on very Advanced recording techniques but not really knowing what to make of it again this very aggressive very but also very contemporary and very Progressive kind of So-Cal Progressive Viewpoint of know data driven science where you just kind of let the data speak for itself and uh allow the statistics of your uh you know or do some kind of machine learning um on on your kind of on your data and expect that to kind of feed into an explanation for language a lot of those techniques um also discourage this kind of theoretical reflection um and if you look at people like KL friston you know he spends most of his time he's the world's most influential neuroscientist he spends most of his time just doing theoretical Neuroscience because it's that's that that's really where we're at these days in a lot of these fields it's about consolidation interpretation a lot of the a lot of the um I mean I was surprised when I when I started writing this paper I was surprised that a lot of the clues and answers to this puzzle of how syntax is implanted in the brain are kind of already out there they just haven't been very you know uh the dots haven't been connected the uh the principled relations and logical relations between different findings and different um you know recording methodologies um and the kind of more principal relations between them haven't been established yet or haven't been fig out um and I think there's often a push and a desire to just you know do another experiment uh you know get funding to do more and more experiments and collect more data and do more analysis that's obvious essential I I do that as my day as my day job um but outside of my day job I think it's it's also important to spend some time you know thinking about how to thinking more carefully about this so that you don't need to do any more experiments for a while um so you or at least so you know that you know when you do your experiments you know the the landscape better um and you don't end up making the same mistakes that other people do um but really it's it goes back to this issue of kind of cost cost benefit like you know how do you how do you kind of weigh up the um the pros of collecting more data with the um you know the the foreseeable benefits but the whole notion of foreseeable benefits empirical foresee foreseeable benefits really presupposes and needs this framework of what the benefits are likely to be if the benefits are just I'm going to just let the data speak for itself and get a bunch of different you know machine learning um or llm architectures to kind of figure out the story for me you're probably going to be disappointed um whereas if you take a step back and think about a more principled architectural approach like think about the brain the way an engineer it would um and figure out like which level is going to be best served for a different a particular cognitive process that's that's the basic mindset behind behind this model it's about figuring out like you know which scale of operation is going to be most helpful for you great well on that kind of research program scale the compass rose it's a great model um I was curious about a few other settings for speech like listening to a video or recording at a different speed than 1ex or watching subtitles or just the idea of reading and whether there was some kind of a um clean handoff between one sentence is heard and then one is read then one is heard is it beyond the sensory modality by what stage or what elements that are extra lexemic like Pro and timing and so on play into for example speech as opposed to writing where there's formatting and italics and so on yeah no that's a great question so um there's a there's an there's there's an unanswered question at the moment which is to do with the bottleneck of reading or speech process well speech processing not too much but definitely for reading um we don't really know that much about the bottleneck like how fast you can read um so the rose model talks about Delta rhythms it talks about the rhythms these are very slow waves if you ever tried speed reading it becomes very clear straight away that human beings can read very quickly um so if you if you you know code in mat lab or or python some kind of RSVP style um you know uh textbook where you can just like have one word flashing on the screen at a time and set it to different rates if you have it you know 50 500 milliseconds away no problem it turns out you can go way faster up to like you know 15 20 words a second and you can still get interpretability um you you'll be surprised if if you try it you'll be very surprised about how fast you can actually read um so you might think that poses a problem for the rose architecture I don't think it does I can get to that after I've answer your question it doesn't POS a problem at all um but so that's that's a good question so we know that there are certain parts of the brain that do um in the vental temporal cortex um which is the Lower Side of the UND side of of the temporal low they are responsible for um fun transforming visual information into orthographic information and in fact the work of Oscar wol now in my lab he's done the most impressive work on this by far and Inter very Exquisite like inter cranial recordings of how human beings um in fact his whole research is on reading so you should probably definitely read his work it's it's basically about how the human brain takes you know visual information and then trans uh converts it into an orthographic space a constrained orthographic space a space in which you know uh your mind I guess will be sensitive to particular statistical configurations of shapes like you know this one's a letter this one's not a letter so that takes place in a certain part of the venal temporal cortex and then maybe somewhere around there that will due to endogenous um you know processing um limitations probably not to do with vision probably due to you know some kind of uh next next stage process to do with interpretability and because as you know we can read we can see based on card rates and and all the rest the number of like objects and things we can see in a given second is is is is very large indeed the human brain mostly filters out you know most of its sensory information every second just to kind of focus on the stuff that's key to its G model the stuff that's key to kind of um you know minimizing the free energy of it of it g model and keeping it kind of sustained and um not changing the Status Quo Etc but on the reading level uh we know that um at that stage that's when you get the Sentry motor what I call the Sentry motor transformations in high gam activity so that's where you get that high gam activity being responsible and sensitive to the mapping from that visual information to the linguistic information because obviously somehow you've got to you see words on the screen you see squiggles and lines somehow you got to convert that into a more abstract space so that all takes place in the rental tempal cortex and then you get some interesting connectivity um and top down information from being sent from frontal cortex back to rental temporal to constrain and re and and kind of coordinate the that that bottleneck at least that's one of the main theories that that exists um I'm not an expert on reading per se I'm not a vision scientist but you know as far as I understand that's the kind of um the general framework is that there is a part of the brain that's sensitive to the St statistics but Al also the symbology of orthographic information um and we know that it takes place in very short time scales um when it comes you you asked a very interesting question about the the kind of um you know Co the kind of dual modality like when you're watching a film you're listening it and you're also reading sub Tiles at the same time um that's a very tricky question because um on the motor side we know that you'll get auditory cortex involvement and orthographic kind of occipital temporal um involvement engagement at the same time but somehow they both have to converge on a single interpretation right because we know that um you can't comprehend things in parallel you can't read two books at once um or at least most people can't so that means there's got to be a single kind of interpretation procedure and a single kind of semantic integration process that is being instructed in a form by different modalities but when you think about it that might sound difficult but it's actually no different from when I use hand gestures right now right so when I use hand gestures I'm providing some kind of extra modal information to you uh it's obviously easier because this is more hand drestes are usually kind of pragmatically informative rather than explicit propositional of course unless you speak sign language um but with it's it's still just a case of like different sensory motor Transformations taking place so that would still be at the at the O Level that would still be at the the O level of art it's still high gamma Transformations that are then fed into a more uniform um uh discrete and Abstract syntactic inference being made there's only one syntactic inference being made about the meaning of the sentence but it's being informed by multiple sites now you do raise an interesting question because that might that might be the case it might be the case therefore that this low frequeny Delta complex therefore has to entrain and functionally connect with multiple cortical sites it might have to to speak to aary Cortex but also Ral tempal cortex if you're if you're gleaning distinct um types of um if if if the lower level lexal representations you're getting are being sourced from auditory then orthographic so for example if I give you a sense and I CH and I get you to hear the first word and then read the second word and then hear read hear read here or listen I should say listen read listen read if you go between listening and reading but you're still integrating a single unific a unified structure we know you can do that human beings can do that so that tells you straight away that you know it can be done um but the question is how it's done like I said I I suspect it's through this this dual kind of tradeoff between Cent motor um instructions being sent from auditory cortex to to the same unified low frequency program and then the visual information too so that's that's actually kind of a nice way to separate out the distinction between you know centry motor store from the more abstract unified kind of syntactic information that's being built um and in fact you've just given me a good idea for an experiment so thank you cool yeah because language is so linearized it's like being pulled through a needle and then in the Cade so-called speed reading but it's not simply moving the linearization faster speed reading can leverage formatting and all these other strategies like almost thinking through other Minds ways of reading and also having an off center effect in visual system and the way that that kind of convolves the orthography versus in listening you basically always want to be listening more clearly because the moment is the only time you're going to hear it the active listening components like you can't let it fly by but reading you can you can take Cade strategies and cognitive strategies that that you just can't take and that's kind of this like all at once versus one at a time element there's actually there's a framework in in pych linguistics called the Now or Never bottleneck so the now or never bottleneck refers to what you're saying right in in Reading there's no now or ever you can just take your time with listening you're totally right it's it's now or ever you have to pay attention now and integrate or your working memory is going to dissipate or your attention is going to or your phological Loop is going to Decay and you're going to ask the person to repeat themselves again and again um so it's a very it's a very different performance system and it's also very different from Braille um when when you're touch using touch and reading Braille when you're gesturing and using sound language you know language especially syntax truly is a modal it's it's completely independent of any modality you know the Neuroscience of speech is very different from the Neuroscience of language the Neuroscience of of gesture is very different from neurosci of language your language is a more kind of a modal abstract system that calls upon these very various Sentry motor kind of you know processes um which is what and you know most people intuitively try and ground language in a sentot kind of context because that's natural of course you know that that's how we access it that's how we trigger it but obviously you know most of most of our daily language use is probably just thinking to ourselves you know um using language maybe on subconsciously using the using the computational capacity that language affords Us in non-linguistic ways meaning to to construct hierarchical structures of thought and planning and uh you know and all the rest of it um in in some kind of subconscious way uh rather than explicitly saying I am saying a sentence or even I am think thinking a sentence in my head because even when we think a sentence in our head that's still just an internalized form of externalization right so when you think about in your head that's still ex that's still externalization it's just a different type of externalization you're not externalizing it with your mouth but you're still putting it out into your own phological Loop but that's not that's still externalization internalization is truly the subconscious process of generating the syntactic inference which is done rapidly reflexively uh you know intuitively often without much thought often meaning attention often without much attention being directed to it and any kind of conceptual implications being made um so most of language use is outside of the centory motor space I I would argue maybe I'm wrong about that but um this is a point that n trumpy has made a lot and I think he's right about this um you know a lot of the use of like the daily use of the language infrastructure um is AC like I said I mentioned the universal currency metaphor it's it's across these different conceptual spaces um and it's it's it's potentially represented very redundantly across sparse neural codes as I mentioned in in the Rose architecture such that it survives brain damage it survives all sorts of different things um but um but it's still keep it's is still crucial and you got a lot of people like Rose M and federo you know going showing work that um you know damage to well you know using Imaging research showing that um the language network is not activated during XYZ n linguistic cognitive tasks or damage to the language network does not damage you know XYZ nonlinguistic tasks and that's all fine um but it's really that's kind of a separate issue from whether or not the more abstract syntactic neural code that I that I've presented in the paper is recruited on some level by nonlinguistic uh resources which I suspect it is um again another empirical question for you right um but I think that's a reasonable framework to kind of assume at least and yeah cool one one I guess reflection on that and then one last question um you described language human language as being a kind of psycho technology with supporting architecture and inculturation all these different features that are are totally relevant influence it that allows us to articulate like the sense making an action like when we look at figure 4.3 in the active inference textbook and we have a basian graph that factorizes out through the sparsity of just how things are related like how the measurement of the thermometer is related to the temperature in the room how the temperature in the room changes fundamental concepts of place and time where preferences fit into that what this is about the semantics of this variable whether it's kind of like a central tendency or whether it's a variance estimator like confidence which is something that you brought up as like a strong linguistic um utility so it's kind of like it has an element of just being the geometry and topology of thought and thinking and generative modeling that has Ultra mundane everyday uses because this generalized apparatus really does have utility pragmatic value in communication so it can be used for the most referential um just one bump above pointing at something and pointing at something and grunting and pointing something say look or look it's a like you can keep going and but often what's only needed is the first little bit especially given a context and yet there's this open-ended arbitrary State space navigation element as well yet it's only I just I think it's incredible how it's laid out and how what you described with a heavy emphasis on the neurophysiological and the computational comes into play with active inference and the generalized State spaces and all these Concepts so that's just super exciting I guess my sort of closing or or we can keep talking or whatever but how do do you see this relating to language learning for first language and for not first language learning yeah I I I I I totally agree with what you said about the active inference framework like I think I think um you know linguistic semantics and well you know syntactic structures are a unique kind of inference that the human brain has to make um the um I I I see a lot of the the properties of Le lexo semantics in human language as being a unique type A Unique contributor to the active inference framework and I think it's it's a surprise to me that more linguists haven't turned to active inference to think about certain properties of because it seems so obvious it seems so compatible I've tried to do it in some work um and I think maybe some other people have too potentially but it's um it's it's an obvious kind of well I mean I cited the Peter hag paper he cites that work too a little bit um but no it's it's a very promising way to to beue it um in terms of um language learning and acquisition that's a very very good question so in the I mentioned at the beginning some of the low frequency um Delta responses to syntax all of that research is in adults well all of it was until um some researchers at Cambridge UK a few years ago started to think okay well maybe is this how children process language too um or maybe is this how is this where they process language in the same regions it turns out if you look at um teenagers and children and you do the same kind of Lo um you know SC scal b or maybe even Meg research I'm not sure I can't remember I cited it in my book um the uh low frequency responses change over development in terms of which um ranges are sensitive to the periods of syntax so it's not necessarily you know 1.3 HZ precisely that entrains the syntax of course not this gets back to the point number earli about speed reading right it's all about the flexible coordination and packaging of representations um into a given complex um again there I mentioned the issue of trade-off between you know number of representations you can chunk and the F and the Fidelity of of the representations you can have a few and well represented in Gamma or a large number and only a small number of spikes uh per representation that's just kind of you know that's a very general framework that's been um supported in the attention literature too it's not just um my proposal so so that that that poses the question if children and teenagers show a different kind of you low frequency phrase response how do we deal with that um I don't have a clear answer to that question I think the rose architecture can very readily be modified to that because it's not as if you know for they'll still have the same architecture they'll still have the same you know R to O to S to e the particular frequency band of Interest might shift over development and in fact we know from working memory and attention that Theta Dynamics and Alpha Dynamics definit and and beta Dynamics too do change cross cortically over over development um and these are behaviorally relevant to things like um development of working memory and attentional resources that's that's been very clearly studied and very well studied too um so it's more like the there's a more abstract code that simply shifts its spatial temporal profile as the brain gets older and then changes more when we get even older so I have a paper that going to um come out fairly soon I hope to do with um aging and what happens when we when our brains Decay and we get old um there there's some nent kind of research looking at the uh language processing not at the behavior level but in terms of the neur level the neurobiology of um language processing in older people um and how it might also relate to you know breakdown of semantic information access and things like that and what are the potential correlates of that so you can imagine very clearly if you take the rose architecture which components will be disrupted or modified based on if it's a syntactic or a conceptual or electrial kind of deficit but you the the the isomorphism is as I said very crude so you can you can predict that very clearly and in fact there's some research in that space that I think is concordant with this which is what I discuss in this newpaper um so um it's it's you know it it like I said it's a relevant architecture it's a very difficult question about how the whole brain um matures over time because you know there's certain aspects of knowledge that may not be represented um in ways that we currently know how to um you know uh detect or record um we have the four or five measures main measures that I mentioned in the paper they're they're what we have right now maybe there's a particular form of neural encoding that it just goes Way Beyond what we can physically provide in the year 20 23 um I don't think there's any reason to assume that we've reached the limit of like decodability of neuros signals and their complexity absolutely not um so the learning process is is a very mysterious one um so yeah I think I think it's it's also it's also a really good way to falsify a lot of this stuff by the way it's a really good way just to completely falsify and test a lot of these proposals to do with the architecture itself um and then developing code over time as well so yeah it's a very relevant concern the the the best way to do it is um to get Interra recordings in children uh that's very difficult because so there's a uh in Austin Texas there's a lab there has that has that has these recordings and and uses to um access to uh children with epilepsy and they get these children to you know Watch trailers of films and listen to stories and things like that and they do some interesting language research uh in these kids that's ex exceptionally rare data and very very very useful data for answering these questions I don't have access to that data um and most of that research has not been forthcoming yet there there's been a couple of inter cranial um papers in in in children and language but it's it's fairly sparse fairly low patient numbers and the types of analyses have been too kind of remote and and departed from this framework to really test it but that would be the way to test it get you know um electrodes directly inside the brains of of of children and potentially even younger I think the youngest I've seen is about four um but you know even by 4 years old it's maybe too late to to chart the actual full development of acquisition of language because by that stage they've already acquired syntax right if you could get even I don't want to sound like a mad scientist but like if if it's possible ethical to to one day get access to intercal recordings in very young children then it would be possible to chart this developmental process especially if the children are in the hospital for uh protracted periods and in fact get some kind of I mentioned BCI implants if they have some kind of implanted device over time that would be the most direct way to test this stuff well not just test my theory but just you know just just completely chart out the full development of profile and the evolution and the development of the neurophysiological basis of of speech processing and language processing um but right now that's kind of as far as I understand that's kind of like the current landscape of of of where the field is right now wow well um you can have the last word with any last thoughts but thank you for this this amazing presentation and I hope that if people are interested that they can of course read the paper and learn and reach out and maybe we can have 64.2 when the time is right but anything you'd like to kind of leave it with yeah no thanks so much for having me on man um it's been very it's been great you've been great i' I've been enjoyed it's been enjoyable just kind of outlining my own Theory you know you read your own paper over and over again and you realize all the things that you kind of misinterpreted or misread on your face read through um in terms of like phrasing and all the rest of it so it's always good to to refresh these things but no absolutely if people are interested in in this stuff I'm always open you know you can contact me via email uh on on Twitter um very happy to talk more absolutely So yeah thank you for listening thank you for having me thank you peace peace peace