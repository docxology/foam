all right welcome back everyone we're in cohort 7 chapter 7 so for some of us this will be our first time on seven others not not so first um but where would anyone like to begin with a specific quote or question about seven or how did anybody take seven or where do they see seven in the book maybe I'll say uh I I listened to the uh video of the last session the evening session where Andrew talked about chapter 7 and so what interests me uh and I'm still struggling how to code things like free energy principle and how to um you know how all the math Works Etc but um and he did he did help explaining that but what I got from these sections was that they progressively um are looking at modeling different parts of mental life um and showing that in each case you know the this apparatus um uh can be used to model that and so in my case uh like so basically like perceptual processing like deducing an intended signal uh the teamas with the rat like decision- making planning uh epistemic versus pragmatic and then information seeking with the isaad uh seeking position where you can get it kind of yielding a street light effect and then learning a novelty so this synthetic worm exploring its environment changing the generative model and then finally like hierarchical or deep inference words and versus sentences putting that together together on separate time scales so so what it seems like is that um you end up you you know you you see oh I could use active inference for modeling this um and then um you do things of you know whatever sophistication you can and so I'm interested maybe in the opposite to say okay I'd like to have develop a cognitive model I think that I'm going to have like a continuous part and a discrete part like a procedure ual continuous mind and a discreet declarative mind and then I'm going to maybe Wonder like how they discover critical points navigate them um you know have a language of critical points so so I guess I'm just still learning about U the um active inference but I'm trying to pick up on that connection between like having a mental process or experience in life you're trying to model and then thinking okay where does predict addiction error come in I guess that's probably what it's about that's where I'm at right now thank you awesome summary anyone else want to give some thoughts on seven or like a a section or a quote or a figure or equation that they want to jump to um I mean figure 7.2 with the the plots about uh The Listener are a little confusing I guess um I'm not sure what I'm seeing in the First Column of panels there maybe someone with some more insight could kind of walk us through what these panels are showing yeah it's a great point because this chapter is the discret setting but then it's like wait a minute why are there continuous traces here with a discretized model so these are kind of like some model outputs from the SPM mat lab scripts um but yeah we we can definitely get and also it doesn't help that they're black and white yeah so it's a little bit like well but are we expected to I mean how can you trace so I agree they're they're not super informative there do we know at least like what they're meant to be showing like what is yeah I think like I could say the main idea if you show the diagram there if you go up to the diagram the main idea is that there's an amateur musician kind of playing some of the notes wrong and um but if you go if you go to the if you go to the screen someone's listening and they kind of know what the melody kind of should be it should just go dun dun dun dun and then D so when the musician misplays it which would be the lower right they they misplay it but the person who has the idea of what the melody should probably be like they interpret it well it's gonna it really was meant to be that it's the intended signal as opposed to the actual signal and so active inference is able to you know if you have a strong enough Matrix where the pattern is so insistent that you know it's going to survive the truth uh then um then it can model that so yeah okay and what's happening with these figure specifically so top left posterior probabilities about each note so what's happening here is basically how confident are we each of these is a different note but they they can't be determined so it's like in time point one and also does it doesn't help that it's kind of offset yeah here but it's sort of getting at they being like the most likely one is on the top so that's one with the highest posterior probability which is kind of selected if you only get one selection and then on the lower left is the the prediction errors over time so like you can see there is a higher prediction error when the incorrect note is played okay and but each line though is is what it's a it's a posterior probability about a note yeah yes so it's like the the the Laten um there's one spot for what's the true note being played like we're going to receive a one hot observation like we either hear um note one two 3 or four that's coming in with a vector that looks like 1 0 0 0 for the first note y like in this situation then we have a prior belief distribution over those four so we could have a uniform belief over the four 2525 2525 you know or you could have um 90 333 sure okay so then the relationship between the skewedness of your prior and the attention to the sensor input is what dictates belief updating which is when the prior becomes the posterior so in the extreme case of no attention it's like the observation didn't even come in you just carry your prior forward in the extreme case of total attention you just basically update your posterior to whatever the observation was and then everything in between is like attention weighted belief updating and so there there could be some value of attention where this is exactly what would be heard but in that point you don't even need to do basian statistics you just do descriptive statistics on incoming information right yeah or or the converse so at what what when you're looking at like the trace of your simulation at each time point you have the belief distribution over possible notes so again even though it's only like one latent State Dimension it's a distribution it's a categorical distribution over four options and so this is kind of like plotting the again we we could replic and color these lines to trace them more clearly but like we can see that in this S3 moment here's where it's sort of most mixish like there's just a little bit of weird stuff happening but to investigate it more we we'd want to um run it but this is like this and that's why it's built up this way because again chapter six is kind of the recipe okay so just just to be clear so on the on the plot so like let's take one of these lines for example say that the Top Line um yeah that one right there that is a curve so this is going to correspond to the probability the posterior probability that it's I don't know note one and then there's a corresponding line at the bottom where that where those where they bifurcate right is that the so like uh at the split around like. three do you see that on the I am really not sure because there's there's a flatline at zero and one which might just be like graphical yeah I think it's yeah then there's one two three four five six seven eight notes yeah well there's but there's four notes right right so what I'm not sure what the eight lines are so I is it like is it like one of the the lines corresponds to the posterior probability that it's not the note that we're talking about you know I I'm not sure what it's what it's meant to be showing I agree and I'm not sure if if there's eight notes like in the scale and they're like tending to zero here which is why at the end but then why why would you have high posterior probability belief in multiple notes at the end right I mean I mean it it looks like they're meant to be suming to one so I think it it would have to be like like one like two of the like the lines come in pairs basically I think because otherwise it's not summing to one right cars like a upper and a lower and maybe they but they don't sum to one uh they don't sum to one if you look at the third column they definitely don't sum to one but then it's not a probability distribution what what what they look like uh they look like error bounds like from below and from above like how confident are you that you hear what you that you hear what you're hearing right and and somehow like with the third one the upper confidence just drops like uh I don't think you know we're not sure we can't be sure because there's a goof here so yeah it again we should investigate it more I agree that this is not super clear also it could be if it's a posterior probabilities about each note then it could be tra there could be eight notes possible yeah but then it's like um you know yeah yeah like at this moment it's like there's an 80% chance it's Note One 70% right but then so that doesn't sum to one because that's I was thinking yeah that's why I was thinking like if you take that that 80% example there might be a corresponding line down below that's around like the 20% that's supposed to be like the like the not that note line you know so it would some to one but is that not what it is yeah I I I agree and also so just again the fact that it's continuous yeah and it has like different Dynamics it's just it's part of the trace of mat lob okay in the discreet setting this doesn't really come into play but it's yeah I I agree like it's not very clear okay so I'm not alone in that that's good to know yeah and and especially just because this kind of gradient method The Continuous um gradient subtime step scale gradients which can happen but that's not the calculations that are needed for discrete calculation which is just a basian belief updating which is just done in one shot in this case um but yeah like this chapter the first two examples are kind of like two of the core Tools in thinking about perception and action models it's they're really really critical just to structurally understand that there's observations that are emitted from a latent State there could be seven dimensions of s projecting onto one o or it could be the other way around any configuration and there's some intermediator a that is able to take a latent State distribution and project it onto an observation distribution and vice versa so that's the sort of bacing nature of a that it can be used in its generative capacity or in it recognition capacity you need a Laten State prior to kick this whole thing off um and it's usually shown with three but really it's just two it's really just you kick it off and then you're only looking at one transition step and then where you transition to becomes the the prior Distribution on the next moment so even though there is a a trace of observations we don't model observations as causing successive sequential observations we model changes happening in an unfolding Laten space that emit observations and then action enters the picture in choosing the transition operations in the latent State like those are sort of key pieces that are at a very high structural level important for this type of modeling Anders and those latent spaces are kind of States I mean are generally kind of imaginary like it's right I mean like that's partly it's it's usually not necessarily like exactly real but it's more like that's what's that's what's either modeled um by the modeler or modeled by the organism but yes is that Bally a good way to look at it like they're not they're not intended necessarily to be real let's say it's a temperature situation the agent's model is like the the true underlying temperature but it's the agent model of the true temperature and the observations they're getting so it's not the generative process how it's described in the book of like the quote real temperature in the simulation mhm so yes this is like these are all variables with in the agent's cognitive model and then there's another which is also our model because we're modeling the agent it's like a okay we're both modeling together as friends yes and that's that is brought up in chapter nine that's the metab basian perspective which is we are outside of the agents generative model proposing that as a map of a cognitive territory which is itself mapping a reference outside of itself um but there's another degree of mod freedom in like saying well like um there could be aspects of the environment of the agent that the agent doesn't even know about so that that and I think I think that that's a key thing for discret language like how why discret langu anguage works at all it's because different people modeling you know basically a similar situation are going to come up with similar answers even though they're you know even though those latent states are all not real but but they're real in the sense that you're going to get similar answers and so um and so and they're going to get discreet answers so you found the similar critical points you know you found so I think that's that's the Wonder of a discret communication yes that tension with continuous discreet comes up in in so many guises both in the treatment of time and in the treatment of the state spaces themselves so here we have in chapter 7 basically a focus though with some some spice added discrete State space discreet time so again confused by these Trac is there's not necessarily differentiability there's just snapshot based discre updating in the continuous State space um how but the advantage of the the discretization is first off it's very easy to understand the computational resourcing and when it comes to action selection it's easy to roll out counterfactuals like chess Trac search chapter 8 brings in the continuous time and continuous State space mathematics but yeah where we can go to another section or we can look at um the specification in PDP um or I wanted to ask is there an open source like a version of mat lab like o octave will that open work these files or not there's a standalone download of SPM that runs without a mat lab license there is octave which is like a patched open source mat lab I've never run SPM in octave so that's why in the sort of post 2018 is period there was movement just away from at laab but it still is used by many people who and many models that are in there but um you know of course any language can can emulate any language but using Python and Julia and a lot of other uh language it's taking us closer more to the the data science pipelines that are and the other packages that are relevant so I would say the best place to look for this is in the pmdp documentation like that's why it's called Pi mdp pmdp is not trying to be a generic model of all base graphs kind of in this in the spirit of RX and fur the agents is literally defined almost exactly according to the textbook the same tas's situation but this is exactly how it's laid out with agents and the ABCDE okay nice it just goes through them just there you know categorical Distribution on a b Matrix that's how you encode the movement preference prior on hidden States d and here ABC D are specified and then when you all there is to run and and pdps have been around for decades they're not always fit using a variational or an expected free energy but this is basically what the loop is you get the observation from in in this case from the location in the grid World belief updating on the latent State what is my true location a curse so that's inference of the latent States given the observation index and the a matrix and your prior Distribution on latent States so that's belief updating that's the sense making that's the perception that's the inbound that's the music listening then there's going to be action selection first expected free energy is calculated for each possible action so that's for the given time Horizon it's going to ask if I were to do that sequence of events whether it's just one action like one time step planning or whether it's multiple time steps of planning in the discreet case each of those chains of actions will be unrolled in terms of their expected effects on latent States via the B Matrix and then those get unfolded into the expected observation distributions those expected observation distributions are evaluated in terms of their epistemic and pragmatic value pragmatic value how well would those observations align with my preferences epistemic value what would be the expected Information Gain from those observations those scores constitute the G Vector which lines up with your policy options those scores in G which don't have like an intrinsic meaning are used to reweight the policy prior into the policy posterior so policy prior is what you're believing that you're apt to do before the observation gets re ated according to expected free energy values relatively and renormalized with a softmax so that it stays as a probability distribution over actions one action is chosen from the policy posterior distribution that is going to be the selected action and then at the end of this cycle the um it's it kind of click ahead to the next Laten State belief and then that will be used here in the next cycle as beliefs about States so that's one procedural way to have the sort of imperative style for describing a perception action Loop but there's other orderings that could be possible like you could you could do different orderings I'll just say that so that's why there's a lot of degrees of model or freedom because this is not it's not like this is the only way to model the handling and that's even within this simple single observation single action setting but that's how it works in pmdp which is basically what is described in the textbook nice that's super helpful um what did you mean by other orderings orderings of of what um like there's um this is kind of a classic like observation comes in update beliefs choose an action based upon the updated beliefs but for example you could have a a a Time step situation where it's like at the beginning of each time step the agent chooses an action based upon what it believes and then gets an observation and uses that in the next time step to I see so that would be you know and then especially if you're dealing with in this example there's basically only two operations happening the state inference and the policy inference so those are kind of the two main categories of orderings right which one do you update first and it totally makes sense to update the observation first um as you get more kinds of variables in play and more cognitive mechanisms there become more ways to imperatively specify The Ordering of the loop right like if there was a read and write to memory if there was an attention element if there was a policy search all these different features and then what's what's really interesting and what kind of returns the focus to to the high road and the low road is like the free energy principle is describing the physics of flows across these graphs not in discrete time but it can be discretized but as this sort of unfolding simultaneous flow in terms of belief updating on this graph so and and the way RX INF fur kind of aims to handle that is with with reactive message passing sort of on demand just in time node updating but even then that's not happening continuously it could be happening rapidly or infrequently but it it is happening in especially on digital computers at some point everything is going to be discretized in a way um so figuring out what the duty cycle is for the agent and that's where you get like the tote like this is sort of an older like test operate test exit this is one like you know whatever it sort of seems like esoteric or strange to be talking about the ordering of perception action it's like there's tote and then of course there's the UDA Loop which is another discretized way and and that has been connected with active inference as well so just when you get down to building on the low road which is what chapter seven and eight and everything the whole second half of the book is about you get down to like these details about which variable are exactly undergoing which operations and which orderings but that's not something that the framework is opinionated on but it is something that's required to have operating code yeah if so um I remember that like one of the central not well to me anyway at the time that I read it it seemed like a central tenant uh was that what active inference sort of does was is is that it um sort of like flips the way that an agent uh perceives the world in that instead of waiting for the observation to come in and then making a prediction about what they're seeing they make a prediction first about what they're they think they're going to see right and then they take the observation and it's the prediction error that like kind of Cascades through the system right so is is is that like a different order that that you're talking about or is that uh kind of set in the way that it works does that question make sense yeah yeah totally so like um there's a few ways to go about this if you have a sequence of alternating you know belief updating and then action updating you know Laten belief updating action State updating at some point which one happened first right just alternating and so it it it doesn't really matter but then when you think about the injection of an observation that's kind of what we were just exploring like observation belief action observation belief action was how the PDP had it as opposed to Observation action you know so once you get to to three or more you do get different sequential possible orderings as well as at the level of the simulation where okay now we have the like for example if we look at the open AI gym environment so this is a discret environment where every time step um whatever it's called now but every time step like there's getting gets an action sends back so that's a kind of call and response style but when it's one agent in one one environment you could do that or you could have it send two and then one back or something like that but um then you kind of point to like this idea that that the agent is is like action as fulfilled prediction planning proceeds by inferring an action what the agent feels in Char nothing but like can't understand you your audio is cutting out a little bit the the uh the organism is in charge by making predictions all the time like even if it knows nothing then it predicts that it knows nothing but typically it knows a lot about its environment and it's uh you know that that that knowledge is stable and just it's reporting minor changes to that you know within that environment yes like yes there's the sort of like inner agency of like it's not just taking punches from the environment even just when it comes to sense Mak so just thinking about the first 7.1 example each observation is meeting what can be thought of as like an active prediction but it's the prior the prior is being brought to the table and meeting the observation and that is the basan updating moment so there's that element which is it's not just processing inbound information but there's this sort of active listening approach and then that goes further when we actually consider over action especially action in terms of what is expected to be perceived and then the agent is unsurprised when the consequences of action are what it expects to be surprise enters when the consequences of action are not what was expected so that kind of centers action in setting what is the envelope of observations that would or wouldn't be surprising but it because it's so General we describe rocks and you know other kinds of you know abstract um boundaries it's hard to personify it or apply too much of a psychological lens to the generic case but in cases that are able to have that kind of psychological projection that's exactly that's how we compose expressions in the active inference ontology to make structured models for those phenomena and and one difference uh that comes up like in that so like in cognition I think that's very much the case where like you're always predicting uh your so you can always be surprised and you can always deal with that surprise but in the case of emotion uh you have expectations and so if those aren't met you may feel surprised or or if they're met excited or sad or happy but in the case of I would say like fright or disgust you refuse to make expectations you know there's certain things that happen that you refuse to expect and so then somehow you're dealing with a different situation it's a different game that's interesting what do you mean um you you refuse to make an expectation in cases where what where like well so this is a this is a simple this is a simple model of emotion but if I'm have a theory you know and it's confirmed uh I'm excited you know if it's about the real world if it's not confirmed I'm surprised oh what happened um but and if things matter to me then it's not just uh excited surprised or I'll be happy or I'll be sad you know I may be devastated but if something happened on the outside and I didn't expect it because it was too fast or too weird or just too some kind of I just didn't want them have that expectation those are the things that are frightening you see so those are or vice versa if it's on the inside and I just refuse to make certain expectations or they're just too sudden or they're too weird uh those are the things that are disgusting so that's an emotional model but but it's it says that in the emotional World it works a bit different than in the cognitive world yeah the some of the citations and work on emotions and and exactly that like when the rate or type of change of a primary model um that is where certain emotional phenomena could be modeled and and but again how you actually what phenomena you choose like for if we were doing a body temperature example it's like maybe if the first derivative of surprise through time or like the time rolling average of surprise is low even if our body temperature is going up and down our anxiety level is low but then if there's rapid changes there's a second level model or a model that's taking in as observation the first or the second derivative of the changes in Surprise and body temperature that that could be associated with an anxious response and maybe just say like active inference is active by Nature uh so in these situations you may refuse to have a generative model you know of certain kinds because that's not the generative model you want to live by you know or so then when things go outside that you just resolve to passive inference you just throw up you just throw up or you just uh you just lay down and die or just you know you go into some kind of reflex modes where there is no generative model you're just acting you know passively passive inference I don't know if there's no generative model in that situation yeah a person looking at that a person looking at that in in an observation setting it's not like just cuz a you know squirrel has a flight or fight it doesn't cease to have a generative model right um that well that's I no I guess so the the thesis would be that in certain situations you don't need a generative model you just need to act and you just act as your program you don't need to learn you're just going to you know you're just going to but I think that is model right it's just that you have maybe different like a like a like a refined or um confined set of actions that you could take as a result of whatever you're perceiving right yeah no like for example like death like I don't have a model of my death I don't think about it it's not healthy to think about death you know so typically like you would not want to model certain things like that at all you just don't touch them then just model though you do have a I don't know like a state that is a reaction to death or thinking about death or or in fact in your case the state would be not thinking about death right exactly so if I'm that's still part of your generative model I think well what I'm trying to say is that there's something more to life than just to generative model right there's the territory I mean this is just there's the territory this is the accounting ethology behavioral scientific approach to modeling cognitive systems but it's like yes there's an infinite number of points that are sort of correlat like that maps are not territories restated in any number of important ways like the structure of the observations coming in from the thermometer does not have to be anything having to do with what the cognitive model of the agent as set up by a given individual is MHM and and that's sort of The Refuge of the instrument anals because it's like here's our proposal for how to reduce our uncertainty about this do you have another tool what what other tools are in trade-offs with this one whereas the realist is actually looking to to wrestle on that more ontological reality mapped dimension about things as they are rather than more of the statistical [Music] um approach to modeling perception and behavior as perceived which is why but that's part of this fascinating view from the inside view from the outside dialectic mhm because people will bring up first person phenomenological experiences and there's so much work on neurophenomenology and cognitive modeling From firstperson perspective whereas in Behavioral Science and entomology and things like that it isn't it's not waiting for some kind of first-person report and and and I think there's a dialogue between the continual continuous mind and the discreet mind like there's a cedal continuous mind that just does its thing reflexively but it you know it looks they're they're helping each other and so there's this discret mind that's managing this generative model and you know basically is able to and somehow they're able to do but sometimes the discret mind just lets go and it just goes into continuous mode wherever things tumble well that's sort of what is laid out here but this whole thing is a generative model so it's it's not like there's any utility as far as I'm seeing it just to disre the whole thing is the generative model and now whether it's done in a more habitual fashion or it engages in a discretized tree based policy roll out or some other proposal for like recurrent switching between different modes however it's accounted for that accounting is the generative model but it can engage in completely you could say well I have a generative model where at the top level there's a switch and it's you know it's Counting Apples and then it switches to counting oranges I guess I guess the presumption that I'm making is I'm drawing the line not between an organism and its environment but between the organs organism's internal mind and then its whatever mind it has that represents that environment like the unconscious so in a human being like it be the conscious and the conscious there's a gap that's what's being modeled with all of this framework um so the unconscious is really just part of the world so to speak and you're trying to talk to your unconscious you know manage your you know relate to your unconscious perceive it and and and act on it yeah like the B matrices in the te's example in chapter 7 it's like these are the mouse's beliefs about location mhm can intention upon it doing what and then that in this case gets just sort of faithfully enacted by the environments but that part is not emphasized here but then there's there's situations like the windy grid World which is a classic um grid World kind of variance where you have um that kind of up down left right movement and then there's wind that blows it like zero or one or two cells so in that situation or icy grid world where it slides occasionally so but but the agent's model might not it might be like whoa now I'm over here so it doesn't even know about wind or ice it's just like oh but I want to be expect to be here I expect to get information if I go here but yes so that's something in the Triangle I talked about the triangle uh language geometry language I'm doing and then I realized a good way to do it um that's in this spirit is that the the participant the agent or the triangle Creator the S the one who's looking for these triangle centers they only understand triangles in terms of integer lengths you know so it's basically like rational numbers so they don't have a concept of the real number so they're trying to find a center which may not exist as a rational number and so that's the kind of like it's already in a paradoxical situation where it's trying to do something basically impossible so it'll it'll do it as good as it can and then it'll move on to another task let's say so that's a nice so it's nice that it can enter into the model that way naturally oh yeah like let's just say there was a super sharp preference for to land on the number 10 um and but you had the policy you could only move up or down by 50 to 80 so you were just sort of like overshooting and then undershooting overshooting and undershooting um and then you could have another level of the generative model that was about task switching and there's different ways to do task switching or like going back to the the um the playing dead example like you can either have um stay as one of the actions in a one layer model up down left right stay or you could have a two-level model where the top one is a binary decision to move or stay and then within move there's four actions like those are all different maps and again which map you make of the city depends on what you want to do with it who's funding you all these different kinds of questions what cognitive model you make is contingent upon what you want to account for what you what you um do and don't want to be surprised by and especially when it comes to these cognitive functions and modeling them like where these models sit from mainly taking in data even though the in in theory these are totally just two two directions in the same window especially when we get to chapter 9 with the empirical data analysis but sometimes the model is set up to be taking in data and the modeler is interested in the parametric estimates at the end so to use use this framework to model it's a human experience um whatever I would find interesting I think it seems like the crucial thing is to discover well what is the prediction you know and what is the error like if because is that how I have to think in terms of in order to this active inference framework or are there other Concepts I have to worry about you don't have to worry about anything I want to worry about something um I I think it's relevant to look at if we're thinking in discreet time but figure 4.3 shows the the the isomorphic nature of the continuous and the discreet time generative model kind of Meta Family units again these can be nested composed concatenated all those kinds of category theoretic operations are possible but this is the motif which is like what is the unfolding State space what observables are sloughed off of that unfolding State space and then what are the interventions in that unfolding State space so there's there's sort of simplification cases where it's like there's only one action so just it unfolds according to just a Markov chain without policy it's just a Markov process and then you go okay well what if there were um multi-way options like in in the sort of wool from Computing ontology in the multi-way compute where there's like different bifurcating possibilities from a given position then it's a Markov decision process and then if the observable is the chain unfolding itself you don't need a partial observability elements but then if you want to model sensory ambiguity or some kind of degenerate or or nonlinear or um ambiguous mapping between the true unfolding Dynamics and observables to a given measurement maker then you need something like an a matrix so if I could just interject there for a moment there's not much time left and I have to go at 9 speaking of the a matrix can we go to figure 7.4 or yeah yeah these matrices and just um they're not too complicated but maybe we can just like kind of go through each one and just be clear what they are and so um the caption anyway says I think there's a type on the caption right it says um it says so each element of these matrices is the probability of the outcome Illustrated at the end of the row conditioned on the context being one and being the location indicated by the row so there the context being one here is it would have been clear if it was written as a one but there's two contexts this is context one with the food on the right this is context two with the food on the left so here flipping back and forth yep we see basically we see these two are flipping and this 298 is flipping so basically there's two a matrices in this example there's what context what context is one in that's A2 and then there's what location am I in that's A1 okay see that's confusing I thought I thought the context meant uh what the rat saw the Q to be yes a to be it's not the context is where this thing actually is there's kind of two there's two scenarios two actual scenarios right when the context is unknown that's this one okay so okay so let's let's read off one of these columns just see if we can understand it so like in in cell one and A2 this is the probability that the rat is going to be in so I think it's a typo so it should be that the rat is going to be in the state indicated by the column right given the the that there's no context or that that what if I'm in the start location okay I am sure that I don't know the context don't know the context okay if you're in the bottom location I'm GNA I'm GNA find out what the context is so then then you do know the context then yeah that gets injected in when it does go there when it discovers art so then when it goes when it goes to the bottom that this is where A1 comes into play okay when I get to the bottom in context one this is the difference between these two y then I find out that the Q is R okay so it's the probability that you find out that the that the Q is R when you're when you so hold on sorry this is the observation and each observation we're getting two features from the environment this is the no food MH sorry if I if I said this was the no context earlier this is neither food nor not food okay this is yes for food this is no for food so starting position I'm sure I'm in the starting position and there's no food bottom I'm sure I I'm sure that the L that is telling me the Q is r and there's no food okay so let's go to row two that's where something interesting is happening this one yeah yeah um if I'm on the left my my belief is that if I go left that there will be a 2% chance of finding food and a 98% chance of no food if I go right vice versa right but it's all given that the Q is on the right that that the que points to the right yes so so does the rat know that the Q points right yes so in this casee it would have had to it have learned that that R means this and L means this okay so we assume so I think that's what I was missing so it's already been trained it's already been trained on the que okay see I didn't okay I thought I had to like go down first get the que and then make a decision there's no learning in this model okay so it just so we assume that the rat has seen or knows or learned the queue exactly and this is the whole you know Journey are we studying the learning acquisition of the queue or are we just looking at forward inference on a behavioral trial given learning given the learning okay thank you cool okay um thanks all again like there was Daylight Savings in some places but the place of reference look at the UTC time in theod to look at the calendar events the UTC time is not changing the calendar events don't change so that's where you'll see everything so good thank you Daniel bye