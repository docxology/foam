hello it is January 25th 2023 and we are in covert 2 of the par at all textbook Rune meeting 13. today we are going to jump back in start our seconds interval of activities there are a few ways we can go we can just review structural aspects of Dakota and accommodate anyone's like suggestions or notes on some things that could be interesting to develop with in this one or an aside little sandbox then we will look to the textbook itself and we will look at where the first five chapters got us and where we're going with the second half of the book which has a different Form and Function then the first half of the book so first off anyone want to just adony General comment how now that it's 2023 where are they in their Active Learning and application Journey how is our Niche similar or different than it was in September through November when we worked through the first five chapters any thoughts or or we can continue on just want to leave that space okay feel free to raise your hand or just unmute or put in the chat or anything like that um broadly the layout is the similar textbook group overview has information on our live meetings and um that's where you can download the textbook the textbook section itself contains different types of things that are in the textbook such as the equations which have all been brought out with images and page at least but there's a lot of improvements that we could make to the descriptions and the tagging similarly with figures we have all figures brought out but there's a lot of contributions that can be made to um descriptions and tagging boxes and tables similar code implementations we um I'll add a link to block prints so if anybody um which is what we've one thing that we've worked on last few months we have about uh 40 or 50 implementations of active in Python C plus plus Julia Matlab so um accessible from here um and we can for those who want to start um getting more into the code and I'll just show one more piece that we worked on earlier today in the block fronts meeting in model stream 7.2 um a notebook was used in epistemic contextual multi-armed Bandit simulation was provided by Connor Heights um just works perfectly no no tweaking is needed uses octave Loop defines Etc and what we did today was we took the active ontology and we then said how is this set up in the contextual Bandit how do they set up B okay here are here's how B is set up one can click this and then in a plain text paste in the whole script so this is not the only way that we're going to be working towards modeling but as the second half of the textbook is about building a generative model in the process the recipe we have like multiple functions in this cohort too as we go through chapter six or ten one function will be to to the extent that we want to develop our own generative model and simulation just didactically just to have something that we increment along to help us understand or if there's some outcome that people want to pursue research or application oriented like second half of the textbook is um the time to do it and even relative to last September we have significantly better tools so there's totally an approach to go from a natural language understanding of these ontology terms two how to do it in pi mdp and it's pretty reasonable that somebody who wants to pursue this direction we could just add another column copy it over make the tweak and there's a few other pieces but a lot of that is going to come up in chapter six um in chapter notes and questions we have the chapters themselves and a detailed table of contents and then each chapter has subset view of the questions so if you have a question within a given chapter or you want to help improve and curate the discourse please just like add a row in the questions section or just make improvements to the answers and discourse um so we'll um continue to work with questions as well as whatever notes people add uh to just whatever anything else they want to highlight um into the more discourse sections here's the home of the questions table but it's shown in the chapters as well um ideas and insights people are always welcome to add just sort of nuggets or summaries for what they're updating their models with what they're coming away from from these sections math learning group has no current um live activities but there's a huge amount of uh resources and and some summaries that are written but there's always many things for people to do with testing out math learning um project ideas we can return to but that's kind of where we left off with in the last meeting of the first half um future textbook groups we organized that at the end of last interval but as always if people are having like thoughts or they want to give comments or have ideas for just it can provide the feedback here directly or um other notes and Errata which have been shared with the authors I'll also note that um on J February 27th Thomas Parr is going to join for a live stream so if anyone is um oh let me just check the UTC time right now but if anybody wants to it'll be 17 UTC 17 UTC on February 27th so it'll be in Zoom just like this um and we have one month before then to prepare some questions that we want to highlight and ask so um those are just some overview Coda elements and some updates that have happened in the broader modeling space over the last few weeks and months any just general or comments on that is a um over a paper or is it going to be over the textbook or is he just joining to the question or what is the subject matter it's this textbook also your audio is very off but yes this textbook okay any other daughter questions or we'll turn to look at the book okay well anyone who has been in cohort one or otherwise how would they characterize chapters one through five as opposed to Chapters six through ten is any better no not at all okay then I won't okay just you can type it or just add it in the coda um Ali go for it as anyone else I think uh chapter one through five was um basically for a building the the requisite fundamentals for uh designing and maybe uh applying those Concepts in a much more a practical way to some real world situations that we deal we'll deal with in the second part of the book second half of the book uh but uh in my opinion uh even more than this dichotomy between the fundamentals or application oriented approaches between the second between the two halves of the book uh the very structure of those chapters I mean the pedagogical structures of those chapters are very different because uh as much as in the first chapter we're dealing with some general propositions and some general structures and Frameworks in order to frame the theory in a comprehensive and a kind of uh layered structure in the second half of the book we're much more in a case of study based approach and we're dealing with uh some uh solved examples so to speak and in some other cases even some open questions that we can uh we can try our hands on later after well learning the basic fundamental approach to solving these kind of problems in active inference framework but in my opinion those these two halves of the book are can can even be uh seen as two separate books uh because of their uh fundamental differences in in every aspect very interesting thank you anyone else just what are your thoughts how have chapters one through five sat with you now that you've read it and digested it and then if you have looked at six through ten how would you contrast it with chapters one through five and then we'll look more in fine grain I would say one two five was like the blanket and six through ten is like the hidden States ah a awesome keep the keep the octane fontology 100 percent a great metaphor yep observations one through five observations six or ten hidden State inference Neil yeah so the first half I I didn't get as much out of it as I would like to have it's it's still very mathematical um but that maths didn't really lead to insights um I've I've gone ahead and had a look through chapters seven uh and eight and they look uh well a lot more like their applications that I I get I seem to be getting more from that than so that's that's looking good thank you yes some sometimes it helps to do the the applications before the theory um to give you some sort of Direction yes anyone else want to add a comment or all add a general comment on the chapters and then we'll go to the subsections and so on uh Ali I also agree with Neil that maybe some of uh the contents of the second half of the book uh might work better if they were interspersed with the material from the first chapter uh to uh have a much more goal-oriented vision in mind or and to not lose the big picture uh for the coming chapters yeah we have with a lot to infer and do with the pedagogical ordering and respecting all different learning preferences and paths um we're going to be heading into chapter six in the coming um two weeks in our cohort and here's from the summary of chapter six um in this chapter they're outlining design choices and they provide a four-step recipe which we're going to spend a lot of time working on because like that is our you know we're all Sous chefs in the kitchen this is our recipe structure that every single time a sous chef gives their input on how to improve it or how to make something that's a little bit tacit or implicit into a checklist or a template or an automation every time a sous chef sees that opportunity the recipe gets better um this sets up the remainder of the book which is again what we're going to be working through in the next three months putting these ideas into practice through illustrative examples which ali um referred to as like solved examples and basically they are they might be trivially solved but whereas what we saw in terms of solved examples in chapters one through five was like the frog jumping out of the hand which is kind of a solved example of Bayesian inference now we're going to see some solved examples of the type the active inference models are like with a partially observable Markov decision process in the second half of the book is designed to showcase the theoretical principles presented in the first half of the book so let's look back to the first chapters and then see how that is going to be showcased chapter one is like an introduction and on the other side of the bookshelf chapter 10 is going to be like a summary recap so that's kind of like the opening and the closing bookmarks um chapter 2 and 3 cover the low road and the high road to active inference we're not going to uh or don't need to go into it in a lot of detail right now but those are the two paths that are laid out to get two active inference and chapter four puts us squarely in active inference with a focus on what is at the heart of active inference modeling which are generative models chapter 5 then focuses on one of the areas where active inference models have been most applied and applicable which is in neurobiology and so chapter five looks at several neurobiological systems in detail and how active inference is applied and then has some tables that show more broadly where those models have been applied so introduction on what the book is about and its overall Framing and structure the two roads to active inference from the mechanistic and the Bayesian in the low road and from the imperative for survival and the free energy principle on the high road chapter 4 describing the structure of the essence of what this kind of modeling entails at least in the style as the authors are laying it out and then immediately jumping into examples and somewhat of a literature review overview on some of the systems where it's been most applied that are the theoretical principles presented in the first half of the book low road High Road what the model is itself and how we see it applied in neurobiology in the second half of the book chapter six is going to start us off with a recipe and um this question what are the four steps previously we had a lot of good discussion on these and a few other questions so improving the discourse as always adding questions is super helpful just checking people's understanding checking your own understanding everyone adding one question per week would result in a quantity and quality of questions that would be transformative truly one question per week even if it seems trivial or it's a speculative question so questions are huge and in chapter six we're focusing on this four-step recipe it's about how to design active inference models and we'll have a lot of space and time to connect it to The Cutting Edge work in pi mdp and approaches that we're using with the active inference ontology so that we can have a pathway from a natural language understanding of a given system of Interest on through the kind of state space representations that are required for pi mdp so that's what chapter 6 is about the recipe and the structure as the authors are laying it out and also keeping in mind um not sure exactly which um moment this was said but the audience for this textbook I believe Carl said the audience is something like a master's students in computational Psychiatry looking to apply this to their own research so that is like squarely what this chapter is oriented to after um again all he said like chapters one through five were about building those requisite fundamentals all right then chapter seven and eight kind of like the cousins of two and three are gonna present uh duality or some other kind of minimum two system chapter seven is gonna look at acronym in discrete time d a i discrete active inference which is often affiliated with decision making cognition and then chapter 8 is going to present active inference in continuous time also sometimes called m a i or motor active inference because it can be and has been used to describe continuous motor reflex and actuation processes like joints and movements so there's many flavors and variants of active inference every time we see like an adjective active inference deep affective sophisticated branching time all of these flavors and adjectives there's a whole growing Zoo Wildlife Preserve but one of the most important and also didactic differences amongst active inference models are their treatment of time along the lines of many other simulation approaches the difference between discrete time and continuous time where the discrete time is more like taking a sum over finite sets and the continuous time is a lot more like doing calculus in chapter 9 knowing what we now know about how active models can be cooked up and about two major classes of generative models discrete and continuous time we'll look at model based data analysis so um I'll just show one figure to um highlight here's figure 7.1 so we have a prior hidden States s b is how the hidden States change their time a is the mapping between hidden States and observations this relationship between the hidden States and observations is sometimes called the tale of two densities um just Loosely slash poetically because this a matrix can be used to take a hidden state and generate data What observations would we expect given the hidden State and a or you can take observations and through a do inference on hidden States that is using a generative model in its generative capacity which is from the hidden states to generate observations or in its recognition density from empirical data back to Hidden State inference of unobservables so in chapter 9 um that type of data based uh modeling is described whereas in the previous examples uh things were more oriented towards like just what is the structure of the generative model chapter 9 is going to bring us to confront this question of with empirical data how can we then do state inference which is a task that starts to look a lot more like what day-to-day research and Analysis looks like and then quickly as we begun chapter 10. is an overview summarizes the structure of the book again gives a quick recap of each section and provide some closing articulations and next steps so again they've laid out the book broadly into sections the first half gets as quickly as one can two the heart of active inference modeling the generative model then reminds us of some of the central applications over the previous years in neurobiology also using that as an opportunity to discuss message passing which doesn't centrally feature but is something that one can imagine will be developed more then chapter six or ten what we're going to be focusing on in this second interval of activity for cohort 2 we're going to start with a math free chapter where we um are just looking at this recipe that they're going to lay out which it's going to be just super exciting discussions and there's a lot that [Music] um everyone will be able to contribute on this because we'll be able to come to a lot of intersubjective clarity about how they are laying out the modeling approach in active inference again according to par Zulu and friston and also use that as a starting point for specifying what they've proposed asking questions that aren't addressed in these short texts and then connecting to our experience with modeling whether we've used programming languages or data analysis or indifference disciplines and settings all right so I was just giving a little overview on the chapters and the sections anyone have any comments you'd like to add on structure or chapters M Carl yeah um I have a question I'm not so sure whether this uh is a little bit off but if you're so bad show this this model this hidden Markov model that you just showed with the hidden States and and the observations I am wondering so so I I would like maybe I can just say this briefly you already read to what my research is about uh Daniel I think you know so so I have a no I can't I may have but please feel free just for everyone's context whatever you like to add go for it okay so so I have a huge amount of data and I'm wondering whether this um so behavioral data actually and I was wondering whether this could be the right approach to model this and my question here is so the Matrix is a and b are I guess independent and so if there is a decision on this hidden States as s and the emission of the observation through an a matrix this is um somehow independent from the successive State observation right so I or is it or is there a possibility to to tell the system that the success so that the emission of one observation from a state depends a little bit or the successive State depends on what the previous state has emitted what observation was produced I understand my question so it looks like uh the the transitions are independent from the emissions and I'm not so sure uh what this actually implies in the modeling of my data um does that question make sense awesome thank you so there's a few pieces anyone want to give a first thought and then this is like again it's an example of what we can add as a question you don't have to go and tag everything with the active fontology if you want but certainly one could because you use a lot of active ontology terms but regardless of how fully formed or appropriate one thinks like adding the question to these tables is one of the most helpful ways that those insights that we do want to share in this space can have like extremely highly leveraged impact even without large language models being trained on these documents which will surely happen these are important questions so I'm just going to try to take notes as people discuss this on this questions and topics page so Giuseppe and anyone else so if I can answer my own question or a thought at least so one could add at the output a kind of a language model um or maybe and I don't know are there are there such tweaks that are um possible in this whole model so if we if we say that the one observation does not only depend on the state which has emitted it but also on the previous observation how can we model I mean one way to model this would be to have a language model that runs over the over maybe um um alternative possible observations and then decide which chain of sequence of observations one has the highest likelihood this is or how could some something like this be modeled is this uh is this taken account to uh in some ways yeah great questions Giuseppe then Neil than anyone else I don't hear you Giuseppe um yes I do okay uh so I was thinking although the the transition in my understanding the transition matrices are pre-specified then at the at the moment of learning in a sense the the matrices are updated so to reflect the observations so but but they're not immediately I guess and they're not immediately updated on the basis of the last observation is that is that correct yeah I'll just briefly directly respond in the simplest possible framing of this partially observable Markov decision process there's no learning or parameter updating at all A and B are fixed however we're in the Bayesian statistics World we're in the Bayes area so everything can be learnable for example in this Pi mdp script first there was an active inference Loop specified and then the kind of cousin function was specified where the B Matrix was learnable so one can have every variable here fixed or learnable it just depends how you actually do the modeling and that's again what chapter 6 is going to confront us with one can imagine that if you have a fixed a matrix all you have to do is specify the a matrix if you want to have learning the state space and the dimensionality of your model has vastly increased so that may be worth it in certain situations but now you're dealing with Decay rates and learning constants and critical forgetting and just there's all these features that you're just not dealing with with the more reduced fixed model so all the parameters can be fixed or not okay and then was there a second aspect or on to Neil yeah thank you [Music] okay my so I'm not really I don't really understand this but my feeling is if if a and b are interdependent does that mean that it's not a matter of decision process uh and if you've got a system where it's where the current state is not just dependent on the previous state but on on the States before that then that's that's not a a mark of process awesome yes that was the the Direction I was going to add so from a pure empirical perspective the observations may have a strong correlation so if you did a descriptive statistical approach like arima or just time series modeling you'd find that like there was a statistical correlation amongst similar observations again we're just thinking of some you know temperature in a room hidden State thermometer readings and the observations there's some like time autocorrelation what the markovian property is even the last names aren't informative this is just what is called a markovian property is that the presence is a Markov blanket between the past and the future in other words this is a map this isn't the territory this is a map that helps us reduce the dimensionality of all possible models by considering those that have this one very important simplifying feature which is that the past only influences the future through the present so yes observations might be the same across different time points or they might be correlated from a Time series perspective but architecturally from the Bayesian graph model that we're going to use the way that we're going to model those observations through a Time is by having the observations emitted or received Tale of Two densities by a hidden state which undergoes time evolution so there's no direct Edge between the observation at T minus 1 and the observation at T the a matrix could be the same if it's a fixed a or the a matrix may have even changed if it's learnable a but the key feature that makes this partially observable is the fact that some parts of the model are observable like data observations and some parts are not observable hidden States so that's the partially observable po part and then what makes it a Markov process is this present acting as the blanket between the past and the future and then what makes it a decision process is that we're inter this is just a partially observable Markov process in figure 7.1 partially observable hidden State observations markovian property current moments interleaving between the past and the future what makes it a Markov decision process is that it has the markovian property and we are embedding action into the Markov process how by having evaluation of alternative policies and how they intervene at the B Matrix so that's why this is a partially observable Markov decision process it has all of those attributes and there's justifications for why we want it to be partially observable why we want it to be markovian and why we want it to be a decision process and if somebody has some other modeling scenario in mind then some of those adjectives might have to change or you might add adjectives um Ali and then anyone else uh yes adding to which what you just explained even when uh defining the B Matrix uh we just add the indices based on the state factors that are controllable that are controllable or um because in that case uh with each action the B Matrix would be different so this means that we would need an index specifying which action is actually taken but for other contextual states which are not in the under the control of the agent we don't need any additional a transition probabilities for each action so yeah even in defining the structure of the B Matrix we distinguish between the states that are controllable and the contextual states that are out of the control of the agents awesome thank you yeah and and as we go through chapter six in the coming two weeks which is a qualitative chapter and then also look towards exactly how these are set up in pi mdp like this is a movement up down left right or this is just a Left Right movement or stay these affordances and transition probabilities and everything like that they get encoded in matrices and these operations are like linear algebra like arrays or tensors or matrices kind of being collided with each other the circles and the squares are variables they're variables of slightly different types but they are all variables and then the edges reflect like which we're going to combine and so each given variable has a semantics which we associate with an active inference ontology term D prior s hidden State a ambiguity Matrix oh observations B transition Matrix Pi policy policy is just the set of possible actions that are evaluated by the agent e is used for affordances which is like the action possibilities in one moment up down left right and then pi is affordances considered over the given time Horizon so over one time step depth so not a deep model affordances are the same as policies because it's just the list of affordances whereas if you were doing like a depth of three in time then you would have affordances to the third power that number um how are policies evaluated using free energy calculations how are policies selected free energy minimization what does that look like in code here's the active inference Loop the heart of the octave inference Loop is inference on States that is taking in observations and doing hidden State inference then inference on policy what am I updating my policy posterior to be and then sampling from your policy posterior this is like observe and Orient this is like decide and act but what pi mdp has done an incredible job of is making it so that the a b c d are defined you have to Define what those are here's how C is defined and then you define an agent as a b c and d my agent a is a b is b c is c d is d we Define the agent that's the generative model we Define the environment that's the generative process and then we write the loop that connects the generative model and the generative process Giuseppe yes uh so you you talked about the E Matrix and you called it the Matrix of affordances um I think I remember in the book it was it was more like the habits was it is it correct yes this is the same thing yes so um affordance I I you know I'm thinking about uh gibsonian uh affordances but is it this I maybe I don't see the links uh all right great I'm gonna go for um a short answer and then a more um something that connects us to some ongoing debates in the area the E Matrix both describes the affordances in terms of the action possibilities as well as to what extent they're habitual and so like let's just say that there's four um we can go up down left right so if there's um a one one one one for up down left right that's like saying you can go up down left right and they're all equally likely to happen if it were like one one one nine then it's like you can go up down left right but this one has a higher prior probability on policy if this were like one one zero nine it's like this cannot happen as well as things that aren't listed can't happen so the E Matrix describes action possibilities and by doing so whatever is included in the list is an is at least there is a prior on that action happening and then quantitatively the value of the E Matrix describes the habitualness and then like in chapter five we saw about how like dopamine mediates or is modeled to mediate the handoff between more habit-guided here habit just gets passed through actions are selected more based upon what one has already acted upon in the past whereas here we can see free energy evaluation as sharpening your policy prior into a policy posterior that you then sample from come on so free energy minimization is then like kind of like that type 2 Thinking where we're sharpening our policy distribution so that we can make a decision that has a lower expected free energy even if that's not the one that we would have gone to from habit and then just to connect it to um some recent um discussions I'll put this in the chat so request um access if if you want on the gibsonian note there is this paper um trick or treat and long story long story but there is like a Markov blanket trick paper by these authors and then a bunch of commentaries and then just a few days ago they made a comeback summarizing the commentaries and going further and um basically their main issue is the fep affordance concept isn't the gibsonian affordance direct perception of action possibilities concept ergo read the paper to find out more but we had very fun discussions and it spoke exactly to the gibsonian question okay well thank you very very clear thank you awesome okay in our last just like few minutes any other notes awesome so um we're gonna be in chapter six for the next two weeks chapter six is not that long um so this will be a good time to make this process of active modeling our own and customize it provide templates connect it to the work that's already happening in pi mdp explore ways that we can go from vision of the scenarios that people want to model into the kinds of models that will have pragmatic and epistemic value for us any last comments or I will close the recording quick question uh because I haven't I haven't watched the the p y p y MVP uh talk yet but is a like all the codes that are in the in the book are actually been reward are reworked and are available in in Python no that is not the case yet but with some automated and semi-automated work it could be um in model stream 7.2 which you can find from live streams um in the video description is that is this notebook so um but we don't have um notebooks for the Matlab code let alone python trans uh formations but if somebody wants to do that let's do that okay thank you yep and in the code page there's there's a GitHub repo so if some it just if somebody wants to add the code just feel free all right so see you um cohort too thanks for continuing on see you future weeks at this time and also there's the optional like in like eight or ten hours or something like the Discord office hours we'll just chill and um just there will be people from different cohorts and we'll just go where people want to go so thank you feel free to stay on for um cohort 2 beginning in just a minute all right thank you thank you