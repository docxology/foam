all right i think we are live hello everyone and welcome to the active inference live stream this is active inference live stream 11 it is december 16 2020 and there's a lot to get to today so thanks for tuning in welcome to the active inference lab everyone we are an experiment in online team communication learning and practice related to active inference you can find us at our website activeinference.org on twitter as inference active at our gmail account our youtube channel or our public key based team and username this is a recorded and an archived live stream so please provide us feedback so we can improve our work whether during the live stream or after all backgrounds and perspectives are welcome here and as far as video etiquette for live streaming goes mute if there's noise in your background we'll always remember to use respectful speech behavior etc so thanks everyone just a few announcements and points of process there are two more meetings for 2020 and they will both be from 7 30 to 9 00 a.m pst and both of these meetings are going to be about the paper's sophisticated affective inference simulating anticipatory affective dynamics of imagining future events a 2020 paper from the iy conference and that's what this 11.0 is going to be primarily about so if you're listening to this at the end of 2020 then uh we would love to have you at either 11.1 on december 22nd or 11.2 on december 29th and also we are very happy to now announce for 2021 that's right that is going to be the year 2021. um we have announced our whole year's schedule so it's gonna be tuesdays from seven to nine am pst and all the instructions everything you need to know is at this link rb.gy kvn pyc and just to show you what that link looks like it is a spreadsheet and on the top is information about how to participate in the discussion so fill out this form if you want to participate email us with what dates you want to attend and then we will add you to the discussions event that day and then if you want to collaborate check out this link which i'll get to in a second and just looking at a few of these papers that we have up until the middle of april for every single paper we've been really lucky enough and have an awesome community of authors who want to join on so we'll have an author representative of every single paper up through the middle of april and beyond and we'll have most weeks we'll have an author on so we're going to get a lot of opportunities to hear from the authors about what they were trying to do with their papers i'm just really excited to hear from all these different perspectives and then of course by bringing on people who are learning active inference or who are from any different field of expertise or experience we're going to be able to try out some new combinations that maybe haven't been tried speaking of the active inference lab beyond the live stream if you go to activeinference.org you'll see a call for collaboration for 2021 and this aweber slash t slash ausm3 link you'll be able to fill out a form of interest and just let us know if you might be interested in collaborating for 2021 because we have three main projects that we're really excited to be working on the first has to do with an active inference book of knowledge which is going to be like a participatory and an open and a very interesting designed textbook reference and uh source of online course material that'll be project one that's very um educational driven project two is gonna be the live stream and some other associated content types that we'll get to in 2021 and then project three is going to be tools for remote teams so this is going to be related to the frameworks for analysis that we laid out in our september 9th paper um viatkin at all and um we're going to be working on how we can do analysis and design for remote teams so that will be quite exciting all right thanks for all of that sorry about the relatively long introduction here we are in active stream 11.0 and the goal of acting stream 11 is to set the context for the next two weeks of discussion which are 11.1 and 11.2 the paper that we're going to be reading in both of these weeks is sophisticated affective inference simulating anticipatory affective dynamics of imagining future events and that's by casper hesp at all 2020 and the researchgate link is provided this video.0 is an introduction or a context for some of these ideas it's not a review or a final word or a judgment the video is just an attempt to contextualize some of the ideas and the vocabulary as well as some of the formalisms for the paper which will be really helpful in understanding the paper for people of all backgrounds the punchline of the paper is that we can add features to active inference such as anticipation and affect and aiming for more powerful simulated agents and perhaps new insights for computational psychiatry so we're going to be looking at it with two main foci one is on the simulating agents side either computational agents or robots the other side is sort of the human side with the computational psychiatry and how are we going to be using this to have insight into the human brain and mental health the sections of 11.0 first we will go through the keywords and that will be like a bridge or an on-ramp for those who are from those different fields maybe learning about active inference for the first time then we'll talk about the aims and claims abstract and the road map of the paper how they get from a to z then we'll go through the formalisms and figures and in this paper's case the formalisms are are actually drawn from a few other papers so this video might go a little long and it will contain information on the two uh citations that give us sophisticated affective inference which is the sophisticated side and the in the uh affective site but we'll get to there in a few slides in eleven and uh point one and point two we will discuss this paper so if you're listening in the live chat it'd be awesome if you have any comments uh as well as in the comments after the video is done or if you wanna put it in a twitter thread or however just let us know what questions we could ask the authors and also the panelists on 11.1 and 11.2 about this paper and if those discussions have already happened then keep on adding comments because the discussion never stops all right so the keywords the best part the keywords um as usual there's so much to say about each of these keywords and my target here is really the construction of the on-ramp for this paper and the on-ramp for active inference so if you're in the active inference community i hope that these keywords are an invitation to explore some adjacent areas of research and if you're just learning about active inference and you want to familiarize yourself more then hopefully these keywords are like an interface or a foundation for your understanding and if you have any thoughts or any questions then always just leave a comment or get in touch with us or come on an active inference stream because we're all really just learning these ideas at this point and so we just want to hear what people think about what are the connections that are possible and certainly my hasty production of these videos would be greatly improved by people in the live chat or comments just letting us know where we could take the discussion so the keywords of the paper included anticipation counter counterfactuals affect and anxiety so maybe some of these words are more common than others people talk about anticipating events a lot in everyday life as well as of course anxiety and affect or emotionality counterfactuals you don't hear as much about in everyday life but maybe one does they just don't use that word so we'll come back to that in a second all right the first term is anticipation so anticipation is a really cool term and there's a lot of interesting research and my goal here is to really draw out this thread of anticipation itself apart from for example systems approaches to ecology or cybernetic approaches to action so we're going to really focus on this anticipation link and that's going to hopefully enrich in all of these different areas because we're going to see how they make this puzzle that fits together it's bigger than all the puzzle pieces so we're going to start on the anticipation side with a couple of key citations which are related to robert rosen who is in the middle of the 1900s did some very influential anticipation research and then also this 2017 paper by louie and some other recent review papers on rosen's work helped contextualize this discussion for me on anticipation so the axiom of anticipation as they say is that life is anticipatory so we've heard of life as a replicator we've heard of life as a megantropic force locally like an organizing force and here we're going to have another facet and that's that life is anticipatory so we're really thinking about all kinds of systems just like we were thinking about definitions of life as being pattern making or replicating anticipating is now going to be one of our key features for what is life like at least according to this lineage of research and this is going to relate to a ton of other ideas including the counterfactual which is really important and the work of rosen and others on anticipatory systems led to them formalizing what an anticipatory system was and here was the actual diagram that they used and um again there's many perspectives on anticipation the cybernetics of russia and uh non-russian non-western anticipatory research but i'm just going to trace out this lineage of rosen for right now and certainly the concept isn't new but the systematic study of it was new when rosen was writing his book and so here's a quote from the um mathematical foundations that leads me to this figure it says rosen's rigorously mathematical study of this biology inspired subject led to a sequence of papers culminating in his book anticipatory systems philosophical mathematical and methodological foundations so here's the definition that is provided of an anticipatory system an anticipatory system is a natural system that contains an internal predictive model of itself and of its environment which allows it to change state at an instant in accord with the model's predictions pertaining to a later instant an anticipatory system's present behavior depends upon future states or future inputs generated by an internal predictive model model-based behavior or more specifically anticipatory model-based behavior is the essence of social economic and political activity input and that was drawn out as this m-e-s so it looks kind of familiar to some diagrams we've looked at in active stream but it's actually different letters representing different things so m is the model of the system we might say that's like the generative model e is the effector those are like the action states and then s is going to be the system or the niche and the environment includes the total system and then the inv the effectors influence the system and then there's a bi-directional relationship with the model and the effectors now um i hope this isn't too far down the rabbit hole but i think there's a few things that active inference and non-active inference people can learn from this here because um again it helps to distinguish which parts of what we're talking about are related to for example inactivism or which parts are related to bayesian computation statistics which parts are related to thermodynamics and by tracing out the different lineages of thought that culminate in what we have today we can also clarify not just uh previous ideas and realign them in the context of active inference but also we can start to potentially uh work on all the systems that were within the scope of these disparate ideas within the scope of what we have and so it is very important to make the mapping and to be specific about it rather than just say well yeah active inference reimagines it so it's going to be totally different well it's not going to be totally different actually because a lot of these figures are from the 1970s and they're going to remind a lot of active inference people about probably a lot of things things that i'm not even perceiving which is why i put it out there for other active inference people and none to be thinking about so um we saw from an activism and from the ecological psychological domains that we're developing in the 1900s that there's many rich ways to think about this shared interaction or the interface between the ecological niche and the skilled and intentional organism we also saw from multi-scale systems complex systems that there's many ways to think about internalism and externalism and about causal relationships there's no privileged level of causation or other multi-scale system approaches okay now we're going to focus on anticipation not these other multi-scale domains we're going to be one domain one type of niche what are we going to really be looking at with anticipation okay so um the uh anticipation research frames this world as a multi-loop situation there are simple or complex versions that include the formers the observer's formal model f as well as the natural system so down here on the bottom we have f which is the formal system of the agent that's like internal to the agent and then we have n the actual external natural system and so we've seen this again in the context of internalism and externalism and in action and inference but here it's actually only about anticipation that's why i think it's so interesting especially because it's actually called inference what the agent is doing with the formal model and that's inference under a formal model so a lot of um hopefully connections are being made and the idea of the anticipation research is that we can find analogies amongst natural systems within rosen's holistic anticipatory ecology so one formal system this is going to be our formal ecology and we're going to go out to a bunch of natural systems deserts and rainforests and we're going to be doing a decoding process and by decoding the causal entailments of the natural system by inferring what kind of feedback loops are uh anticipating and being anticipated by that system which is our own loopyness over here by undergoing that process we'll be able to find structural relationships between different natural systems so here's natural system one and natural system two and this line of research is interesting because it introduces a basis in logical areas as well as in category theory and dynamical systems so it bridges a lot of areas of formalisms and that enables this kind of law-like and semantic or ontological addressment of systems which are things that the active inference research frontier is also focused on like um is active inference a theory of semantics and so um i think there's a couple ways in which active inference could come to this anticipatory framework and have some insights that are evaluated from active inference so first the formal model of the organism doesn't have to be formal in any sense that we traditionally understand but it is something that is formalizable or maybe it's related to the church turing hypothesis or there's a lot of ways to think about this but active inference is pretty vague on purpose about the exact nature of this model by just saying well it's something that we're also inferring as an observer who can make a certain kind of model so we're not sure that we're on the right one but this f is a generative model so it doesn't have to be just an analytical or inferential model it's actually related to control systems so here it's encoding and decoding but we talked a lot about action and about perception so active inference more squarely places this loop not in the realm of signal and abstraction and meaning like semiosis but within the control theory loop of system state and internal states and effectors um second the formal model as we've talked about with the internalism and externalism and tail of two densities the internal model or the formal model doesn't have to be simply inside of the organism it can exist in this exocortex way in this extended or embedded and cultured or a collective way and so it doesn't need to be all within the bounds of the organism now rosen probably was aware of all these tensions and used fuzzy sets and ecological thinking a lot of other things so it's not again i'm not really commenting on the anticipation sorry anticipation research don't know too much about it but i'm just thinking about where we could draw and build upon and really this is so interesting that in the anticipation area there's a dialectic or there's a dynamic between the formal system and the natural system so it's almost like natural and artificial and then that's related to encoding and decoding so it's framed about information and about natural communications with an unnatural almost whereas the active inference approach takes that ecological insight and connects it to control theory cybernetics so it's action oriented that's the action research side as well instead of the semiotic elements and seeing the semi-symbiosis as emerging out of action rather than seeing the semiosis as primary and stimulating or signaling action which one is primary well which one was around first and uh again really important precursor research for complex systems a lot of other areas and just we're coming at it from anticipation we're not using too much active inference jargon we're just thinking wow if active inference could map to anticipation then every keyword in literature about anticipation we could be able to be one jump away so that's why semantic indexing of research databases is so important as well all right second key word counterfactuals so counterfactuals are very related to prediction and to anticipation and that is why um they're in this order so many philosophers and this is drawing from the stanford encyclopedia philosophy many philosophers have proposed uh to analyze causal concepts in terms of counter factuals and the basic idea is that a causes c and that's related to this claim that if a had not occurred c would not have occurred so that's called the difference-making cause or the cause that makes a difference so it's like you imagine two worlds where something happens or it doesn't happen and then you ask about how they'd be different so if tomorrow there was no sunrise in california then it wouldn't be the temperature it is today so you can think about an alternate world even one that can't happen or wouldn't happen and then you can talk about that and say oh well that's because the sun causes the day to get warmer when it rises or when the earth rises should i say and what's good about this counterfactual is that you can go beyond simple counterfactuals and you can actually have quite nuanced logic of counterfactuals so here was an example from lewis 73 where depending on the way that more information is added uh it changes the truth value of the counterfactual so here's just an example of how that can flip and then also how we can use logic not going too deep but just we can use logic to denote these sentences so if i had shirked my duty like not um signed up when i had to no harm would have been sued no harm would have followed so if there would have been i this event i then not h no harm and then in b we see if i had shirt my duty and you had two so now it's kind of like the and operator i and u two events happen event i and event u then there would have been h and then here in part c we see i and u and part t then not h and so this is kind of like a formalization but it is can also be done in ways that are a little bit more data driven instead of formal framework driven but it's very related to so many things that we've talked about like infinite grammars and logical sequences and about the ways that you can have a generative model and then you can ask about how things are based upon how things could be in a different sense we're going to of course come back to that with the papers here is where the counterfactuals come a little bit more directly to inference so counterfactuals in the inference case are like can we understand how things are or were by asking how things could be that's purely about inference and then the action uh orientation of that question is can we reduce uncertainty about future states like can i make sure that i have a good core body temperature by asking about how things could be so that i can choose the right actions so if it gets cold later tonight and i'm going to want to have to have a jacket or feel warm then i might need to get a jacket right now and so that's what this paper is about that's what we're going to return to in precision but let's keep it within the sort of keyword level analysis and here's a plot from uh scp from stanford encyclopedia philosophy and it's a strict analysis so categorical of how the antecedent what happens before not the ant the antecedent is related to what does or does not that's what this kind of um l means not the consequence the consequences are what happened after so in this situation we have things that actually happened before above the above yeah the x-axis and then things that didn't happen before like you know if the sun wouldn't have risen yesterday then that's this not phi that's not what happened and then the consequences are shown on this symmetry axis so in this quadrant on the top left we have things that did happen before and they did follow so this is like today i tied my shoe and it did stay on so this is sort of normal reality the shaded region must be empty why because it's things that actually did happen in the antecedent but didn't happen in the uh consequent so this is like things that where you know i boiled the water but then it wasn't hot or something like that like something where you did the setup correctly but then it didn't occur so we know that that doesn't really happen and then there's this whole set of worlds below the x-axis which is like if anything had been different in the past if i had been wearing a different color shirt if dot dot dot all of those worlds whether what actually happens happened or not all of the worlds of the past are accessible because they might relate to a similar world outcome or not and we can nuance this sort of categorical approach to what's called a similarity analysis and so a similarity analysis is where we can start with our estimate of our current state current moment the causal relationships and all that sort of stuff at this origin point and then with the same axes of what did or didn't actually lead up to the event and then what did or actually didn't follow from the event we can have more of a continuum so um yes there's still little shaded area here but as you get to events that are further and further in the future you get to things that potentially there's more latitude but the sphere is a similarity idea it's kind of like philosophers discovering numbers they're going from the categories and they're like maybe it's a one through ten scale maybe it's a continuum maybe we could take an integral over it maybe we could take a derivative what would all these things mean and so that's kind of the fruitful discussion with people who have a quantitative and a qualitative background because the rigor of this approach which is barely scraped out with this just summary abstract that i have it's a lot of horsepower to plug into if we can reconsider some of these topics in terms of a more integrative way of thinking then we can come back to everything about antecedent and consequent and reinterpret it and re-enliven it so that's what's really exciting about transdisciplinary research and teams hopefully not to always be returning to that point though but it's really true all right affect so there's many usages of the word affect just looking at the dictionary definition uh there was just so many and i i found this image and i thought i don't even know what to say about this image because person a has an angry emotional affect so that's like using their character about them as their they had an affected character and then trying to hide their anger person a put on an affect because affect has a uh connotation of being how other people perceive your manner of speech and affect also has a sense that means affected like changed altered in a way once he entered the room he started speaking in a fact in an affected manner now doesn't really describe anything it just says he did it in a different manner but still person a then affects affected that's what this is trying to show in this left cartoon i believe affected person b by pushing them into the pool the effect of this a versus e was that person b ended up in the pool right side so that's what i think was trying to be shown was the common sense and the confusion which is the affect is the cause and the effect is the consequence so that's why it's interesting because affect and effect of course common typo but it relates to what we just saw about the uh precedent the antecedent and the consequent in terms of counterfactual structures the world but also affect has to do with of course emotionality that's why we're here that's what interests us and so in that more classical psychological sense affect is considered to be related to like emotion or experience or qualia again not my area just from my skimming in preparation for this video and often affect is displayed on these lower dimension manifolds or axes of variation so for example one axis might be from relaxed to stimulated now that doesn't mean feeling good or bad you can be feeling good and relaxed or bad or tired or um here there's a mild too intense so these are emotions that don't grab your salience so much and these are ones at the high intensity that do like being astonished or being odd or shocked then there is a orthogonal so at a independent angle axis on the x here that goes from unpleasant to pleasant and so whether you think of it as a two by two like there's the pleasant and intense experiences in the top right and mild and unpleasant down here being a little bit too cold or something like that you can think of it in a two by two you can think of it in a circle you could think of it as having more dimensions you can think of it as having measurements in this phase space so if this is maybe the first time you've seen all the emotions on a chart think about what all the options of charts are and then all the options of emotions and then that's kind of what we're going to be getting at so not just points in space but we could actually be talking about trajectories through that phase space whether it's an emotional cascade or a pathway to radicalization like we were talking about yesterday in um 10.2 whatever it happens to be or just your daily routine if you wake up and you're here how are we going to get to here this is from feeling afraid through feeling excited and happy into content and serene now not that this is a pathway or the pathway or whatever but perhaps if we use tools like active inference or other computational frameworks could it be possible to introduce some ways of thinking about this diagram that would help us actually navigate these ridges and find paths find policies for people who are in one area of this face space to find a trajectory into different parts of that phase space so they already have the phase model of the valence and the effect and then there's already this trajectory model the fields and trajectories coming together and now we're gonna reconsider and um here's just a couple citations on the left about non-active inference neuroscience approaches to valence and to affect valence being positive to negative just like an electron or a proton has like a valence um valence is positive to negative axis so that's the x-axis here it's considered to be one of the major axes of variation as people who feel good or bad or change how they feel throughout time can attest to and so again we want to think about affect in a couple senses not just the semantic we want to think about affect as a statistical uh phenomena especially one that can be studied in all kinds of animals as well as in even computational agents and in that situation affect as a statistical phenomena is like feeling greedy or feeling volatile or feeling regretful or feeling confident these are terms that we might want to apply to even a chess playing statistical machine or a gambling machine oh it's really acting shy the intentional stance from dennett maybe that's a valid um thing to say but the statistical sense of affect is just purely the way that the system's behaving how would we describe its intentionality as if that's very behaviorist um very from the outside then there's the neuro side of affect and that's related to the neuroscience kind of literature that's here people who are actually looking in the brain for electro and chemical differences and people who have different affect and different affect states connecting it to different features uh dynamical or otherwise of the brain so that approach is very internalist it's focused on things internal to the organism and it tends towards this sort of neuro scientific reductionism and then there's also affect in the psychological and in the psychiatric sense which is the experience and that's where of course this whole area this field of emotions that maybe some people experience a little differently than others but no one strongly disagrees or says that it's preferable to go on this side or the other i mean that's kind of the question in many ways of cognitive diversity though and this is where i believe active inference comes into play is you have the statistical behaviorist could be about robots could be about anything you have the neuroscientific very internalist very neuro human related and then you have the psychological psychiatric which is very social and very semantic and based upon the clinical relationship in many cases here's where active inference comes into play it adds in a level of computational uh computability but also philosophical agnosticism about a system that using systems engineering other approaches we're going to be able to talk about systems very precisely while also remaining basically agnostic on several key issues so when people think that some aspect of uncertainty in a framework is a simply negative thing it's not that i'm doing apologetics here i don't think every uncertainty is a good thing certainly not but there are several areas just like we discussed at the end of 10.2 we're actually saying yeah we're using it as a tool so whether the person chooses to have cultural script a or cultural script b about this experience we're not going to make a value judgment on that but potentially from a purely statistical framework we just want to be able to describe certain kinds of behavioral state transition matrices being different in our model so that's a way where people can have a cultural experience in a personal experience but also use tools that are empowering so um also beyond the computational and the systems tractability we bring in this whole control and action perspective because all these are about thoughts you know words words words thoughts thoughts thoughts and rumination and overthinking and underthinking can also be a maladaptive state for individuals or for collectives so how are we going to orient this psychiatry especially in action instead of just like you're in brain state a so now we need to zap you or give you a chemical to put you into brain state b well it's not so simple or at least we haven't figured out the simple way to do it yet so how are we going to think big about the niche and the culture and the extended environment and then ask about how can we navigate this um you know care support team experiencer network how can we navigate through this landscape which is defined by specifics for this person in their situation how are we going to find a productive policy to get from here to here so those are the kinds of things that get me really excited because i feel like they're strong yet neutral and um powerful ways to talk about mental states and to give one example of a mental state which was a key word so i have to go into it for this section but um it's something that's you know in our experience is anxiety so i'm not a medical doctor of course and i'm not your medical doctor so this is really about that computational psychiatry perspective though um we all feel anxious we all want to help each other no one is alone or should feel alone so we all want to work together and help get you on a productive path wherever you're at all right so here's the definition of anxiety that's given by none other than anxiety.org anxiety is the mind and body's reaction to stressful dangerous or unfamiliar situations it is the sense of uneasiness distress or dread you feel before a significant event a certain level of anxiety helps us stay alert and aware but for those suffering from an anxiety disorder it feels far from normal it can be completely debilitating and in the anxiety.org literature they provide three different categories of anxiety disorders again this is contextualizing why we're studying this area as well as trying to find what are the footholds where active inference could start to make an impact whether in people's lives or in the biomedical system or in the health insurance system just where across the board are we going to see this insight take place in systems change so the three kinds of categories of anxiety that they talk about are uh one anxiety disorders which are general featured by excessive fear and anxiety kind of i don't it's a little self-explanatory but uh second category is obsessive-compulsive and related disorders which are related to obsessive intrusive thoughts and compulsive behaviors these behaviors are performed to alleviate anxiety associated with obsessive thoughts in their quote and then the third category is trauma and stressor related so one time or chronic stresses and all these different interacting factors that are so nuanced that is related to this third category so what to say about anxiety i mean wow so first is there's just many kinds and there's many experiences so we want to respect that everyone's having their own experience and it's going to be a totally unique experience to them and it will demand a personalized way to help them just like everyone so that was sort of the first point then there's of course to say that there's many aspects to this and there's many causes and factors just from the clustering of diagnoses that can be considered within the category of anxiety disorders according to the dsm let's say it's quite broad there's many uh features that some people might present with versus others and there's no clarity on the underlying neurophysiological or even situational basis and also it influences many kinds of thoughts and behaviors but what's a theme in anxiety and something that connects all these different areas is uncertainty is a theme and when we see the word uncertainty in active inference it's like a doorway because active inference is all about agents that are trying to reduce their own uncertainty about action in their niche so we see uncertainty and anxieties about uncertainty we want to think about how we could build active inference into a broader discussion about psychology and psychiatry so let's think about these different manifestations of anxiety and reframe them in the context of active inference and a couple of other topics that's partially where this paper is coming and we can start um with the uh integration of all the keywords together before we go into the paper so starting with anxiety let's go first to affect so anxiety it's either a dimension of affect or it's a point in affect but the point is it's someone's lived experience that they're having anxiety and specifically that they're feeling negative about it and they want to get better because if it's not feeling negative about it then it's not pathological that would be considered i believe within the you know realm of healthy but not suffering but if the person says puts their hands up and says yes i'm suffering i would like to have less anxiety that's what we're talking about in this situation as well as managing it for everyone whether they realize that at a metacognitive level or not the next keyword is anticipation and anxiety can be very related to anticipation which is like predictions or estimates for the future and here's one thing that we can unpack at this point as we start to turn towards more mathematical sections for the rest of the talk and it's actually that the estimate is really like a package of a couple of things it's the specific contents of the expectation but also it's its likelihood relative to other things that could happen and its confidence so that's like a way to say that we can separate what the prediction is from how likely it is and from how likely we think our prediction is going to be good and let's combine that with a few examples with the counterfactuals okay because i said it's how likely something is relative to other outcomes and that's related to the counter factuals that's related to those spheres of similarities and those similar worlds and so counterfactuals are essential for anticipation but they're also critical in the current moment so let's think about anxiety as a theme and counter factuals and anticipation and about the past present future so a counter factual about the past that might lead to anxiety would be like i wish that in the past i had done x instead of z or i wish i never did z you know two hours ago or 20 hours ago or 20 years ago and then a counterfactual about the current moment is like i wish it were like x right now instead of like z right now just i wish something were different in a state about the world but here's where we get those confidence estimators and the anticipatory systems element because we don't have to anticipate the past or the present that's just kind of how times arrow is funny huh but when we're talking about the future people don't really include these confidence estimators about the present they don't say i'm 100 confident that it's daytime they say something like it just is daytime but when they include something about the future it's very common to include a confidence estimator like i think it's unlikely that my friend will do x in the next three years and then you can have always predictions amidst other predictions so like i think there's a 10 chance that my baseball team wins the world series that means that there's a 90 chance that you don't think they're going to win the world series and then you could have a critique or a metacognitive estimate for your estimate like yeah i said 10 and 90. but actually i have no idea so it could be way way way off so you have a very loose estimate even on the 10 and 90 other times you're like yes i'm very very confident now again you could be wrong you could be way off you could be asking the wrong questions you could be you know not saving the text file so the world intervenes in ways that go beyond this model but we're thinking about just this simple decision-making context and so in the context of anxiety we can think about the generative model that leads to the production of affect of experience whether it's epiphenomenal or not later day but this generative model is in this strange attractor of a zone of thought and action and that strange attractor is whether it's ruminating or whether it's related to any of these other manifestations of anxiety it's like there's a strange attractor of thought and then that can be overwhelming or it can lead to negative experiences or it can lead through a trajectory that goes to negative places so we want to be maybe moving towards thinking about this landscape of attractors of thought and action and niche and social environment thinking about all these factors together and then this field of affordances the field of consciousness the free energy landscape how can we bring all these things together think about how to help people who are experiencing anxiety and other situations and before we go to the paper it's this slide we'll return to and it's what does free energy principle and active inference say about the relationship between agents in the world when in this case the agent is affective emotional and imaginative and here's the affective agent who's also imagining future emotions so this is the kind of model that we want to keep in mind for the paper it's about an agent who's acting in the world um and right now it's just a simple interface but you can imagine more nuanced interfaces at a later model and this agent is having an experience but that's not um a philosophical claim it's just a parameter that it's calculating and then it is also calculating perceived future likelihoods of different states okay so with no technical details at all that's what this paper is about agent in the world with this valence affect here it's simple it's zero to one like good to bad but you could go in different dimensions but here it's just good to bad agent in the world thinking about the future okay now it's going to get more technical that's what the paper is for though so sophisticated affect of inference simulating anticipatory affective dynamics of imagining future events it's from october 2020 so just like two months ago um at the first international workshop on active inference iy 2020 at ghent and the authors are listed here so cool first annual good bold start we wish them the best of luck in their series the aims and the claims of the paper are as follows so they write in this paper we aim to provide a mechanistic account of how afflictive responses can be generated by imagined future outcomes and how this can become dysfunctional during rumination by combining two recent developments in active inference anticipation and affect we provide a formal model of these phenomena and simulate how overthinking a situation can occur continuing to the point where unlikely yet aversive and arousing situations emerge in one's imagination so interesting motivation for the paper no and in non-active inference terms i would frame this as how can we model affective and anticipatory active inference agents what features do these simulated agents display in simple environments and then because this is such a short and inter introductory paper how could we think about this being useful in the fields of psychiatry cybernetics all these different areas and of course we'll go into the formalisms soon so the abstract of the paper in this paper we combine sophisticated and deep parametric active inference to create an agent whose affective states change as a consequence of its bayesian beliefs about how possible future outcomes will affect future beliefs to achieve this we augment markov decision processes with a bayes adaptive deep temporal tree search that is guided by a free energy functional which recursively scores counterfactual futures so we're already seeing a lot of the key words come back into play our model reproduces the common phenomena of rumination over a situation until unlikely yet aversive and arousing situations emerge in one's imagination as a proof of concept we show how certain hyper parameters give rise to neurocognitive dynamics that characterize imagination-induced anxiety and so we're going to use the computational psychiatry definition of anxiety and uh yep it's a short abstract relatively short paper invokes a lot of formalisms and so i hope that people find it interesting the roadmap is pretty short we only have to go to a few gas stations on this one there's an introduction there's a methods figure one is a directed acyclic bayesian graph which we'll build up to figure two is an illustration of the state space of the task with all four states and then table three has a lot of formalism and it's the predictive posteriors that provide the empirical priors for the generative model three is the results and then there's figure three which is just an example of simulation results showing detrimental effects of overthinking so they uh made it about overthinking but they didn't overthink the complexity of the paper so it's a simple straightforward paper but again it invokes a lot so let's get to the formalisms and let's try to really understand them or at least give them a space where they can exist even if we don't know all the details where are the edges of the formalism so that we could be thinking about it correctly or asking the right questions or just the questions that make sense for us whatever they are that's the best question to ask best question to ask in a live chat best question to ask in a comment or on a live stream but definitely just ask it because someone else is going to be asking it and you'll be really helping them so formalisms here's from the paper they wrote by combining the ensuing recursive update scheme of sophisticated inference with deep parametric affective inference i don't have the british accent to say it the right way though we can derive a general purpose generative model of the following mathematical form summarized graphically in figure one and in tabular form in table one okay so they're combining two citations here and so it's worthwhile to ask what these citations were and they are sophisticated inference that's first in at all 2020 the first citation in the sentence and then there is hesp at all's paper deeply felt affect which was actually published november 30th 2020 so it was a pre-print i think at the time of this one being written but then now it's been published so here's how to think about this paper sophisticated affective inference that's what everyone is listening to this video about that's what this paper is about that's what the discussion is mostly about so it's combining you know building on the shoulders of other shoulders the affect side with the temporal depth side both of which we're going to go into in this video which is why it's a background video this paper builds on top of them another brick in the wall another uh citation in the network and we're going to be thinking about where does that go given that this was in october 2020 and it's only december 2020 um or maybe even only a few months later if you're listening to this but where are the next places to go well there are the directions of making more advanced simulations like taking something that they took as a fixed variable in this paper and just asking if it could be a vector of variables or if it could be a continuum or if it could be another type of model inside of that and then give it a new acronym and make it another meme so what simulation directions could we go just purely exploring or making it more mappable to other fields then um how could we move in a way to integrate better with computational psychiatry and psychology so how can we integrate with experts and with vocabulary and key questions in those fields so that this isn't just like a machine learning parallel universe related to mental health but it's actually something that's connected to how social workers in the field or how caretakers in their daily experience relate to these topics and then another direction which i don't know too much about but i hope that we can have some people on to teach us more um are about new models for robotics so how do does including these kind of top level parameters like affect and in the context of a deeply uh nuanced counterfactual anticipatory model how does that relate to a robotics context and will that help you know robotic birds finally come out for public use well let's go to sophisticated inference first so again temporal depth and affect are the two pillars that we're going to build on we're going to go depth first search some of you are going to get that here is the sophisticated inference paper which we're not going to read for an active stream so i will just read the abstract active inference offers the first principal account of sentient behavior from which special and important cases can be derived for example reinforcement learning active learning bayes optimal inference bayes optimal design etc active inference resolves the exploration exploitation dilemma in relation to prior preferences by placing information gain on the same footing as reward or value in brief octave inference replaces value functions with functionals of bayesian beliefs in the form of an expected variational free energy key point in this paper we consider a sophisticated kind of active inference using a recursive form of expected free energy sophistication describes the degree to which an agent has beliefs about beliefs so higher order theories we consider agents with beliefs about the counter factual consequences of action for states of affairs and beliefs about those latent states in other words we move from simply considering beliefs about what would happen if i did that so that's a first degree counter factual to what would i believe about what would happen if i did that that's a second degree counter factual so for example it could be i really want to know about a pen's relationship to my affordance of writing but i don't know how heavy it is and so you can keep on thinking about well what should i do with my hand to find out how heavy it is so i can resolve my uncertainty about it being in affordance these are the kinds of nested and open-ended frameworks for cause which can be extremely contextual and ecologically conditioned we want to set up these causal chains in a ways that that we can capture them that's what this is about but the state space is big so a common theme we're going to come back to is like how do we look through these big state spaces the recursive form of the free energy functional effectively implements a deep tree search over actions and outcomes in the future crucially this search is over sequences of belief states as opposed to states per se we illustrate the competence of this scheme using numerical simulations of deep decision problems so um one way of interpreting this last part about here is this search is over sequences of belief states opposed to states per se this is really taking that full jump into the world of action instead of just inference on world states so instead of like i'm going to have all my computational power on what the temperature is going to be in california in one year from today it could be like i should just have between one and three jackets and then within an 80 20 but really more like 99 1 all have the right policy but no one puts the big computational power on the jacket prediction algorithm they go on the climate prediction algorithm and there's a lot to say about that why that decision is made not in that specific case but just in general why do we go with all of our power on predicting states in the world rather than doing prediction on policy when in the end policy is like what we can control and bound and then we can leave space for the unknown we can leave space for how likely is this tsunami every once in 30 years or 50 or 100 what's the most resilient thing we can do right now what's the best inference on policy for our beachside community not what is the gaussian distribution of tsunami waiting times do people hopefully see a few directions in which active inference steps into these issues about uncertainty here's some of the formalisms from the paper they write our objective is to optimize beliefs so an approximate posterior over policies pi as always and their consequences which are hidden states s and those are basically s triple line it's like a super equal sign and it's saying s is uh related to this tau the t is like the tau the policy horizon so the hidden states are s from some initial state s one stay at time one until the policy horizon tau so that's the length of the prediction the depth through time um given the observations o from up until time until the current time t this optimization can be cast as minimizing a generalized free energy functional f of so it's a function of something and that function can be enormously complex like a neural net is like a function it's a mapping of inputs to outputs it's a map functions are maps and so f of everything it's like that's the biggest possible wormhole but that's why this is a powerful approach and then it's q of s and pi so this functional is around q which is some distribution of states and policy so the world state is like what the actual my estimate about the world's state is going to be and the pi is my policy so here's what is being asked here for those who might be learning about active inference or wanting to really go into these formalisms for perhaps even the first time this is like asking how can we have the best policy over a given time horizon so that's the big control theory question given tau and given the distribution of affordances pi what's the best pi over tau not division just what is the best pi over the time horizon tau so if my policies are left or right um in a you know a collision situation and then there's a time horizon you only have those two choices and so you can pull back to the metagame and say do i have another choice there's always space for innovation and for breaking out of the box and for reframing it but at this first base level let's just focus on a certain time horizon and a certain set of policies that are fixed so we're playing like connect four here or we're playing like backgammon it's gonna work for these models too and we wanna ask how can we estimate the consequences of pi so of our self of the policies of others and the policies of groups and the way that we're going to do that mapping rather than go infinitely deep on what is a causal model of the world or have every atom simulated in the world we're actually going to go to a different way and we're going to ask how are observed states related to our estimates of hidden states and how does that relate to our underlying causal model of how hidden states change through time and how our policy influences them that's the framing and there's times where you can like you know breathe as much as you want but you're not going to change by yourself the co2 in the atmosphere so by modeling it this way it doesn't mean that there's going to be a way to make the estimate the agent might not be set up in a way to succeed but again it's the framing here that matters and you could frame a winning chess game or a losing chess game or a million pawns versus one or any board size all this can be included that's what we're using these numbers and letters for because then the pie can be really nuanced it could be a million different self-driving car parameter settings but it could be evaluated they continue this generalized free energy has two parts the first entails the generative model for state transitions given policies while the second entails a generative model for policies that depends on the final states so emitting constants so the generalized free energy of sophisticated inference which is deep time inference is going to have two parts one part is going to be a generative model they're both general models but they're kind of like two-stroke engine one generative model is about state transitions given policies and then the other half of the generative model is about policies given state estimates of the world and so those are manifested in q and p and they're both related to policy but they're related in really specific ways so more details are provided above this is just the um screen screenshot from the paper but we have two key equations that come at the bottom here q so mind your q's and p's just classic q is conditioned given policy it's about observations and states given policy and it's related to a model of how observations arise from states o conditioned on s and are related to another model about how states are conditioned on policies okay so kind of makes sense because we're conditioning here on states i'm sorry we're conditioning on this right side q with policy and then here on the p we're conditioning on s but then we're doing an s estimation here so we like maybe it kind of cancels that's how we ultimately get s on the left side here like this one somehow scoots to the left side ask a statistician but there's more nuanced layouts this is just the simple one and um it's basically related this p and q internally maybe there's another i don't see how cute i don't think it's recursively defined i think it's two components of q but let's hear the clarification from the authors then there's this p function and that is related to policy selection itself so it's not conditioned on policy p is about policy and this is related to expectations across policies and the free energy generalized free energy of the policy so p is like the policy selection side and q is like the inference side because this is like what are the states and the observations of the world given policy that i do given that i go on a run every day what would be the states and the observables of the world that would be different so it's a counterfactual but i'm framing it within this type of approach and then the other half is given that that's a likely or a possible or a preferable or a curious or a fun or a uh you know habit-forming whatever it happened to be however it fits into e and g defined formally that relates to the policy selection path that ends up getting enacted by p so yep definitely let's get some more clarification from the formalists themselves they continue with this section equation 1.3 and so here's something pretty interesting this is um they write this corresponds to a form of approximate bayesian inference i.e variational base in which equation 1.3 is iterated over factors of the mean field approximation to perform a coordinate descent or fixed point iteration so they are saying that this formalization corresponds to approximate bayesian inference i'm going to provide a little bit more information on that in a second i found that to be kind of an interesting claim and uh not sure are there mathematicians or machine learning experts who could clarify this issue that would be appreciated and here's what they wrote which i thought was really interesting sophisticated inference recovers bayes adaptive reinforcement learning in the zero temperature limit so cool because it's like saying in the extreme no noise case in some info thermodynamic way it converges to a certain type of other thing so just like some algorithms might converge to a normal distribution let's just say you sample a bunch of weights and they converge to normal this is like a convergence but it's converge this model family is converging on bayes adaptive reinforcement learning so we take all that we know about bayesian adaptive reinforcement learning all those neural nets and then now we have the best one and then it's about converging into that best funnel in a higher temperature space that's even going beyond the model parameters of those bayesian approaches quoting the authors again both approaches sophisticated inference and the bayes adaptive reinforcement learning perform belief state planning where the agent maximizes an objective function by taking into account how it expects its own beliefs to change in the future and evinces a degree of sophistication aka being good at chess being sophisticated go the key distinction is that bayes adaptive reinforcement learning considers arbitrary reward functions while sophisticated active inference optimizes an expected free energy that can be motivated from first principles key difference people who are looking for a key difference between free energy and something else that was one while both the bayesian approach and free energy can be specified for particular tasks the expected free energy additionally mandates the agent to seek out information about the world beyond what is necessary for solving a particular task so that's extremely key this goes beyond for example framing the potential value of play in terms of the estimated values of the deliverables this actually um something that we've heard so many participants on the active stream like blue and others highlight is like making space for play and this full formalization of the expected free energy it includes the information gain as well as the value driven components and some other components so actually on equal footing down to even the units of information used at least according to this first interview i listened to a couple days ago um it's on our one of the playlists on our channel um the same natural unit or at least the same framework whether there's a coefficient that balances them he seemed pretty negative on that but i think there could be another way that they're integrated in a more um nuanced uh way than just simply an 80 20 20 80. this isn't bipartite partitioning this isn't nature nurture 1.0 this is relational causal networks and so it's going to have a really different way of phrasing it it's not going to be just a coefficient but it'll be like a coefficient i believe because there's systems where it is like it's 80 20 or it's 2080. in terms of delivering on um something standard versus novelty so like we talked about scripts and 10 you know there's the scripts like the ritual that are meant to be carried out exactly then there's the ones that are unstructured so that whole space back to the authors this model allows inference to account for artificial curiosity that goes beyond reward seeking to the gathering of evidence for the agent's existence i.e its marginal likelihood this is sometimes referred to as self-evidencing and the citation there is the howie 2016. and so we can think back to active inference 8 when we were thinking about that mountain car and about how it just wanted to explore but by exploring in that admittedly trivial setup it did discover the goal in the way that the optimal um reward uphill climber got ground down so how can we move beyond just one well settings move into more nuanced maybe even semantic innovation landscapes and optimization landscapes and converge to approximate bayesian inference in the truly formal case where we need to but then relax those assumptions with instrumentalism and use approximate approximate bayesian inference empirically empirically just as statisticians as scientists as policy planners that's really the question in the doorway all right another from the same sophisticated paper amortized inference effectively and also see active inference stream eight with um alec who gave us some really great information about this and hopefully we'll have alec on a future discussion as well so amortized inference is learning to infer variational autoencoders can be regarded as an instance of amortized inference if we ignore conditioning on policy clearly amortization precludes online inference that's like real time like data in the loop and as such may appear biologically implausible however it might be the case that certain brain structures learn to infer e.g the cerebellum might learn from inferential processes implemented by the cerebral cortex so this is definitely related to a neurophysiological argument for like grounding the plausibility of certain computations being performed or as if they were being performed by certain brain regions that have certain macro histological arrangement or micro histological structure sounds great um i would say in the case of insects um could we study whether they're doing it or not or i just think maybe it's simpler or it will help us realize that oh wait we don't really need the neurons to be doing that we just need to be able to think about it just like we didn't need the neuron to be doing a linear regression for us to do a linear regression across neurons so i don't think that using these frameworks necessarily casts the system being analyzed into the same statistical framework any more than the linear regression frame does so that's to say they all do implicitly and that's the transparent concept that's the water we swim in given that it's the water we swim in and there's a few different fish tanks i just don't see how using free energy on a system makes you strongly committed to that system being doing a certain thing another part that was interesting from this paper was this focus on separating the intrinsic and the extrinsic value and so there's a lot of ways that this can be broken down but basically a few cool equations so this is the divergence the kobach libra kl informational divergence which is a measure of how distant two distributions are informationally and um the kl divergence between this q and the p is seen as the risk and that is equal to the um like the risk of certain states like whether the red light is going to signal something or not and then um the equal sign on the other side there's risk in terms of the outcomes so here's s condition on pi here's o condition on pi and then here it's p of s instead of p of o so this is a divergence from the observations given the outcome so this is like the this q is about observations p is about observations and it's condition on policy so this is divergence in states divergence in outcomes plus expectations this is about q of observations being conditioned on policy so we're kind of functionalizing and conditionally conditioning on a lot but this is actually about the states and this is about the states given the observations and the policy and how that is bringing us close to what the mapping between states and observations which is the interesting part and so there's so much to say here but they unpack it in terms of the intrinsic and the extrinsic value so there's basically this um separate sections i would just say not just in the interest of time but just in the interest of knowing that these formalisms really demand to be unpacked and mapped in a really formal way not just discussed in an introductory lecture so let's save them for another time as far as the general and the specific cases of this there's a nice figure here with a few different special cases that descend into certain uh different sub areas so if there's no prior this is like an uninformed or optimally uninformed bayesian design so that's the information maximization principle that's info gain if we have no ambiguity like if the prediction can be completely perfect as far as the observations are concerned like all the thermometers are perfect in your building for example then you can have basically risk sensitive or aware policies that's like cybernetics as well as informational control and kind of occam's principle i'd be really curious to learn what they meant here but maybe that means like argument by simplicity in the context of systems engineering could be pretty interesting then if there's no intrinsic value so if it's just pure curiosity um search pure exploration search then it can it can converge depending on how you value intrinsic versus extrinsic to a variety of different types of theory and then also there's this maximum entropy which i would also like to learn more about from the authors about no ambiguity or prior so i'm kind of curious how these two no priors and no ambiguity how does that relate to the no ambiguity of priors and then is there one that doesn't have any with no intrinsic value either like what happens when you have nothing all right and this one is going to come back in a very very similar format in the figures for the paper but basically it starts off and it's like here's us at the top at observation time point three and then there's one two three four things can happen and then from thing one or three happening four things could be observed and then from one or three of those or from two or four then you can have one two three four things happen and here outcome one and two and four lead to one of four observations and so this is like an unrolling this is like a roll out of a deep time prediction on a tree and that's related to a couple different ideas which is why we introduce them which is the prediction through recursion and the counter factual branching so the first thing to remember is that the branches are literally counter factuals it's like what would my prediction be but it's really just predicting the whole distribution so instead of thinking as predicting is my team going to win or not just think what is the distribution of likelihoods of each team winning the world series and then that's like what is the likelihood of each of these outcomes conditioned on this and you keep on conditioning on conditioning on and rolling that out through deep time so it relates to counter factuals and the state outcome mapping so state of the world and then mapped onto your observations the sensory outcomes through this learning of the relationship so here is what it looks like in the format that we looked at at the end of 10.2 you have b the transition matrix it's like there's a state it emits observation it's this dark kind then there's a an action policy whether from the agent or from and or from the world and that modifies or not the state transition matrix and then the state goes to the next state and then through a which can be similar or not it emits another observation that could be probabilistic or not so we're going to see this again in just a few slides but pretty interesting and that's just the first approach and that shows that the sophisticated inference paper was the one that really brought it out and then also this is pretty interesting figure eight and here's the caption this schematic summarizes the various imperatives implied by minimizing a free energy functional of posterior beliefs about policies ensuring states and subsequent outcomes the information diagrams in the upper panels represent the entropy of three variables where intersections correspond to shared information or mutual information so professor jim crutchfield at uc davis or anyone in your area i would love to be learning more about this question of the overlapping venn diagrams because i remember a lecture with some overlapping venn diagrams and information theory from professor crutchfield that was very influential for me and then the caption continues a conditional entropy corresponds to an area that precludes the variable upon which the entropy is conditioned note that because there is no note that there is no overlap between policies and outcomes that is outside hidden states this is because hidden states form a markov blanket i.e informational bottleneck between policies and outcomes two complementary two complementary formulations of minimizing expected free energy are shown on the right in terms of risk and ambiguity and left in terms of information gain in entropy respectively one can see that both will tend to increase the overlap of mutual information between hidden states and outputs that's what we really want is we want the states and the outputs we want to be learning that relationship both will tend to increase the overlap of mutual information between hidden states and outputs while minimizing entropy or bayesian risk in these diagrams we have assumed steady state such that risk becomes the mutual information between policies and hidden states for simplicity we have omitted dependencies on initial observations fair the various schemes or formulations considered in the text are shown on the bottom these demonstrated the bayesian control theory iekl control and bayesian risk and optimal bayesian denying an optimal beijing design figures complementary imperatives okay bayesian design of what the answer is of experiments so this is optimal experimentation conditioned on everything you know okay so this is like given the state of what's known how can you get information gained and then here is related to making uh the lowest possible risk through policy given to the states that are known and that's related to what's known as kl control and so what we're seeing here is in this mapping of active inference and not necessarily other frameworks i'd be open to correction or expansion on this but not necessarily in other frameworks are there um such even ways to understand and equivocate a really broad range of strategies for example you could do really this is kind of like explore and this is kind of like exploit except instead of the parameter switching explore to exploit or one mode to the other it's actually like a more nuanced trade-off mediated through policy and what that policy is enacting in is a co-optimization of information gain that's this outward and it's expansive in this variational principle with the downward coordinating bayesian risk precision optimization so the bayesian design is like you're on this point on this uh you know wherever you're at and it's expanding outwards with the info gain with the optimal experimentation and then it's collapsing inwards in order to decrease surprise about the world all right now on april 6th and 13th 2021 casper hesp and other authors from this recently published paper will be joining the active stream so we'll go through the paper and all the figures and everything then but the figures will just go through it one first time because they're going to be basically exactly copied over for the sophisticated affect of inference so where we start is m1 and we'll go through these pretty fast m1 the first layer of the model is about how hidden states instantaneously are associated with observations so here's observations here's a likelihood mapping here's the states we're estimating states given our prior d and then from observations through the likelihood mapping a some math now m2 is a generative model of anticipation so here we have d our initial priors and then we have b which is how d changes basically how those those priors change and then we have states through time one two three and then at each time we're having either a prediction or a confirmation or updating of an observation that's the time specific predictive density so m2 is like how does m1 which is at one time point change over two or more time points so that's m2 m3 is a generative model of action so this is where we introduce the action layer and so there's a couple of pieces that play into it the first thing to notice is that we have this exact same m2 it's literally it's um the exact same image copied out here's m2 looks kind of like three letters there's three prongs pointing down and a little head with the d same exact shape here okay so m2 the box is clarifying this is the exact same m2 that we just talked about m3 is around that and so how does m3 come into play well it's all about pi policy and so p policy plays into the b matrix which is how the state estimate changes through time so our policy is really if i exercise every day then i'll be getting healthier in this way so something like that and the pi is again only playing into these b matrices it's not playing into the s state estimation it's not playing into any a matrix learning it's a different part of the brain different part of the model or so they say maybe and the pi reaches downwards into the b but also it's getting influenced by a couple of new things up here which is the baseline prior over policies and the phenotypic outcome preferences which are c so c is your preference matrix e is like your affordances that's like your your baseline affordances of your prior of affordances just like um endowed from evolution and from learning and development what are the tools that are at the disposal and then there's the phenotypic preferences which are also evolutionary priors that can be updated and they can be contextual and through g there's a policy selection okay more math or math but it's about d this internal model of how states and observations are linked and then we're going to hook p pi policy in here through using this g free energy optimizing function then g is the interface for where this generative model of implicit metacognition comes into play and so this estimation of meta confidence so remember we talked about well it's ten percent that my team is going to win the world series but i'm not too confident about that estimate and so implicitly about the past present and future we speak about it in different ways but we have not just a state estimate about the world but a precision estimate like it was around 70 degrees or it was exactly 70 degrees i looked at it on a thermometer and so here gamma is this precision parameter and um beta is the prior over precision so uh it it's because beta that is the parameter i think of this gamma distribution so the gamma parameter is what is kind of the high to low temperature on g so it is like the explore exploit trade-off in a sense but it relates in a little bit more nuanced and and surely with a lot of different consequences um it relates to this um optimal experimentation versus precision management convergence divergence uh expansive expansive retraction and tensile and compressive tensegrity synergetics it relates to a lot of these other areas all right so to conclude that section yeah this one is a little long but it's fun and it was a fun one to learn about so um hopefully we can return to this slide now and say okay the affect um and the temporal depth are two pillars and now we're going to build on top of them we're going to think about an agent that goes deep and one of its predictions is about its own affect so here's the figure from the paper that we're reading from the hesp at all and the reason why i went through it in the previous section was because as you'll see it's very similar to the previous version so we have states and the a likelihood mapping states and observations of the world then we have b the matrix of how states change in the world and then we have u which is action here and u is as before interfacing only with b okay so that's where we've seen before but now we're going to be estimating precision and free energy at each future time point so we're going to be considering our action and our importantly our precision parameter which is required to calculate the g from the top we're going to have basically this initial condition d and then there's going to be a state that carries over into the next situation so the next branch down the row this this whole thing is gonna get copied over so you can have these big you know graphs all these recursive functions calling each other basically but this is the state and then a here um is going to be initially just giving this first state but again we're going to be at each time point rolling out in a deep sophisticated way task specific sophisticated inference as in first in 2020 we're going to be doing this counter factual analysis about this deep branching and our precision and our valence about it at each time now here's the illustration of the state space of the task with the four states so it starts off neutral and then basically there's a transition that's possible so you can imagine a 4x4 matrix with the state transition probabilities and the transition matrix that they set up has a ability to go from a neutral to a precise small gain that's two it's a good probability of getting um a good outcome or you can go to this dangerous high gain where it's mapped here i believe it has um the three so if you land on a one you start in the stay in the neutral position if you get to a two you can go to either one or three or they have it connected to two but i don't know if they mean that edge um properly then if you get to three you can hop to one two three or four again i don't know if they have an edge there as well and then if you get to four it's an extremely painful state and it's absorbing it only leads to itself and so here it's like a dead end so at the first time point let's just say we're starting at t equals one and we're just evaluating i'm in state one what could happen okay so here you could go to four now it you can't on that first one so maybe the likelihood of outcome four is zero so you're like wow all my outcomes are great i could either have this two or this three not that those are the values but you can at least say at least one road uh one down the road gain of one gain of two one step down the road both my outcomes are good then you look one level deeper and all of a sudden there's a few things happening first is this branch is staying very high positive all the estimates are very positive but on this branch you're starting to see that it's possible to get this negative valence so now your estimates out of these four you're like well it could be pretty good pretty good very good or kind of negative so now at each time point not only are you tracking the likelihood of different estimates but really you're tracking it as like a distribution and the distribution is about state estimates and uncertainty and the variance the prior beta gamma those are the key pieces here that's why this is so interesting and so as you can see from this graphical layout this kind of markov state transition matrix layout which we could see maybe in the code you can see that eventually you're going to get to four even if only one percent of the time from three to four you go to four if you stay in four you're always going to stay in four it's an absorbing state and so eventually if you had 100 little ants or 100 particles and they started here they'd all end up in four if you set up that way and they can't escape and so here's what we end up seeing well first before we get we see these are just the mathematics we're not going to go into it in this one but they're described there and they're described here and here and here's what you get when you do the simulation and so remember that the uh negative states were absorbing and there was just an increasing number of them and so four charts all on this time scale from zero to two thousand so the first thing to notice is that the perception of the good versus bad it starts in the middle then it goes high maybe as it's discovering some of these shallow branches where there's a lot of winds but then around 500 it starts to really slip down and that's in terms of how many states it's um playing out the simulation in okay and now so even though the simulation each round is totally winnable let's just say if there was any agency in the situation by imagining that there's an infinite or a growing number of future outcomes that are negative it leads one to have bad affect in the way that they modeled it in this model another interesting feature is that initially as evidence starts pouring in precision increases but then around the same time that the valence drops the precision drops basically as well this looks like a crypto just dying but the precision dropping here going from a high of around 1.8 to florian at 0.6 that is uh showing that there's a increased variance of the estimate it's like would you rather know that you're going to have ten dollars plus or minus one or ten dollars plus or minus 40. it's like wait i might have negative 30 from this deal that sounds like very different maybe i'll just take 10 plus or minus 2. and so that's related to risk tolerance and design of experiments okay let's look at this bottom right and then we'll go to the top right the bottom right is the threat perception which is the fraction of imagined events that are negative so again at one temporal depth there's zero percent of these uh outcomes are negative because we haven't gotten there yet in this first step none of them can be negative you can't get any of the bad outcome but as more and more simulations roll out there starts to be this converging amount that are negative now here again they just called it a proof of concept but they're just showing one parameter combination so it's not a statement about how a certain natural system is in just any way it's a framework for thinking about it but as the threat perception increases and levels off there's also a stabilization of a uncertain predictive posterior for action so when things are good precision is high and the posterior on action is obvious so it's like very clear we're getting a lot of big winning states and there's a very low posterior for a lot of negative states then as the percentage of threats starts to increase and interestingly it's actually after it starts to get a little better but maybe the state space is just branching out even further as that happens there's a phase transition in the precision and the valence which in active inference are very tied up because anxiety which is a negative emotion we're saying in this one in excess is increased by uncertainty and so basically this is like a good level of uncertainty our posterior action was pretty we're pretty clear about which way we were going to be able to go but then this is like even though the green is still at sixty percent um the teal is kind of at like uh you know so the good ones are not losing most of it is actually rewarding but there's still a small fraction that are damaging but it turns out that by having that level of uncertainty it generates negative affect negative valids through this low precision of the model so that's pretty interesting in this reduced action model precision is interesting too so that's basically the figures of the paper it was relatively long but again the paper was short so i hope that you read it but at the same time it clearly builds so directly upon the other two work that it just didn't make sense to only read the formalisms from this paper when it was so linked to previous work all right so the concluding questions are just what are frameworks for affect and anticipation what would a good framework for affect or anticipation enable for us what does affect encompass other than valence like other than the plus minus what other features of affect are there what are some unique predictions and some experiments of this model whether in general or in the specific situation but like what is something that this model predicts that we might be able to go out and test or measure or already have the data to know and then what are the next steps for active inference how will active inference increase to another level of sophistication or include another group of researchers in the conversation or integrate best or emerging practices from another domain how can active inference grow from this encounter and serve as a you know helpful reference point for the other fields as well and then what is the goal of this research um they were mapping things onto anxiety but of course it's just a parameter and a model and certainly few authors would say that their models are anything but parameters and models yet it's so difficult to especially the multiple senses of anticipatory systems and living systems and affect in different systems robotic systems it's at the nexus where it's almost like granting agency to models but then removing agencies from humans so you know having affect in a model but then not caring about a human affect when they're telling you so that's sort of a not not of course saying that the authors are doing that or part of that or anything like that it's just that when we have these affective emotive agents it's like yeah that's us that's how we should be respecting people so how can we build on that and take this model which seems to be really affirmative about human agency and choice at the very least enabling of human agency in a way that other models again not that they weren't but that is different that's kind of the discussion that we are having and that's what's been so awesome so thanks for participating everyone it was kind of a fun discussion a little bit more than an hour and a half we will provide follow-up forms to the live participants so anyone's feedback suggestions questions would be super helpful and awesome stay in communication with us and uh yeah we hope to see you in these last two discussions of 2020 and then the new 7 a.m to 9 a.m pst 2021 i'm really looking forward to that i know a lot of our teammates are as well so check it out go to the website get the updated information thanks everyone for listening in live or replay and it was a fun discussion i hope that you got something out of it alright thanks and talk to you later