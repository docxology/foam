all right hello and welcome everyone it is October 24th 2023 and we're an act in live stream number 55.0 on realizing synthetic active inference agents okay welcome to the active inference Institute we're a participatory online Institute that is communicating learning and practicing applied active inference you can find us at some of the links on this page this is a recorded in an archive live stream so please provide feedback so we can improve our work all backgrounds and perspectives are welcome and we'll be following video etiquette for live streams head over to active inference dorg if you want to learn more about participating in live streams or other activities all right well we're in live stream 55 series with a goal to learn and discuss these two very interesting papers on realizing synthetic active inference agents part one on epistemic objectives and graphical specification part two on the variational message updates as with all videos it's an introduction for some of the ideas not a review or a final word we're gonna introduce oursel then jump into a fairly lengthy background section that will prepare us to ask the questions and get to a place where the figures cont or the papers contributions can be figured out so let us begin with introducing ourself and saying hi and saying maybe something that was exciting to us or made us want to participate in this series so I'm Daniel I'm a researcher in California and I was interested to go a little deeper on message passing it's something that's brought up a lot in the textbook and implicitly in other papers but this was an opportunity to tackle it head on and I'll pass to Bert yeah so I'm ber uh I study civil engineering in the Netherlands um and I struggle with the math of active inference but recently I picked up reinforcement learning and together with this paper I think it really helps and Y hi I'm yakob I'm also a researcher in California and I'm really excited about this paper from a number of different angles I guess the graphical notation and the notation the paper introduces I think can have um really profound impact on the field from both a computational and a um theoretical Viewpoint and um interested to um learn more about the implications of um the new notation for for the research yeah new notation just dropped okay there's a pair of papers as mentioned and the information is here so each of us can phrase the big question that brought us to the paper but I wrote it this way which is right there in the title there's at least a triple play a triple ponre and there's a diad of papers so what is this realizing in the context of the title well in one sense we're realizing something in terms of implementing it or manifesting it they're deploying something that is being realized so there's a accomplishment sense of realizing also the work calls attention to our own realizing process our relevance realization how we come to appreciate and interact with synthetic intelligence ours and then we're also talking about building agents that do some kind of realizing in themselves like realizing agents in that sense so what kind of inning starts off with a triple play I don't know Bert or yakup what big questions brought you to the paper what do you think the paper takes on um I think in terms of creating scalable active inference models that are reproducible um across a variety of settings is quite um exciting so maybe realizing in that sense across a number of different domains uh is part of um part of the meaning here um and of course the triple play uh that we were exploring with our own work from going from just a simple graphical representation to a mathematical description of the generative model and the algorithm for message passing and updating the generative model through time uh to then a code implementation that can be deployed in various Dynamic setting um that um is also um what I think is in important part of uh of this paper oh yeah and uh for me especially as not an expert on active inference but someone is more interested in applying it uh their work on working towards a p torch of active inference is really valuable and I think uh their way of deconstructing the mechanisms of uh expected and variational energy and to combine them into one function makes it uh simplifies it a lot I think cool so we're going to look deeper at the papers of course soon but just a few of the aims of the paper part one they construct a purely synthetic approach to the otive inference framework motivated from the point of view of engineering rather than neurobiology and we're going to talk about what synthetic is and in part two they use a variety of technical phenomena variational calculus message passing and reactive programming to simulate a perception action cycle on the Tas okay one of you would you like to read the first abstract and then the other can read the other abstract whoever wants to go first um I can read the the first one so the free energy principle Fe is a theoretical framework for describing how intelligent systems self-organize into coherent stable structures by minimizing a free energy functional active inference is a coroller of the F that specifically details how systems that are able to plan for the future agents function by minimizing particular free energy functionals that incorporate information seeking components this paper is the first in a series of two where we derive a synthetic version of active inference on free form factor graphs the present paper focuses on deriving a local version of the free energy functionals used for active inference this enables us to construct a version of active inference which applies to arbitrary graphical models and interfaces with prior work on message passing algorithms the resulting messages are derived in our companion paper we also identify a gap in the graphical notation used for Factor graphs while Factor graphs are great at expressing a generative model they've so far been unable to specify the full optimization problem including constraints to solve this problem we developed constraint forny style Factor graph cffg notation which permits a fully graphical description of variational inference objectives we then proceed to show how uh cfgs can be used to reconstruct prior algorithms for active inference as well as derive new ones the latter is demonstrated by deriving an algorithm that permits direct policy inference for active inference agents circumventing A long-standing scaling issue that has so far hindered the application of active inference in an industrial setting we demonstrate our algor gorithm on the classic t-m task ensure that it reproduces the information seeking behavior that is a Hallmark feature of active inference thank you and the second paper H yes so the free energy principle describes biological agents as minimizing variation of free energy with respect to a generative model of the environment active inference is a Cora of the FP that describes how agents explore and exploit the envir M by minimizing an expected free energy objective in two related papers we describe a scalable epistemic approach to synthetic active inference agents by message passing on free from for style Factor graphs fgs a companion paper part one introduces a constrainted FFG otation that visually represents free energy objectives for active inference the current paper derives message passing algorithms that minimize generalized free energy objectives on a constraint uh for an effector graph by variational calculus a comparison between simulated bet and uh generaliz free energy agents illustrates synthe behavior on a team ma navigation task with full message passing accounts of synthetic active inference agents it becomes possible to derive and reuse message updates across models and move closer to Industrial applications of synthetic active inflence great thank you here's the road map section titles of the first paper here are the section headers of the second paper so before we jump into the background and then the papers let's just have one last train stop what is synthetic and what's synthetic about active inference so as it being 2023 we went to the language model and we asked for some adjectives that are in the semantic neighborhood of synthetic and you can see them here artificial lab created synthetic counterfeit phony deceptive inauthentic unnatural a lot of these are somewhat negative associations semantically so how does synthetic come to be meaning something negative or deceitful and then in what ways is that a similar or a different sense of synthetic then referring to the unified compositionality of something that's Blended and similarly we could talk about artificial like artificial intelligence is that artifice like crafted or is it artificial like phony bogus false so in the context of the paper there's probably a bunch of different ways that we can draw it with the authors and a little bit here too what is being synthesized if you have any thoughts on this but what else might be synthetic it might refer to something that's not just a hypothetical like a real synthesis or realized synthesis it might refer to information risk and synthetic intelligence it might refer to synthetic judgments those whose predicates are wholly distinct from their subjects and then recently at The topos Institute there was a great talk by Jonathan Sterling synthetic domains in the 21st century so there's a lot of very interesting senses and ways that synthetic is used those preliminary thoughts on about these Pap these papers um I think I guess building on uh what you already said part of the synthesis uh could be the um decreasing the gap between the mathematical description of a model and its graphical representation and its subsequent code implementation so the focus on graphical models on constraint forny sty Factor graph um combines the aspect of generalized re energy or Bey free energy which uh is motivated by a forny style graph structure um with the actual implementation of a synthetic agent uh or an artificial agent in uh in code or in synthetic settings which themselves are trying to model some part of uh reality who we'll explore okay so to ber for background part one and thank you for all the work leading up to this. zero Bert so take it away with the background just let me know when to switch slides yeah all right uh so for the background of part one uh will Del into what are base crafts then how do you do inference over these crafts and then the authors use uh make extensive use of ouren to optimize uh over the graph the for Vector graph and then some miscellaneous stuff uh that will be relevant too that play smaller parts in the paper all right next slide so first off base cast uh working up eventually to for graphs uh but starting with the simplest one which is just a b ban Network and then the classical example is the yeah the earthquake all yeah earthquake network uh so you can so each circle is a random variable and they represent a particular state so whether for example the alarm goes off yes or no uh and these variables can be continuous or discrete and so the total generative model is the joint probability of all these random variables and you can factorize them so they only relate to uh one or two or several others at least a limited set of other variables and I'm moving on from that is the hidden Mark of model where you add uh time so you have multiple time steps so in this case X1 x0 X1 X2 and and this works on the The Mark of assumption which is that all the relevant information of the past is in the current time step so you only need to to consider the current and on top of that you can only uh you cannot observe it in stats directly so you need uh yeah observation Arrow so that's the E and then the next step building on top of the hit Mark of model is that partially observable Mark of decision process which is a lot of words um but really it's the same where you have a hidden State s with an observable State and you transition from States but now you add an action and the action acts the policy and it acts on uh the B the transition so for an example would be I expect S1 to have a certain value given my action and this observation O2 should be in line with that and the policy selected using the expected free energy all right next slide and then how do you actually figure out uh the values of a base graph and that requires inference and there are multiple ways so the first one is exact inference which is what you would do if you uh calculate by pen and paper which is really only practical for small discrete models like the the example model on the last slide and if if you want to go to bigger models more complex models you need approximate inference and within that Monte Carlo sampling is a a key pillar and there a bunch of algorithms that applied that use it but the core idea is the same you sample many times from an idealist distribution to approximate another distribution of Interest another method is method which uh you may be familiar with this variation of free energy which yeah active inference us a lot and then you indirectly minimize the difference between two distributions using the K Divergent oh yeah you try to minimize the kale Divergence but you cannot do that directly so instead uh yeah you maximize the elbow and this works with a family of distributions and a family is for example a cians or exponentials which you have to pick one and I'm better free energy uh works on this it's also a free energy but it has the assumption that only local interactions matter so instead of going over entire generative model you only look at one factorized part at a time and optimization which is also used in the paper uh to find some parameters and is Newton's method but you have a function and you want to know where this function goes through the x-axis so you can take the slope and iteratively uh take more slopes until you get at approximately the point where it goes to the x-axis all right next slide and then authors use paper so to quickly introduce this it is a method to describe an objective function with constraints uh so and the first derivative of the Lin if you set it equal to zero those are the optimal points so that would be where the blue and red curve intersect in this picture and the Loni multiplier Lambda is the rate of change to objective objective function would change if you relax the constraint so in this example it will be the same as changing the constant B of the the head function um so concretely if the Lambda was positive here then increasing B would result in objective function also increasing so you have some leeway to work to improve the function even further so you can optimize more that's what it's saying righty next slide and that's some miscellaneous stuff um so the term entropy is used a lot especially in terms of epistemic foraging but for now it's just a measure of how uncertain a distribution is and in general sampling and uncertain distribution gives you more information and sampling a certain one for example if it rains every day seeing rain again doesn't tell you much because it rains every day anyway a direct Delta function is a probability distribution that is one for a single point and zero elsewhere and then a statistical moment um I justly in mathematics the moments of a function are certain quantitative me measures related to the shape of a function's graph if a function is a probability distribution then the first moment is the expected value so the average the second is the central moment of variance the standard deviation the third is the skus and the four is the curosis and then finally the coolback light control which is a ter from control theory which basically attempts uh to make a system converge to a set prior and adusted by minimizing the K Divergence yes thank you great background so that kind of speed runs basian stats first layer now we're going to head into a second layer of background that's going to bring us into the the for KN graph space and after the second background part we'll be in a position to understand two papers a little better so here's the big picture on background part two even with all of background part one in hand there's also some more modern important ACM as well as non-ac INF related advances that are going to get us up to speed so for a lot of the concepts here we're just over it first and then we'll be talking more to the authors about them and so I'll take a more narrative overview of recent updates and then we'll steer towards the technical so first graphical models active inference and belief propagation over the last years Carl friston at all have been collaborating with the lab and collaborators of bird the right and around 2017 they released several very important papers one was a factor graph description of deep temporal active inference and another was the graphical brain belief propagation and active inference so as ber alluded to earlier many of the operations or formalisms of active inference can be understood as manipulations of parameters or variables that might reflect data like observations priors precisions different kinds of variables and that is given exact form in the graphical model specifically the basian graph and here we see the familiar figure 4.3 from the 2 uh 2022 textbook um now the nodes on that graphical model are variables and edges are their causal or their informational relationship and so especially after Pearl at all and the causal modeling developments in the 1980s and 90s this was adapted into a probabilistic or cybernetic setting where certain nodes on this graph were associated with action with perception with cognitive phenomena and so this is a causal Model A basian graphical model it's the kind of thing that we see in very many active inference papers now the basian graph is awesome it allows us to tackle some really challenging compute problems get a lot of semantic interpretability and so on however there's also a few limitations or challenges in execution so first just emically there's some side information that is needed to provide in order to get to a fully reproducible basian cical simulation and live stream 54 shows how that information is provided formally by category Theory but more to the pragmatic point for this discussion in actual computational execution whether you're running that Bas graph on a single core single thread or whether you're using multiple computing elements a given or a particular generative model must be implemented in a certain way or order if we were doing a single agent or a multi-agent simulation we might wonder so should we update the perception of everybody and then let everybody make action or should we do action and perception of number one then number two then number three but then isn't that unfair because then isn't one of them always getting to see an act first and so on so just drawing the graph doesn't give you the actual order of operations to carry it out reproducibly so that under specification of the basian graphical Logistics or scheduling leads to a lot of degrees in Freedom in model deployment now this might be an issue or not be an issue for any given task however whether you use an off-the-shelf or a custom solution to address this challenge these different approaches might take time they might not transfer they might not be General and so on also there might be different simulation outcomes or different computational costs that happen when you implement the same graphical model differently so that Li limits High reliability use and also transfer and then lastly kind of related the computational complexity estimations are difficult to understand just by looking at the base graph it'd be really nice if there was a way to have the model and then know how much it's going to cost or take to run so enter the forny factor graphs in 2001 for wrote a technical paper called codes on graphs normal realizations just like normal 2001 stuff and this introduced some fundamental components let's ask the authors and find out what exactly those fundamental moves were but what was introduced LED to the development of what is now called a forny factor graph FFG or a normal graph again another interesting question how is normal being used here the forny factor graph representation is dual or informationally equivalent to Any Given basian graph importantly though ffg's enable message passing message passing provides node local and whole graph scheduling logistics for messages in a way that allows for more tractability in execution importantly these messages are being passed amongst variables at a very granular level this is not referring to like two bounded agents sending each other a postcard simply the network or the graph it's a very general data structure so it's not surprising that we're going to be encountering multiple kinds of graphs but it is relevant to know which kinds of graphs we're talking about and because this FFG representation can be applied to anywhere a basian graph is used people have applied both basing graphs and to a lesser or more recent extent for Factor graphs to a bunch of different statistical problems like filtering smoothing prediction mdp PDP and so on so to kind of lock this in here we see on the right figure 7.3 from our Zulo in friston's textbook so this is the standard discrete time partially observable marov decision process and on the left here is a figure from The graphical brain paper of 2017 so across the top these two basian graphs are actually identical they're the same exact type of graph and they're both the same base graph and then the 2017 figure shows that that base graph has this one to one relationship with a for Factor graph what is the difference with a for Factor graph wh why do we need to have a different format to describe what might at first glance appear to be the same information let's go to graphical brain 2017 we use graphical representations to characterize message passing under deep generative models that might be used by the brain we use three sorts of graphs to emphasize the form of generative models one the nature of Basi and belief updating two and how this might be accomplished in neuronal circuits three so here's the three sorts of graphs that they're going to talk about first basian networks or dependency graphs that's the one that we see the most commonly nodes correspond to unknown variables edges denote dependencies amongst variables 40 Factor graphs have nodes that represent local functions or factors of a probability distribution over random variables while edges come to represent variables per se or more exactly a probability distribution over those variables and finally neural networks have nodes that are constituted by the sufficient statistics of unknown variables and other auxilary variables like prediction errors while the edges in those graphs denote in exchange of the functions of sufficient statistics crucially these graphical representations are formally equivalent in the sense that any basian network can be expressed as a factor graph and any message passing on a factor graph can be depicted as a neural network however as we will see later the various graphical formulations offer different perspectives on belief updating or propagation so this is a very rich topic this background section was to say that forny Gra graphs have a different style or format than basian graphs however they exist in this dual relationship so there's things like algorithms and procedures that you can do on FFG that you can't do on Bas graphs but it's all good because you can go from the Bas graph to the FFG representation and then Implement some procedure on the FFG so let's get to the papers the background one and background two sections have got us to perhaps the point where we're very excited to see how the authors implemented fly synthetic active inference agents using message passing logistical and operational scheduling algorithms on forny Factor graphs representing basian graphical models crafted to calculate a constrained Beth free energy as a generalized or unified free energy imperative unifying the variational and the expected free energy for sense making and decision- Mak in active inference agents so now we're heading into another double movement of the coming to papers the first paper is itself going to be like a background and a notational paper but also one that adds to the literature and then the second paper will make the addition on top of the advance of the first paper so lot of material let's go into the first paper yes so uh for the first paper we'll be going uh over at chapter by chapter to start with setting up thein then defining uh yeah the epistemic objective and how to include it in a a synthetic agent then in chapter 4 they layout what it mean what like Lan active inference means in chapter 5 they uh describ the the notation for the constraint foror graph and six they highlight why the original generalized by classical active inference and the original generalized three energy algorithm are special cases of the loin active inference so of definition of the for effector graph and then in seven they do an experiment uh for policy inference yeah um and for chapter two the the conent approach to message passing uh so as Daniel described for Factor graphs represent a factorized function over variables which you can see in equation one and figure one uh so on the left you see equation one uh that shows per note where V is uh so a is a note in the set of all nodes V and so on the right you can see the image uh which says that each note is aor of all the variables and the variables are on edges and that's really important and as mentioned in the background approximate inference is used in this case variational inference and so we start with a free energy function an equation three on the left which is used to approximate variational distribution qar and qar is the optimal uh distribution that we want to get to and we uh achieved it by minimizing it uh and so be free energy is distinct from variation of free energy by factorizing the calculation of free energy so instead of computing it all by once out once you comput it uh per note and Edge and then at the results which you can see on the he each local free energy will include entropy terms from all connected edges and since edges can be connected to two nodes the entropy of these variables would be counted twice so one Edge is a variable and if you connected to two nodes you would be counting the same variable twice and so to cancel that out uh they add the one minus degree of the edge and at the bottom added that and normally an edge has always degree of two which might be sound weird because how can an edge have a degree because normally nodes have deges um but in chapter five we will show that it's possible to have dangling edges that are just that are not connected uh that are not factorized on one end so it is possible to have edges with degree one and last uh three constraints ensure that the sum of probabilities for each note and Edge equals one and it's normalization and also that it is possible to retrieve Edge and note probabilities from The Joint distribution so that the edge says something about the nodes and the noes say something about the edges yes next one cool yeah just have something to say yeah just just that um we have the variables on the edges of this graph and the fs are like functions or operations or little factories where variables can come in potentially multiple variables can come in and some activity happens but we're putting the variable that would be in the node of the base graph and we're having it on an edge connecting functions so again the information is identical or congruent but the everything that we're going to see now is flipped in into this space where the edges are the variables and that's what it's going to enable the node local computations and then in chapter three uh defining epistemic objectives um the the artist writes that ages interact with the world they inhabit and until a generative model of the environment achieving future goals can be cast as free energy minimization and then uh they asked the question what should this free energy functional look like and why and that sets up the the rest of the paper basically uh only optimizing bad free energy or variation of free energy does not lead to exploration but K control uh which means that only prior values are satisfied a Hallmark of active inference is alternative functionals specifically made for inferring policies like expected free enery uh which includes uh information collection and so epistemics arise from optim optimization of approximate Mutual information Mutual information uh uh on the bottom right is a metric like the r squ if you make a linear and that it tells you um it tells you how much one variable relates to another one and to go back uh M Mutual information between x and z an equation 10 on the left to work on it the uncertainty entropy of X Set uh yeah that's in the height equation so it's how much you know about the one given that you know the other and so say x is an observation and Z is an internal State then an agent can choose X to see about are related to each other and then how do you how to define a functional that comines battery enics so to have add negative Mutual information and minimizing the free energy functional the elbow with in negative Mutual information means maximizing the mutual information so you're trying to get as much information uh about internal and observation States yeah just one comment there BT and then y feel free to add anything that's a great comparison you made with the r squar for linear aggression so in a linear aggression R squ summarizes how much the two um axes the X and the Y AIS resemble each other R squ of one means they're exactly collinear they're AR a manifold R square of Z is there's no linear relationship and R squ of negative one would be a negative association mut information is kind of like that but two characteristics are importantly different first off you can't have on the worst thing that two things could be or the least that they could be is just noise to each other so you can take the negative of the mutual information but you can't have negative information on something and then secondly it's not a linear relationship you could have something that is um an inverted U and the linear aggression might find that that had a low R squar because the best regression line might go through the middle of the U but then if you just think about that a little bit more generally of course one of those variables has information on the other variable and so it's kind of like moving a lot of our intuition and also some of the epistemic status of linear regressions into more of a pure information geometric space and it's a really important Point too that the vfe doesn't endogenously have an epistemic drive it's just about the realtime surprise level of beliefs and incoming data and so a Hallmark of active inference is the construction of these functionals such as expected free energy or free energy of the expected future or generalized free energy okay and so I expected free energy only works for future time steps whereas uh variational and bad free energy work for past and the current time step and instead the authors uh posted generalized free energy uh works for both the same time and it includes a part that tracks in equation 14 so that's on the end you have P with a curvy stripe XK and it basically keeps count of which time step we are at at this current moment and also note that um the policy uh or control uh is fixed so that's you with a a hoof on it and so past time steps have OB data and are locked using the direct Delta function which was the function with a probability of one at a specific value and zero at the rest whereas future time steps are still open to be optimized using generalized free energy uh and so below that you can see this free energy how you lock uh some values and keep them open at other moments and so for a sneak peek uh on the right and the figure in the right um from paper two you can see that as time goes on and time steps are observed data constraints are added and that's the the little black circle with the delta in it and committing to a full model specification are limits what a generalized fre energy function can do instead making it fully not local is synthetic active inference as the AR side okay and then in chapter four they discuss the Lin uh active inference which is the key of the paper uh and so with no node local generalized free energy we can construct a Lin for active inference and the goal is to have a distributed inference proed procedure solving for each node individually and constraining this solution as show shown in equation 13 so on the right and we need to assume that actual and approximate probabilities are about equal to each other uh we had to make that assumption so I guess we can ask it next week and now uh with this messages can be derived as done in part two which is the next paper however in this paper they attempt another way to arrive at the no Lo node local generaliz free energy and this is done in two steps so first they apply a mean field factorization uh that ensures edges are independent for each node which you can see on the right where you have the factor of the node Sr has a a product so for all edges so they are independ and then the second move they make is that you can partition the connecting variables edges into two sets one that is adjusted and the other that is left alone and to the adjusted set they apply P substitution which is very important and this basically replaces a local free energy with a local generalized free energy and on the bottom uh is the formula for applying P substitution which I also don't fully understand so maybe you guys know a little more about that definitely will ask I'll just note here that the slash is used to mean except for I hope this is correct so here we're able to take something that contains all and we're able to kind of pull out one with this more intractable integral and then still do the simpler log but we'll ask uh the second paper will show how P substituted nodes are gradually removed from the the F Factor graph over time as these notes are now in the past and do not need to consider consider the future anymore again for sneak peek see on the right uh everywhere you add the the delta in the black circle you remove the square and the square is the uh notation for p substitution and then to construct the active inference Lin it is important that P substituted nodes work with different messages generalized free energy instead of pet free energy and in this way add epistemics the optimal points of the Lin where the first derivative is zero are the stationary point of the message passing process which means that nodes do not change anymore if you keep update and so there a very long formula for the Lin um and I said you split the nodes into two one set that you be substitute and the other that you don't and on top of that you add three constraints uh which have a LTA in in front of them and that is the marginalization the normalization of both notes and I just that's very important about the station Ary point of message passing being kind of like settled where everybody can pass all the messages they want and nothing is changing and that's going to be um probably leveraged in the reactive message passing programming environment where rather than needing to send all messages once to the calculate and send all messages again it opens up up the ability for different regions of the graph to be sending and receiving messages at different frequencies so if One sensor was sampling a thousand times a second one was sampling one time per second no longer do you have to decide should we coar grain to 1 second or should we waste 999 Cycles on the slower cycle sensor now with reactive message passing because there's no local descriptions it's possible to open up that implementational space and now we'll get into defining the notation for the constrainted for Factor graphs and so foror graphs are use useful for describing generative models but it is important to know the exact functional to be minimized and the authors develop a new notation for writing constraints directly as part of the for Factor graph because normal for Factor graphs do not show that it's just a figure four on the right builds upon representing factors with squares nodes and edges as variables that can be factorized and they add circular beads which indicate constraints that Define our family q and that has to do with the variational distribution a bead on an edge denotes um yeah of the H QSI while a bead in the center of a node is uh qsa and then they build uh they introduce four constraints that are needed uh as notation for the for Factor cph so the first one is a factorization constraint uh and it can either be a naive mean field or a structured mean field when naive mean field is a stronger uh constraint which means that every factor is independent which is figure five it's above it's in the middle on the right and uh structured is less strong because you can factorize multiple variables together and I added some example uh formulas many edges like needed for uh if you want to have many edges many variables into a factor uh they introduce the notation with dots in between and this is useful when you have for example a Garian mixture model which is a bunch of uh yeah components we'll we'll see if this is uh accurate but let's imagine these four variables are coming in and meeting in the factory four prerequisite components of the car assembly process the fully factorized way to represent that is shown here that's the mean field assumption that we can just treat those components separately like if what we were doing was just multiplying or I mean adding the numbers together maybe we could treat them separately but then also there are these intermediate structural factorizations where you can take four joint coming in and then you could separate it into these two are separate and these two are connected or two pairs so it gives you the expressivity to do the Continuum from fully joint to fully factorized mean field and everything between all the combinations in between in a per node fashion rather than at the whole graph level whereas that is often how it's discussed elsewhere somebody constructs a big generative model and says and then we took a meanfield approach to the graph so here we have that kind of expressivity in a given node unmute then continue good call H so the second is a pH constraint uh which enforces a particular uh yeah function uh or distribution really on a local marginal of an edge or a Lo uh figure eight shows what enforcing aing constraint on an edge looks like and figure nine shows uh two different constraints on the the notes and the authors explicitly note that a constraint on an edge is independent of on the notes and that it factorizes into and vice versa so uh the messages pass and then after everything is done you it's like squeezing clay into a box it just has to fit but it's only after the fact effect and then they note dangling edges which do not terminate on a note on one side but um so they wouldn't require a beat but you need it to be able to do a form constraint so they still write them in um and you have that's why they add a sort of dummy Factor note on one end and then the third constraint is a Delta constraint uh the Delta constraints and data points allow us to incorporate measurements into a model equation 30 and figure 10 show this for data constraints these are special since they denote observations and block the flow of messages so these are these points are now fixed nothing goes through it because it is already set and then another option is that when you don't know which value to fix it to so uh the S I had then you can optimize the value and then it is called a Delta constraint and the op optimization of this is don't using expectation maximization what I saw in this section was let's just say that we were drawing height observations from a forest so one way to think about that is the the gaussian distribution that we're drawing from okay but now you get the data point and you could think about that data point as just an entry and a value you could also think of it as a dirck Delta distribution parameterized exactly by the value of the data point and so thinking about data as being a dero constraint uh variable where here the variables are on edges brings unification between empirical uh data coming in from the outside or passed around internally and broader distributional perspectives and then the fourth constraint is moment matching which replat the hard marginalization constraint used to include the entropy of edges and so this lo orginization as now only the moments need to align uh and equation 8 contains both note and Edge terms since the moment matching constraint applies to both at the same time uh and they apply the both at the same time because of the the top uh formula and the middle one the middle formula shows uh the sufficient statistics described by T capital T and so basically what this means is that you pick a distribution and you only pick the moments so the first one would be the mean of the distribution tion and the second will be the the standard deviation and so only those need to fit you don't care about the rest and P substitution is the final piece needed to represent active infen on a constraint for Factor graph and constructing the local generalized free energy using mean field factorization and P substitution was only done to represent the L active inference on aint for and recall that P substitution involves substituting part of the model P for Q in expectation only and that is the the formula on the the bottom and it's represented with a square in the for Factor graph and equ shows the substitution on figure 13 replacing uh the local variation of free energy with a local generalized free energy oh replacing Q on the data or on y with P that conditions on x and z this red piece is being called attention to and we'll we'll unpack that more with the authors and on top of that uh lastly the the authors compress the the constraints forc to make it easy to read and only deviations relative to the default battery energy are shown and the bechain is introduced as a series of bead beads connected by edges and is summarized if it contains no extra information and the authors go in really into depth but I will just keep it to this where they go from the left image to the right so the right is the cleaned up F Factor graph and then you can easy more easily compress it and make it smaller for very large diagrams yeah allow us to kind of compress or skip through the uninformative parts and just call attention to the new information that's being intersected then in chapter six they highlight how classical active inference and original generalized free energy algorithm are special cases of the developed lonian active inference so an integral part of message passing algs is the choice of a schedule which Daniel already explained and the which is the order of messages uh up in which they are passed iterative methods are sensitive to the order and thein active inference is an iterative method and might be sensitive to the choice of schedule so choosing the schedule carefully allows us to recover classical active inference planning algorithms as a special case and figure 20 on Blow shows the constraints for Factor graph as a composite note of a composite note for the Lin AC inference on discrete State spaces uh equation the equations on the right show the corresponding factors where ha is defined as a function of the transition Matrix required for the other equations and figure 21 shows the message updates uh some cannot be solved in closed form and instead require multic estimates uh U ofx is the average free energy of the composite not and corresponds exactly to expected free energy of us and standard active inference where a composite notes the the block with striped yeah strip block around it m of set and M of a are solved differently than the rest they require c bar is solved using Newton methods as it tends to fluctuate between multiple extreme and Ma is estimated using a sampling procedure and so uh below shows the generative model of a discrete pump and the equations uh to below that show the factors and note again the head on U so that the AES are fixed and calculating the generalized free energy is still using a forward sweep which you can see with the arrows arrows on the bottom right going from left to right and summing the free energy terms over all the substituted composite notes and these should then be equal to the result from the shown equation cool these images are just so interesting even without knowing what they are and reconstructing original generalized free energy method is then a matter of including past observations for past time steps adding data constraints while for future time steps adding P substitution and naan field is applied to all the notes the schedule the order of messages is shown below the update equations of the generalized free energy using this model are the same as of the expected free energy and then the authors work on our example uh which is the the classic teamm task uh yeah so the tools in this paper are not limited to restating prior work uh it offers more advantages one of which is the ability to directly infert a policy instead of uhing post hog selection uh choose using actions which have the best energy terms instead you can do it immediately so the optimal action is to take is therefore to visit uh but the optimal action in the teamas is to first visit four because you can get information about one uh two and three rather than immediately try to go to two and three and that is uh yeah the Hallmark of an active inference agent yeah lot to explore here but instead of relying on the post talk comparison of energy terms this is in reference to the way that usually expected free energy is used by taking in habit the policy prior and then iterating over every element in pi the policy prior and sharpening or updating them according to the expected free energy with the pragmatic value and the epistemic value component so you get some policy posterior and then you might select simply the best one or you might take some temperature guided sampling across the policy posterior so that's a post Haw comparison of expected free energy terms and with the that the gener models now have the ability to directly infer policy potentially without explicit consideration of counterfactuals or at the very least without this kind of a post Hawk comparison and so they build on that uh and create yeah a full model and note that in equation 47 they use a mix mixture model of candidate transition matrixes indexed by uh UK so each action has a different transition Matrix and yeah a buch of illustrations and figure 28 shows an agent that initially prefers the epistemic action and so moves uh down to State four and subsequently exhibits a preference for either of the potentially rewarding arms so goes left or right and this shows that the loan active inference is able to infer the optimal policy and another approach can reproduce P results of the teamat and then the authors uh do it again but now by adding a data constraint and this is Sim similar to using a maximum posterior estimate which basically means that the action is yes or no so it's 100% or not Yeah by by pushing through the point Mass constraint kind of like that derck Delta constraint all that can be shared is the first moments which is just the data points values so here it's like you might have a 70% chance of doing thing one 20% 2% 1% but then the action selected is decisive and so you have this decisive passing of action and the the decisive realization of location even if also there's like a location distribution that includes Support over the entire maze or a policy distribution that includes support Over All policies and then to conclude in this paper we have proposed a Noel approach to active inference Based On LAN optimization which we have named Lan active inference we demonstrated Lan active inference on a classic Benchmark problem for the the literature I found that it inherence epistemic drive that is hmark a hmark feature presents three main advantages over previous algorithms first and Advantage is the computational efficienc afforded by being able to pass backwards messages instead of needing to perform forward houts for every policy like aearch so it skills linearly over time a second Advantage is that it allows for directly inferring posteriors Over Control signals instead of relying on model comparison uh like Daniel just explained and thirdly it is in heavly modular and consequently works for freely definable constraint for an effector Cas while PR workers focused mostly on specific generative models and they have also introduced a notation for writing down constraints and P substitutions on a forny graph and the constraint factor for graphs are useful not only for active inference but for specifying free energy functionals in general and authors hope that this can become a standard tool similar to foror grass when it is desable not just right the model but also a family of distributions in the future work the plan to extend uh the work to more node constructions to further open the scope uh that can be attacked with active inference awesome work B great job preparing it yakob anything you want to add on part one no at the moment okay scaling linearly in time is really fascinating like if you planned 10 time steps should the 11th step be a 10% bump in difficulty or should it be another combinatoric explosion every little kilometer deeper into the future so second paper Okay first just going in deeply to the first sentences before accelerating across so they begin the paper saying free energy principle postulates that the behavor of biological agents can be modeled as minimizing a variational free energy and this is commonly brought up that we can model biological agents as or through or with minimizing variational free energy just like saying we can model this regression by fitting an L2 Norm we can model this biological agent by fitting the elbow or the VF active inference which is aif in this paper is a Cory of the Fe that describes how agents propose effective agents by minimizing an expected free energy objective that internalizes a generative model GM of the agent's environment and prior beliefs about desired outcomes so vfe is the real time Behavior minimization EF brings it into the prospective setting by introducing epistemic imperative and also talking about observations that haven't happened yet variational objectives for active inference can be minimized by message passing on a forny style Factor graph representation so everything we know about basy and graphical models transposes into the FFG space the FFG is not a kind of base graph it is a dual a different kind of graph conveying the same information in a restructured format that we can then optimize or Implement differently several authors have attempted to scale active inference under message passing framework however agents based on these approaches lack crucial epistemic characteristics so one question why was that was it that previous authors only modeled vfe but not EF or was there some failure of the EF loading on epistemic value I think the answer is the first one in part one they identified this Hiatus in the specification space and they introduced the C FFG and and then in part two which is the current paper we use the cffg notation as introduced in part one to Define locally constrained variational objectives and derive variational message updates for GFE generalized free energy base control using variational calculus the resulting control algorithms introduce epistemic behavior in synthetic active inference agents we reason purely from an engineering point of view and do not concern ourselves with biological plausibility what a sentence in this paper our contributions are three-fold they use variational calculus to derive message update expressions for GF control they derive specialized messages for discrete variable model and they implement the results in a reactive programming framework simulating a perception action cycle on the Tas with a full message passing account and reactive implementation of GF optimization it Bec was possible to derive and reuse custom message updates across models and get a step closer to realizing scalable synthetic active inference agents for industrial applications so what is it about their contributions that makes the industrial and the engineering work more transferable or scalable then they summarize the coming sections section two reviews variational base section three reviews active inference perception learning and control in terms of message passing on the cffg section four focuses on the constraint definitions around a submodel of two facing nodes hash Alis and Bob and derives stationary Solutions and messages for GF based control section five applies the results to a specific discrete variable goal observation subm model that is often used in aif practice they then work towards implementation in a simulated setting and describe a perception Action Cycle in terms of time dependent constraints section six the team A's task is described in section s and simulated in a reactive programming framework in Section 8 section n has a summary of related work and the conclusions are in section 10 it's also useful to put table one and table two up here table one is an overview of notational conventions nice list of letters would be awesome to connect to the active inference ontology and then table two has a bunch of acronyms okay section two review of variational message passing so this section briefly reviews variational message passing as a distributed approach to minimizing variational free energy so first they review variational base 2.1 then 2 . 2 they review forny style Factor graphs 2.3 they move to the Beth lran optimization using the Grange multipliers we can convert the optimization on Q to a free form optimization problem of lran where the lran multipliers enforce local constraints the fully local optimization then becomes this expression again more to say they're using the lonian constraint framework and the Beth flavor of free energy which is already node local to provide a very constrained which is to say possibly more solvable and tractable node local computation and now they get to the constrain fory style Factor graphs as we heard in part one an FFG alone does not unambiguously define a constrained vfe objective interesting question what is needed for that unambiguous identification of the vfe and so here they review their cffg notation here's figure one and we can again see that they go from the initial Factor graph on the top left with an explicit cffg on the top right then they compress it down to the bottom left and then that uniquely identifies a logistical or an operational schedule section three review of active inference by variational message passing in this section we work towards a message passing formulation of synthetic active inference we start by reviewing active inference and the cffg representation for a GFE objective for control so 3.1 they Define active inference 3.2 they Define generative model now they go to message passing in this section we formulate a synthetic active inference uh as a message passing procedure on a model of past and future States in inference on a model of past States relates to perception and learning while inference on a model of future States relates to control what is control if not just perception and learning we haven't had yet figure three constraint 40 style Factor graph representations for variational objectives on models for past left and future States right I don't know if one has to cross their eyes or do some other magic visual experience here there are some small differences like here there's a dashed box that's not here there's a data constraint clamp dangling edge here whereas that constraint is open here however the rest of the figure looks pretty similar and that tantalizingly point points to some similarities between learning and memory in the past where we can clamp down part of the model to be data and consideration of the future which is to say action and control where the observations are distributional beyond the dirck and they haven't happened yet and we have agency over them happening any thoughts on that either of you it's kind of cool and it's kind of foraged in in some of the other graphical models but we'll ask the authors 331 talks about past States and then 332 goes into the model of future States so a lot to read in the paper but that key idea because future outcomes are by definition UNS observed we include goal priors on the future observation variables those are preferences we expect there to be observations and we know that they will become constraint to derck likee form but in anticipation we take a distributional approach to observations that haven't happened now what if we had uncertainties out the past and we were doing kind of a policy like search in our fuzzy memory then where would time be section four they get to General GFE based message updates in the model for future States the goal prior and observation model impose simultaneous constraints on the observation variable in the corresponding cffg this configuration is modeled by two facing nodes so I I believe those nodes might be the two in the dashbox here in this section we derive the general GF based message updates for paap facing notes we express the local optimization problem as LR using variational calculus we then derive St local stationary solutions from which we obtain General update expressions for GF based messages so they describe the the goal and the obser ation model 4.2 local agian after the substitution of the factorization and applying P substitution to the local variational free energy objective they get the local GFE the GFE is all set up to construct this lran and to do a variational optimization on that lran to get qar 4.3 local stationary Solutions we are now prepared to derive the stationary points of the node local lran we start by considering the node local lran as a functional of the variational factor Q subx LMA one stationary points of L as a functional of Q what does LMA one do or show LMA two we derive stationary points of equation four as a function of Q subz note that by symmetry a similar result applies to Q sub Theta what does LMA 2 do or show in this section we show that the stationary Solutions of section 4.3 correspond to the fixed points of a fixed Point iteration scheme theorem one theorem two what of these theorems do and show 4.5 conversions considerations some further considerations and a corollary One what does it do or show now we get to five application to a discrete variable model in this section we apply the general message update rules of section 44 to a specific discrete variable model that is often used in aif practice using the general results we derive messages on this specific specific model and so here we see figure five with all it's been taken all the way to the point of the logistics of the messages for those two facing noes 53 data constrained message Updates this uh the message updates for a data constrained VF objective figure six on the left reduced to standard variational message passing updates as derived by citation 28 and appendix a so here we have those two nodes with the dero intervening here we had X intervening in figure five so we had a distributional bandwidth now we're dealing with a d distributional bandwidth or Channel which is to say a data point being passed now we to section six perception Action Cycle in this section we formulate a perception Action Cycle that extends upon the GFE formulation specifically we illustrate how cffg notation allows us to be explicit about local constraints as a result the perception Action Cycle can now be visualized as a process that modifies constraints over time pretty cool at the initial time T equals 1 no observations are available and we initialize the perception action cycle with the cffg of figure 7 on the top we got A Sneak Peak earlier now is real figure 7 as actions are executed and observations become available data constraints replace the P substitution on the observation variables so it's almost like the P substitution prepared us to flip it out with data in some way like data constraints are a a secondary or a further constraint that is enabled through the P substitution when the time Horizon's reached and all observations are available on the bottom data constraints replace the P substitution on the observation variables so it's kind of like we'll know when we'll know and then it'll all be inferenced like memory but before we know what we later found out it's more like control so whether we're in a retrospective memory setting a real time sens making setting or a prospective control theoretic setting it would be pretty cool to have like a mega unified imperative and ATT tractable local procedure to do it which in a sense is what they do so the perception action cycle with time dependent constraints thus unifies the tasks of perception control and learning under a single generative mod model and schedule this is the huge piece is only through the FFG and then the constrained FFG can we get to not just making a base graph of perception cognition and action cool enough bring in an explicit node local scheduling and Logistics approach wow the experimental protocol is summarized in algorithm one all it requires is a generative model and a variational distribution with Associated constraints and then it's kind of like a dance do infer act execute observe slide we then get to section seven with the experimental setting in this section we describe a teas task that serves as a classical setting for investigating epistemic Behavior Citation 10 the setup closely follows the definition in 30 Citation 10 is frisen at all 2015 active inference and epistemic value and citation 30 is from F Velar at all same authors in 2022 active inference and epistemic value and graphical models so here we have the Tas that was shown earlier with a smiley face no smiley face here and it's laid out and labeled starting position o q q c that's where the epistemic value is and then L and R the two reward arms and just for for those seeking continuity here's figure 7.4 from the 2022 textbook here we have the 2022 active inference mouse in a Tas and from 2021 here's our active infer ants simulation where it's actually appropriate the nestmate is like much smaller so for the nestmate they can wander around a lot inside the teas that for the mouse it only has one location it can be in so it's not as closely Allied as 7.4 is with figure eight here but it's like the same you could do it in the same lap they further specify the the teamas and the probabilities of different things happening they further specify the teamas and the probabilities of things happening and then in figure nine they get to a cffg describing the teammates let's go through it with the authors and annotate what it means we have execute the same experimental protocol as before and plot the minimal free energies in figure 10 top right the BFE based reference agent fails to identify epistemic modes of behavior the specific choice of Prior for the observation Matrix prevents any extrinsic information at least initially from influencing policy selection by the lack of an epistemic Drive the BFE based agent sticks to policies that confirm its prior belief without exploring Poss possibilities to exploit available information in the tma's environment a histogram of Ideal a histogram of the number of wins per run is plotted in figure 11 on the left the histogram suggests a bodal distribution with a large mass group to the right and a smaller mass in the middle for reference dashed curves indicate ideal performance for agents that already know a from the start for agents that first must learn a deviations from ideal performance are expected the smaller middle mass then indicates that GF optimization offers no Silver Bullet for simulating fully successful epistemic agents namely for some choices of initialization the GF agent may still become stuck in local Optima section nine I won't read it they describe a wide swath of related work range in from early work on the introduction of for graphs on through expected free energy and active inference and in section 10 they conclude they took a constraint Centric approach to synthetic Act of inference they simulated a perception Action Cycle through message passing derived from a single generalized free energy objective and dot dot dot in this paper we have adopted a purely engineering point of view and we have not concerned ourselves with biological plausibility specifically the derived message updates come with considerations about stability and non-standard expressions although we have engineered solutions to overcome these complications it seems unlikely to us that the brain resorts to such strategies interesting mic drop but very humble and so now as we give our last thoughts we've always held up the side by side at The Institute with a minimum of two and we've talked about that before in the textbook figure 4.3 setting with continuous and discreete time but there have been many other Min too experiences that we've all shared together and not just with this diad of papers but with this new int eligibility of the relationship between Bas graphs and different styles and constrained forms of for graphs we're in yet another Min two setting so say ining as we include the zero uh yeah I look forward to the point one and point two have a bunch of questions about for example what P substitution really means and um for example the the time window how many uh time steps you need to give your model already or whether it can afford automatically uh and just in general to hear what they have to say because it is a very interesting topic yeah um same here also interested to um hear what the authors have to have to say and um I think yeah whenever there's um um whenever there's a generalization that um at least in the semantic space uh affords a wider um wider connection to different methods and especially in the context of uh models represented on the graph I'd be interested to um learn more about how we can represent agents in different kinds of graphs or how these constraint for Stell Factor graphs um afford different types of uh optimization methods to be performed on them um and how this work can help active inference to interface with uh other domains which try to solve similar problems or perhaps different problems from a different angle awesome my last thought is like we planned to learn learn at least to try here so I commend you both for that policy selection and now looking back it's like data or a memory and then in science it's like oh it's 1994 this new genome is available or like this new thing is exciting and here's the next step and it's like one must be as excited as can be in making the right measured decision then which later becomes an observation at a different time Point yeah and a different perspective so there are probably many exciting and important syntheses that this work is going to build our skills and our expressivity around and the computational element is just excellent so thank you again Burt and yakup see you Fells in the do one all right and