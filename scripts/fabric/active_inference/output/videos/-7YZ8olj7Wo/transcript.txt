okay it's September 16th 24 and Andrew is going to give an overview of chapter four then we'll see what questions we have slash other questions already written so go for it Andre thanks Daniel uh yeah so again this is chapter four active infer uh 2022 textbook uh we're working with cohort 7 so this is the first week of going through chapter 4 so I figured I'd give uh an overview of the chapter uh we're already told off the bat in uh section 4.1 the introduction uh that we're going to be introduced to the relationship here between free energy and basian inference uh the form of typical active inference generative models that we often see in active inference implementations uh and we'll also look at the Dynamics obtained from minimizing these models free energy so specifically we look here at both discreet and continuous time models as well as the neurobiologically motivated idea of inferential message passing underlying the computations and predictive coding involved in active inference um so again this is this is the first half of the textbook so this is much more more Theory rather than direct implementation however chapter 4 is particularly uh mathematically involved uh in comparison to the prior three chapters um of course bases rule figures very strongly here so we see that in section 4.2 from basian inference to free energy um so we recall that we're working with approximate inference rather than exact basian optimality uh given the problem of tractability or intractability uh as well as neurobiological grounding of uh of limited resources so the idea being that for biologically plausible models we have to actually consider uh any kind of um computational limitation of resources or metabolic and other biological uh limitations on the processes that that proceed during pre- energy minimization so that's the kind of matching between biological plausibility and why we're looking at approximate rather than exact uh uh free energy minimization so the uh or rather surprise minimization the mathematics involved here are drawn from linear algebra uh differentiation and calculus and the tailor series expansion uh the textbooks appendices give further details on the relationships between these fields so I strongly REM uh recommend looking at those uh if you if you are still kind of learning the maths involved uh we're shown in equation 4.1 bases rule uh so here this this helps us to better understand a generative model and active inference uh which is a generative model can be described as uh here we can see it as like the probability of x times the probability of Y conditioned on X and then we can flip those around on the other side of the equal sign uh and so that that gives us a way of understanding like we can we can use B's rule to potentially update any aspect or any component of B's role uh whenever something new is updated just kind of uh sort of plug and chug for the rest so to speak right so that means whenever we have like new observations uh come in so our model our our our active inference agent observes a new observation we can update its uh posterior beliefs about States so um so part of how we're able to do this also this is kind of a key aspect to understanding what free energy is relative to surprise and a lot of the other theoretical terms that were introduced to um Jensen's inequality renders optimization here possible since minimizing surprise itself would be next to Impossible it's intractable whenever it comes to like very complex models uh integrals that that Things become rather difficult to keep track of or there are limited computational resources whenever doing the kind of computations involved with numerous or highly complex matrices um we we can use Jensen's inequality which is uh this idea that the log of an average is always greater than or equal to the average of a log um it's you know I don't want to call it a trick but in a in a sense it's what allows us to say oh this uh this tractable uh variational quantity we call free energy is always greater than or equal to surprise um that we can see how that math is played out in equation 4.2 on page 65 so the idea is that uh free energy becomes this tractable quantity that we can calculate uh it it it becomes an upper bound on surprise so well if it's the case that we can't perfectly compute surpris in all cases we can compute free energy and so if we know that we can reduce that free energy as much as possible uh it's it's going to close in that that bound that that bound is going to move further and further down closer to to zero such that you know if if we can ideally we'd want free energy to be zero and hopefully that's a good approximation of surprise beinging also being zero it necessarily would have to be so um in equation 4.3 we're also introduced to kind of a broader um way as well as equation 4.4 uh how to actually compute pre energy and so we can see that that's a combination of two terms a KL Divergence or koback leeler Divergence which is a way of kind of quantifying the difference between two distributions how different are they from one another uh and so that's that's why the Divergence term has these two different uh terms within it right it's the difference between our variational posterior Over States Q ofx uh the the difference between that and the um uh probability of X condition on y so so it's a way of kind of finding the difference we can minimize that as much as possible then all we're left with is negative log model evidence which itself is kind of a proxy for surprise so if we can minimize the Divergence as much as possible then we come very close to also uh minimizing surprise so um section 4.3 I'm just going to make a couple jumps here because it's the rather broad chapter um section four 4.3 were introduced to uh Factor graph notation for static perception models first uh which are kind of like a precursor to eventually get getting into active inference uh in static perception models we're we're just dealing with perception call that active inference is a combination of action uh uh perception and action you change your mind or you change the world and so without action we're just left with this kind of static perception right so it's this kind of model that updates based on new data but it doesn't itself act it doesn't do anything to change the world and and therefore it also lacks many other components uh in it in its architect texture that you would find in a full active inference model um so it gives us examples as to how a prior and likelihood the core components of a generative model are involved in the the model computation uh we're kind of explained like in terms of like binary classification how we can look at a static perception model through positive and true negative rates folks who are familiar with the kind of machine learning not even necessarily machine learning uh but but that that kind of logic is very much at play there um and then in figure 4.3 we're then introduced to active inference models specifically in figure 4.3 there are uh discret and continuous models uh where a temporal Dimension has also been added where states are conditionally dependent on the state at the prior step that is the model carries its own beliefs about how States transition over time so um here actions and po or or policies policies are considered to be sequences of individual actions are introduced and as I mentioned State transitions are introduced the agent actions derived from their policies impact the environment and observations they receive over time so as we recall agents are are self- evidencing so what they will do is that they have a belief about how to go from state to state via acting and then by acting they're going to choose actions that hopefully will elicit the observations they want to see and we've all uh already been introduced to the idea of preferences just like a prior over observations so the idea is you you you expect to see or not necessarily see but observe particular observations and so you act in order to eventually make those happen so if someone uh you know is hungry and they want food or they expect food then they act in order to obtain it you know and eat it and so on so it's uh it's this one of the most interesting kind of uh aspects to the framework of active inference is the is the self-evidence thing but it it in fact plays out in the model logic um as we look at it here in this chapter so to get further into those components uh section 4.4 goes more into specifically discret time models where we're looking at specifically partially observable markup decisionmaking processes where as we know from previous chapters the agent has no direct no direct access to the true states of the world and can only infer them um so the agent will attempt to infer them through free en free energy minimization over various model components so we in a PDP in this case uh we can map the components we've covered previously to components of the pp uh a is our likelihood model which we've already seen in the equations describing a generative model um B is our transitions model I already touched on that it's the it's a it's a distribution over what is the next state going to be given what the current state is as well as an action that the agent can take now basically what is going on now and what should I do in order to get to a more preferable State um and then D is our Vector of Prior overstates so what does the agent believe at the onset uh that's a it's sort of like the initial belief that's kind of right for being updated and then uh as I already mentioned earlier we have preferences or the C Vector over expected observations um we're also introduced to G as a Quant to be minimized uh it's not exactly equivalent to variational free energy which is often denoted F because G is kind of like the uh free energy of the future or expected free energy and that's where it's it's within that competation that c actually gets directly included so it's kind of like it it allows agents capacity for planning that is they actually incorporate what they want to see into uh kind of their policies and ways of inferring how they should act uh it's it's really in G that that happens so we can think of G as as like kind of planning towards the future meanwhile F variational pre energy is minimized sort of Moment by moment you know um we can also further decompose G so as we saw earlier F to be uh decomposed into like a Divergence term in a negative log model evidence term so with G this can be broken down into actually many ways uh one of them is info gain or Information Gain or epistemic value all those are equivalent uh and pragmatic value and these are probably this is one of the most uh interesting to me personally one of the most interesting aspects to active inference which is that uh G takes account of not just how can an agent realize its goals in terms of pragmatic value which can also kind of be likened to the word utility as it's used in economics or or Game Theory um but also Information Gain which is an agent actually will act to reduce uncertainty so part of that involves engaging in exploratory behaviors where the agent isn't necessarily trying to immediately uh realize a goal it has instead it might be seeking more information about say the environment that it's in you know so it's kind of like if you if you plan to to fulfill a project like uh you know you could sit down and try and do the project but if you're not sure what kind of research you need to do yet uh and you you skip that that those preliminary stages of seeking more info uh in order to realize your goal of finishing the project then you might end up creating a very subpar project right and so so all of that plays into kind of classic uh in reinforcement learning and other other domains like how do you balance or even Define uh exploratory Behavior with exploitative behavior um exploitative meaning directly realizing goals which is also relatable to that pragmatic value term that we saw expected free energy so the idea of expected free energy part as an answer to that kind of explore exploit dilemma is that you the idea is you can have both you can have both of those included and Via uh expected free energy minimization the agent kind of naturally balances those two things it doesn't mean that they're always going to be literally equivalent it doesn't mean like 0.5 for one and 0.5 for the other it just means that uh the way that this is commonly done in say reinforcement learning is that the programmer has to uh choose some way of defining what exploratory behavior is and more often than not it'll be through some kind of uh arbitrarily chosen uh rule such as Epsilon greedy Behavior which is where you say okay the agent will try to fulfill its goal with a probability of 0.9 it'll pick an action uh that it it believes best to fulfill its goal and realize that pragmatic value of 0.9 uh but with the probability of 0.1 it'll just do something random right um and then that becomes equated to exploratory Behavior active inference is is is very different right because you don't have to do that uh at all the the modeler doesn't have to make a definition of what exploratory behavior is it's the agent who sort of autonomously decides what is exploratory behavior and it's not necessarily doing it randomly either right that's another trueu aspect so um forgive me if that's a lot but I'm personally interested in that that side of active inference so and I think it's very valuable uh in in applying active inference to other fields that more typically do try to resolve that that explore exploit explore exploit uh dilemma but don't always necessarily have an answer for how to go about it um to wrap up uh the some other topics that were introduced to or at least uh that are discussed or brought up in this chapter are uh marov blankets separating the agent from its environment or a system from uh as Mark Stone says the not system uh right so it's it's a it's a way of finding statistical independencies such that you can actually Define a thing and kind of separate it out from the environment around it which is what allows us to kind of delineate like here's where free energy is happening it's happening within this agent and not U you know it's internal to this this particular system right um we're also some other topics include generalized coordinates of motion um that'll come up much more in chapter eight future so I won't go into it but uh that's used more expressly for continuous time models and that's sort of how the free energy uh computation plays out so a lot of it just relies upon ideas like Taylor series expansions right so as you as you add more terms you can potentially become increasingly more accurate at at kind of predicting what direction uh certain quantities will move going forward and that's what allows for the agent to start to uh making these kind of continuous time predictions and then update its beliefs accordingly um basy and message passing uh mess passing which uh which we'll figure much more in chapter 5 um but we we just kind of get a hint of it right now this idea yeah um passing messages along cortical layers which can be represented in a a broad variety of ways um you can you can represent it more uh distinctly as like these are cortical micro circuits or you can represent them as more simply like nodes and edges uh on a factor graph and imagine it like a a message passing kind of network um the the active inference Institute we we working with Folks at bias labs for example who have a very interesting way of of representing uh message passing on on Factor graphs or what they call constraint forny Factor graphs um it's a really nice kind of uh ning clature and and and and generally quick way of like um sort of normalizing how we represent these kinds of things because it allows for further work but in any case U message passing yeah has messages being passed different kinds of local computations being formed passed around so kind of reminds of uh communication in the brain you know our uh our neurons are not all uh fully connected uh we'd presumably be very overloaded if that were the case so we're dealing with these kind of you know sparse networks that uh you know pass messages to each other in kind of certain kinds of distinct ways um that you know at a broader scale allows us to update our beliefs following the active inference framework so um I'll leave things there uh sorry I realized now that that intro was much longer than it than I planned but uh I'll open the floor if anyone wants to to discuss anything or has any question questions or we can go into any particular topics thank you yeah as you pointed out it it it's a interesting chapter with a mix of both seemingly General mathematical points to make like base theorem Jensen's inequality as well as putting some details in the appendices and of course even more just implicit for learning but General mathematical details General visualization motifs and then it's kind of like the sighting of the models that will resurface in seven and8 with an interl of five being the empirical evidence and studies in the most well studied setting just by like number of studies the human nervous system then six with the recipe before going too much into the details of these specifically so it's almost like fours a preview plus a bunch of background like pmdp again a general long existing um way to model perception and action so it's interesting that for really contains a lot of general math and learning before and after a sort of preview of where it's actually going to be described in more detail in seven and eight after the recipe is shown and the evidence too yeah definitely yeah this uh and just as four is a kind of preview for the second half of the textbook it's like chapters two and three are also sort of these four runners up to chapter four um I I feel in that chapter two we have the low road uh and so we can get to active inference from B's Rule and so but but of course before we can get there for anyone coming to this textbook who's interested in um kind of cognitive computation in Neuroscience uh it maybe maybe you have to kind of take a the step to say how do we how do we teach people about this from the ground up and how do we get their interest and so so to begin with the basy and brain hypothesis for example and starting with the bases role I think you really do have to to kind of make that point and and describe it well but then of course we're going to have to get to the mathematics about it and if we present all of that simultaneously um I don't know how well the rest of the textbook is going to read so we do have this kind of back and forth between dropping this into the mass we pulling us back out like resurfacing like where where are we now and then chapter 3 oh we go much further above the surface now we're at the high road and we're starting there with free energy manifestation so in a certain way I think the chapter 4 kind of brings us like it's like oh both roads have now met now we can now we know that we're starting with B's role from the bottom and we know that from the top and so now we get to get into Factor graphs and and uh message passive and the actual like derivation of free energy and and why we can justify the computation of this quantity free energy using ginon INE equality and all these other sort of details um I think chapter 4 is great in terms of I think it covers actually so much it's sort of like it precursors so many more advanced ideas but then it also gathers together all the kind of simpler components in the preceding chapters and it's tough to find a concise way of summarizing it though I will say let's look at any questions or see if any are typed but let's just see let's go from the bottom just if there's new ones okay okay oh wow how how are games related to active in generative models okay that's someone thinking about how to to have a playable generative model also another another well one one reading of of how games are related would be we could model games like Checkers chess go tic-tac-toe has been done Game Theory Etc then there's the point that Jana made there about the visualization and then another Avenue that some people are exploring like Pablo FM this was like experiential actm games to where we based around ontology terms and and um role playing and then also Pablo has has made the three 3D adventure of curiosity game any other thoughts on how active relates to games okay I think yeah I think they immensely relate to games I just want to say that really quickly like uh you know in the in the same way that because I don't know how generally the person means that question but I I also think of it as in the way that we can try and understand any entity in its environment whether it be you know a neuron within a cortical layer or it be Mario jumping on uh enemies and getting mushrooms in a video game uh like what we're kind of doing is is that this all relates to the idea of studying p uh and how things kind of act and and behave and and how they update themselves internally as well so um I mean that would that would be my answer I think that you could potentially given the right like model architecture you could have an agent who plays almost any game um I I I could easily see that being doable and and reinforcement learning more generally uh already I mean people are using that to to both create games as well as uh you know take existing games and so that's that's been done and so you can very much do that with with active inference as well um and then the fun part is if you do both uh other methods in reinforcement learning and then Benchmark those and compare those two active inference models um a fun way of doing it so any also this made me think about um discreet and continuous time nested models so it's like baseball the way it used to be played you have the inning structure and then the discrete time with the pitches and any amount of time could it collapse between the two um events and then there's the timed games like continu time and then when more recently they added the the shot clock or pitch clock to baseball then that's like there's a discrete structure of of events in at bats and innings but then also it's like at the lowest level there's a continuous [Music] duration it's not exactly the same thing but it's just kind of like you can have dis discri nested with IND discreet continuous nested within continuous or the Hybrid models that are in chapter8 and then a common hybrid model for the folk psychology and for the updated baseball timing is the continuous on the proximate level and then the discreet at a slower level yeah that's a nice Point like with with baseball on the one hand there can be kind of a realtime visual process say you're a batter for example um there can be a a sort of continuous realtime processing visualization for you of of what the pitcher is going to do what kind of like throw that they're going to do and uh so you might be processing all that in real time but you could almost consider like the classification of oh they're going to pitch it this particular style or this style like and then you can make that as kind of a more discreet classification choice of like that's what they going to do more exactly so you can have definitely that sort of interplay based on how you do the nesting in the model between these like continuous uh observation inputs or variables and and making these kind of discrete choices and the other way around I think could work as well what would you say does active inference require SL describe let's separate it into two questions what would you say for these two questions does it require observable behaviors does it describe observable behaviors that's if we take the theoretical presuppositions in the first half of the textbook to be true or at minimum entertain them then I would say from one angle no they don't require observable behaviors but then that I mean that's really going to get into like kind of philosophical semantic discussions of like observable to whom right um like is the inside of a rock currently minimizing free energy I can't see it uh it's hard for me to even say it's Behavior because it doesn't really match up with my typical notion of a behavior which is where I might see something moving or varying over time um but if you take the free energy principle to to if that's still standing for you then uh yes like free energy minimization is occurring is occurring in many many different systems around us and so that said if you would like to if you as a as an experiment scientist would then like to go on to describe something in terms of active inference by observing Its Behavior um then it kind of just depends upon your experimental methodology right are you are you studying um are you studying a mouse in a teaz experiment uh like that that that more easily is observable in the in the sense that I think this question is coming from uh then again we also observe tons of like social human behaviors where it's immensely more difficult to experiment and see how active inference works there but if you take free energy if you agree with the idea of free energy minimization then you can start to kind of infer uh use that as an axene so to speak and kind of make inferences about how you think the whole society of people behaves or or try and explain Its Behavior based upon that in active emerance terms and from there you could attempt to model it um but anyway I think I'm getting further away from the original question yeah I mean it's it's you're right though does does it require observed behavioral I mean if you're observing something every phenotype can be seen as a behavioral you know that's the leg length behavior of that time and scale and system but like without the observable it's like okay you know it's it's I'm I'm imagining this creature's femur but it's like but then is that a mental observable so that does get into like C can you you know would describe something that wasn't there but then what what are you really trying to what are you really trying to do with that model let's delete this one okay both the dot and the prime are used to indicate a derivative equation 47 yeah great question here the ticks are used for the generalized coordinates of motion so that is first second third Etc derivative that's happening these two stacks for two paed equations Y which is the primary observables coming in from the Imaging for example and then x dot which is the spatialized flow map of the underlying neural States so just fitting a one layer fmri model you have the fmri raw data coming in with the observables on y that's like the input for the regression and then you're fitting a rate of change on neural activity so that dot is like a special just reflecting that you're modeling a sequence of observables and an underlying flow landscape and then both of those are being modeled across this applied series of derivatives for the Taylor series yeah I think that's well said whenever it comes to the more strictly mathematical I'd rather not add too many yeah it's hard to know yeah it's all good okay the primes are just you know more more primes means you're just expanding the the Taylor series expansion further outward right by adding more terms but then the dot is like that rate that you're trying to yeah to approximate and it's super it is very general and then it's like but if you're then then that's something that Carl has joked about with like this is like s say how many layers the brain have or how many layers of tempal depth and he'll say like five or six or something and then say like just because that's how many cortical layers there are first off but but that's always been interesting me because the cortical layers are not the hierarchical basian layers each cortical columns five or whatever layers are one hierarchical element so I don't understand why he describes it in terms of then the anatomical layers but that being said then just also realistically higher derivatives outside of edge cases may be less important or there's ways to just make them go away which is like why PID control which only goes to to two or three generalized coordinates is enough for a lot of Robotics settings okay for 411 some previous times I know we've discussed the italics and the Bold okay 4113 okay um I'm not sure who wrote this I don't know who wrote it or who could evaluate right now but it's all yeah so I mean equation 4.11 that's that's like a decomposition into a sum over time like what you're going from free energy to like you have that like f subscript Pi tow term which I believe isn't that referring to like here's the evaluated free energy of a particular policy at a particular time step um like basically like it whenever it comes to policy inference because the agents are always like looking at whenever they're doing policy inference they're looking at like they have a planning horizon or inference Horizon thus the the to and as and to is usually used as like it's used similarly to similarly to T but the reason why it's a to and not a t is because like it's a reminder that this is the time step in internal to the model so You' be running a simulation for 50 time steps but if the agent's current belief is about now then it's just going to be to it's not going to be tals 35 it could be tals 35 but it'll still be just house agent then Pi being policy so that that was my understanding of that bit and then if the equivalent for S would be like here's the belief of you know what's going on now was just yeah this is just just just to show this is not accurate but then it's like but is it a force and then it's like is that a super deep understanding SL metaphor where like variational free energy is a force acting on a policy habit or is that just a rapit hole just a hallucination because it's not grounded in the ontology it's just looking at the latch Standalone and so it just picks a a plausible sounding interpretation I mean I could easily imagine skepticism yeah okay another good math question let's just see if there's any okay let's just why is the gradient of policy of f being zero C having policy which follows the soft Max not sure we could think about it more but but it's all good but yeah if someone has a great concise way to think of I been at it yeah I mean that that that term on the right was very like that's just policy inference that's just I mean they've not included uh you could include gamma and E uh in there but that's that's just the definition of of policy inference and where you're including spected M3 energy minimization and then on the left hand side the the upper is just the the gradient of f for so the idea is an agent will infer a policy that attempts to bring free energy to zero is is yeah how I see that if I just look at that one image long yeah it's possible it's like the stationerity for policy like if you're pulling from the best possible policy distribution you can't do better probabilistically than pulling from the best policy distribution that doesn't mean that you win every like coin flip or something but but you you wouldn't be able to out plan better than doing that yeah yeah you could yeah that's one of my favorite equations oh yeah oh yeah policy inference just because it's so it's fun to think about for me um it's like oh like here's a way of quickly relating G is like what I think will happen versus F which is like what I think is going on right now versus e which are my habits which are kind of like what I've accumulated from the past so it's just kind of like it's incorporating past present and future like really explicitly addressing like behavior and what someone does so so you could have like super precise like heavy habits uh you could think of like a cigarette smoker who deals with stress by smoking right it's like well your G might be great your F might be great but if your habit is like really really bad like really strong then that's going to overtake the computation of your final final posterior uh posteriors over policies such that you you go and smoke you know I don't it's crude way of like getting into it like that but uh I I just kind of I look at that equation sometimes I'm just like I don't know why I enjoy looking at this so much and like thinking about it anyway um but yeah we can move on to other question yeah like those are the two halves of inference there's perceptual sense making inbound inference and then kind of like full stop that that's on the A and then there's on the B policy inference and then there's so many questions related to that like what are how do you learn what actions you can take everything about habit and learning and updating context switching policy selection different time Horizons different tradeoffs different sensitivities a lot of shared apparatus with perception that's why it makes sense to model them in like a unified way and with a single imperative which is ultimately what happens the agents minimizing free energy on its joint distribution so it is getting jointly optimized and then yet still you can kind of hold multiple parts of it constants and then still like zoom in on just how how one part gets optimized or like how policy is updated without considering because it's factored off from the A and B are factored off through each other through the S markof blanket this one pending um the someone to write the verbal [Music] description or writing a prompt that can transfer these into verbal descriptions with the ontology okay nice a lot of good math questions what is meaning meaning of the Tilda ETA is this the ETA yeah I I think so is that the um that kind of doesn't that come in as some kind of additional cause or Force sorry I can't I'm not exactly sure here because I thought that'sa was this shape but maybe that's the uh we'll come back to this oh yes okay here's the the twin dynamical equations the fmri kind of classic equations here's the signal and noise of the sensor data here's kind of the dominant Trend underlying function and the faster frequency stochastic variation of the underlying neural map which could be itself noiseless as sometimes done like there's a Kind of Perfect noiseless neural flow landscape and then we're getting noisy sensors also it can there can be a noise term in the neural layer so it it's self is probabilistic and then it's like f and g it's just common modeling like just because f ofx is the first one and then it's common sometimes in notation just to use the next letter so there's a funny joke I will not repeat here just about like why the vitamins are named the way that they're named but it's like why are there you know 12 BS but then like why does it Skip it's not it's not an scientifically accurate joke but it's fine the syn ta for describing expectation is never described box okay someone can add more what is meant by Niche okay here's one answer environment of agent may be possible to modify construct and interact what would you say is Niche yeah it's uh it's like it feels so easy and tough at the same time um I mean it's the answer given uh seems really fair the first place my mind goes is uh it would be the environment of an agent uh but then that said like to give put a little bit more meat on the bone of why we would use the word each rather than environment is perhaps to emphasize the idea that as we could think of like you know any organism or animal or human or otherwise being within a niche we can think of like an environment that specifically like the the organism fits or maybe better uh is trying to fit right um so that that's kind of how I think about it it's like uh I I would be very out of my Niche if I were uh stranded on the North Pole uh without reasonable thermal equipment uh if I just teleported right now to the North Pole or something right um but to be where I am right now where you know I have an entire kind of ecosystem of like affordances around me that that work well with maintaining all these homeostats that make up the phenotype that is me at this moment uh that's that's a good Niche to be at I think um so I I don't know would you think of a niche that way just like it's like an environment but with like a with extra friendlier steps to the agent or something like that I don't know yeah those were all good that was interesting that it's like the organism or or system of interest it's like it fits there and also Fitness is calculated there so there's kind of layer and a half of of fitting in and then also like e logical psychology it's like no one was saying that organisms weren't in niches or environments yet ecological Psychology was was a call to incorporate more holistic and and kind of agentic ways of thinking about interactions with ecologies like well if it can't see that wavelength then it it doesn't make that ecological cue is invisible um then there's I think some of axle constant's papers have like separated the selective Niche from the the cognitive and developmental Niche and so I I think a lot of Niche Theory makes these sub niches but but yeah especially when you build the generative model then it's kind of like saying what is outside of the territory versus what is outside or you know what are the con what is labeled Niche on this map and then that's usually quite clear and categorical this is in response to the previous session asking about how priors originate the first prior in addition to self- evidencing optimism bias noted chapter 2 I want to notion the mention of genes as prior I.E genetic inheritance has been framed in active as part of the prior belief that constitutes itself I was unable to find it but believe it was suggested by Paul Badcock yeah the hierarchically mechanistic Mind Badcock ramstead constants priston and then perhaps more recently but not quite exactly um on on uh there with the empirical biological in the bio formatics data sets but but that'll be TBD here's an example of like the sensory motor interface of the worm and so that kind of primary behavioral layer of interfacing with the physical material Niche Etc like the light coming in and the receiving the the actions of the organism and then there's also a slower adaptive process happening one that can still be analyzed with particular partition Fe Etc renormalization and then here it's like well these are these are other these are beliefs about this is like a phenotype of a population being AIC distribution like you'd have height distribution so but there's a lot to do here to connect empirically yeah nice what what yeah that that that'll be what what are your last thoughts on uh four and Andrew and then slyy if you want sure uh I think all in all I think it's great I think it it serves up a lot of information that like I I would almost dare to say that if if you had to read a chapter of this textbook in order to get a sense active inference and you could only choose one chapter 4 might be the way to go and that said it's like you can't quite contain the whole textbook in that one chapter you have to read the rest too but uh it's good okay any other comments okay next time later or earlier for chapter 4 chapter nine a nice complement to four square numbers also skipping the generative model details to focus on on the on different parts of the math and science okay yeah cly go for it sorry um yeah sorry I I I um didn't really contribute a lot actually I'm just on chapter two at the moment so uh it's all just pretty new um but I um do mean that the next one will be on chapter nine if I heard it correctly well at this time like next week week at this UTC time yeah it'll it'll be but okay it's all good it's just going across different chapters I mean you could even argue for the advantages of it it's not like it's a story where you'll you'll get spoiled by reading the end yeah so just the earlier time then it then we'll be next week earlier however many hours ago chapter 4 part two just altering times yeah it's like we have two cor uh two cohorts running simultaneously and then that way everyone who cannot make the morning session on a Monday can make but can make the evening session on the following Monday that way so we basically spend two weeks on every chapter but we switch which cohort is featured uh between Monday between a morning and evening if that makes sense so it's like you know right this is Cap cohort 7 right now next we it'll be cohort 6 at this time the following week it'll be cohort 7 at this time so on um but yeah it it gives everyone an opportunity to participate in h whichever chapter reading they want to get into okay okay thank you thank you so much yeah feel free to add any written questions or just or you know write them in Discord but then we'll just go wherever we go especially this many cohorts in okay have a good one thank you farewell