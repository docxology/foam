all right hello everyone it is July 11th and we're in the second discussion on chapter two so before we go into any of the questions does anyone just want to bring up anything or just start with anything about chapter two um Ali and then anyone else who raised their hands uh thank you yeah I just uploaded uh the equation to 0.5 walkthrough uh in the um I guess I put it in the equations table if I'm not mistaken but equation 2.6 needs a little bit more fine-tuning before it's ready but uh I'm sure it'll be ready for the next week so I think I put it at the top of the notes section of equation 2.5 so if anyone wants to uh but yeah that's it foreign looks awesome can we maybe uh go over it or can you just walk through it or yeah sure yeah uh well first of all um we began with um just basic definitions uh such as some fundamental definitions such as the Shannon entropy and then to derive uh the first line we put we substitute the Shannon entropy term uh into the uh I mean the first line of equations so uh and we can see there's uh an interesting parallel between uh this kind of formulation between energy and entropy and also the path integral formulation and variation of preology but the essential difference here is that here the first term represents only the energy but for the path integral it can be best described as the energy constraint uh so that's um more of a side note there and then for the second line of equation 2.5 we get but before going into um the second line just let me unpack the first line a little bit more so for for the people who who are not familiar with a callback Library Divergence uh we put the definition of callback library at the top of the um or yeah at the top of the page one and then uh by using uh James inequality we get uh the Callback the lighter Divergence bounded by the expectation of the log p over q and that allows us to substitute the Shannon entropy term into the expectation of the log p over Q so that was the essential move for unpacking the first line of equations so I mean without Jensen's inequality we wouldn't exactly get the the exact term of the first line of the equation because obviously the order of the log operator and the expectation operator is different than uh we need here so yeah that's basically a straightforward algebraic manipulation um and the the second line of equation 2.5 or you know the terms the trade-off between complexity and accuracy similarly can result from uh substituting uh I mean by expanding uh the first line of the equation and then substituting some of the term as the Callback Library Divergence and then we get the complexity term uh and the rest will be the accuracy so this what it means is that as pointed at the bottom of the page the greater complexity is uh in other words the more one needs to change beliefs to explain observations the Lesser predictive accuracy will become so in this case variational free energy uh would be just the minimization of the complexity or at the same time maximizing the accuracy and again it can be compared to the path integral formulation it's almost identical to the path integral formulation of the trade-off between complexity and the accuracy uh all right so for this for the third line of equation 2.5 uh we try to somehow get the trade-off between the Divergence and the evidence but in this case evidence is just uh something that acts as um as the bound or the uh evidence lower bound uh so it's something that's always greater than or equal to surprise right so by unpacking the um the last line of equation 2.5 into these two distinct terms or the this trade-off between Divergence and evidence uh we are allowed to have this um elbow or evidence lower bound or in other words the negative upper bound that would enable us to regard BFE as the optimization parameter uh or over the parameter to be optimized rather than uh trying to achieve the exact value of uh free energy but just some optimization parameter which would be much more uh tractable than trying to achieve the exact amount of the free image foreign work nice cool stuff anyone want to ask a question or or make a comment on this could you maybe explain a little more like zoomed out from this document what does the variational free energy uh do in the model like in the textbook yeah so A variation free energy is a variational technique that sorry as I mentioned allows us to do the approximate computations of Bayesian inference uh in terms of optimizing a certain parameter namely the variational free energy because Computing the exact Bayesian inference of the orbasian output sorry Bayesian inference with regard to both posterior and prior would be almost impossible especially in complicated complicated situations and by complicated I mean everything that's not trivialism a simple situation so that would basically uh are all real-time situations that we encounter um and uh obviously we're interested in modeling so this this approximate Bayesian inference technique is a very useful way to overcome this shortcoming uh exact Bayesian inference in terms of its of its intractability and it makes the computation of or the optimization of the variation of free energy much more computable and tractable as compared to um exact Bayesian inference uh which would obviously have uh many practical um I mean it can have uh many practical benefits uh and not just something uh that's described in theory and doesn't have any practical applications and modeling and so on so yeah that's uh basically the idea behind using the variational technique and using a certain parameter as the upper bound or in other words the negative of a lower bound that needs to be optimized whether maximize or minimized um instead of just trying to compute the exact value of Interest so variation free energy on the other hand includes all the um established Frameworks for doing Bayesian inferences so for example the techniques developed by James Kahneman and others that I I think it was um which table was um which figure I in one of the figures in the book I I suppose it was in chapter two I guess uh there's a nice comparison between uh the different terms of variation of free energy and all the other theories of uh Bayesian inference yeah exactly so we can see that it's um more generalized theory of optimizing the Bayesian inference than risk sensitive kale control and other techniques of amazing inference that's that have been developed throughout I mean the past several decades and um so each of those terms can be accounted for by including or let me put it this way by vomiting some of the terms and we can basically get the exact same formulation or the exact same previous formulations we had before but as we see this is the much more uh General way of um calculating the approximate Bayesian inference okay Anuj do you want to ask your question or do you want me to read it yeah I just had this curious like uh is that case like when we already know that uh like I cannot do exact inference that are there cases when uh I should also avoid optimizing this variation free energy given that in any case I cannot do exact movement I'll give a first thought on that you always could you could choose your models however you want but you will be doing strictly worse with respect to the accuracy complexity trade-off so you could but you can invent an arbitrary statistical method but you you will not outperform the um information geometric maximum possible um performance yeah thank you in any given free energy that you do compute the the model may just be rolling to the bottom of the hill and you might just be way off base for a real system so this isn't the model adequacy problem this is the model optimization problem so it's analogous to the l-tune norm in the linear regression framework like every scatter plot you always converge to the one L2 Norm progression r squared p-value all of this so this plays a somewhat of an analogous role um by enabling these uh different uh generative models to be optimized in a real-time sequential way and it turns out that it's the same um optimization strategy that variational autoencoders use uh and just variational methods in physics so it's not like variational methods comes from fep or or active it's just using Bayes optimal model fitting just like L2 regression let's just say is optimal linear regression fitting optimal base fitting with the variational free energy which is a functional because it's a function of a function it's a function of Q the function that you're optimizing over and why the data that are coming in so generative model of vision and sensory incoming data which is what is like the thing that is is getting the best trade-off of accuracy and variance thank you okay and then um Ali or oh and yeah go for it uh sorry yeah and one um I think crucial Point here is uh the reason for using um the Callback Library Divergence for comparing uh the two distributions so uh I suppose the justification for using KL Divergence is not explicitly stated in the textbook but it it derives from the name in Pearson Lemma which is basically says something to the effect that most efficient way to compare two distributions would be to compare the logarithm of their I mean to compute the logarithm of their likelihood ratios so that's basically what's meant by callback libler so it's not just an arbitrary technique for comparing to this distributions it's actually a proven theorem or Lemma that that this is actually actually the most efficient way to compare two distributions so uh yeah I wanted to point that out as well yeah thanks and just adding one piece I'll put this in the notes there this is uh with nor Sajid and others and Carl and they use the Rainy Divergence so in principle you could use different Divergence or distance measures but the kind of um I mean it's a it's definitely an interesting question about where one might have different properties but KL is kind of like the go-to in at least this sense yeah Alexi and then anyone else this may seem like a silly question I think Ali gave a fantastic mathematical uh Road uh but is there a metaphor for variational free energy versus free energy that's free energies explained in the book well the variational cell this one is intractable this one is tractable this is an estimation but uh I don't know in terms of you know uh is there an example or a metaphor that can bring it home a variational for energy specifically does anybody have a yeah I'll think about it I'm happy to say one but does anyone else want to you have a thought like what is free energy and you know and variational free energy how can we think about these Ali that anyone else who wants to um yeah I'm not sure about um particular metaphor but uh you see uh the I mean the optimization approach as opposed to calculating the exact value of something that basically comes uh or it can be uh likened to the situation we have uh when uh when very in a very simple situations uh we have a function uh that can get an exact value of something as compared to the asymptotes of uh getting increasingly uh close to the to the value but never reaching the value so uh by optimization we allow for even uh the exact even for the situations for for which we don't have any information uh with which we would be able to calculate the exact value of something but instead we can get closer and closer to the exact value with the information we have but how but nonetheless we can reach a very good approximation and obviously we can Define uh what is what do we mean by the good approximation based on uh the error we we want to reach but uh yeah in most situations we don't have enough information to calculate the exact value of the parameter we want to calculate so it's more than the question of intractability versus tractability in some cases it is uh I mean impossible to compute the exact value based on the information we have so um I believe in these cases the optimization technique or variational technique is the only way we can get close enough to the real value or to the exact value that's great Point um that like even if the the variational model is just woefully not structurally mapping onto the real external uh generating function like the generative model is a unimodal distribution um and then the the out there in the world there's like five bins and so then there would be different patterns of model fit like it might just fit the one that has the most or the one not the most or blur the whole thing but according to its generative model it would never get worse in terms of all of the considerations in equation 2.5 it will never get worse on the complexity minus accuracy Frontier or it will learn that trade-off manifold optimally so those are some fairly um good statistical uh aspects just of any Bayesian model that's fit this way so that doesn't guarantee like adequacy in the real world because again you could just have an inadequate generative model then cease to get to the charging station or whatever um so it's not a success or a function guarantee but it's a model fit or it doesn't mean that you'll have um adequately balanced you know or had a memory window that's optimal or all these other things unless you've really taken them all into account and and then just to Alexi's question uh or Broadway do you want to add anything um equation 2.6 is the expected for energy I'll leave maybe do you want to summarize how is equation 2.5 different than 2.6 Yeah so basically um they're very very similar structurally uh but uh obviously we need to take into account uh the pi or the policy that needs to be um I mean in variation free energy we we only deal with the situation in which uh the perceptual data is um we only deal with perceptual data so we don't need to uh act upon the environment in order to fit the data better to our generative model but in expected free energy we delve into the action domain of the I mean action perception so obviously in this case we need to take into account uh the effect of the policies on our both priors and posteriors so uh the point of commencement uh for for derivation of equation 2.6 from equation to 0.5 is exactly how applying the policies to those prior and posterior terms can affect uh the whole equation and that's where we get equation 2.6 and its uh variance in other lines of the equation awesome one point about equation 2.6 is uh first off it's G not f and it is uh like the argument that it takes is pi which is the vector of the list of all of the policy trajectory possibilities so variational free energy which was described um really comprehensively earlier is basically that trade-off Frontier um between accuracy and variance estimator according to a generative model that's the Q and the Y on the variational free energy this is like a sense making or perceptual real time and the self-evidencing component of variational free energy is like if you're repeatedly measuring your body to be at homeostasis and you expect and prefer that then like things are working out and that's sort of the closure of the adoptive organism is like by fitting the variational free energy about homeostasis then it stays within homeostatic bound but expected free energy uses this pie or policy variable and so whereas variational free energy is more like signals processing expected free energy is more like control theory because it's an explicit evaluation of different possible futures does anyone have any other like thoughts or or ways of thinking about variational and expected free energy um I did have a this is more of a form of question sorry but uh I thought it might be useful so we have here in chapter two page 34. um when evaluating the free energy of outcomes the outcomes are the consequences however when evaluating the expected free energy the outcomes play the role of causes and since they're variables that are in the future but explain decisions of the present um would you say that everything you said this far is kind of gotten to that um kind of explaining what that quote means maybe paste the quote here just so we can see it thank you meanwhile let's let's uh look at this question can anyone throw some light on these terms both are posterior so indeed sometimes like the like initial prior D is called like the prior but technically every variable that gets an observation coming to it in a Bayesian framework is a prior an observation in a posterior update on something it's not like a free-floating prior so every distribution that's Bayesian that's why it's like prior on state space or prior on policy which is like habit that gets sharpened by expected free energy so then the output of this operation is like habit the policy prior sharpened by g into policy posterior and then that policy posterior can be sampled from or just selected with the best option um then about the um specific interests you paste it in all um we'll look at it but just now to these two terms mentioned so Q x given pi and Q x given Y and Pi so this is a question about the KL Divergence um so the the computation of the expected free energy for a given policy everything is conditioned on like that policy happening and so between these two things uh two sides of the double line they're both conditional policy and they're both have an aboutness of the Hidden State Through Time X tilde so the only difference is that there's that there's this y tilde observations Through Time on the left side so if the observations that you expect under that course of action aren't going to update your hidden State beliefs then the the Divergence between these two cues is zero the information is meaningless there's no information gained you're not learning anything you're not updating your hidden State model based upon the observation whereas if it was a epistemically informative course of action and do you expect it to reduce your uncertainty um on this course of action then y tilde would lead to an update on X tilde so there would be a Divergence here so that policy would have epistemic value whereas the pragmatic value is about the alignment of preferences with the observations that you expect all right does anyone have a thought on or or on on this quote from Andrew I'll just give one reading not sure if this is the the full um or only way which is like um when we're talking about the uh the sensory data themselves which are some sometimes just called outcomes sensory outcomes so like when we're talking about the the why that were um the outcomes that we're actually observing um those are the consequences of hidden states that are like emitting those so we're doing we're doing equation 2.5 um where the consequences of the causal model are what we're trying to fit um in contrast in 2.6 those observations in why tilde have not happened yet so they're projected observations so they are um unobserved like it's not it's the opposite of time travel say you and I haven't observed the temperature in two hours but I can have a tight or or a wide uh prior on is that variable but it's um it's a type of hidden cause analysis to say well if this happens under this condition and then basically kind of back propagate that into the present so as a causal impact of an informational State that's expected and that's not like a paradox or anything like that but so there are the outcomes of a causal process but then in the efe they also have a causal Force because differences in them lead to differences different differences in expected observations lead to different action selection anyone else want to ask a question or it looks like there's at least one that's from the cohort Alexi yeah um so I was really uh happy to to read this paragraph where they talk about generative process and generated model and they're saying that uh they could be in different state spaces one could be five dimensional one could be two-dimensional continuous and categorical I think that's a very profound statement uh and uh for example if I talk about temperature outside and I use words and I see things like hot and cold right so I I place a continuous outside variable in my two categories so I could model this way but it's it's a bit of a distortion if you wish but I don't know if you have any comments I'm just thinking out loud about this that this this is this is a thing it's just mind-blowing that you know we're modeling something but we will be in a completely different state space and different variables different variable structure right yeah that's a great Insight uh one thing I'd add to that is like um if you measure the the height of the people in the classroom you can optimize a binary classifier tall or short and then you can do optimal model fit to make the the line between tall and short you know optimize some trade-off like recall or something like that accuracy Mouse complexity you could do three category model four category model you can do a continuous model all these statistical distributions and like they're all gonna not complain they're all gonna get optimized so that's kind of the the blindness but the power of essentially just Bayesian statistics is that once it's all lined up it just is going to get optimized now it may be hard to optimize it maybe easy again it may be adequate or not but it's kind of like within so so just that um yeah it just this is what the the the strengths and the weaknesses of empirical modeling which is that modeling doesn't have to reflect the structure of the modeled system at all um and it doesn't for scientists and it doesn't for the models that are made but some of them are adaptive still so those are the lifelike ones but pedagogically they don't have to be lifelike that's a very great example it helps and one more question if I may and then I'll be silent at the end of the chapter they use the word intention you know and I posted in the chat the the exact quote where they say in psychological terms this implies that preachers believe about policies directly corresponds to its intention which it fulfills by acting right I'm just a little puzzled by the use of the word intention which typically means motive of an agent you know um I don't know how it's meant here this is where I got a little lost and what exactly do they mean by intention here seems an unconventional use of the trend anyone want to give a thought on that okay I uh oh yeah go for it uh yeah this is just a speculation but um maybe um the meaning of the word intention here and particularly in this paragraph uh is related to the way it's used in um some of some of the literature on action philosophy so for instance Alicia Juarez has developed a theory of intention as a kind of the process that results from the causation of constraints so by intention uh she means basically the process that puts the system of interest in its causal constraints so it's not necessarily um maps onto or at least precisely maps onto the psychological sense of the term so but that's just as I said only in a speculative thinking I may be wrong okay another um angle is from the paper um active inference models do not contradict folk psychology it was live stream 46. does anyone who participated in that or was there want to just like summarize what they thought this paper's argument was about that issue so basically they use the belief desire intention framework BDI um which I I had not heard of but it's a commonly used framework um and it actually came up in the first lecture by aval in the um active inference for the social sciences Ben White mentioned folks psychology and aval kind of like followed up was like what do you mean by like by by this basically but the belief desire intention models just widely used to explain everyday behavior and intentionality it's like what people kind of slip to um you know this enzyme wants to bind to this or you know prefers to bind to this in a way just kind of broadly and they identified those constructs belief desire and intention um with different constructs in the active inference generative model so they just basically said like you're not wrong it just it just it's just a description but they uh but the beliefs are the hidden state beliefs um and uh they kind of unpack this in the context of uh also distinguishing between the discrete time active inference um chapter seven and the continuous time active inference chapter eight and so they kind of do simulations that pull out the um belief desire and intention [Music] pieces um in the context of someone who's going to the fridge and getting ice cream which Gene had a field day with um yeah but but another more deflationary way not necessarily like an experienced intentionality like the set point of a thermostat or the set point of a motor limb you can call it what you and it's just as long as you understand the map of territory then such an intentionality is is not massively metaphysical I I found the use of the word intention there just so like from within the confines of the models to described as far as chapter to just be referring to like we're including a c uh Vector that is preferences like those are included along the way like there's a yeah something like desire or some kind of you know direction that agent is heading as opposed to just total free form you know going for anything right yeah good point about how these um intentions or preferences or um expectations uh for for observe observed outcomes that those form kind of like explicit intentions like if you have in terms of the directionality and the amplitude and uh and yeah there's a lot to say on on that but this is what goal oriented or um adaptive Behavior would look like not saying that every single um implementation of such a system is like you know or taking on any of that like we don't really talk about reward um or goal in the active ontology so that's why some people have very um broad views on like intentionality and action but the deflationary and instrumental answer is always it's a variational Bayesian model with action signal processing plus control theory Bayesian statistics dot dot that's not even including free energy principle or Bayesian mechanics or going into any of that part at all so it's purely defensible even without fep just thought I would say that foreign did whoever added this question want to explain it um or anyone else who's here want to ask something just while they're here Okay so about equation 2.6 and epistemic value so value of new information instead of minimizing the Divergence we want to select policies that maximize the expected diversions hence Information Gain okay so only with respect to the epistemic value more um informative observations is more epistemic value that doesn't mean that those highly informative policies are going to have a pragmatic value like discovering What's um at the bottom of the ocean May um disrupt pragmatic value about your body temperature um but it is an epistemic policy how can we reconcile the above statement with page six all facets of behavior in cognition living organisms follow unique imperative minimizing the surprise and the approximate variational free energy of their sensory observations anyone have a thought on this so models of perception and action that do surprise minimization have the best possible generative model minimization of surprise is equivalent to maximization of model evidence if you knew exactly what to expect how much to expect it that's the same thing as saying you have the best fitting model so maximization model evidence is surprise minimization that can't be exactly solved that's the exact phase issue that we discussed earlier the most modern way to solve it is variational accelerated optimization on the Bayesian evidence lower bound now you could do that about any variable in principle but what this imperative does is it connects it back to sensory observations which can be interpreted as for example homeostatic so minimizing surprise on homeostatic variables minimizing surprise via Fe of any variable is doing the optimal Bayesian inference on it you could do strictly worse on um accuracy or variance estimation but you don't if you want to use the phase optimal phase information Criterion optimal model this is just how it's done but this connects it to the homeostatic potentially adaptive imperative but it doesn't have to be seen as like super adaptive and strategic it can be seen also for like an inert object um that's the variational free energy so that's the kind of unified imperative of real-time self-effidencing Behavior but as was mentioned it does not address action selection it's a functional of beliefs cue and the data y so we need the expected free energy which is explicitly prospective now within the expected free energy there's the two terms of the that different policies are evaluated based on epistemic value in the pragmatic value such as one of the decompositions that that I will all look forward to the um the breakdowns on but yes it is the case that for a given evaluation of a policy the more Divergent the sensory information are the higher the epistemic value would be but that doesn't mean that it would be associated with um a pragmatic value so an adoptive agent would um you'd hope avoid extremes of both extreme information seeking that risk pragmatic value or vice versa so that's the model fitting questioned balancing all the parameters so that the strategies actually adaptive um okay Alexi and then we'll continue with this question I wanted to add to what you just said uh Daniel just a very nice way to summarize it that seeking epistemic value seeking knowledge is for humans pleasurable you know this is an effective Neuroscience called the seeking Drive literally the dopaminergic exploratory system we enjoy that this is the enthusiasm curiosity that drives scientists and artists and other things and when all our biological needs are met when we're not hungry anymore when we're safe we default back to that system we start exploring the environment around us to see what's out there to gain epistemic knowledge to maximize evidence to decrease the surprise the negative surprise me in the future so that we're not killed you know and we're not dying from Hunger once we explore the environment and find out where's the worship and where the Predators that helps us in the future to avoid unpleasant surprises nice um so the Divergence for the variational free energy let's look at two point well we we've seen them previously um maximizing Divergence to maximize Information Gain appears logical however maximizing Information Gain would maximize ambiguity and risk which is um the uncertainty about consequences of action in the world and it um or um uh this could be describing risk um in these two lines which are two very similar representations of equation 2.6 um like the left term is the same and here is observations so this is the risk of like sort of conditioned on a policy um about how uncertain their uh how much uncertainty there is about observation sequences and here is about hidden States and I believe that this number is always less than this number because you're always more certain that proposing something hidden you're always more uncertain about I believe there may be a different reason but it it's like you're always more uncertain about proposed latent causes above and beyond um surprise uh bounding of observables maybe there's another way to think about that's it thank you Lexi wooden beliefs assign low probability to policies that will maximize discrepancy expected free energy ambiguity and risk well kind of yes and no um what would be the the most epistemically salient would be something where you were sure about the outcomes and they were going to contribute to Information Gain like I have a trusty book and I know that so I have a hundred percent certainty about how opening the book to this page about kind of like the epistemic quality so it's a Salient um and a mapping between the the underlying semantics and the observation so this representation just maybe there's another way to see it too but or I mean I'm sure there are but just like this isn't like Risk like Danger this is um as as far as I understand um looking at uh how your action uh maps cleanly and preferably and here's the the more sensory mapping not to get too deep in that one point but yeah anyone else have any questions or thoughts on uh chapter two Ollie that was awesome um work how are you gonna continue uh well we'll continue to unpack uh all the other at least essential equations if not uh all the single equations in the textbook but we're focusing on uh developing uh similar derivations for all the central equations in the in the textbook and particularly from chapters two three and uh four uh which I believe uh constitute uh the most uh fundamental chapters of the textbook so um I hope we can prepare it in time so it can be uh hopefully useful for anyone who wants to unpack the understand them uh a bit better awesome anyone else have any thoughts well um we will head next into chapter three so why do we seem to interested only in discrete State space discrete actions policy discrete time is fine yeah um well chapter eight you're gonna love but uh it is presented as as um there's always a [Music] um the screen continuous time are just two options or two two families of models that can be hybridized in chapter eight but yeah 100 the book focuses on both um and Thomas parr's bookstream is uh um he describes the history and the differential Focus between continuous and discrete time models and it's a big topic that we talk about in chapter seven and eight do you have any other information yeah and even before those chapters that we encounter uh preliminary formulation for continuous time active imprints in chapter four as well yeah and five with a spinal reflex arc so they're just different and uh I mean the and the figure 4.3 the kind of Rosetta Stone figure is about the structural similarities between discrete time and continuous time models but also understanding their differences so chapter three is going to be the uh High Road so figure 1.2 chapter 2 was the base theorem so that's why we were talking a lot about like the fundamentals of Bayesian statistics because up until this point this is the same thing as just saying variational Bays with perception and action that is exact no someone can implement the variational Bays with perception and action differently but kind of thinking cybernetically that's what they would need to make any kind of active inference agents whether it's you know using fristonian active inference or just or not but if it has to perception in action chapter three is gonna take a very different approach that's not going to um Focus as much on the how as on the why of self-organization and the way that this is modeled with different Bayesian architectures this kind of prepared us on how it's going to be done chapter 3 is a focus on the why and the free energy principle and then also it's going to arrive at active inference chapter 4 is more about the generative model discrete time or continuous chapter five is neurobiology kind of a sampling of different kinds of generative models how they connect so that's kind of the next three chapters all right so enjoy everyone thank you thanks again Ali and um and everyone else who helps with the math oh yeah there will be um math learning groups I believe there are Wednesdays at 13 UTC they're on the calendar um so uh you know whether there's one person or more than one person I hope people enjoy studying there and and connecting and just improve the documentation do whatever people feel like doing um but uh there's not a specific Focus or a facilitation around these sessions at this point but if someone wants to whether they're familiar with math or not they're welcome to um but just good luck in the math learning group all right thank you bye thanks everyone see ya