Hello, welcome. It is July 3rd or 4th depending on where you are and we are in active inference guest stream 110.1 with Tuya Isomeura discussing the triple equivalence for the emergence of biological intelligence. Previously, we had some discussions in the live stream 51 series when we visited Area 51 together and we talked a lot about a double equivalence and now the bar has been raised, the increment has been incremented and this is a really exciting area that I'm sure we'll have a lot to discuss and learn from. So, thank you again for joining and looking forward to the presentation. Great. Um, thank you Daniel for invitation. Um, so thank you for inviting me for this uh guest talk of active inference institute. I'm very happy to share uh my recent paper on the triple equivalence. So let's get start. So I'm interested in the theory of intelligence in general. So maybe baby had no uh such high uh intelligence but through learning it obtain the intelligence. This can be modeled or understand in terms of the self-organization of neuronet network. The newborn neuronet network may don't have may not have uh enough information regarding the external world but through some optimization which is typically expressed in terms of the energy minimization it achieve some uh obtaining obtaining of some uh good structure to recapturate the external world which is the basis for prediction and making insight or making creativity. So we would like to model uh those emergence of uh intelligent function within the neural network uh through the energy minimization formulation and so far there are to my opinion there are three major pillar in the theory of uh intelligence. So intelligence occurs in the brain. So uh we model the brain using a network of neurons. And uh this is a a diagram of electrical circuit and similarly a single neuron can be modeled like this. So this diagram represent a dynamical equation of a single neuron and through some approximation we can uh represent such a dynamics in terms of the energy minimization. So here the dynamics that descent this energy gradient uh energy landscape represent the time uh change of the neural activity like this. So this is the view uh from the dynamical system. The another view of intelligence is the computation. So it is well known that any algorithm uh can be expressed in terms of the Turing machine. Turing machine is a simple abstract machine that express the computation. So uh which involves uh finished state machine that's some make some that make some computation and there is a long tape. So in the tape uh some information is encoded. So like uh uh binary signals and when uh this finished test machine read uh this uh information uh it um incorporate that information into the uh of the this state machine header. Uh so uh those component can be expressed uh by uh mapping uh shown here. So given the current state and read out information it provides the move and writing information and the next state. So this is a basic idea uh underlying the cheing machine and interestingly this simple computation is sufficient to express any kind of computable algorithmic uh algorithms. And another view uh recently focusing on is uh the brain as the uh inference machine. So brain is considered now as a agent that perform basian inference. So this is an example of the bijen or statistical inference. So here there is some apple uh nearby the wall. By seeing that we don't see think that apple is locked in the shape of wall but uh we uh guess that uh this apple is hidden uh by the wall in front of the apple. So this is a kind of inference based on our experiences. So this can be formulated in terms of the basia inference. So bian inference is basically uh defined by the equation called b theorem. So this is the uh b theorem that tell us the probability of state uh given we can obtain the same solution by just minimizing uh energy which is called variational free energy in the basian inference field. So idea here is that so if we uh reduce the uh state sorry if we change the state uh to reduce this energy and then if it reach the bar of this energy landscape this point uh represent a solution of B theorem. So instead of uh directly computing equation by just uh minimizing the energy we can get the best guess about the external world and this process is expressed by like like this. So this is the idea behind the uh theory called the free energy principle. So free energy principle as you may know a theory of the brain proposed by Kristen which states that perception learning and action of all biological organ are determined to minimize variational free energy and by doing so they perform variational bas inference for external world. Uh this animation is uh the one I often use to explain the frenzy principle framework. So here there is a animal which is our agent that infer the external world and external world comprises observable information and unobservable information which is a hidden state and the task for this agent is to infer the hidden state based only on observable information and uh by constructing some prior belief in the uh sorry By constructing the posterior belief uh in the brain it can uh guess uh what is the current hidden state and this is can be done by minimizing the free energy. So idea is that uh if we change the uh posterior belief s uh uh to minimize this landscape then we get uh the optimal solution uh which is called posterior uh belief or posterior expectation and uh uh this is the equation of the variational free energy. it comprises uh prediction error term and uh entropy or complexity term. So uh to achieve this sort of inference we also need to update the model itself. So this is done by update of the parameter theta. So in the external world there is a some mapping from hidden state to observation. So we imitate uh this mapping uh using the generative model. So by tuning this seat our generative model is optimized to recapturate the external world and then we get the best guess about the hidden state. This is the a mechanism underlying the perception and the an unique point of the free energy principle is that it can be applied also to the optimization of action. So here we consider some the we we consider that there is some uh preference prior for this agent and to achieve this uh sensory input uh this agent can uh select an action uh from uh given set. Here there are three options and this optimization can be done by uh minimizing the free energy in the external uh free energy in the future which is called expected free energy. So except free energy is a function of action. So by selecting the action uh that achieve the minimum free energy minimum expected free energy uh it can maximize the probability to obtain the preferred input in the future. So this is the idea so-called active inference. So like this uh free energy principle is a normative theory uh that can express both uh perceptual optimization and action optimization. But for uh neuroscientists like us uh the most interesting point is the what is the neuronal implementation underlying those uh inference. So we would like to uh show uh actual neuronal implementation of this sort of uh active inference. So to address this issue uh we recently proposed equivalence double equivalence between uh neuron dynamics and basian inference. So we start from evaluating the neural activity equation. So neuroactivity equation is uh have long history. So it uh have a clear biological background. So we consider that this is a plausible one. And uh if this equation is derived as a gradient descent of some energy function, we can obtain the original equation by just taking the integral of this uh activity equation and get uh energy uh which is called hermo energy. On the other hand uh for basian inference once we define the model generative model about the external world we can derive the free energy functional. This is a variation of free energy and its minimization indicates the achievement of bijia inference. we show a mathematical equivalence between those two uh energy functions which means that for any neural network in this class there is a interpretation in terms of beta inference. So we can in general see uh neural activity or neuronet network dynamics including synaptic plasticity as uh inference about the external state. So this is a more mathematical definition of our equivalence. So we characterize new activity equation using some rate coding model which is derived from uh realistic spiking model uh through some approximation. So it uh form is like this. It is characterized by imbussing mode leak factor and uh uh all indicate the sensory input from input area. W is a synaptic weight. H is the firing threshold and X here is a vector of neural activity which is late coding uh neurons and its dynamics is uh given like this and if this is given then we can consider the original uh energy function by taking the integral of this activity equation with respect to x and we get a explicit form of uh Helen horse energy like this although it is little bit complicated uh it's just the integral of original equation so not no not worry about that don't worry about that and uh those uh definition of bar is here and hat indicate the sigmoid function of uh w and uh uh phi is a threshold factor defined like case and interestingly although this energy is purely derived from activity equation the same energy provides the plasticity equation. If we take the derivative of this a with respect to w then we get uh heian plasticity equation. So this is nonrivial right um this is purely derived from this activity equation but it also provides plasticity. Moreover for basian inference uh once we define the generative model we get the variational free energy. So this is the variational free energy under the assumption that the generative model have the shape of the partially observable marcoition process or pomod. So if the external world is expressed as a discrete state space then we get this kind of variational energy and its minimization provides the solution of bij inference which is a posterior belief about state and we also obtain the uh posterior belief about the model parameter. So which correspond to learning and what we say is that there is a formal equivalence between those two energy function in the sense that each component have a one to one mapping uh between those two. So s here indicates the posterior expectation about each state taking uh zero or one. So it is expressed as the block vector just like uh the block vector of x and xar and this logarithm correspond to this logarithm and this a actually have the block matrix structure which is exactly corresponding to this block matrix. And this operation in a product corresponding to this uh product of matrix and vector and this log d which is the state post state prior uh is formally corresponding to uh five here. So as a result we can say that for any neural activity and plasticity in this class that minimize the uh common termhorse energy we can uh be uh we can lead those dynamics in terms of the basian inference of external states. Okay. And moreover uh this framework uh can be extended to the empirical application. Uh so to apply the theoretical framework into the empirical data, we first record uh neuronal activity from real brain and uh we assign those data into our canonical neural network which is our network model and uh by taking the integral we can get the underlying hero energy which characterize the neurodynamics and plasticity. Moreover, uh we can estimate the parameter from data uh to characterize uh uh for characterize this energy function for uh specific for individual and through our established equivalence we can get we can identify the generative model and the corresponding operational energy from this a and this works as a synthetic agent that perform active inference. So it derivative uh uh produce a learning algorithm or plasticity algorithm that uh update synaptic weight uh to adapt to the environment and its time integral provides uh prediction about the learning process. So we call this framework as a rebar engineering uh in the sense that from neuro activity data we can get the genative model which is a blueprint for the individual animals. So by doing that we can uh get a synthetic agent that imitates the original animal's m activity and behavior. So now we can make the examination of the frey principle. Uh so our idea is that so we can uh do this based only on neural activity in the initial learning stage. So we we record the neural activity before training and characterize generative model and make prediction of the subsequent running process based on the synthetic agents that perform active inference. If its prediction is consistent with uh new activity data recorded after training then it indicates the probability of the theory underlying this synthetic agent. So if this is the case then we can validate the we can validate the predictive validity of the free energy principle and active inference. So this is the idea. So we apply this or uh we apply this to uh in vitro neuronet network uh cultured on a dish. So this is a neuron taken from rat embryo and we culture those neurons on a dish that have 64 electrode at floor and we stimulate neuron those neuron using designed uh sensory signals. So which is the electrical parts. So to stimulate uh neurons we uh design those uh stimula stimulization pattern uh using two hidden states. So those are hidden status hidden sources that is invisible for in vitro neural networks. So they can receive signal directly receive signals only from sensory stimul layer here. So by receiving those mixed sensory signals those neuron are required to infer the hidden state. So if it can infer the hidden state then it uh support the prediction and pregnancy principle. So we test that and we found that actually some neuron uh response preferentially to a specific source. So uh the prediction of frey principle is correct in this setting and we also uh statistically estimate the effective connectivity between those neurons and uh uh plot those trajectory. So synaptic weights change during the training. So we brought the that trajectory onto the theoretically derived free energy landscape. So this is the free energy uh characterized only by the initial data uh of this invitual learning experiment and we now brought the trajectory onto this. So this is the empirically estimated synaptic weight trajectory which uh started from the high point of the landscape and it reduced to the reduce uh the free energy to reach the bottom which is consistent with the expectation of the free energy principle that uh synaptic plasticity occur to minimize the free energy. So yeah, it's consistent. Uh if this is the case, we can make synthetic agent that perform frenzy uh minimization. So this is the result of the simulator that just uh exploit the gradient of this theoretically computed free energy landscape. So it is just a simulation uh without using data. Nevertheless, its result is highly consistent with actual observation meaning that uh the theory have the prediction ability in this setting. So it shows the validity of the freency principle and then we extend our idea to action optimization active. To optimize action, we need to consider the modulation of heavy plasticity because our action is changed based on the given reward or punishment. So uh classically this sort of uh optimization of action uh is associated with the hepian prosticity modulation by neurom modulator various neurom modulator. One uh famous one is the dopamineic modulation of heavian type plasticity. So it change the timing window of the STDP. So STDP here means the uh spike timing dependent plasticity which is a sort of uh heavy plasticity. So it change dopamine change drastically this window of STDP like this and we incorporate those effect into the he uh into the plasticity equation and we also consider two layer recurrent neural network uh with output layer to model uh the action of animals. So it is uh basically same uh model as the previous one. Uh we call this uh canonical neural network. And uh one uh important uh characteristic of this canonical neuronet network is that all of those equations both neur activity and plasticity can be derived from a single energy function which means that there is a corresponding basian inference characterized by variational free energy. So we again uh get the one to one correspondence between neurodynamics and bija inference and interestingly this sort of neuron can perform uh maze task. So this is a typical delayed reward task but by uh inferring the best action that obtain the uh maximum reward in the future. So which is uh in other words uh minimum risk uh in associated with the future outcome. Uh by doing so this network uh can uh achieve uh the best uh action uh to uh realize uh this main task. So so far we show uh double equivalence between neural network dynamics and bas inference. So in general uh neural network a canonical neuronet network that minimize some energy function by both activity and plasticity it inevitably perform uh ba inference active inference uh in some sense. So uh frenazi principle is such a generic uh general framework to characterize uh this sort of biological approach for neural network. The next step is uh incorporation of the algorithmic computation because so far I discuss about um optimization perception and action which is not uh completely generic uh intelligence form. So it is uh limited uh only for optimizing uh behavior to obtain uh to to minimize the future risk. But question is whether this framework can be applied to the emergence of a generic intelligence generic algorithm that's uh my interest. So to address this issue we proposed the triple coariance. We show the triple equence between neural network dynamics and variational vision inference framework and the turing machine. So here uh we have two cheing machine one is internal turing machine and one is external turing machine. So instead of characterizing environment in terms of the gantium model uh we characterize the the environment in terms of external cheing machine but the point here is that such a cheing machine can also be implemented in terms of the probability uh distribution. So which is actually expressed in terms of generative model. Uh I'm moreware because cheering machine typically deal with the uh deal with the discrete state space. So this is expressed in the form of pom dp. So we simply consider the pom dp with some uh external tape. So this is uh what I actually did. So to infer such environment we have the uh cheing machine which is basically have the same shape as the external cheing machine and we show that this type of cheing machine can be implemented by uh canonical neural network. So idea uh is that so we first uh characterize the canonical neuronet network in terms of the energy function like this and we also characterize differentiable turing machine uh in terms of in terms of the uh energy minimization. So if we get if we write uh Turing machine in some differential equation by taking the integral uh we can again obtain the energy function. So and uh through this process we confirm that actually the energy function derived from touring machine is equivalent to that for canonical neural network. So this is this happened because uh output layer of canonical neuronet network can be seen as a tape uh for touring machine and this operation reading out and writing uh into tape can be implemented uh in a biologically proible manner through uh mental action that uh affect some uh change for the internal state and the writing can be implemented by rapid plasticity of output layer uh simot weight. So through those process uh we can uh implement the function of chewing machine which is the um reading and writing and state update and header position movement is also implemented by the neur activity uh sparse neural activity that expressed an address of the information. And uh once we get uh energy function which is common for all uh component in the system then we can say that there is a corresponding variation of free energy. So uh we found that actually this sort of cheing machine uh formally correspond to uh kind of pom dp genative model and uh you again uh this mapping from uh output to uh state posterior correspond to uh read out of uh information lead out of information and uh if we rapidly change the C matrix which is a policy matrix that determined our action then uh this uh act as memory writing. So rapid change of uh policy uh can be seen as uh writing of information. So in short what we show is that we characterize neural network in terms of the energy minimization. So it involves both neural activity and plasticity. Interestingly, this typical neuronet network dynamics can be lead as both mapping uh of cheing machine and bed serum in the sense that so this is a energy minimizing activity and uh if energy is minimized with respect to internal state of neural network then this solution uh can be seen as the solution of basian inference. which is a bas and also in the simultaneously it also represents mapping uh this mapping which means that uh this network is not limited to infer the uh pom db typical to pom dbp in the external world but also it can infer the cheing machine in the external world and imitate that function into uh uh inside the network uh dynamics. So it can uh im uh imitate uh mimic the external algorithm using neural network dynamics. So that's the idea. So uh based on this generic framework uh we performed some demonstration. So this is a uh demonstration using other. So other means a machine that add count up the number. So here we provide the input as the uh emin hand visit. So actually this is only binary signal. So each uh becomes either zero or one and this uh 16 16 uh binary uh number represents uh inputs and the external che machine count up those numbers and memorize that sum uh into the tape. So this is what the environment works. Given this system, the internal canonical neural network which perform active inference can perform the imitation of this dynamics by receiving this 100 digit. It infer whether this is zero or one through uh this uh layer and the internal computation make addition of those uh signal into the um previous sumation of the uh which is uh stored in the memory and the memory is actually implemented by output layer neur output layer synaptic weights. So here uh by by given the internal state the middle layer neur activity it uh send some signal to output layer which correspond to address of the uh information and given this uh output layer activity generate action. uh this weight correspond to the memory uh in the tape and it takes either zero or one. So by by sending your signal header information here uh it receive uh the memory information and it feed back to the internal states. So this is uh how this network works as an other and the writing of new information into the output layer is done by heavy plasticity modulated by uh risk factor. So this uh plasticity occur in a rapid manner. So that uh by receiving new risk it uh drastically change the signup rate either from 0 to one or one to zero which is sufficient to implement uh the lighting function of the cheing machine. So this sort of neuron can implement a cheering machine in a biologically proible manner and uh this is a result of inference. So by receiving hand res hand uh digit which is uh noisy information uh it can correctly infer the hidden state uh like this and uh it successfully store the information in the output layer uh which represents the summation of the number. So it count up the input number and store that here and through running the accuracy of inferring uh hidden state and memorize uh information uh sum some summit s some number is improved. So before training uh the estimated number is largely different from the true number but uh in these four sessions uh which comprises uh 2,48 steps it achieved uh good inference and uh uh this is a quantitative uh evaluation of prediction error it decrease uh with uh time increase and also this network optimize its parameter uh by minimizing free energy and uh uh the parameter estimation error decrease with time like this. Okay. Um this is a this is the demonstration of al algorithmic implementation and inference of external algorithm using canonical neural network. However, there is some limitation in this framework. So here we assume a predefined learning uh sorry predefined writing rule which is implemented by risk function. So if we can design uh risk function or which is corresponding to expect free energy apply okay then we can train the neural network in a appropriate manner. But question is whether uh those predefined function can also be optimized through a biologically proable uh process. That's our next question. To address that we consider uh extension of our framework to the evolutional time scale. So evolution occurs through the update of gene and we associate that with the update of model. So we now extend the framework to the basian model selection framework. So uh by updating the model uh we get a better generative model and based on that model we update parameter through the scientific plasticity and then infer the hidden state and action uh through neur activity and its result is evaluated and then uh it's uh iterated so on. So we model this framework using extended hermhor's energy which is uh a function for a species not the individual. So we now define uh the distribution of agent like this. So this represent uh distribution uh or over observation sequence and gene distribution. So which characterize uh what kind of agent exist in our environment okay and how what kind of information received uh is received uh by those agent. So we now consider the populations. So this is defined uh by adding uh some component to the individual perm energy defined previously. So this is um Hermho's energy uh we discussed and uh we add here to some factor. For example, this uh represent the reproduction rate which is the evolutional fitness function and this is the uh parent gene distribution which correspond to prior distribution of uh gene here. And this is um uh entropy uh but it is representing it represent um posterior belief uh about uh the observation gene distribution. So it is analogous to uh conventional variational free energy but now we uh also optimize the model. So interestingly by uh taking the derivative of this or taking the variation of this uh functional we get a solution like this. So this solution of course it has a meaning in terms of basian inference but it has another meaning. So interestingly this uh solution uh posterior belief represents uh uh is given as the product of uh evolutional fit function and marginal likelihood and the prior gene distribution and this marginal likelihood can be seen as the observation uh conditioned by the gene. So this result actually is equivalent to uh the solution no uh natural selection simple natural selection. So now we found that uh by defining Herm energy which is uh equivalent to variational free energy uh and minimizing that we get the solution of uh natural selection in a uh natural manner. So uh this indicate that the solution of uh bijium model section involves uh conventional natural selection and uh this can be also understand by this uh inequality. So here it indicate that uh population level perm energy or uh variation of energy upper bounds uh this factor. So this is a negative logarithm of uh partition function z and interestingly under this framework this partition function uh correspond to the total of offspring number. So uh minimization of free energy uh provides the maximization of total of offspring number. So if uh this sort of uh agent want to maximize their offspring then it's uh naturally minimize uh the free energy. So that's uh what we uh characterize by through those equations and uh we confirm that um through this process uh agent finally achieve the species of agent finally achieve uh the good model for making inference of the given environment. So before the evolution uh optimal gene correspond to uh some machine that is different from others. So its genes like this. So it's operation provides a solution different from others. But through training through evolution only gene that achieved the uh operation or mapping which is correct as uh other uh survived and after sufficient evolution through 40 generations uh finally uh most agent uh converge to um machine that perform as adults. So this is a result of bianium model selection but uh it's uh more explicit uh it's more actively uh select the best uh external world to achieve the maximization of uh offspring number. So it is uh called uh active uh vision model selection and through this process uh estimation error decrease and uh also uh total number estimation error decrease. So uh it's showed a successful uh model selection uh by simply operating natural selection. And finally I I briefly mentioned about that um this framework can also implement universal cheing machine. So universal tuning machine is little bit uh more than conventional cheing machine bit because it can imitate any other cheing machine although it's abstract definition implementation is very straightforward. If we have two mental action one represent data reading and one represent program reading then we can implement a universal cheing machine using canonical neuronet network. This machine can infer the environment even though environment comprises 10 different uh machines. So given sensory input it can guess which machine now generate sensory input and select best position of uh header or reading program and by receiving a program written in tape uh it gets the it characterize internal computation uh in a adequate manner. So it's very flexible neural network and given this program it can imitate uh the given uh uh it can imitate the um the environmental current environmental machine uh uh through this process and uh here a different color indicate a different machine and uh black color indicate the position of header that neuronet network uh inferred. So uh before training inference is little bit noisy but after training it success accurate uh inference and by doing so uh parameterized dimension error and model selection error decrease and uh subsequently state prediction error also decrease. So uh it su successfully uh uh imitate 10 different machine in the external world only in the uh single neural network architecture. So in summary uh we show that the dynamics of canonical neural network that minimize shared herh energy can be cast as minimizing variational energy. So it's basically perform active inference in general and canonical neuronet network with mental action and rapid modulated plasticity can implement cheing machine in a biologically proible manner and perform variational ba inference of external algorithm which is expressed by turing machine. And if we extend her energy minimization uh to the evolutional scale uh then spacey level hero energy uh minimization uh involves natural selection. So that that process uh can be naturally derived from uh minimizing energy providing a possible explanation uh for the emergence of generic biological intelligence. So finally I just uh briefly mentioned that uh those uh programs uh I mean Matra or Python codes are all available at my GitHub page. So if you are interested in please check that. Thank you. Thank you. Awesome. A lot to cover there. For people watching live, they can write a question in the chat. I wrote down a few as well. So I'll just sort of start in no particular order. Are we seeking to find pairwise transformational edges and then maintain overall network equality through transitive properties or do you see these different equivalences as arising from a more general form or notation? Thank you question. So uh c can I see that uh comment by myself? I mean yep you give me one second. Yes. Yes. First part is little bit complicated to me. pair-wise. Oh, when you did the work in the double equivalence and now with the triple equivalence, do you seek to uh find pair-wise strong relationships and keep everything equal through the transitive property? or do you think that there could be a common representation that has more of like a hub and spoke topology with a common underlying format that then is connected to each of these domains? Um so I'm not sure if I'm correctly understand the question but uh uh unlike double equivalence which is uh correspondence so in double equivalence all neural network property as long as it minimize shared energy function it is always basia inference. So there is a set of basia inference. It is very general and there is a sub population which is biologically proible basian inference. So all of those sub suboration is involved in the generic bij inference. So uh if we design neuronet network uh that uh by by considering the energy minimization then it always is involved in uh generic vision inference framework. On the other hand cheing machine or in particular uh universal cheering machine is special one. So not all not all cheering machine uh works as a universal cheering machine. So we we may design some random network or random machine and we can say this is a chewing machine. It's not uh it's not uh mis I mean it's in some sense correct in some sense it's correct but uh it's not useful so far I mean universal uh computation cheing completeness uh means uh that computation computing machine have sufficient ability to deal with uh algorithm computation So yeah that is something outside. Uh so what we are now thinking is that there is a group uh that achieved the beta inference and there's another group uh that performing complete computation and uh there's some overlap here. So if we focus on that that that would be interesting uh to to consider the emergence of high level intelligence. I don't know. Okay. Awesome. All right. I'm going to paste into the chat so you can see it. I just wanted to read this uh this quotation from a right I double check that and yeah, okay, this is a from a 2017 article by Andre Carpathy uh called software 2.0. And so he wrote, I sometimes see people refer to neural networks as just another tool in your machine learning toolbox. They have some pros and cons. They work here and there and sometimes you can use them to win Kaggle competitions. Unfortunately, this interpretation completely misses the forest for the trees. Neural networks are not just another classifier. They represent the beginning of a fundamental shift in how we develop software. They are software 2.0. And then a later section is it turns out a large portion of real world problems have the property it is significantly easier to collect data or more generally identify desirable behavior than to explicitly write the program. Because of this and many other benefits of software 2.0 programs that I will go into below. We are witnessing a massive transition across the industry where a lot of 1.0 code is being ported into 2.0 code. Software 1.0 0 is eating the world and now AI software 2.0 is eating software. So how do you how do you think the kinds of analytical and empirical results that you're yielding might play into how we think about software engineering and designing different kinds of intelligent systems? That's that's very interesting. uh question. Um yeah. Um right. So so thought of neuronet network we I I'm I'm working on is uh yeah largely different from the state of uh deep learning machines. So we are more focusing on how uh the re real brain how real brain works uh when it's doing some uh computation or making decision and uh yeah although uh the large gap between the the neuronet network model in computational neuroscience which is too simple and the um state of state object AIS. So we we think that if we want to examine whether what we are doing is correct as the model of the brain then um what we are doing it have meaning because so when we want to do some task for animals nonhuman animals only they can do this just a simple task. And to my uh belief to my uh experiences most of those task can be implemented by simple pomod architecture and some require some extension. But basically uh what we are dealing with here is sufficient to characterize what uh animals doing in the system neuroscience uh sense. So yeah, beyond that we may be able to consider some uh more functioning uh neuronet networks through our strategy but uh it is it it is not not soon. So we need uh yeah many other validation before uh going to that step. What does the reverse engineering as you have it in the GitHub or as you imagine this developing, what does it yield that a systems biology assessment wouldn't? You mean you what is uh sorry can can you rephrase that? Yeah. What do we gain and learn from the reverse engineering? Uh right that just a circuit level dissection doesn't provide. Yeah. So circuit level dissection basically provide us uh static information right information about architecture neural operation uh at that point. So we see um snapshot. So what we are interested in is more prediction things. So uh through reverse engineering we get a genative model which has uh so it have learning ability it itself is agent. So instead of making connetoics or making some uh the characteristic of static neuronet network we can characterize the dynamics of neural network in terms of generative model. It provides us a prediction of long-term future after some learning. So which is completely different from what uh conventional system neuron science does. Okay, another question. I put it in the chat. So how do we reconcile the traditionally essentially errorfree nature of touring machines and digital computation with the more fundamentally probabilistic nature of neural and basian systems like part part of the reason why the symbolic architectures are useful is because they can be used deterministically. So are we seeking something that's deterministic or probabilistic? Yeah, thank you for asking that. So it is related to our demonstration using uh others and uh uh 100 digit uh numbers. So 100 digit uh your noisy uh stochastic information and once we our network uh extract the the hidden features from such a stoastic information then hidden layer is become uh becoming more uh deterministic in the sense that if we accumulate sufficient information the pom db model becomes either zero or one state, right? So in that case uh the state transition can be very uh deterministic. Of course we in general we need to deal with the stoastic uh stochastic um environment but yeah sometimes either uh likelihood matrix or uh transition matrix can be deterministic and uh under that situation uh our machine uh provides uh very accurate uh prediction about states current state or future state. And moreover, although conventional naive cheinging machine is very deterministic or discrete uh but um differential cheing machine incorporate uh the current uh continuous dynamics and discrete uh chewing machine. So it is a cheing machine that is expressed by the differential equation and we extend uh that idea to the energy minimization in the sense that differential turing machine uh of us is derived as the gradient descent on some energy. So this dynamics is something between the the discretized uh symbolic computation and uh continuous dynamics and based on the condition just like inbas temperature parameter we can sift uh that dynamics both to uh discretized symbolic computation and continuous dynamics. That's the idea underlying what we are doing. Great. Okay. So, in computer science theory, the halting problem or Turing's halting problem is the description that uh or the problem that the description of a computer program and the input you cannot determine whether the program will finish running or run forever. So if we can make this kind of software 2.0 neural network representation and or like this software question mark with the basian interpretation as well. Are they also bound by some of these constraints? Or do you think there could be some angles of approach where problems that are not solvable in a procedural computational framework could be approached probabilistically and vice versa? Yeah, thank you for the question. Yeah. uh the simple answer is I don't know the the exact answer but so I I try to make my opinion so um yeah first of all although we consider some neuronet network that perform cheering machine so it it is uh still in the framework of chewing machine or chat chewing t in the sense that yo what we are doing with just uh computation based on algorithms right you even though we are designing very realistic brain model comprising hosin hack spiking neuronet network so it isn't just algorithm so it is implemented in terms of cheing machine so in that sense nothing different but uh and uh it it means that we do not solve the hurting problem. So our network can uh conclude whether this program is finished or not. However, we can guess whether this is a good strategy or bad strategy. So one interesting difference from the conventional turing machine is that this our neural network works in a real time. So time is uh passing uh during a computation unlike cheering machine a conventional cheering machine. So which means that if we select a b strategy that does not stop uh during the meaningful time frame then that animal that synthetic animal die or eliminated through the natural selection stage. So uh survived species should be uh should have some uh meaningful function meaningful algorithm that works in a realistic time frame. So yeah that works as some debac or selection of algorithm. So that is what I'm thinking. Yeah, the the connections with the neural Darwinism are very interesting and also the open-endedness of successful life. It's like those are the programs that haven't halted and you don't know whether the environment could change and they could all of a sudden die. But what you know by observing their existence is that they haven't halted yet. So it's like one sense they're able to carry out a computation in plausible time and on the other hand their persistence as a species as a population is still running. Um so how will you proceed from here? What what directions do you plan to follow? Um the plan yeah the plan involves some emergence of new algorithm. I I mean yeah algorithm. So now we have mean to implement represent uh arbitrary algorithm within the neuronet network architecture which is corresponding to extended pom dp. And uh what now we are interested in is whether the function that can the the function those uh network can do is only limited to uh imitation of external world or it can do something different from the simple imitation of external world. So if the internal AL algorithm itself have some new meaning then that will be more interesting. What would that look like or how will you explore that? Yeah, it's a difficult question. M and what what can happen within a fixed topology of a baze graph or neural network or program information flow and then what is possible when the structure of the network changes because there's a space of semantics that can be explored with the quantitative variation just through the weight updating and then there's another shell of possibility ility based upon topological change. That's true. That's true. So for example, we now we do not involve uh structural plasticity uh within uh lifetime but the model selection done by update of gene involves the change of the size of network. You know by by changing the gene we can freely uh change the number of neuro involving network or whether it is a two layer or three layer like that. So anything can be characterized by gene and it selection means the uh model selection uh from the yeah very various model types. So, so I I mean yeah in principle we can consider many things but question is whether it is proible. I mean it yeah intuitively it requires very high computational cost uh you know it is something like a random search in the uh huge binary space. So as you may know yeah uh combinator optimization takes uh exponential time. So question is whether animals do that or animals know better searching algorithm or animal avoid to do that and yeah have another uh solution. So that kind of things is very interesting to me. Cool. Is there anything else you want to add? Um yeah. So although I I'm not fully sure whether we can uh validate uh the cheing machine uh relationship between cheing machine basia inference and neuronet network using real data. At least we can uh validate uh the double equivalence between neuronet network and the bij inference and we can be extend some something to the evolutional uh direction or trig machine direction. So yeah I think as the neuroscience I I I think I'm a theoretical neuroscientist. So as the neuroscience we need to do both developing development of the theory and validation of theory uh they are interact with each other. So uh I'm very interested in both site and if you are interested in this sort of research I'm very happy to working with you. Thank you. Last question. Do you think there's a fourth player at that intersection? Yes, that uh that very interesting question. So, so one thing which I'm used to be interested in is consciousness things. So yeah many people nowadays interested in consciousness and there are several theory of consciousness but as long as I know those three pillars uh neuronet network ba inference and touring machine algorithm computation does not in do not involve uh consciousness idea so I'm want to ask some expert that whether consciousness can be involved in those framework or it is different from those framework. Maybe that can be a horse pure. Awesome. Okay. Thank you very much for joining. It's exciting to see how things have developed with the empirical work and this new theoretical layer as well since a few years ago. So looking forward to where you take it from here. Thank you very much. Thank you. Bye. Bye.