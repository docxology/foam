all right greetings everyone it's June 20th 2023 we're in our second discussion on chapter six so we'll first just have any general comments or anything then we'll turn to the questions table and look at what questions we didn't get to last time and just kind of revisit maybe condense um some questions or just see what we can do with with what is here so anyone just want to make any general comments on chapter six uh I believe this is the second session on chapter six right correct or maybe I must okay yes yeah there was only one onboarding needed for the welcome back here so we started one week like faster into the Rhythm um okay so it looks like these were the questions I remember we left off with this one let's just develop this into what was um into a question that will continue to continue on okay um is there a common or good representation or rubric for about evaluating generative model generative process which is two generative models and generative processes anyone want to give a first thought or just some other related questions yeah well uh go on please sorry no that's okay uh yeah uh I I don't know I'm not sure about uh what What's the exact criteria for evaluating generative models regenerative processes but uh one thing is for sure that uh well I mean one of the main right at least uh when evaluating generative model one of our main criteria should be how uh closely uh it tracks uh our situation of interest and specifically uh how relevant it is for addressing the question that we're trying to um I mean we're trying to examine so uh it's not I I don't think it's something a clear-cut or I don't know written Stone and based on the context and the situation uh the evaluation criteria rubric should be different I suppose both for regenerative model and generous process yeah so again we'll revisit this generative model generative process um question later following the recent live stream but General process working regenerative process as the underlying uh process that gives rise to the observations this would seem to be more adequate to the extent that it can better describe the measurements generative model similarly is being evaluated based upon its ability to to fit to the generative process as well as [Music] um phenomena of Interest so not just to um fit visual data but maybe to model something like some illusion in visual then um there's a wide range of more General statistical modeling techniques so first is like the ultimate grab bag which is just how relevant is the overall modeling um then there are statistical evaluations of model adequacy and model selection IQ information Criterion Bayesian information Criterion base Factor um hierarchical likelihood ratio test if you have a parametric model bootstrap and non-parametric statistics just general modeling and then taking that more out of the statistics into like the engineering uh uh model life cycle then that's where you can think about validation verification validity equality Etc systems engineering model life cycle any other thoughts or questions on this Okay so um I'm coming from um kind of an early career data scientist background here but um I mean as far as I mean what I find attractive about active inference and doing things as generative models is the attempt to you know describe or explain what's going on in the data and that being said um you know in terms of a lot of mini applications of like data science machine learning um the emphasis upon is upon prediction and so are these listed statistical metrics you have here base Factor Bic Etc I mean are those basically like your error measurements are they your um how to say just attempt at measuring like accuracy of prediction or or is there some trade-off between explainability and and prediction if that makes sense yeah just to kind of summarize these um so when you have nested parametric models then you can evaluate whether two models are better in terms of including or not some parametric factor and then testing for their likelihood ratios so this is a pretty straightforward test but it's pretty limited to just strictly nested parametric models so just just getting that out of the way in general we're in the Bayesian setting and so the one of the advantages of the Bayesian setting is that you can compare two different models that have totally different architectures on the same data set so one way that that's done is with this aikiki information Criterion or the Bayesian information Criterion both of them do something very similar which is they reward model fit and they penalize the number of parameters so actually in that way it's a lot like equation 2.5 you want to reward the fit but penalize the complexity of the model base factor is kind of like the hlrt but it doesn't have to be ratios of nested models you can just compare the relative evidence in in favor of one a model or another so this is used in structure modeling and and uh structured learning then in terms of but this is all like kind of like testing amongst a portfolio of models which ones are better then how do you really get into the space of like well how effective is this model um you could test on a new data set you could do all the regular techniques like cross validation leave one out Etc or test on a new data set but then the very interesting question is how do you establish the efficacy of an action model because um you know it's it's not just a passive inference model so there you would need to get into like benchmarks like the open AI gym and other um other settings where you can actually test the efficacy of an action model against some test input rather than just a recognition model and some input but that gets so situational that there aren't as as there's not like General not there's not as many General considerations there another strategy is actually to even if it seems like a passive inference problem like the mnist digit data set you could frame that in terms of the the labeling is an action so sometimes you can then take what seems to be a passive inference problem and then frame it as an active inference problem so then you don't need to worry about these kind of like out-of-sample novel context action models you can just kind of use standard benchmarks and also as far as I know uh probably the only serious work on benchmarking the performance of active imprints models um is the work of um theophy champion and his colleagues branching time active inference which is uh they've proposed several different variants of branching time active inference Each of which I mean with increasing performance in terms of their benchmarks and aside from that I'm not aware of any other work that takes this benchmarking study seriously enough to to be reliable I guess yeah surely there's a lot of proprietary work in this area um the paper discussed in in um live stream eight scaling active inference so here they they use like the kind of um several standards um testing environments I forget what the pendulum the hopper and then I think like the mountain car or maybe maybe that's not this one but they test the standards um AI tests all right we're just looking just you know going through the ones all right are the transitions be independent from the emissions so for [Music] um uh context we're talking about figure 7.3 discrete time active inference are the transitions independent from the emissions and what is the next observation depend on short answer yes they're independent that's the sparsity of the base graph so we can clarify and give it a cleaner textual answer but yes the conditional independencies which is the sparsity of the base graph which allows us to do factorized variational inference and get all of these advantages that's exactly what we're looking at so this visual graphical model is the sparsity architecture of the conditional um independencies so yes A and B are conditionally independent conditionally independent based on what hitting the state that's how Markov blanket works conditionally appended on the blanket A and B are independent that's true of all Bayesian graphs so without worrying about the Markov blanket and the interface and the cybernetic agent and all of that just any node that intervenes between two other nodes is the Markov blanket in that setting and then some other node you know something else is blinking to get from something else but yes they're conditionally independent what is the next observation depend on well a matrix is the emission Matrix Tale of Two densities it can emit from a hidden state or it can recognize from an observation so any given observation is only dependent upon the hidden State at that time and the hidden State at the next time is only dependent upon the transition Matrix the transition Matrix is uh has a slice for every action that can be taken every policy makes a slice in the B tensor so it's like temperature in the room hidden State thermometer observation turn on the heater or not and there's some B Matrix for the heater is on and there's some B Matrix for the heater is not on those are two slices in the same object and then policy selection means which Matrix which sub Matrix would be which slice of B should we multiply this to get to the next time step and then what observation would I expect there okay good good um kind of standard question okay what is the relevance of thinking about good regulator theorem for thinking about the generative model so from cybernetics good regular theorem originally stated every good regulator of a system must be a model of that system or more accurately every good regulator must contain a model of that system here's a few quotes from a textbook one way to approach this again these are just all kind of big questions but we can just see them many times what happens to bad Regulators well information processing sense making decision making has a non-zero informational cost land hour limit there's a certain amount of actual joules it takes to write and erase a bit it from bit Chris Fields everything that is in that area so information processing is never free so in a dissipative and even adversarial universe to fail to regulate is to fail to exist how do we operationalize regulation in a setting that's going to be revisiting some non-equilibrium steady state so if we're an observer looking at a system in order for us to measure it as diff as signal relative to noise it has to be persistently re-measurable over the background so we have to repeatedly measure it or an organism let's just say can re-measure itself so minimizing surprise about its homeostatic temperature is being adaptive now if temperature were just flat and so you could be unsurprised at homeostasis by doing nothing you'd get lazy agents but if temperature was really variable and contextual and there was kind of these non-linear cues in the environment and all of that then in order to reduce surprise about temperature you'd end up coming to effectively have a model of the causal Nexus that gives rise to observations so the structure of the generative model doesn't have to be the structure of the generative process however they may come to have certain isomorphisms with each other or at least statistical regularities if there's actually a 24-hour cycle in temperature then you're going to see some kind of oscillatory model in the generative model so there's more to um say there but oh and this is one good note perhaps rather than good or bad regulator the language of morality or preference the language should be accurate and inaccurate in effective and effective viable and viable skillful unskillful so there's always many ways to see it but basically if the generative model in the in the limit case it just totally knows the causal architecture of the world that's the easiest way to be absolutely unsurprised and to have things as you expect slash prefer is literally know how they're going to play out that's not plausible we use course grading and approximations and heuristics like variational inference so the best we can do is just iteratively optimize towards bounding surprisal so it's kind of like an empirical optimizable heuristic for being a good regulator without getting too bogged down into like the philosophy and the exactitude the point is the ones that do well enough to live live ones that don't do well enough don't but active inference is in the lineage of cybernetics so it's unsurprising that good regulator theorem requisite diversity viable systems models a lot of things in the cybernetics ontology have a natural home in the active ontology that they're you know they're talking about the same territory adoptive agents so it's not surprising that like they don't invalidate each other or anything like that and actually I think uh it's one of the reasons cybernetics um that experienced kind of revitalization in recent years especially in the past couple of years so yeah all right how can organs others in the brain be making inferences so there's a few angles on this the first um or Ali or anyone else want to give a thought uh one thing to point uh is this sense of a kind of semi pan computationalism that's been um if not time computationalism but but something that bestows um inference not only to complex self-organizing systems such as the brain but even to very simple linear systems even a system as simple as an inert to rock uh so basically it's it it covers the Spectrum there isn't I mean from the point of view of fep there isn't anything that's specifically unique about the brain uh in other words the same mathematical technology can be applied uh both to inert rocks as well as the uh the brain so in my opinion this question should be turned on its head and it's not that how does inference can be seen in other systems that are simpler systems but rather it should be I mean the relevant question should be uh how does active inference or the notion of inference inactive inference literature applies to all of those situations uh so one way to do that is to define a kind of sparse coupling between the environment and the agent and define variational density as the internal states of the system and also obviously the external states of the environment would be the states that needs to be tracked by those variational densities and in this case there isn't anything inherently different between the way the brains uh or I don't know even sentient agents uh uh somehow undertake uh inference from the way that the inert rocks and partition and their states into internal and external States but the main difference would be the way the markup blanket in those simpler systems can act as as a kind of statistical boundary that allows for non-causal relationships I'm sorry non-linear causal relationships as opposed to as a sorry linear causal relationships as opposed to non-linear causal relationships as observed in complex agents or systems so yeah that's uh some of the main distinctions between those Michael awesome yeah and then the classic paper that we we often return to uh like Ali mentioned the inner Rock so this paper has the uh kind of visual taxonomy from simpler to more sophisticated agents um sometimes the papers are in white sometimes they're in Black here inert systems active classical conservative systems strange systems with World models of their own and all of this um just but but this is a great response which is in a pan pan computationalist or pan cognitivist or pain inferentialist world then how does active inference apply one other angle is like let's just think about the liver or the pancreas and blood sugar that's our system of Interest realism is like is the pancreas actually doing inference on blood sugar and people can have a range of opinions but in a pan cognitivist world the answer is yes or one can kind of pull back and just say we're going to model the pancreas as doing inference on blood sugar so it's it is no different it's just an interpretation of the same statistical apparatus basically but there might be a setting where um scientific realism is is more Justified there's multiple lines of conversion evidence um the model is is uh comprehensive and so and being used to generate unique explanations and predictions versus like we're just going to do a linear relationship between these two things in the public health and so then we're not going to confuse the linear model with those with the actual cause of architecture but there are situations that you can design or analyze where the sparsity structure of the system which necessarily points to is what grants to all these interesting properties is becoming known to an extent that Within two or three or four Sigma it's like we're starting to talk about how it is not mistaking the map for the territory that's the map territory fallacy but also not doing some kind of map denialism which is the map territory fallacy fallacy and that's the paper which I'll add into by Maxwell at all and also if I may add another point uh with regard to the distinction between uh realism and instrumentalism uh I believe at least in the realism School uh probably the most relevant or well situated stance to uh reframe active inference I mean uh reframe its ontological status is structural realism as argued by Majid Benny and others in several papers nice yes he's joined several discussions and it's it's great to um okay is there some quotes from a book but yes basically I um forget organs other than the brain how could anything be doing inference and every and and then another angle to take is just like the way that a baseball uh computes a parabola like you don't need to think that it's doing it like a calculator but it but that's kind of like naturalizing the computation that's a path of least action in a spatial space but also you could have a path of least action in a cognitive space that's Bayesian mechanics and then you could have more realist or more instrumentalist angle yeah yeah please uh sorry just one one thing that somehow uh I mean it gets confused is uh some sometimes people think FEPS claims that okay so if a self-organism I mean if fep formalism applies to a self-organizing system then it should persist Through Time by preserving its markup blankets intact but actually the claim of the fep is the other way around so its main assertion is that if anything persists Through Time how does fep applies to it so in other sense fep doesn't provide any justification per se for describing the way that the system persists through time but we take the Persistence of the system through time as the premise and then apply fep to somehow investigate the implications of that premise through Bayesian mechanics and fep formulas on yeah without the implicit or explicit acknowledgment of the persistent existence of what you're measuring or yourself you don't even have something to discuss and a lot of times when people just start to specify what they mean by like the nouns and the verbs and the adjectives they use that's a deflationary approach well what if there's something that comes into being so so fast in between moments and it's not being measured and you can't detect it it's like well then how do you know it's there that's not within that statistical sensing apparatus so you have to take the existence of the of the thing to to be Primary in modeling something an actual constant has a lot of work in that area could you please pull up The Path integral paper on page four if I may sorry yep very nice thank you exactly right there the fep addresses the following question and it's like well if we're talking about something that exists even in a mental geometry that's what we want we want to start with if it exists even hypothetically so people say can it really describe all things it's like well all the things that exist or could exist we could use this modeling approach to model and talk about what properties it must possess but if you're willing to open the door to things that don't or can't exist then of course this guy's limit on what properties they do or don't possess because they might it's like the you know non-elephant animals things might not exist for a huge variety of reasons however things that exist either from an external measure or measurement or from self measurements they must be acting as if they're self-evidencing reducing surprise relative to generative model path of least action through an information geometric space if it isn't doing that you're not going to observe it and that's where we get the particular partition and the particular partition in the in the particular physics slash Bayesian mechanics since Carl first since 2019 monograph a free energy principle for a particular physics that was like a big inflection point in this line of research whereas in the 2016 to 2018 there's a lot of qualitative work and the philosophical work applying to multi-scale invested systems and and self-organization um amidst other empirical simulations happening continually in all of this so reading reading works of different times like different pieces are kind of going to be made clear or not what is the role of precision in nested models well here I'll uh and also by way of demonstrating the the uh transferability of active inference generative models these three figures are discussed in live stream 28 from the original paper Smith at all computational phenomenology so this is a static perceptual Bayesian model we have hidden State observations and we hear as a modulator literally a neuromodulator on the a matrix Tail of Two densities recognition Matrix generated model you have the Precision so Precision is one over the temperature so whether you think of it as like higher temperature is lower Precision or lower you know or vice versa they're they're the same when your Precision is low your temperature is high a gets blurred out the high temperature limit is like a is becomes flattened whereas in the low temperature limit a becomes sharpened and so this is a common method in uh recognition modeling okay now they move into adding action in so here there's the policy figure 4.3 figure 7.3 everything we've looked at and then they move to this um nested model now in the Sanford Smith paper it was being mobilized in terms of basically phenomenology and meditative experiences direct sensory perception you know visual perception and isaacades attention unreportable attention and then awareness at a third level observing that and so the mo you you can add an uncertainty like a Precision on any variable you could have an uncertainty on your prior D you could have uncertainty on all kinds of things but sometimes uncertainties on specific variables become associated with like certain cognitive phenomena in this case they're using it to describe introspective and explainable AI systems taking the exact same figures exact same formalisms just moving them into the AI setting so um Precision on a and here's that live stream 28 and the slides and everything Precision on a is like sensory ambiguity um Precision on G so how how um precise are you on the the free energy um that is associated with the affect in this uh sophisticated affect here's some discussion on embodiment and the Alexander technique um so suffice to say precision and nested modeling is basically like the general Precision concept which is basically used everywhere this is how we fit Bayesian models we have some hyper prior prior Distribution on a parameter and if that prior distribution is too sharp then you're you're basically that's a it's a pathology of the of the prior it's too precise if it was too imprecise you have an underfit model so it's like that and especially in nested models Precision plays a role in kind of gating just in this case it's a general question so you could make it do anything basically but here the Precision on a is like gating let's just say the first and the third level so if there's no attention being paid to sensory input don't be surprised that they don't come up to attention but if the if this um gating can be like super direct and forceful then you'll have propagation of informational causality on this network up to the higher level h113 in the textbook all right the decision so this is about planning as inference which one of these questions um was also about the decision whether to model alternative futures counter factual features conditions upon policy selection how would the world change if I did this or that is largely tied up with the choice between discrete and continuous models because the idea of selecting between alternative Futures defined by sequences of actions is more simply articulated using discrete time models all right so figure 4.3 figure 4.3 is like the Rosetta Stone it juxtaposes the discrete time continuous discrete time generative model and the continuous time generative model so I'll just copy this in the discrete time model you have S T minus 1 s of t s of t plus one so Futures and pasts if it's sophisticated active inference are being explicitly modeled so it's like what would happen at seven o'clock if I did this that is explicitly addressable with a discrete time model of the correct time Horizon so you have to explicitly say I'm talking about an hourly model and seven depth and so then you in branching time active inference just like a chess algorithm it's dealing with like the branching structure because if you have a lot of affordances then then you have and you have a lot of time depth you can imagine this this is a combinatorial explosion um in contrast though these two generative models are shown here to emphasize their structural similarity The Continuous time generative model is actually not explicitly modeling past present future time steps rather it's modeling the generalized coordinates of motion x hidden State X prime rate of change X double Prime second derivative so in that way it's a lot more like a Taylor series expansion so a Taylor series expansion technically even a Taylor series expansion of you know depth one it has an answer for every single point in the number line but that doesn't mean it's a good one um and so the continuous time models kind of trivially have something to say about all possible time steps just by analytic continuation of the Taylor series expansion in the generalized coordinates emotion away however you don't necessarily like know how accurate it is for any given points it also doesn't have explicit counterfactuals so if you do some Taylor series expansion it says yeah at x equals three over Y is 5. but then if you said well what if it were different the only way you could do that would be change the parameters of the Taylor series and recalculate it at that point so the model itself is not exactly doing these like what would happen if I did that so Futures are explicit in discrete time models and interpretable explicitly whereas in continuous time models pasts and Futures are kind of trivially predicted such that it doesn't really make sense to talk about just um counterfactuals in the same exact way and these models can be hybridized and and fused which is in um chapter eight can we generate a a code template looks like yes but there's of course more information but it's an important question how is temporal depth specific to planning does temporal depth in perception make any sense what is temporal depth so temporal depth is how many time steps are the models considered in the discrete time case um this temporal depth make sense in perception well perception is always modeled as instantaneous however depending on the temporal scale of of a model that perception may be instantaneous over a certain temporal thickness power Y is temporal depth specific to planning so in planning as inference policy selection is inference your selecting or sampling from policies based upon their expected free energy in order to plan over a given time Horizon and actually evaluate the um the play outs you need to have a temporal depth of that amount Thomas Parr in his um book stream so early implementations were coming from the filtering of a generalized filtering approach maybe it wasn't generalized at that point but particle filtering approach and I equipped these models with action then people started thinking about how to get sequential Dynamics Predator prey lock of Volterra models winnerless competition neural Darwinism in these situations there's in aversions of sequential recurrent continuous Dynamics like a limit cycle of more than two then people wanted to model explicit long-term planning and so from around you know 2014 or something there was a lot more development in the discrete State space model which enabled the well understood partially observable bar composition process and a lot of the characterization of the planning as inference explore exploit um then later developments supported um nested models here there's a discrete time on top and a discrete time on the bottom but also it could be continuous time on the bottom oh yes then continuous State models were reintroduced as the lower levels of higher level discrete time models and um that is kind of like the folk psychology live stream 46 active inference does not contradict folk psychology discrete time decision making up top you know discrete time and discrete decisions and then more on the sensory motor it's more like continuous time continuous action okay new question figure 6.1 all right particular partition how is the mutual interaction between active States and sensory States meant in six one so the bi-directional line here can they mutually change their states without impacting neither internal nor external States yes they could you could have um nodes that are these nodes are in communication with each other in general this image it's more important what it what it doesn't show so there's no backwards Arrow from external to octave or from internal to sensory you can't have your thumb on the scale and the symmetry of whatever that is from the outside and the only other constraint is no telepathy no telekinesis the only way to receive information about external States is through sensory States the only way to act on costly intervene on external States is through active States so no thumb on the scale and the mirror no telepathy no telekinesis that doesn't mean that for any given model these arrows are like all important or all relative uh or I mean all relatively the same importance so if you want to design a computer system where the sensory States comes in one computer and this is a second computer and this is the third computer so like there's no direct Edge between sensory and active States that's you can create that causal architecture what is it supposed to model nothing modeling of supposed things is done in chapter six and Beyond but in general this is not trying to model any specific situation despite the brain in the world could they Circle Mutual mutually modifying their states and then eventually arrive at a state where they change the external internal States yeah maybe they have a faster time scale or something or maybe they're in communication with each other and then active States ends or like sensory States ends up influencing internal States via active influencing it and so yes it could happen would that mean that we can model with this trick any arbitrary Behavior it's not necessarily a trick it's just a particular partition without allow us to model terrain equivalence I'm not sure if there's an understanding of what formally demonstrates turn equivalence then I I but I believe it's possible I think as a turing architecture as far as I understand it abstracted from the Von Neumann architecture is basically just saying like you can do a touring tape so I don't see why not why would we need that 512k ought to be enough for anyone right I don't know why we need it we expect it but yeah the these graphs in general are more like the space of the possible with the important caveats of that were mentioned with the no thumb on the scale and the mirror and the natural empathy note telekinesis but how relevant these edges are or what systems have what Behavior or what cognitive phenomena are granted by what Dynamics on graphs there's just no General answer to those things because if you do a graph for one setting it's going to be different what did you mean when you said that any entree could be ordered with any side dish like that in this recipe theme that we're in models that include continuous or discrete variables or both what is meant by variable States or observations how can States be continuous as those here are probably familiar with States or observations could be like discrete like zero or one or any integer or it could be a continuous number computers discretize continuous functions to approximate them but there's so many exciting directions with unconventional Computing analog Computing mem computing Etc that like there's more to it but just simply it could be any type of variable okay like this new new question this is this is um let's maybe look at this one in closing if the external state is unknowable how can we set up a generative process so that's what's generating the observations when our experience is based solely on the process of reducing variational free energy based on predictions and sensory inputs across the markup blanket this person has just described the challenge of life I don't think that there's a specific answer to that I think this is literally a restatement of the particular partition if this was just said um the challenge is based is to given the unknowability direct unknowability of unturned States The Challenge and the opportunity is to set up a generative model based solely on the process of reducing free energy based on predictions and sensory inputs across a blanket and adaptive action I'm not sure if they meant process or model here because setting up a generative process is something that the human modeler does when they're designing a simulation but not like what the um animal has to do what I'm trying to get at here is we are making an assumption about the generator sensory input when making the model yes but that model can never be accurate well it absolutely can be accurate it's never going to be a one-to-one map as the territory but of course it can be accurate we don't need to understand I have an atomic simulation of the sun to have a generative process of how many photons are going to hit my window tomorrow at 7am so there's a core invalidity in the notion that we set up a generative process model not sure what ontology mixing is happening but almost by definition we're introducing an error in the model by setting up the parameters for the generative process the general model we remove the fundamental of aspect of actin which is the dynamical system has only one thing you can do and that's to reduce free energy so there's some some good points and some mixed things so um it's not what it does is the action it takes in the world variational free energy is just a tractable computational heuristic yes if you set up the generative process to be a number continuous number between one and ten and then the generative model to do the exact same to kind of have pre-structurally learned the problem then it's going to be a simple simulation whereas you can have a more sophisticated simulation that involves structure learning as part of the agent's generative model are we not introducing information the model that would not be available in the real world if we actually defined the generative process yeah you can give any model too much information essentially so if it has if the model actually knows what is really happening then you know like if you were doing a um video game and it and you had a agent with supervisory access to the other players inferences or even control their actions yeah that's not going to work in a tournament but here with a particular partition we can actually know the information encapsulation and Majid Benny explores that in terms of the partial information encapsulation so are we not introducing information to model that would not be available it's your restaurant do whatever you got to do with the recipe if you want a pedagogical example that just make some clean graphs and is very straightforward and doesn't engage the complexities of like sophisticated cognitive structure learning that model is not going to complain if you want to do strange Loop reflexive structure modeling for ambiguous inputs of unstructured multimodal data Etc then that is your challenge so for many people it's just in one closing comment and many people this is the first time they've been exposed to statistical modeling and iterative modeling formally so that's why there are often questions that are like less about active inference but sometimes crop up about basically using statistical modeling overall which is a great thing because these are challenging and and areas with a lot of implicit and tacit knowledge so thank you fellows looking forward to uh next discussions and into uh heading into chapter seven next week Ali maybe we'll do a um maybe we'll do our DOT zero for chapter seven and eight but not in a hurry but we'll figure it out sure thank you so much thank you thank you bye