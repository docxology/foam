right welcome everyone to the active inference Institute uh this is week one of uh running through cohort 7 uh we're starting with chapter six of the textbook this is beginning the second half of the textbook as we know in the first half we're covering a lot of the fundamentals of active inference uh you know we started with an introductory chapter environments looking at a lot of basic fundamental principles behind ideas regarding uh behavior of of you know sentience organisms and so on we're looking at uh neural process theories and so how is it that neuronal populations perhaps function in a way that leads to different kinds of inferential processes such that uh you know beings kind of get around the world they update their beliefs uh they they make particular decisions and kind of wait those decision amongst one another uh they have things like attention we've been introduced to terms like prec and precision modulation that in the literature gets related to the idea of something like neurotransmitters and and and transmission and uh variety of other topics that that you can you know have a look at uh we tend to publish these these textbook reading chapters like these um sessions that we do and so you can review those on on YouTube under the active inference Institute Channel Chanel and then uh we'll start quickly here this is the cohort for anyone who's uh new this is the cohort uh seven uh page of the Koda so we use Koda is kind of like this open uh platform and forum for anyone who's not familiar with it um you can like actually just go in here and depending on like as long as you've registered for the textbook you should be able to like edit particular things you can place um you know there are Pages for for communications we have page that involve like you know different equations figures that are within the textbook for quick lookup and reference being able to index them to like a natural language description of what each of them are uh which has been incredibly helpful for people to just like you know rather than being stuck within a single chapter it helps to get a a broader holistic sense of what's going on in the textbook and then um let's see this course yeah questions these are are sort of like major ongoing questions this is kind of an overview this is not specific to any particular cohort right and so that allows for this kind of nestedness of you know intercohort communication and kind of leaving each other uh uh in a stigmergic fashion uh notes for one another different things that people have been contending with in their minds like what you know what what is surprise minimization what are these things like the high road and the low road active inference that we get introduced to in chapters 2 and three um why are we phrasing things this way all the way down to like deeper you know a lot a lot of topics in this book are kind of thought-provoking for a lot of people it brings up a lot of questions about what is consciousness and what is life and you know pan psychism and all kinds of interesting you know kind of additional topics that we may not cover directly in the textbook group but it it kind of begs the question for a lot of people some of these things so so it's a it's a very interesting full kind of historical archive almost of questions about you and then sectioned into each chapter so that way you can kind of like see what else is you know going on in other people's minds and thoughts so um we also we previously were running a math learning group I believe it's still ongoing with um someone who go goes by the Alias octopus but they're um you know very smart and this has been very useful to to a lot of people because a lot of people are coming into to active inference not necessarily having a background in in mathematics they don't necessarily have an intuitive sense of Matrix Matrix operations or or what a tailor series approximation is and things like that so it's very useful to have kind of like these sources that perhaps kind of spring up around the textbook without being confined to just the textbook itself um so we have you know plenty of other things we have some resources regarding like telling you about like pmdp I mentioned earlier uh you know there's coding documentation so it's a it's a very kind of open science environment where it's you know it's it's this is not a deep hierarchical uh structure that we have right so a lot of people contribute what they want to contribute and they kind of you know hope to to to get out of it what they put into it and vice versa and um yeah so that that's a I would say that's a decent um introduction and then there's also the onboarding page I'll also mention that quickly where you can um you know it kind of gives you overview of what going on in Dakota and then we can also get to like accessing the um the textbook itself I want to mention that um like so the the textbook is freely available now uh as Daniel mentioned earlier it's been around for like nearly three years now so already to this day like there's been an immense amount of research that's been P published since then um I would say that many many many of the core principles ideas even equations in the textbook are still highly relevant today that's part of the utility of continuing to go over the textbook rather than treating it as if it were something that's you know already obsolete um but then that said it's I mean for anyone who's come here because they saw friston's pixels to planning paper and renormalization uh uh generative models and and all the interesting things that have come out much more recently that you won't find them in this textbook you will find many of the kind of guiding principles that went into the design of those models however however so once again like you know if there should be a central node for learning active inference I personally would argue that it should still be the textbook probably um so to move on from there uh so yeah we're looking at chapter six today um normally I provide a very long summary sometimes too long at the beginning of these sessions whenever I'm the one leading the session I'll try to keep it a little bit shorter especially because like in the same way that chapter one was an introduction uh active inference the reason why we' split things up this way is in part because when you start chapter 6 it's actually like this is officially the second half of the book in the sense of It kind of has its own folky that it looks at so the second half of the book is going to be much more centered on modeling and directly modeling uh active inference agents and environments and and so on as opposed to many of the like kind of natural language descriptions of Core Concepts so so find some in the SE second half of the textbook so it's worth reading the whole textbook uh whether you're interested in cognitive modeling or you're interested in the philosophy or phenomenology of mind um so with I guess I'll get into it then with chapter six um this is a very general kind of chapter oos to the rest of the book maybe aside from chapter 10 which is just a broad overview of a variety of disciplines and how they relate to active inference so um for anyone who's also new to active inference actually jumping to the end of the book chapter 10 where we suddenly get to see a clearer picture of how variety of fields from like psychology study of emotion and affect to Robotics and cybernetics and uh even economic theory all have their own kind of interesting inter relationships with active inference like that's actually the the end of the book so so uh jump there if you're you know coming from maybe a different field and want to see how this relates to your own field um chapter six is a recipe for Designing active inference models uh and so this is really just kind of providing you something like a recipe or a you know the second half of the book can be read almost like a cookbook uh in the sense of let's decide on uh just a couple of Exemplar models that could be used in particular scenarios and then from there uh what are their core elements and then yet again from there you can start to figure out how to adapt them to your particular use case or phenoma of Interest so with chapter six um they try to boil it down to something like a simple four-step recipe um this it's one of the relatively shorter chapters in the book it's like an introduction to the second half um I do want to point everyone out uh point out to everyone this which is um I've always found this rather interesting um unlike many other approaches to computational Neuroscience the challenge is not to emulate a brain piece by piece but Define the generative model that describes the problem the brain is trying to solve what's the problem is appropriately formalized in terms of a generative model the solution to the problem emerges under active inference with accompanying predictions about brains and Minds um so so you can kind of see how you know as opposed to some sense of let's let's model some uh you know several billion neuron uh kind of brain model this is more about trying to model a system uh for anyone who's who's read the first half of the book you've already become familiar with the notion of a Markov blanket and so it's kind of like can you identify a particular system of Interest could be a person uh it could be you know just a particular region or or or or substrate in the brain it could be an entire like society and having nested marov blankets but the idea is that the you know the marov blanket allows us to sort of delimit the particular thing or system that we're trying to model and understand and so whenever it comes to like modeling let's say like a artificial or theoretical person who has a brain um the idea would be not so much that you need to model every single facet of them you're actually modeling just what is of Interest what what holds well together together what can be tested what has different kinds of physiological uh substrates and could be traced back to neurobiology so we make sure we're not running too far off into artifice land and um and so very typical modeling you know concerns and problems that are found in in data science or or or even economics or or or machine learning like essentially how do we how do we model something and how do we do it in a way that is generalizable such that it it can extend beyond itself it's like I've you know I've created an agent it can be in this situation it can be in that situation um but then also we we need it to to hold to realism right and being able to trace it back to the literature and and testing refining going back and forth um and so on so that's kind of what chapter 6 is trying to set us up for um we're just looking at what what does it make sense to to model so that's that's why I've always found this interesting we're looking for a generative model that in a sense represents sort of the the mind if I keep going with this artificial person that we're modeling to use an example of that then we're looking for the the generative model that they kind of hold uh say we Model A person who is engaging in a behavioral task for example then what is the model that they would be using uh you know for that if if their if the task is to play some kind of card game then do we necessarily need to Model A a variety of like other facets of that like like um do they have to be able to feel hungry or not or is that not really relevant to the particular situation that we're modeling um and and it's there that that's what this chapter centers around in the sense of how do we choose uh what to include in our model and and and starting with step one what even it what direction should we go and try to decide what the model should be which system are you modeling right so I've kind of kind of loosely already covered uh the sense of that we see um this may not be as simple as it seems it rests on the identification of the boundaries I.E marov blanket of that system and it might be useful actually now that I do have the coda it would be useful to have a look real quick this is a classic figure um you know move the um thank you oh yeah um sorry I'm not sure what it looks like on my screen just the the zoom windows I believe the vertical and the horizontal bar yeah um AR grade out but it looks good now thank you okay I see um so so in this case whenever we're modeling a system of Interest right it's it's kind of like on the left here this could represent our environment uh and then on the right this could represent our agent uh the terminology is for an agent that's the generative model and then for the environment it's the generative process um I won't say that those terms are necessarily arbitrarily chosen but it can uh you know for some people who are new using the word generative very frequently it might be a little confusing at first so I'll just say that for the agent It's usually the in the agent that we were interested in modeling and in one way of phrasing it someone else has phrased it this way I I believe it was Mark SS who who's worked a lot with Carl friston um it's kind of like we're modeling a system of interest that being our agent or and then the environment is kind of like the not system uh sounds very informal or even colloquial but the sense is is not your agent in this situation being able to draw that kind of defining line and then what is it that actually allows your agent to interface with this environment or or survive within it uh if that's the kind of Paradigm that you're looking at or or to interact with it in some kind of way and so it's it's here where the agent commits actions that then affect the environment it's not a direct onetoone relationship it's kind of like we have this sort of vicarious relationship between the two where an agent commits an action which is becomes kind of metaphorically an observation for the environment and then the environment takes that observation in itself then emits a new uh uh it's as if it's acting uh but that that action becomes an observation for the agent so there's this kind of reciprocal process occurring over the course of what could be conceptualized as an action perception Loop where an agent receives through their sensory States and observation uh that's perception and then through action they they may select an action or another term policy that they and commit which affects the environment and of course this can be formalized in a very discreet bit uh you know Loop by Loop way uh like over you know over T time steps or over you know T time steps within s trials or simulations uh but but in terms of sort of the literature and the actual the findings we tend to view these things as very rapid actually continuous processes right and in terms of like a neural process Theory so there's certainly different ways to to look at it and then um back to the the textbook uh other questions what is the most appropriate form for the generative model what what should it be what should it look like um we'll we'll be introduced in chapter 7 to discret State space models uh the PDP or partially observable Markov decision-making process is sort of one of the uh Exemplar models for discrete State spaces discrete State space for some people who are unfamiliar as opposed to it being like a continuous we're looking at values that are not continuously valued in the sense of like on a range of 0 to one you could have 0.1111 one5 like not that it's uh instead it's discrete State space so maybe there are three colors red blue and green um it it'd be that kind of setting and that that's very useful whenever it comes to thinking of situations where maybe an agent has discrete options you know it eats the food it does not eat the food it moves left or it moves right um and so on and how do how do you set up the model so that that's looking at things like varying time scales have hierarchical models and agents and so on and then how to set up the generative process which is essentially the environment you know the the not agent the not system um and and I want to briefly note that since someone mentioned um earlier that they're you know they're in an they're in their own environment where they're uh being confronted with reinforcement learning and and how that's being carried out to do cognitive modeling which is certainly uh you know a fair fair approach and it's being it's being done and it's you know it's very interesting it's starting to be done in the social sciences as well which is sort of my personal like deeper background um and then that said uh there's still a lot of kind of missing um theoretical or cognitive components to that so actually it was it was last year that a talk that I gave where I kind of made the case that is actually active inference that supplies a lot of the missing uh sort of empirical and and and wellth thought out sort of you know being able to trace all of these components of a PTP actually back to the neurobiology and being able to say what what each of these parameters is and then in addition to that the sort of exploration exploitation problem in expected free energy which kind of uh you know the quote in the textbook is that it gets naturally resolved or balanced through active inference as opposed to uh certain kinds of aspects of reinforcement learning where admittedly some of the approaches have been kind of arbitrary such as oh the agent does something random with probability point1 uh Epsilon greedy kind of for anyone who's familiar with that language so so all this is to say I I think active infer personally uh fills in a lot of spaces that that have yet to be really filled in or fully formalized within the reinforcement learning Paradigm for cognitive modeling it's like from chapter one in active inference it's like we already have a very large normative framework here that we can begin to apply and and test so um I didn't even need to go to the figures it's already here um I think that we're already over halfway through the meeting so I will start to just open it up now um for anyone who has any kind of questions or or thoughts or Curiosities this is just week ones so I don't think there's any strong imperative to to to get too deep too quickly so yeah anyone who wants to speak please go for it or they have a certain part of the textbook they want me to jump to and we could look at at it together yeah uh uh you have a specific example for the the first cartoon figure you you showed the figure 6.1 um you know maybe something on hand that's very particular so so this is a very yeah sure no and that's a good question um so this is a very general kind of notion in in active inference actually the you know as far as the figure goes like the caption action perception Loop between an Adaptive system and the environment so this this is kind of just a way of understanding like our agent has its own internal states its own beliefs what it's trying to infer um and then it uses those in in a sense maybe used sounds a little too um uh you know that has its own Nuance to it but it kind of it's as if it it it those beliefs are being used to figure out what actions to take that's what's represented here in the active States and those are what influence the environment so I mean um chapter 7 uh after this we'll get into discret State space models so pdps there there's an example of like a teenas where it's um you know it's a very kind of classic simple experiment where where uh there's like a mouse and it has to navigate a t- maze meaning there are two arms in the Maze it can go left or it can go right and then um one of those arms will have you know what what we assume to be like cheese like the essentially the reward uh that the agent seeks or wants or prefers um and then in the other arm will be you know either something uh uh innocuous or it'll be like uh like a shock or something negative something the agent does not want the mouse does not want and so the the agent has to kind of choose which way to go so what's going on within that agent is that it begins to model its environment uh you know in its beliefs and so it has beliefs about where it thinks the cheese is is it on the left or is it on the right and as more trials continue assuming that that agent has different kinds of adaptive capacities which in reality probably yes in terms of modeling that's kind of up to the modeler to to do their own research on how to to kind of evidentially back up the assumptions they're making when they set up their model but the that would be the sense like the so we have the mouse uh to the right um they they have a belief about where the cheese is uh it's on the left of the right so they choose to move uh as an action left or right and then by moving left or right that moves them through their environment and they get to now see the new observations of having gone left or right and those observations are taken in by the sensorium of the agent uh you know could be a visual modality so they see the cheese or not or it could be a more uh you know sense uh touch or or feeling physical touch kind of modality and so it's maybe unfortunately it's the shock and so they feel that uh and that comes back to the agent so so the point is that the agent has beliefs about what's going on they act those actions then elicit new observations from the environment that the agent then senses and it updates its belief um was that helpful yeah yeah I think so um I'm just um so the generative model is how the agent believes the data is creative and the generative process is how the data is actually created um and uh I'm failing to be very creative here and I apologize for maybe this next example but um if I consider myself as the agent maybe my beliefs are that if I cut down on the amount of coffee I drink per week I will get better sleep um the process is actually going to be myself because I'm going to actively cut down on the amount of coffee I drink during the week and my body is going to give me information about whether I actually sleep well or not um is that kind of it's the thing that came to my head right now but I wonder if that's maybe um okay it's a it's a really good analogy actually I mean in the sense of you know whenever it comes to like learning difficult material it's often useful to just make it familiar right like actually make it familiar quick from the beginning because then you can kind of ease into the concepts and that's a really good example uh in the sense that you know you you kind of have a belief or a hypothesis let's say about what kind of action you should take or could take to change uh you know the observations that'll be in elicited from your environment uh towards something that you prefer or want you know such as oh I want to drink less caffeine I will be you know healthier um and then that's also that's a solid ins sight uh regarding like oh my body is actually the the process right that brings us back to the sense of a marov blanket if we were to model that then it's in a sense yeah it's your own so so you know whenever it comes to the sensorium to having sensory receptors and this is throughout a lot of the Neuroscience literature this is not specific to active a lot of this isn't specific to active inference entirely um but in neurosci you know you can have interoceptive modalities where you are sensing things from within your own body and so as far as having a Jura of model and beliefs it's as if like I actually have to model my own body to to understand the physiological symptoms or symptoms the harsh word but signals that uh arise from it right so so actually that's a really good example and and I think it's a good horis and then uh sorry Daniel you you had your hand and then Stephen yeah yeah two two short comments on this first off we see all these examples and kind of become familiar with mapping diagrams and graphics and formalisms and the analytical basis of active inference to situations so that's exactly what chapter 6 is about giving one recipe for how do you go from being like I care about self-driving cars or I care about this person in this situation or myself in this situation to be what's an observation what is an action what is an internal State like that that is exactly what happens and then also just an important note is some people especially more recently describe generative model from the modeler's perspective to reflect the total situational understanding of all of the probabilistic relationships in the model that's being constructed and fewer people use generative process nowadays but when you get into the example and we will then whether you call it one thing or another in English or another language there is a distinction between like this is the agent's beliefs about what happens if they hit the light switch and then here's what actually happens when the agent hits the light switch so they are separate variables um and there can be veritical or off-kilter beliefs about consequences of actions or What observations map to so there separate variables it's just um no that in more recent work generative model sometimes is used a little bit more totalistic whereas in the textbook it's um used to cleanly separate the generative model of the agent being the total description of the agent to the generative process which is like the environment Niche that generates observations and accepts the actions of the agent awesome thanks Daniel I just quickly jump to this figure just to kind of illustr St they themselves are aware of it in the textbook it's like here is the sort of uh here is the the subjective model that we assume like maybe an agent has and then that said we are the modelers and so it's a very meta sort of perspective but it's very worthwhile taking into account it relates back to what I said like oh and machine learning data science reinforcement learning Etc it's like we kind of are making our own deliberate decisions regarding how we're modeling uh sort of the thing in the first place so being able to maintain that sort of Meta Meta level perspective which is ultimately what's going to actually feed into just producing better research and being able to to make that level uh of observation and comparison anyway so Stephen yeah go for it uh yeah like just like to nail down these Concepts if I can from my perspective and uh using like control of eye movements as an example where you have a certain you have six eye eye MUSC Muses that have to be controlled to move the eye so the default control of those eye muscles would be the subjective model is that right and uh so like the if I'm going to um if if I have a Target to move to a planned movement have to move the eyes uh send a motor signal to the eye muscles the eye moves but if it doesn't reach the target if there's a an error let's say a visual error I I don't see that represented in the figure you showed but I'm I'm assuming that's there's a way of there's a obviously there are equations to incorporate that and then the motor command gets updated somehow uh to compensate for the def default signal which was correct yes I I wanted to see if I could find it and I I I wasn't necessarily prepped for it for this particular session but there are various examples uh not many but but there are at least a few examples of of sort of like a isod paradigm and and recreating those kinds of simulations um in active inference so yeah it's kind of like so you're modeling your your agent in this case they have I and so so they're probably going to have some kind of control mechanism you know available to them that you sort of bake into the agent and the the model um so I'll return back to where we were yeah so it's kind of like you know the agent may have their beliefs in the sense of like maybe they have a belief about where they should look or or if they should look somewhere in particular um so sorry so the the word belief I can just replace the word uh default command or belief is the belief is the state of any basian parameter especially an internal cognitive one or a perceptual one at a given time so like the actuality of the process's state that gives rise to given visual input is the orientation of the eye and then there's a belief that we can say about what would I see if I were to go there and that is where continue on Andrew but I and I can add more about the isage because this is a really important key it's kind of like a dropa situation for understanding perception and action thank you keep going yeah that one thanks Daniel it's it's very helpful and uh yeah I I probably should have clarified that so so yeah another term is like this sense of hidden States or or hidden latent states of the environment uh so it's as if the the agent is kind of modeling that in in in their mind and so that that's where I'm using the word beliefs um and that's how that arises and then from there then to active States this is kind of like these are the sort of action affordances that are available to the agent of what they can do so it it's kind of like with the agent there will be these dynamics that you know maybe they choose to do something and the Dynamics play out kind of in the previous example uh that that I think it was Joe who gave uh regarding like oh my body is the is the environment in this case in a certain way it's kind of like oh well whenever I choose to to move my eyes like actually you know I can't change my physiology in a in a you know click of my fingers instead it's that I'm making decisions that I'm subject to kind of the environmental limitations of my eyes and their motor Dynamics and what they're capable of doing and how they're connected to you know and having retin ey and so on so so it's here in active states that like I actually choose something and then it you know it happens right and that's sort of this vicarious connection that I have with the environment around me it's kind of like I have beliefs I act on those beliefs and then by acting it's moving my eyes and from moving my eyes that brings about new observations for me from the environment um around me also just to the vision example it's um it's not a simple single layer model so just four phenomena that are actually incredible entry points for understanding how our our qualia is generated not um recognized only but Clarity in Vision around the periphery as well as color where the density of receptors is low um the absence of a blind spot and the absence of a motor um you know outside of just in in standard vision and the Cade being not attended to those are actually all very important phenomena that so that reflect that the primary sensory input to the retina is not what is being experienced as seen so it's like both the strength and the weakness of entering into a more complex cognitive phenomena it has um a lot more tangibility and like firsters experiential nature and our familiarity with it and yet you can you you may need to invoke several nested models or interacting subsystems but that is the work of cognitive accounting for something like cicing it's just that like the the simple models that don't have a tensional modulation are not going to capture that element of the Cade but they can they can be layered [Music] in uh hello uh so I once heard Daniel use the term UDA Loop and so I see observation I see action uh so my my understanding would be the Orient a would be the generative model and the uh decision would be the policy selection right basically yes UDA observe Orient decide Act is like a procedural parsing of this same system of Interest here there's a simultaneous flow happening across all the states and there's a degree of model freedom in which procedural order or if a procedural order is even used to describe it but yes observation comes in and is recognized where it intersects with a prior that's like observation orientation then there's policy inference which is like decision and then there's action selection which is action okay so that was a setup so my real question is so I was thinking that the generative model would be part of the internal States and so would the policy selection but it sounds like maybe the policy selection is actually the active States policy inference in terms of beliefs about policy beliefs about the consequences of action evaluation of policies in terms of their epistemic and pragmatic value those are beliefs that are internal States action on the interface is like the selected actual action because it's the active State that's exposed to the environment okay so then would you say both the generative model and the policy selection are part of the uh the internal States as as per little earlier generative model is used to in this textbook to describe the blanket States and the internal states of the agents the generative model is the joint distribution of sense internal and action that describes the agent totally that's the generative model and then internal states are the parameters or beliefs of whatever structure that are not on the interface so anything that's insulated from the environment directly is internal States and that can include nesting and metacognition and so on and the blanket States composing that action and the sense for the actual action going out and the actual observation getting spiked in yeah just just kind of second Daniel I mean for anyone who's familiar with the sort of just programming Loops I suppose um that would be a typical one way you could do it is um you know often we use the phrase action perception Loof but uh more simulations I've seen actually do more of a perception action Loop like they're they the other way around so so the agent uh I guess to put it in terms of like an UDA Loop in a certain way it'd be kind of like observe as the agent receives an observation and then Orient could be to take that information into account to update your beliefs or or these internal states that I stated and then decide uh relates to policy inference so you could you in fact you almost should view State inference and policy inference as kind of spe like two distinct Pro processes both of them involve minimizing free energy in different ways um but uh so so to decide in a certain sense is like oh should I do X or Y let's back up a sec and go back to orient well what did I just see and then back up before that what observation was elicited to me that that I observed right so it's kind of like I take it an observation I update my beliefs in terms of internal States then I update my my beliefs about policies or actions uh that's kind of the decide and then and then after that act is to actually carry out the the action right you could you could theoretically have an agent who can infer States and then after that uses that information to infer policies but then in the final stage they can't act because I don't know something happened or uh or something silly like the modeler just left out that line of code to to allow them to act on their belief about action so yeah there's State inference and there's policy inference and there are a lot of components within the agent that you know they relate the two they're not entirely um divorced processes but but in a sense they happen separately and I wanna I know that it's there's a lot of conversation going on in the chat but I could briefly speak and Daniel has answered the questions very well but there's a question is the generative model modeling the prior distribution or are we learning the parameters like mean and variance of the distribution uh in a sense we could say both depending on how you set up the model and so a lot of the kind of General model parameters I pulled this up earlier which can be slightly overwhelming when you're not given any kind of context as to what it is but this this appears earlier in the textbook and then it's kind of the centerpiece of chapter 7 later um but this is a this is sort of a PDP which uh an architecture like this would look very similar for a PDP in reinforcement learning uh maybe some some particular pieces are not shown in this diagram that maybe sets it apart but in certain ways it's very similar to just a standard PDP um and so like for a um the that's kind of like so the a matrix is like your likelihood it's very much related to just a general sense of perception you take in observations and you infer States so o observations conditioned on variety of different beliefs you could have right and then B is State Transitions and that's what adds a temporal Dimension to these models in the sense of you now have an agent who has a sense of what could happen next and so that kind of counterfactual space is now available to them to have beliefs about oh you know if I if if I'm hungry and then I choose an action to eat this food then I will no longer be hungry like that can be a belief you hold and you could potentially have a very high probability of that belief as opposed to other combinations of the the distinct States or or factors within within that sort of State space um C would be your pro it's c d and and e e is left out from this diagram aside from being present within G um but C is your over observations and so that's an interesting one because it's often framed as preferences in the sense of this is what I want to see and so many models in active inference are modeled in such a way that you could learn the C it could be updated over time by uh updating it using uh a free energy uh free energy minimization rule that allows you to like kind of learn uh sort of a hyperparameter on C so in the sense of like oh I could learn to want something different than what I currently want or I could learn learn to want an additional thing in addition to what I already want so that's possible or you can leave it static a lot of people do that whenever it comes to behavioral tasks in the sense of oh you assume during the course of a trial someone's not going to dramatically change what they want in their life or in their physiology or something so so it can be left static so um so that's prior D is the prior overstates so uh as Daniel mentioned earlier like the just the three most General components of getting started with with constructing just about any model are states observations and actions once you figured those out then it's really just choosing what's the appropriate model to relate those three different things and so that's what we get in the case of a discrete State space PDP like a relates observation and States B relates States temporally plus along with actions then C is your prior over observation D prior Over States G that's just your expected free energy term which um you know so that's that's using your prior beliefs about observations and actions here to figure out what policy to take and of course there are breakdowns of this uh you know functionally but uh that that's a general s so so as opposed to getting overwhelmed it's really everything boils back down to what are the states observations and actions of your model and I have just noticed the time and and we're nearly out so um Daniel I don't know if you have any kind of uh inotes or or final words you want to throw out there or um yeah chapter six is like the um practical entry point chapter 1 and also chapter 10 deal more with the theoretical aspects of active inference but before or after reading those if you're like how do we actually do cognitive modeling that's what chapter six is one attempt and one um proposal for and the questions that are asked in chapter six about how do you go from a system of interest on through procedurally constructing a model it's there not every single nook and cranny is there but there plus asking in The Institute Discord and colleagues and looking at papers and code bases it is there so like for those who can code or prompt generative AI or just are getting a first pass on this application it rounds out a lot of like the theoretical discussions some of which may just be perennially open but this is it is really applicable so I hope that um you know whether you're going to stay at this time slot or a different time slot or just however you uh Jump Around the textbook and wherever you're at in terms of like looking for more philosophical uh exploration to the code implementations and actually doing empirical inquiry um six is a good chapter and write your questions in theoda if you have them or email them if you don't know where to put it or just put it anywhere and uh welcome to the next phase of activity for the textbook group and we'll have chill discussions at this time weekly yeah exactly great and and and go through the prior asked questions and some and and where you have uncertainties you do a tremendous service by commenting and writing hey sorry Daniel um my apologies for for coming late is there a a particular section that we're focused on each week or um what would be the best way to prepare for next week yeah if you look at the cohort 7 and cohort 8 live meeting Pages it'll have like the exact contents of each discussion so yeah Andrew's going to it so here's where we we're today at uh 23 UTC next week at this exact time slot cohort 8 is going to be discussing chapter one and then just everyone's been added to the calendar events and just check which week or time but the two cohorts alternate early and late time slots but the two time slots stay the same every week so seven days from now it'll be chapter one discussion two weeks from now at this time slot we'll be back in cohort 7 discussing chapter 7 so um but you can you can read and and enjoy and write questions and add discourse to any section so doing and contributing anything don't be limited to what's on the agenda but this just sets a pace because we could we could spend two minutes on each chapter or we could spend two months on each chapter so it just keeps apace rolling and gives time zone accessibility but there's people who don't even join the live meetings and they're just looking to contribute asynchronously or on their own research so like however it looks like for you to be learning and applying it go for it and as Andrew said like the 22 textbook is kind of a milestone work so it's a good place to ground and connecting it to specific figures equations quotes that gives you a shared touch point with other people as well as opposed to just free floating questions which also can be critically important it's just that they're they're sometimes coming out of left field from other people's view so that's great thank you thank you farewell and I'll upload the recording as well so if you ever don't make it or you want to look at the prior coords and times just check out the recordings okay fair well bye