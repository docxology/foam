foreign hello and welcome it's March 29th 2023 we're here in active guest stream number 40.1 with Banya Visa we're going to be hearing a presentation in the first section and then having a discussion so thank you Vania for joining again really looking forward to your presentation thank you very much um so this presentation is based on a preprint that can be found at Phil archive and this is work in progress and uh probably or hopefully upload a revised version of this preprint in a few weeks so if you're watching this or if you're reading the pre-print and have any comments or questions feedback is very much welcome and I'm also again grateful for having the opportunity to present here because I'm really looking forward to the discussion and any comments that people may have while watching this video so do contact me if you have questions or comments now I want to start this presentation with an idea from this wonderful Novella by tatchiang the life cycle of software objects and if you're not familiar with the novella it doesn't matter so there's some digital entities or digians as they're called in the novella who um at first live in a purely virtual environment so these are virtual entities like virtual pets and human users can interact with them in a virtual environment then in some passages of the novella there are scenes in which some digins are as it were downloaded from this purely virtual environment and are implemented in a physically embodied robot so the program that is running on in within this computer simulation and is controlling the purely virtual body is then downloaded into a physically embodied computer and is controlling a physical robot which can interact with its physical environment non-virtual environment in the same way in which the virtual agent the virtual Digi and interacts with a virtual environment and I find this idea really fascinating and Powerful so the novella suggests that these virtual entities are conscious and that they can switch back and forth as it were between this purely virtual environment and uh physical non-virtual environment and the idea is that the these entities remain conscious when they're in the robot but also went there and returned to the virtual environment and to some people it may be unintuitive or counter-intuitive that a purely virtual entity and a simulated environment can be conscious or maybe some of these people will find it less counter-intuitive to imagine a conscious robot and so the the um idea is fascinating to me because it suggests that well if you can switch back and forth from the virtual environment to the physical environment and in the other direction and really doesn't matter where the the software is implement the system remains conscious and I will come back to this idea at the end of my presentation and we will see what the the account that I'm presenting here suggests with respect to this scenario also this is the overview of my presentation which which is based on the preprint I'm just omitting a lot of details so start by saying just a few things about the pre-energy principle then I will ask what is the difference between an unconscious simulation of a conscious system and a conscious computational system on other words what's the difference between what is called weak and strong artificial Consciousness so strong artificial consciousness is conscious isn't actually conscious uh artificial system and weak artificial Consciousness is constituted by a an artificial system that maybe behaves as if it were conscious or that simulates the conscious being but is not actually conscious and I'm interested in the question what's the difference and a particular version of this question is whether a computer simulation in a computer with a phenomenon architecture can be conscious so I start with the free energy principle and um I don't want to get go into the details so we start with the with a description of a physical system so the x is the the physical system and the fundamental assumption is that the Dynamics of physical dynamics of this system can be decomposed into two components so we on one hand have a deterministic flow term F and then some noise term stochastic noise terms so we end up with a stochastic differential equation which describes how the physical system evolves over time the further assumption is that we can decompose the states of the system into internal States mu external States ETA sensory States as an active States a which together so sensory and active States together constitute the blanket States B and this then is a particular system that can be partitioned into internal Annex external States separated by blanket States and a further assumption is that the dynamics of this system can also be partitioned in the following sense that we can decompose this flow term into individual flow terms for the different states so we have a flow term for internal States mu and can also describe the Dynamics of internal States in terms of software differential equation here okay so these are just technical fundamental assumptions made by the free energy principle but then the interesting thing starts here when we look at how we else we can describe internal States and the Dynamics of internal States so the idea is that we can map internal States mu to I to probability distributions so this is your formulation in terms of states and then the idea is that at every point in time the system will be in certain States so there will be internal States relative to each time point and we can map each of these states to start to some probability distribution Q of external States given blanket States okay so we can do that but then the question is why should we do that and the idea is that maybe we can redescribe the flow term which is essential for characterizing the Dynamics of internal States can we redescribe these flow terms in terms of the probability distribution encoded by internal States and the free energy principle answers yes we can rewrite this term in terms of a variational free energy functional which specifies how the probability distribution Q which is parallel parameterized by mu changes over time so we can re formulate the physical dynamics of internal staves we can rewrite the flow term in terms of variational free energy or in terms of minimizing variational free energy with respect to a probability distribution encoded by internal States and this is then called Bayesian mechanics and it's called Bayesian mechanics well because minimizing variation of the energy involves minimizing it Divergence term between the internally encoded probability distribution q and a posterior of a external States given blanket States okay so to to sum this up I will give these ideas some some labels so I've already talked about the physical Dynamics and this these are the Dynamics of a particular system described by stochastic differential equation involving a flow term and a noise term and recall that a particular system is a system that can be partitioned into internal external and blanket States and then according to the for energy principle we can redescribe these physical Dynamics in terms of as computational Dynamics we can reformulate them in terms of a description of the system's internal States mu as performing approximative Bayesian inference by minimizing variation of free energy with respect to a probability density encoded by mu so right in in short we can reformulate the physical Dynamics as a computational process that involves the form of Bayesian inference now a further assumption that I want to make here is that we can capture the computational correlates of Consciousness in terms of the computational Dynamics as described by the free energy principle so yeah the computer computational corals of Consciousness or cccs are defined as a computational dynamics of a physical system of a conscious physical system as specified by the free energy principle okay so this is not just any physical system it's a conscious physical system forgot to add this on the slide all right so given these initial assumptions and definitions can we say something about the difference between weak and strong artificial consciousness and I think we can um so let's start with the the idea of a computational quality of Consciousness um computations are medium independent so it's plausible that a digital computer can Implement computational corals of consciousness well then the question if we want to distinguish weak from strong artificial Consciousness is is every system that implements ccc's conscious or do systems have to implement these computations in the right way and what would that be okay so to better understand this question I find it useful to look at this diagram and um see where we started so we have a description of a control systems physical Dynamics in the bottom left and then according to the free energy principle we can reformulate this redescribe this as some computational Dynamics and by assumption these include the computational correlates of consciousness and they must be implemented by the physical dynamics of the conscious system now given that these are medium independent properties they can also be instantiated by other systems and here I'm assuming that there can also be that these computations can also be implemented by a digital computer and the digital computer as a physical system has some physical Dynamics and if we can apply the free industry principle to it we can reformulate these physical Dynamics as computational Dynamics and so then the question becomes do these computational Dynamics do they include the computational correlates of Consciousness whatever they are so this is a crucial question that we have to answer if we want to know what the difference between weak and strong artificial Consciousness is maybe there is no difference so before I present an argument to the effect that in general the computational Dynamics of a digital computer will not entail The computational Columns of consciousness before I present this argument I will present some observations on the apprenticeship principle so note that systems that conform to the French principles sustain their existence by minimizing variation of free energy but the reverse does not hold so you can run simulations of agents that minimize variation of free energy and you can do that on a computer which does not thereby sustain its existence so it would continue to exist regardless of whether it runs these simulations or not okay just to illustrate this with a quotation which may be familiar to many so this is by press mat out many theories in the biological sciences are answers to the question what must things do in order to exist the free energy principle turns this question on its head and asks if things exist what must they do more formally if we can Define what it means to be something can we identify the physics or dynamics that a thing must possess and Jacob Howie puts a similar Point as follows for energy principle analyzes the concept of existence of particular self-organizing systems so the idea is that continuing to exist sustaining one's existence means minimizing variational free energy and so any processes that contribute to minimizing variational frenzy and thereby contribute to the sustained existence of the system foreign such processes can also be implemented in other ways by different systems which do not thereby sustain their existence on this I want to suggest is a crucial difference between systems are merely simulate Contra systems and systems that actually are conscious okay so and I will hopefully clarify this idea in in a moment by presenting an argument but before that I need a definition so um um I want to introduce a notion of intrinsic computation and these are just computations that contribute to the sustained existence of the systems so these are the computations that figure in the computational reformulation of the system's physical Dynamics according to the free energy principle and intrinsic here means these computations are Observer independent so it's not the case that we as observers say okay we can interpret the system as performing these computations or it's useful for us to use them as computational devices the idea is that these computations are processes that are intrinsic to the system that only depend on properties of the system itself and not on relations that the system has to observe us or to other beings okay um so here's the argument which in a way is already contained in the preprint but um I did not formulate the argument of this explicit way so I'm grateful to Tommy corbach Who provided some comments on my pre-print and to also suggested a or um a reconstruction of the argument that I'm presenting in the pre-print and uh this formulation here is based on atomic's suggestions and I hope this clarifies the argument that I'm putting forward developing in the pre-print okay so the first assumption and the argument is a version of computationalism about Consciousness and the idea is that causal roles that characterize phenomenal Consciousness are medium independent and can be captured in terms of computation these are computational correlates of consciousness so the idea is that Consciousness does not require a particular type of substrate it can be in principle can be realized by a different types of system as long as these systems implement the right computations so this assumption as I am intended does not entail that implementing the right computations is sufficient for being conscious and see it just meant as a necessary condition [Music] and the idea is that there are informative interesting computational correlates of consciousness and they can in principle be are formed implemented by different types of system then comes the second assumption According to which every conscious system and its computational correlates can be described by a mechanical theory that conforms to the free energy principle so this is an assumption about the scope of the free energy principle and it's at least clear that the free energy principle is intended to have a very wide scope that's not meant just to apply to a human brain it's not just meant to apply to living systems but it's meant to apply to a very wide class of self-organizing systems and um this idea or this intention that the free energy principle has a very wide scope is also evidenced by the fact that recent formulations and recent developments in research on the free energy principles seek to relax certain assumptions that were made in previous version so as to make the free energy principle applicable to a very wide class of systems and not for instance just to systems in non-equilibrium steady state for instance just as one example all right um so and the idea is that we can apply the free energy principle to conscious systems and that means we can move from a description of the physical Dynamics to a description of computational Dynamics and these will include computational correlates of consciousness okay then the third assumption makes a connection between intrinsic computation and Consciousness a system is conscious only if it sustains its existence by virtue of the computational correlates it's it realizes such computation callers of Consciousness are intrinsic computations computations that contribute to the sustained existence of the system so if a system follows certain or Implement certain physical Dynamics which under the fep can be described as computational dynamics that entail computational currents of Consciousness whatever they are then the system's conscious but it's only conscious if it's in this direction so in principle it's possible to implement the same computational processes without being conscious and this is in becomes clear in a conclusion or as described by conclusion one it's possible to instantiate computational Columns of Consciousness in the physical system without instantiating Consciousness namely if realizing the computation of correlates of Consciousness does not contribute to the sustained existence of the system so assuming that a digital computer can perform the computations that characterize consciousness in conscious systems it's likely according to this proposal it's likely that the computer will not thereby be conscious because it could Implement different computations it really doesn't matter what computations it performs it will continue to exist as a physical system regardless of the computational processes that it implements so it does not sustain its existence by virtue of the computations it performs all right um and a condition that is entailed by this is that from the point of view of the free energy principle of computation of the physical system is intrinsic if it matches the physical the system's physical Dynamics um and this will be um important also for the question about Consciousness in in computer simulations so um the second conclusion that I want to draw here is that computers with a Von Neumann architecture cannot Implement intrinsic computations because their physical Dynamics it uses a causal flow that is different from the causal Flow entailed by the computational Dynamics so there's no match between the physical and the computational Dynamics or between the physical Dynamics and other computations that are performed within the computer simulation well unpack this in the third part of my presentation so could there be Consciousness in a computer simulation computer with a classical architecture so um this is an idea that uh already presented and previous works so in a system that conforms to the free energy principle there's a basic flow from internal States via active states to external States and from external States via sensory states to internal States so we have these circular Dynamics and in a computer with a Von Neumann architecture the basic causal flow is a bit different so we have um memory and we have a central processing unit and the units that store the values of the different variables of internal that that stand for internal external and blanket States they are in the memory unit and there's no direct causal interaction between these units but it's always mediated by the CPU um so that's the basic idea and therefore there's a difference in a closer flow and I cannot this means that the physical dynamics of the computer does not have a or the if we want to reformulate the physical dynamics of the computer in terms of minimizing variation free energy we end up with something that cannot match um the that that we end up with computational processes that cannot be identical to the computations that are simulated by the computer um because then there would have to be a match between the states that represent the probability distributions encoded by internal States and the internal States themselves okay so from this I suggest we can derive two necessary conditions for Consciousness one is the flow condition the causal flow of a physical system's computational Dynamics which realize um which may realize computational correlates of Consciousness must match the causal flow of the systems physical Dynamics and then there's a second condition which I call the existential condition physical system sustains existence by virtue of the by virtue of realizing computational correlates of consciousness um so if it's a conscious physical system then this is the case all right um just a few observations or notes about this so A system can satisfy the first the flow condition without thereby satisfying the existential conditions so there's the existential condition is stronger than the flow condition um but if a system satisfies the existential conditions then it also satisfies the flow conditions um and not all systems that satisfy both of these conditions are conscious in other words neither of them are sufficient for Consciousness these are really just strictly necessary conditions for consciousness all right that's me uh return to the the idea that are presented in the beginning beginning from touching's Novella so from the point of view of the account that I presented here is it possible to download Virtual entity to a robot and will it be conscious um or can it be conscious in the simulation um so I'm I should just assume here that these systems satisfy the flow condition or first condition so um assuming that this is a very special computer simulation in which the physical states that represent internal external and blanket states that these physical States also directly causally interact with each other um and um according to the account proposed here the computer simulation that there would still not be Consciousness in the computer simulation because the computer does not sustain its its existence by virtue of Performing these computations it could also run different simulations which do not involve these digital entities and it would continue to exist so according to this the account presented here there would not be consciousness in this system and if we download the part of the program that controls the virtual agent and download it to a physically embodied robot because that robot be conscious well in principle it could if the robot sustains its existence by virtue of Performing the computations that are also performed by the computer simulation and um now this result might be a bit strange because contrary to what the novella suggests it would suggest that the system cannot switch back and forth between the virtual and the physical non-virtual environment without losing consciousness and I admit that this is a very that is a kind of counter-intuitive implication but maybe it only seems counter-intuitive maybe it's not technically possible to download a virtual entity which was trained in a purely virtual environment and and um and download it to implement it in a physical robot and thereby allowing the physical robot to interact with its environment in the same way as a virtual entity can interact with a virtual environment so I know that in robotics there's a certain strategy to uh to train robots or to um yeah develop the controller of the the physical robot naming that you first train it in a virtual and a simulated environment and then you use that to control the robot maybe this only works for robots that have kind of have certain limitations in their sensory motor abilities maybe it doesn't work for highly sophisticated robots that are more like conscious organisms which can react adaptively and very flexible in a flexible way um can interact flexibly with the environment on the basis maybe of effectively guided effectively shaped representations so this would be a maybe an empirical hypothesis derived from my account that this strategy um this symptom real strategy of simulating an entity in a virtual environment and then applying that to a physical entity the the prediction would be that this has will at some point reach limits and will not be successful if on the other hand this hypothesis or this prediction will turn out to be false I'm I think we should reconsider the account that I'm presenting here okay let me conclude um I've asked what is the difference between weak and strong artificial Consciousness and the suggestion is that it's about intrinsic computation that's the difference um actually conscious systems sustain their existence at least in part by virtue of performing certain computations and a mere simulation of a conscious system does not thereby sustain its existence it could also perform different computations and still continue to exist this condition entails the flow condition which is important for the second question called a computer simulation in the computer with a phenomenon architecturally conscious no because it violates the flow condition okay isn't an ad for the Journal of philosophy and the mind Sciences which I'm running together with Sasha thing Jennifer wind and Regina fabri and I thank you for your attention a awesome thank you I'm just getting my video back in the game um while I'm getting everything back on the Stream first just thank you for the presentation and uh wanted to pick up with that robotics intro and conclusion to what extent does the embodiment in the robot matter beyond the ability of the virtual simulation to do things like eject the CD drive or ultimately do physical things just not the kinds of physical things that we see human children do like play with toys um when you were do when you were thinking about the virtualized simulation simulation were you thinking about one that had no access to sensors and actuators or what happens when the digital simulation also has access in some limited way to the ability to sense and act on the outside world if you have any thoughts sorry about that on the stream it was audible but not to you so I see but now I've resolved the zoom so we can from your Consciousness perspective consider it a new question so I just wanted to to pick up with that robotics example um a digital simulation may still have sensors engaging with the world and may still be able to undertake actuation if only something like flipping a switch on a processor so what exactly about the embodiments do you think matters for it to have that kind of adaptivity and maybe even open-endedness and learning that you pointed to as an important property yeah um good question so um it um I think there are many different aspects that you're touching upon are let me start with this one so I um mentioned my correspondence with atomic callback and one thing that he suggested was that um couldn't we regard a language model as a system that has certain sensory motor abilities so it can interact with a physical environment via a linguistic interface so it receives text as input and it outputs text as it outputs text and um can't we regard this as sense as as sensing and acting and um so this this I think is um similar to one of the aspects that your question touches upon so what is it about the the embodiment and can that be different forms of embodiment that might still lead to Consciousness and I don't have a full reply to this just um two things that um I would mention here the first is that there are certainly some analogies between what a language model does when it interacts with a user and a system that maybe an organism that interacts with its environment via perception and action but there are also some dis analogies so when it comes to interacting with the environment for a when an organism interacts with its environment the their temporal constraints um it's really important that it um does the right thing at the right time and reacts fast enough and so on and for a language model that does not play a big role um so there's one difference and then there's also a difference in the format of the representations and in principle you could say okay why does this matter and um maybe in the end it doesn't but I just want to mention that there's some crucial this analogies that I think would be important to take into consideration and evaluate then uh that's the question okay is there something about these more low-level sensory motor skills that is crucial when it comes to consciousness now on the one hand we know that a an organism can be conscious without having any language skills without being able to speak or understand language and so this this is why when it comes to functions of Consciousness for instance people don't look for or usually don't look for linguistic abilities but more for sensory motor abilities or forms of learning that enable or improve interaction with the world and so that this is one thing but of course in principle it could still be that A system that lacks these low level low level skills is conscious but then I would say if if it's possible to be conscious without having these sensory motor skills then it's not really about any ability for interaction with an environment that a system is conscious but then it's merely because of some internal computations that the system performs so if you're thinking about um systems that might be islands of awareness systems that don't receive any sensory input and don't produce any motor output then it's I I wouldn't want to rule out that such systems are conscious and these such systems don't have any ways of interacting with their environment so I'm happy to accept that um the that interaction with the environment is not required for Consciousness and but coming back to language models this would mean that being able to interact with users using language is similarly not required for Consciousness so I would say if such a system is conscious then it's not because of its ability to interact with the environment because of but because of the internal processes and um the what what may be crucial is not the actual interaction with the environment but just the potential for interaction with the physical environment and then it might and in principle it might might very well be that a language model can facilitate interaction with the physical environment for instance if it's connected to a physically embodied robot and I mean there's research going on um on on such things researchers who try to improve the abilities of their robots by connecting them or interfacing them with a language model which can help translate commands into motor sequences and um so what this suggests is that yeah maybe there are some crucial types of representation or computational processes that are actually already implemented in language models or in other systems that don't really not not directly interact with the physical environment and I'm happy to accept that but I would add that according to the at least according to the proposal that I I've presented here you need something more for that and you you need really um the the so it's it's not sufficient to just Implement these computations but they must have a meaning for the system itself in a sense that the system will sustain its existence by virtue of these processes if it is connected to the real physical environment now um maybe that I've not addressed every aspect of your question so feel free to [Music] um restate your question or oh it's great it got to a great place because I wanted to follow up with this intrinsic computation concept so you mentioned that their Observer independent to the extent that anything or any process can can be and that these are the kinds of processes that actually enable the um Persistence of that thing according to the fep and so I was thinking about this first in a bottom up way like this is the firmware this is the Linux kernel this is the kind of enabling software that is supporting potentially extraneous higher order functions and that is allowing some kind of separation or delineation between what we could say are like the vital and intrinsic like almost the homeostatic functions and then second order functions but then I thought about the ecology that the computation is deployed in and so let's just say that the software um is being the the software simulation is being used in a scientific context or to run Photoshop and another cognitive agent keeps that simulation alive because it's performing some function and so from that bottom up sense the Photoshop program is not the Linux kernel so it's not like the photo like the Photoshop in principle is not sustaining the Persistence of the entity in a bottom-up fashion however in deployment it actually becomes a necessary condition imposed externally so and that will also be extremely Observer dependent or subjective so how do we think about um in standard modern computers or in wet wear what are these intrinsic computations thank you that's um that's a great question and um so [Music] I can say more about intrinsic computation in a moment but just one comment before that so I think you're touching on a very important issue and that's the question what is a system in the first place so if we want to [Music] consider the question what kinds of entities can be conscious when we have to first say okay what what are the entities that we're looking in at in the first place what are these things and why can't we look at a piece of software or some process that is running a an app that a user is using um what was the example that you gave Photoshop or something so um why can't we regard Photoshop and a particular instance of this software as a system which exists for some time and it will continue to exist if it's useful for a human human being and it's useful by virtue of the computation where the computations that are realized by it and so can't we say that the system sustains its existence by virtue of the computations that it performs and so that that's um I think a very crucial question because it's so fundamental so what is a a system and currently I think that the free energy principle is sufficient to answer this question but it may be that it's still too General so I mean the the conscious the the French principle gives us an answer to the question if something exists what must it do and so we we it analyzes this notion of uh the continued existence of self-organizing systems and um maybe it does apply to the processes that Implement Photoshop in the computer of a human being who uses this software and if that's the case then I think um we have to add some further constraints to or yeah it may be necessary to add some further constraints on the kinds of systems that we want to regard as potentially conscious or that we want to consider when it comes to the question what kinds of systems can be conscious and one just one suggestion or idea that I think would be worthwhile to explore here is to investigate to what extent something like the free energy integrated information Theory May complement the free energy principle and this regard because integrated information Theory has a very strong emphasis on the notion of existence of what it means to exist what it means to be what it means to intrinsically exist as it were not just in the eye of a beholder and maybe we we need to add constraints from something like integrated information Theory which will then tell us what types of systems really exist and then maybe it would say okay the processes that are implementing Photoshop in this computer don't really exist in an intrinsic sense um yeah so this would be that what would then be my suggestion to add some constraints but of course you could say well no um such constraints are completely unnecessary we don't need to exclude certain systems um and we can regard the processes that Implement Photoshop as um real a real system that sustains its existence but my intuition would be at least currently that such processes would at least in a classic system with a classical Hardware would be too scattered and um there would be so many physical processes interfering as it were that it's it you can regard this as a separate thing which is distinct from other things that are happening in the computer [Music] but I would say this is more an observer dependent property those processes there that so entangled with other processes in the physical system that they are not particular systems in the sense of the free energy principle awesome and again kind of Journeys us to another question about the topological or geometric concordances between physical and computational Dynamics and it made me think of a few different kinds of systems the Von Neumann architecture described with the CPU and the Ram regular desktop computer situation of course we have unconventional Computing paradigms Quantum and analog computers we have the brain and the SPM package in which statistical inferences help us model how brain regions that aren't connected through for example axons can still have an edge in a Bayesian graph they could still have a causal effective or a functional connectivity without being structurally connected and vice versa and then to kind of bring it back to the computer and what you brought up about whether or not those processes would be too scattered what about a computer either a distributed computing cluster or a strict virtualization scheme on the computer such that certain variables were isolated would it be enough for the system to have some kind of constraint again through a physical networked layout or through a virtualized system so that the computational flow and the causal flow could be played with in a different way and then how would we know what would we be looking for surely not simply um test retest accuracy or efficiency in some way that's not what Consciousness is so I mean it really comes down to what are we looking for or talking about if we did have the ability to design different systems that did have different overlap with their computational and structural aspects yeah oh great question so um I think it's very important to look at different types of computer architecture different uh types of Hardware [Music] um and you mentioned some so there's actually um something that was um pointed out to me by Johannes Kleiner so here pointed me to the notion of computation and memory or something similar and if I understand that correctly it um is a slight departure from the the Neumann architecture because you're actually do computations within the memory unit so it's not that you have additional memory units within the CPU but you perform computations in the memory unit itself um which would be a way of satisfying the flow constraint the flow condition that I mentioned and similarly there may be other architecture Maybe neuromorphic Hardware that also could Implement simulations in a way that satisfies the flow condition and as I pointed out in the presentation the flow condition is just one necessary condition which is weaker than the existential condition so all of these systems even if they satisfy the flow condition were not thereby also satisfy the stronger existential condition but as may have become clear I am not completely certain about this existential condition or rather um there may be some ways in which one can describe what's going on in such systems that you can actually say okay the processes that Implement these computations they are systems particular systems to which the free energy principle can be applied even if maybe the material on which these processes run is not directly affected by these computational processes or maybe the if we think about maybe neuromorphic computer chips maybe the chips themselves they will continue to exist no matter what computations they perform but if what's going on if the activity that implements the computations within such a chip is sophisticated enough or has certain properties maybe this activity can be regarded as a an instance of a particular system to which the free energy principle can be applied so I'm not completely certain about this and I think this is something that has to be clarified um yeah I am maybe maybe it will be useful also to see what people are actually working on the forensic principle what would say about this but that's very important point yeah a few things that makes me think of first is kind of like the hard problem of virtualization or something in that some modification of of a hard or easy question um and then also about the difference between a case where the material substrate of computation is its own self-referent sustainer and another case in which the material basis of a computation is projecting let's just say a non-equilibrium steady state like a holograph or or it's creating robots it's spinning out robots or it's doing 3D printing so in that situation depending on how the system boundaries are modeled um the viability of one part maybe even like it's kind of semantic germline is required for the continued propagation of some other part of this persistent system but that part is actually disposable even though it's the embodiments [Music] I'll I'll go to a question in the um live chat and also I think it was a mem computing was was the memory based computer yeah and agree there's a lot of interesting um threats there so um Ali asks a question in the chat he wrote what about understanding if we Define understanding as a kind of correlation or mapping between spaces of semantic possibilities can we say that large language models do indeed understand their prompts and outputs and this understanding in this sense require or entail Consciousness or vice versa so with understanding as a map among semantic spaces what can we say about llms in understanding and what is the relationship between understanding and consciousness thank you and that's a very good or these are very good questions and um of course it depends on on the notion of understanding and if we conceive of understanding as um yeah as a way of grasping inferential relations or associative relations between different Notions if we um and so that certainly is some some form of understanding that um large language models have they can relate Concepts to one another and uh their representations of um Concepts in a vector space with those some important parts of the structure of conceptual spaces of of our language so in in this sense they do understand some things and then there are other forms of understanding and um I wish I would say something in a moment but um because that's a bit more complicated and I I cannot say as much about it I think but um the question whether understanding entities Consciousness or understanding in the um sense you mentioned I would say it does not entail does not require consciousness so you you kind of have that without consciousness and um another question is well does Consciousness require some other form of understanding Maybe and I or at least my proposal here would suggest that yes there is some form of understanding that is required by consciousness and this is an understanding which is related to knowing what things in the world some words or representations refer to so this requires that you actually have a concept of there being a world of which you are a part and I don't think that large language models understand that they are things in the world they don't know that there is something out there of which they are a part and I think that's crucial for a a certain form of understanding um and in order for certain things to be meaningful for you you must somehow have a concept of of the the world and and a sense of that that you're part of this world and how you relate to things in the world and so on now um this I I think is required for some form of understanding and I think it's also required for Consciousness at least according to the proposal that I presented here and the idea is that if a system not only has some internal representations that it manipulates but if by virtue of doing so it sustains its existence then this puts some very con strong constraints on what the system will do with these representations so [Music] um if you um if you think about a a self-driving car um and and principle it may compute all sorts of things and it will not have a meaning for the system for the car itself but if these processes are realized in a way that the system systems continued existence depends on these computations and this puts some more constraints on what it can do with these internal representations and which will give such a system maybe some form of Common Sense and um allowing it to draw certain inferences and avoiding other inferences and so on so um that would be my um hypothesis that there's a certain form of understanding that requires these uh that also requires these the conditions that I think are necessary for consciousness hmm in that I hear a shift from semantics and semantic embeddings to true semiosis and the abductive process of generation of embedded meaning so it's very um interesting okay a few more questions one you've been writing excellent and diverse papers on different mathematical formalisms of Consciousness for some years now so how have you seen the empirical side and the theoretical side of scientific study of consciousness developing in the last several years and how do you believe that the current inflection points in artificial intelligence are like re-contextualizing or modifying your agenda or bringing different relevance to your work um yeah that's a good question and in general I would say that I mean there's there's been since the 90s has been an explosion of empirical work on consciousness [Music] um partly also due to certain methods that were and paradigms that were developed and imaging technology that improved and so on so we have better ways of empirically studying consciousness and so in the past years as in or decades a lot of empirical data on Consciousness has been gathered and many things have been found out and I think that two reasons for which many people are now driven to theoretical approaches again or looking more closely at theoretical approaches the first is that data alone doesn't give you understanding so you need ways of interpreting data and constraining experiments and so on and I I think a some evidence for this is are these um recent adversarial collaborations in which proponents of different uh theories of consciousness team up design experiments that would lead to or could lead to evidence which more strongly favors one but not the other Theory and part of why such adversarial collaborations are needed or um are perceived as necessary by some is that in previous years people working with certain theoretical assumptions in mind or with some with their pet Theory maybe a global workspace Theory they've been um or other theories of course they've then been looking for evidence what that would confirm their theoretical assumptions and maybe designing experiments in a way that is more likely to yield certain kinds of evidence or confirming evidence supporting evidence for their own theoretical assumptions so um realizing that in order to make progress and constrain also the class of theories that you have realizing that it's important to do more rigorous experiments and explore ways in which you can actually find also find evidence that this confirms certain theoretical assumptions that I think um is one of the motivations Behind These adversary collaborations and also also makes people a bit more self-conscious of the theoretical assumptions that they're making um yeah then another big issue is of course that the scope of empirical and theoretical approaches has to be expanded we now have good evidence that many animals that were previously thought to be unconscious actually are conscious animals such as octopuses and there's at least reason to take the hypothesis seriously that some insects may also be conscious maybe bees are conscious and in order to make progress here theoretical approaches are needed to help structure debates and determine what kind of evidence would be supportive for certain hypotheses or um which type of kinds of evidence would be relevant to answer the distribution question which entities which animals are conscious so that's one thing and then of course you mentioned uh progress in Ai and people are now seriously considering what artificial systems might be conscious and whether some existing systems might actually already be conscious and we need theories to to make progress on this or maybe not not necessarily theories but theoretical work and um what I and and also that that's a very difficult problem here that um artificial systems are in many ways very not like not only unlike human beings but also unlike other animals so whereas in research on animal Consciousness you can try and draw some analogies between human beings and other animals it's less straightforward when it comes to artificial systems and this means that Empirical research alone will be less helpful we also need very sophisticated theoretical approaches to deal with these issues and I will always remain some uncertainty just because artificial systems can be so can be physically or physiologically so different from conscious organisms and it's not clear how best to deal with these uncertainties we need theoretical approaches to make sense of all this and I would say we have to we might face the reality at some point so and maybe maybe it turn will turn out that we won't ever know whether certain systems are conscious or not I'm very skeptical that we'll someday find a theory of Consciousness that will tell us exactly which entities are conscious and which are not I mean integrated information theory is a proposal for such a theory and it's for this reason very important that theories like IIT are being developed um on the other hand it makes very strong predictions about what kinds of systems can be conscious and which can't so it um would agree with the proposal I presented here that a computer simulation in a classical Hardware will not be conscious and many artificial systems will not systems will not be conscious even if they have all the abilities that we that are associated with Consciousness even if they can interact with the environment have sophisticated cognitive abilities and so on um so it's um very important that such theories are developed but I think it's also very hard to gain certainty and maybe so this is what I'm some some of the one strategy that I'm pursuing is to try and find necessary conditions for Consciousness which would allow us to rule out that certain systems are conscious so maybe we will never have a theory of Consciousness that says with certainty if a system an artificial system has Acts or x y z and so on then it is conscious but maybe we will have some theoretical approaches that are empirically informed and which strongly suggests that if a system does not have X then it is not conscious so maybe this will be all that we can hope to achieve when it comes to understanding artificial consciousness and I see the the account that I'm presenting here as contributing to this project by proposing some necessary conditions for consciousness and as I already indicated I'm not completely certain about either of these conditions but maybe something like the the weaker condition the flow condition maybe that would something like that could be a useful necessary condition or Consciousness which would rule out Consciousness in a wide class of systems but which would of um for example not rule out the possibility of Consciousness in a computer simulation not in all computer simulations awesome the Via negative Consciousness studies um so one question on measurement and then a closing question on ethics so you mentioned the distribution question what is the distribution of Consciousness in our scenario what kind of distribution is that is it a z-axis there's a scalar quantity that is going to summarize the density of some distribution in space like we were doing some kind of topographical map or is that distribution [Music] multi-dimensional are there different dimensions to Consciousness so to what extent do we even aim for a uni-dimensional scalar representation potentially using IIT or other measures or to what extent will we have a plurality of Consciousness measures without necessarily like a higher or lower thanks um yeah that's uh very tough question [Music] um so as you already alluded to According to some theories such as IIT Consciousness does come in degrees but it's um varies along a single scale the degree of consciousness and um classically there's also there's distinction between the level of Consciousness and the contents of Consciousness or the level would be um defined in terms of wakefulness or vigilance and the contents in terms of that which is experience and the idea would be that uh yeah you can distinguish between levels of consciousness in a unidimensional way but then the more recent proposals According to which Consciousness is multi-dimensional and as you already mentioned and there which means that it may be impossible to define a unidimensional degree of Consciousness um maybe you can all only order conscious experiences along [Music] these different dimensions individually but not um have a total order on conscious States [Music] yeah so I I think these are to a large extent unresolved questions and I don't have a strong opinion on this but um I do think that Consciousness at that at least some crucial dimensions of Consciousness that come in degrees and I'm open to the idea that there will be borderline cases between systems that are clearly conscious and systems that are clearly unconscious so I'm open to the idea so the possibility that there will be some systems for which it's indeterminate whether they are conscious or not and um apart from I mean IIT would not imply this of course but there some some computational approaches to consciousness what specify some properties I mean if you think about the counterfactual depth of internal representations for instance that's something that comes in degrees and it's not clear at what point a system will be conscious and cease to be unconscious what what degree of counterfectional depth is necessary for Consciousness and um yeah so I'm open to the possibility of borderline cases of Consciousness and similarly it's even if we so if we try to apply a theories of Consciousness to other animals than there may be cases in which it's not clear whether what a theory of Consciousness would say so Jonathan Birch has a wonderful paper about the problem of um trying to determine of finding out which non-human animals are Consciousness and the idea is that if you try to use a theory of Consciousness that was developed on the basis of what we know about Consciousness and human beings and then maybe many cases in which it's not clear whether the theory applies or not or whether the conditions for Consciousness are fulfilled or not so if you think about global workspace Theory what is a global workspace and we we can for human beings distinguish between different consuming systems local processes that have access to the global workspace and which receive the contents that are represented in the workspace and which are there by consciously processed but um there are animals that may that don't have as many cognitives up processes that don't have such sophisticated cognitive abilities that may maybe have something like a global workspace but with fewer consuming systems so when does it cease to be a global workspace and the sense that will be required for consciousness and um because of such indeterminacy it may be more useful than to look for um other markers of Consciousness evidence for Consciousness such as learning abilities that's what uh Birch proposals um and in part I think inspired by work by Evangel Blanca and Simone against who suggests that certain forms of learning are transition markers for Consciousness which provides strong evidence for the presence of Consciousness and um yeah what about the distribution question so this is more about evidence for Consciousness and different types of systems and what where the distribution look like in the end I I don't know so um but what I'm really interested is in trying to find out how we can determine whether a system is conscious or how we can rule out that a system is conscious and what in the end this will tell us about the distribution of Consciousness I think is a great open question awesome well as we say in the ant colony the whole Nest is our workspace so different systems will do it differently and in closing I know that you're teaching a course on this so to compress it will be a challenge but could you conclude with a statement or actually a pair of statements on AI ethics one addressed to Natural humans one addressed to the machines um yeah so AI ethics so I don't want to say anything about AI ethics in general but just about Consciousness so when it comes to human beings um what I find interesting is the question what makes what is required for being a moral agent so um most people would agree that Consciousness gives people or gives entities gives organisms at least some moral status even if it's maybe not required for having a moral standing um but it's at least sufficient for some form of moral status and then maybe some organisms matter more than other organisms even if they are similarly conscious or maybe some animals matter more than other animals because of their cognitive abilities and so on and and the question is what what um what do we have to add in order to turn a moral patient as it were into a moral agent a being that can act in ways that are not just in accordance with certain moral principles or not in accordance with them but they can act because of certain moral considerations and is it necessary to be conscious in order to be a moral agent and what I find interesting here is to explore to what extent accounts that look for necessary conditions for Consciousness may also yield some necessary conditions for being a moral agent so even if Consciousness may not be required for being a moral agent maybe there are certain necessary conditions for Consciousness that are also necessary for moral agency and this can then also be applied to artificial systems and principle but of course when it comes to artificial systems it's the the interesting question is should we even create artificial systems that might be conscious or do we have a duty to create conscious artificial systems and my own position would be that well in the case of animals it's already happened we may not know with certainty which animals are conscious and which are not but regardless of our epistemic situation regardless of what we know about these animals they are conscious or are not conscious they feel pain or don't feel pain they suffer they or they do not suffer so the most we can do is to try and minimize the suffering in existing animals but when it comes to artificial systems we can at least at the moment say that most artificial systems are very unlikely to be conscious and we have the unique opportunity now to really think hard about whether we want to risk creating conscious artificial systems and I think we learned at least two things two interesting things in the past weeks or months about artificial systems artificial intelligence and Consciousness and one is that AGI may not require Consciousness um I think most people believe that anyway but there was some um I there was at least the possibility that AGI artificial general intelligence might require consciousness and what we've seen with the latest generations of language models is that they at least come very close to some form of artificial general intelligence um it's very unlikely that they're conscious and so this gives me at least some confidence that future more sophisticated systems that will have a general form of intelligence will also not be conscious or unlikely to be conscious and I think that's good because it will not that there will be um there will be no further incentive to um create artificial conscious systems in order to achieve AGI because it seems that you can achieve that without creating conscious systems another thing which is a bit more concerning maybe is that um we've we've also seen that it's very difficult to regulate developments in Ai and uh big companies can just decide to put systems on the market and make them available for everyone and they will use them for whatever purposes uh without any regulation and so if it will in in the maybe not too far future be feasible to create conscious systems if we do um gain a better understanding of what it would mean for an artificial system to be conscious or maybe how to create one people will do it and it will be very difficult to regulate this so this um might be a problem for the not too far future a problem for a guest stream number 40.2 yes thank you Vania very insightful best of luck with your works and hope to talk to you later thank you Daniel it's been a pleasure very well right foreign