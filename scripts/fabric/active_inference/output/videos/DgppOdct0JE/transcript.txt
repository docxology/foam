all right welcome thanks for joining um we're in cohort 5 in the first discussion of chapter nine in terms of the book we made our way through the epistemic first half the recipe for making a generative model in chapter 6 then the discr and the continuous time generative models in seven and 8 now we get to chapter nine which is the data driven component so pretty much up to this point everything has been like you think of it conceptually you create the model and then it generates synthetic data that's using a generative model in the direction that's usually called generative it's generating data the other direction of use for an active inference model or statistical model is as a recognition model so that taking in empirical data and then fitting parameters that recognize the patterns in the empirical data so chapter nine highlights that kind of back and forth about designing generative models that take in data that's being emitted by empirical experiments like behavioral experiments in lab so that's what chapter N9 is about um you if you want to ask the question that you had first and then we can like jump in there explore empirical data look at some pmdp and empirical code just see what happens but what what um was your question before we begin oh I I have no uh specific question it's just I I noticed a lot of people have commented on that paper so I suspect it's something completely a completely new Direction in in the field so um yes so could you could you comment on the main point of this uh of of this paper yes yeah great so this was the the paper path integrals particular kinds and strange things it was first uploaded to Archive in 2022 and then it was um submitted to This Journal called physics life reviews so physics of Life reviews has a very interesting um scope if you look at the structure of this journal um they publish like regular research as well as comments on research and so during the process of this paper being like kind of undergoing peer review from the archive version they also once they get to basically the final version they solicit from a pretty Broad and open Community these short comment papers so like Ali and I wrote a paper commenting on this like just like a two-page paper those comment papers are not peer reviewed exactly they're more like editorially overviewed um so I mean we see many many names that we know because it's kind of like an easy and fun way to to be part of a bigger discussion get a citation pump up the citations to the target paper um so that's kind of the the The Meta um on this okay so as for the contents itself um it is not entirely new it builds on especially the 2019 fris and work free energy principle for a particular physics um to connect it to the text book all throughout the 2022 textbook like we're talking about the continuous time and the discrete time models so um let's look at figure 4.3 so in the discreete time setting we have a transition operator that basically jumps you forward a discret Time Step In The Continuous time setting the way that we've been discussing it in the textbook is in in terms of the tailor series approximation so starting with a point evaluating at the point then taking the first derivative around the point and then the second derivative around the point and so on um so that is in a continuous setting that idea of like doing active inference in a continuous setting is is generalized and formalized by Framing the free energy principle not just in terms of the transition probabilities in a discret model not just in terms of the Taylor series approximation or the generalized State space of continuous time model but actually in a path integral formation so that's kind of like there's like a thread that's like the likeliest thing to happen that's the path of least action like the baseball doing a parabola like whether you knew about it right at the beginning with the initial conditions or whether you had tracked the whole baseball it's like it does do a parabola that's classical movement but still and then it's kind of like there's like a sheath around that Trace with paths that the baseball could have taken that are just exponentially less and less likely like it could have hit just a bunch of molecules in a certain way at this one point and kind of diverted off course but because the baseball is very large relative to air molecules it follows like a classical trajectory um so the first thing they do is they kind of reconsolidate the free energy principle in terms of ath integrals which can then be like dropped back down into the continuous time that we talk about in the textbook or the discreet time but like especially with maybe the ways that they're taking it even further like the path integral is kind of like the richest formalization like if you go back to the variational calculus or Origins with Richard fan they have to do with path integrals for particles so it's kind of like coming full circle in a way because the findan diagram was developed in the setting of of those exact questions now they're applying it to cognitive particles and then so that's one that's kind of like the consolidation of the formalism component and then the second major contribution and this is also piece I think that um Olie and I focused on in our commentary is like previously people had always talked about well active inference can apply from kind of simpler inert systems to simpler active systems all the way on through complex systems and people had introduced like this notion of like mirror versus active inference for something that a mere active inference system is something you could model as doing active inference but it might be kind of simpler boring like yeah you could model that rock as flying but choosing not to fly but you've kind of brought out a big apparatus to model something that's not moving and so here with this figure and the discussion they brought a lot more clarity to these kind of classifications systems that don't evidence active States in an interesting way to a given Observer not to say they don't right map and territory then systems that have activity but the activity is kind of classical or conservative I don't know if a bacterium is really the Right image here I think something like a pendulum might be clearer because bacteria can also have Rich behavior all all the way on through what they want to highlight here which is like a metacognitive or a strange particle and that's also what um Lars and Lancelot highlighted in their comment was about the basian mechanics not just across the partition but okay do the partition and now in the internal States partition those again as if those internal states have metac cognition so it's it was a it was a big paper for consolidating um the formalism and for clarifying some of the different scopes I see yeah so so it's one of the top down approach to look at active inference yeah I I think so I mean it it doesn't start from modeling a particular system it starts from more axiomatic considerations so in that kind of like physics based free energy principle side whereas like active inference isn't mentioned in the abstract so it's like path integral formulation of the free energy principle systems that do that are active inference systems but here they're highlighting that that high road formulation see there there might be other pieces too and I think I mean the commentaries are I haven't read them all but they're probably people always do funny titles that suggest what they're about uhuh so maybe we can review them but in terms of getting diverse comments on a major piece of work this format which physics of Life reviews does and a few other journals is really useful and like Carl and others have used it multiple times well um we can look at any part of nine look at any questions also I have um pmdp up in cursor so we could explore with language SL models like how you incorporate empirical data with the generative models depends on whatever people want to do yeah I think looking at codes would be great okay okay okay [Music] um okay we we'll we'll see what we can do without um I I I didn't like prepare anything specific so we might have to debug a little bit or have a little fun but um Let's uh see okay um just just through context PDP documentation and the uh package itself infer actively SL pmdp so this I just cloned in that repo so everything that's in the GitHub I just pulled that in um okay so what do we want to look at or make a model of or is there an empirical data set that we want to connect it to or a type of empirical data that we want to connect it to uh I I have nothing specific in mind let's do a discreete Time model of we could we could try to recapitulate one of the examples in the textbook like the L M listening to music from chapter 7 or if there's some other like structure or type of data or kind of action selection that people want to explore we might be able to to do it music is great okay okay here just just um the there's a lot of ways to [Music] um go go into this but um okay okay let's start with [Music] um let's just if this all runs then it'll be good to go okay so agents agent demo so let's just see where where it is in the documents um I just want to find one that already has some visualizations um and then we can see if how how it's built and how we can modify it okay okay maybe the Tas let's let's look at the teamas and and go through it and then see where the empirical data come into play but then we can we could like [Music] um it doesn't have to be a spatial model like maybe the um we we could see if it's possible or like what would need to happen to modify the teamas to be more like a music example or something I mean this is um in in chapter 9 when they overview here are the key figures then we'll go to the code first it's taking everything that was looked at before with a generative model and it's saying like Okay we were making a map of the rat in the te-as now let's zoom out to having the laboratory that encloses that rat in a teamas so we're choosing experimental stimuli and passing them to the rat those are given the label o because they're observations for the subject and then the actions of the subject are our observations in the lab setting so this kind of you you could have another layer outside of the laboratory too but this is just with focus on the the system of Interest this is like what the cognitive models enclosed in um 9.2 shows kind of the process of like kind of what you need to get for empirical results in a paper where you have a te-as build a PDP which we'll look at the code in a second then chapter nine is which I don't think will exist in the code so we can try building that part out um you go from empirical data and you kind of invert the model to run it backwards so that then you could test like five different rats and look at the statistics of how they differ five different treatments of of a drug okay so first just to kind of play with cursor I just said explain this notebook so right now for coding in active inference it it's like literally the most exciting it's ever been because of tools Like This Way Way Beyond most people's coding potential at in a moment certainly far beyond mine is the ability to actually use cursor and other tools to to have a conversation with the material so there's a lot of questions that people might be like kind of having burning inside of them or like wanting to ask another person that are very possible to just ask through language models of the code itself here um is importing the kind of General packages that are needed and then specifically importing the pieces of pmdp that are needed that's Imports um here's the environment the environment is going to be like where the game or the setting is defined we're we're in the discreete time setting um interestingly it's it's not a 100 like when when the setting is like right arm wins it still is 98 and two so there's a little stochasticity even when the the context is like you know when when the it's on the left arm or the right arm um maybe that's just to keep keep it kind of a little bit more in and noisy um just if if you want to highlight the kind of action amidst uncertainty then you know you could just change this to one and zero but but um keeping it this way highlights the uncertainty part and here they call a Tas environment function searching the code base describing what this teamas environment call makes but it stores what's needed for the teamas and puts it into environment it's that method is in another file okay here's going to be the hidden state to outcome mapping that's the quote collection of probabilistic relationships called the a matrix this is the mapping between hidden State and observation that's a likelihood um function and here there's there's [Music] um we can say output the A and it will provide us but but this is basically showing um there's no reward yes reward and there's there's the the null State like with respect to whether you're observing getting the food or not let's just call it food um but just call it reward because they call it reward um uh the top row ref The Columns represent the locations that you could be in the top row represents not tasting anything the middle row represents um tasting the the reward and then the bottom row represents tasting like the opposite of the reward like the other arm so this is saying like the starting and the Q location hidden States map on to not tasting anything the right maps on to tasting the reward hidden State and then the left arm in this case maps on to tasting the opposite the Q mapping so we were in slice one of the a so the first kind of type of a matrix that comes into play is the one between location and taste there's also a second a which is going to be just a 2X two and this represents the mapping between the observed Q in the bottom of the te-as and what context you're in so in this setting it's kind of like an honest Q saying if you're if the um Q is saying that you're in the left better context it's it's accurate but you could flip that to make like a deceptive Q so that defines the two components of the a matrix now we're going to just go through literally a b c d b um is the transition Dynamics so here they start with kind of the simpler B which is going to be the transition dynamics of what context you're in so this one corresponds to the smaller 2x two a this is saying when you're in left better context as a true hidden state that stays that way whereas if it was like a situation where the context was shifting between time steps within a trial you would have an off diagonal now th those are uncontrollable Dynamics now they're going to get to controllable transition Dynamics this is really the key piece in active inference because when when all we have is the um downstairs part this is just a partially observable marov process that's just the a matrix and the B Matrix being inferred but there's no policy selection so to get into the policy selection that is equivalent to making oh to making B not just a trans a singular transition Matrix but B has like multiple files or slices and then Pi selects choosing a policy choosing an affordance is equivalent to selecting which B Matrix is going to be applied to the continuation of the Hidden State transition so it's called controllable because there's a policy selection possibility for choosing which slice of B is applied whereas if you're just like listening to a song then you could infer the B Matrix but you wouldn't be able to choose the B Matrix um there is um it's sometimes unintuitive the structure of these variables but again through printing them and asking you can get pretty far and they're they're they're formulaically laid out and also a lot of development effort like in the open and the closed Source spases has to do with making the specification of generative models overall and especially the B Matrix a little bit more intuitive so that it can be like make it so that this action does that at this point you kind of have to look at the Matrix and and encode how that works so here this is like we're looking at the um controllable component of those two modalities so we can't control the context left or right better but we can control the location so we're going from hidden state to Hidden State at the next time step there's four locations going to mapping to the four locations in this case because the center is reachable from all locations you can choose to move um to the center from anywhere similarly they're just laying out these movement options so those are the slices these slice one two and three on B those are the affordances okay they copy in they copy in the variables they kind of defined them just um by themselves and now they're going to copy them into thisor GM format it's not necessary that the generative model is of vertical representation of the generative process at this point we were just defining A and B like the veritical A and B but we've just copied them in to be the part of the agent's generative model but it doesn't have to be that way you could have the generative model of the agents having a different structure than the structure of like the map in the game but that's just would take more code and everything um now they're going to continue with the agent class PDP is um like the major method is the agent class PDP is built to get to being able to build a discreet time agents as fast as possible essentially and make easy methods for calling that once it's there so we're defining just zero is the controllable index because here b0 the first b0o indexed is the controllable one but then the uncontrollable one it was B one so the second type of B tensor this is just telling as we work towards building the agent that zero is the one that's under control whereas if it believes they control the context at the at the very best case you'd be wasting computational resources on Computing that um here the agent is defined in terms of just the a the B and um the control indices now it gets defaults for everything else and those are going to be kind of like investigated a little bit it starts out with a flat prior for the hidden state it starts out with a flat so it has it it doesn't know where it is in the beginning it has an equal belief across the four possibilities of location and that's plotting d0 corresponding to location that's the controllable index so d0 corresponds to the prior on hidden State B 0 corresponds to Transitions of hidden State a z corresponds to Hidden State and observations it's like and then the context is that second um modality and so here it has a um even prior on which contexted it then they modify it so that it has a precise and accurate belief one hot just means a variable with a one in one location and then the rest of them are zeros so they've modified that to now um look like a strong belief that it's in the zero position um okay now they get to see so after having done this they will have defined a b c and d then that will have basically constructed the agent so they're going to um go to that um reward modality there's some interesting discussion about like how do you actually connect up like an observation to to be incentivizing and and here's their um here here's the C preference variable okay that was it defining the teamas ABCD of the agents here's the active inference Loop okay so let's let's do something like doesn't always work on the one shot but a shocking percentage of the time it does fine it literally did it it literally did it so here's three or here's four time steps it's funny you know it's the half time steps obviously don't matter so here it's [Music] um these plots represent that octave inference simulation so it's like that's always what's super interesting is defining the agent like the kind of scaffold or the template of the agent is really just the beginning because then there's a ton of methods to describe like to visualize the outputs of the agent and to sweep across different parameter combinations okay they're kind of now plotting um they're kind of inspecting the beliefs plotting the updated beliefs and then earlier I was just I I I I didn't really make any but just started to visualize a few things okay let's copy this [Music] again so here we'll do the the chapter nine thing and bring in empirical data it's just some some it's doing a few just minor um just format adding but these lines are not being changed but green means it's adding in a line red it's leeting you yeah uh I I want to ask about the the gp4 does it actually read the paper and the documentation why I this understand yeah good good question like in this case um well first off if if you were just using like the chat interface for GPT or like whatever Cloud 3 Etc um you could just copy in code and then say like improve this script and then it would you know based upon the statistics of all the code it had seen it would update that script cser takes that a lot further because um it does code base in indexing so when you type in a prompt to GPT first it tokenizes your input converts the words into tokens then those tokens are um calculated in terms of their embeddings in the semantic spaces then like that embedding can be used to then generate more things in that semantic neighborhood shortly the cheap part of using a trans formal model is actually going from the tokens to the embeddings whereas going from the embeddings to generating new synthetic material is costly and then obviously fine-tuning it and training it is even more costly so what cursor does is in the folder that you're in it it indexes the code so it runs all the code through the first part to embed it and then when you do a Quest it like um so control enter so here it's scanning across it's here GPT is going to be tokenizing and then checking the embeddings of this prompt I wrote then it uses basically what's called retrieval augmented generation rag you might be using that in some other variants to find which sections in the code itself actually have relevant information in terms of having a similar embedding so like if you had PDFs of a bunch of different disciplines and then you said well like what reacts with methane and then it would look for where methane had been introduced or methane is similar to butane if that if there was a paper that said methane is like butane then it would to a lesser extent draw on papers that talked about butane so this is not co-pilot no you can use co-pilot as well in this setting but this is cursor. sh cursor do okay got it thank you this is yeah it's a vs code fork and and and even if you've been away from it for like a few days you should download a new version of it because like they're the the changing is very rapid um so okay let's let's see how well this did here's the here's what it wrote for visualizing a teamas she it's like it didn't output anything I'm not seeing anything so there's there's the side chat mode where um you can chat with the codebase and then there's kind of this inline editing mode and there's also kind of a tab autocomplete mode that's more like the co-pilot but this inline version is like there's probably so many in its training data set so many simple code examples like just checking if there's a folder like this kind of logic except the changes let's see teamm a 2 e e so that's kind of the danger sometimes to to an extent is like it's really easy sometimes like be spinning your wheels with with code that can be like kind of overwhelming and look relevant and the code might not be like bad by itself but then like you start stacking all this code and then like the maintenance and interpretability costs can be very high he like it's fun also just like this is where we're at I mean this is a chapter nine you know this is kind of where we're at as we continue and other people continue to first off ask GPT about active inference and it includes more and more recent checkpoints in its training and of course web enabled search like perplexity and all this like it gets better at doing active inference second huge piece is going to be [Music] um more and more actual examples of active inference code especially for like higher reliability settings it's cool that there are PDP demos at the same time like I know that the community has more than just a couple notebooks but they're not in the pmdp repo so then the cursor only has a couple of examples to go off of so adding more working examples updated language models with internet access and better code scoping um fine-tuning language models on transcripts from the active inference journal from like our live streams and model streams and the textbook group questions that people ask getting folded back in to fine-tuning and to Rag and model scope if we pulled in the active inference Journal transcripts for all the live streams then we could say something like um make it into continuous time and then maybe in several discussions somebody said like well what's the difference between discreet and continuous time and then that was addressed and then it could go off of those questions to actually inform it so especially for a field like active inference where it's like this is the domain expertise so that being invoked will help a lot but just for doing things like improve and generalize and professionalize this code uh so to pulling data from active Journal does it require tuning like we're not totally set up to do it today but yeah in principle you could pull in the the GitHub repository for the octave inference journal and then it would have the transcripts in the plain text but there might be a bunch of redundant stuff like we might have four different versions of the plain text or different translations or something like that but yeah we could we would prepare a kind of rendering flag like output a single version of every transcript rpt with no time steps and have that and then and and also have papers and more code examples and all of this so like even just playing around with where it's at helps calibrate um we we can say generate e so with these kinds of functions like here it this is not um it's not outputting the data exactly like we need it to be so even just playing with these like it's it's really some of the most and fastest fun I've ever had using active inference because um as long as I yeah go ahead so as as I don't uh exceed the context length I can just put in whatever repo I want actually you can pull in repos that are Way Beyond the context length so let's just say that the context length was 100 just just make it simple and you pulled in um a repository that was a thousand so the first thing that would happen is the Thousand lines of code would be embedded that's the syncing of the embeddings then then let's just say you did a 20 um a prompt of length 20 so you've used up 20 of the 100 of the context window with your prompt then that is going to get embedded and dispatched to cursor and then cursor is going to do its best to fill the other 80 of the context window with the most relevant 80 from the code base that's this part where it's scanning the codebase and then pulling in in the context so then the final execution from cursor is your 20 prompt plus the 80 most relevant that rag obtains so it may pull in like misleading examples but to the extent that that that the the macros and the patterns do exist in the code base it's basically effective then the less that what you're asking for exists in the code base the less of course it can rely on it and so then the more it's just relying on the overall statistics of the language model another thing is that um cursor you you can um you can set um I I don't know where it moved the setting to but you can force it to call another you can force it to call a different endpoint for the language model so then you can use like jan. a or LM studio. a or another one to have a local language model so then cursor is dispatching to a local language model and these are also including code enabled and so on so it's like kind of interesting because it's like it's not the math of active inference but as that gets brought in and then for the equations like we already have every equation [Music] um in the latc form so this is highly readable by the models many can also look at images too but what it's going to do when it gets an image is basically OCR and try to reverse to latch anyway so it's enormously costly so there could be some um repos like maybe the textbook group repo that just have like all the equations in latch or the whole text in plain text stripped of some you know um just spaces and kind of cleaned up a little bit and then those kinds of those kinds of plain text files can be brought in with one line in in git and then you functionally would have the textbook material because it's not it's not only looking at code when it's doing its scoping like here it it looked into just plain text so you know Long Live digital stigma gy contributions and questions that people make really do matter even if they're a starting place for being improved and corrected it it really it really does have compounding effects on the total active EOS system like we could we could have a function to generate synthetic teamas data so that might be one step would be okay we made the team's generative model now let's make a generate synthetic data and then let's do chapter nine kind of get this pairing between the generated synthetic data and the the generative model then you build another function to go from video data to the same format as the synthetic data but you already established that that synthetic data format was able to be parametrically useful for the GM and you could have already developed the visualization sweeping other methods so it can be quite a large code base and you can you can write like thousands of lines in a day because it it just spills out these functions so I think a lot of the previous discussions in chapter 9 in the textbook like they're they're either philosophical or analytical I mean or both and um yet the applying is very much like Computer Engineering and statistics and as the models and the programs get better like in 6 months I think a lot of these will be even [Music] better uh sorry one more question uh agent based modeling uh I wonder if that's a field suitable for active inference yes I mean that's why pmdp the central type is the agent active inference is Agent based model agent based modeling whether you do it at net logo or any other like kind has always had like the kind of incoming perceptual and outgoing action selection so that kind of cybernetic framing of single and multi-agent ecosystems of shared intelligence is not new to active inference really the essential piece is that that entire generative model of the agent is being understood in a unified way right memory attention etc etc etc all the diverse cognitive phenomena are being approached in a unified Manner and with a unified loss or fitting function free energy under the free energy principle but you'll find other agent based models that have a perception and action component uh if I just look at net logo uh it's not explicitly uh done in in the language of active inference right so I I wonder if there is value to be added if you if you bring the active inference discipline into that field yes certainly yes yeah like going to the classic net logo simulations re wrting them to be more active inference and like it's a two-way street people in net logo then can compare active inference you can make um portfolios or models that have actm and non- ACM agents in net logo and then it's instead of like oh well you need to learn this like other software it just brings active inference into whatever software is being used and it might be like as simple as just using a different loss function so my I think oh sorry yeah yeah sorry uh okay I just finished my question I wonder if that's a good uh topic for a master thesis uh I I I think it could be I mean like uh in terms of the implementations we have I've never seen a net log go so it could be it could be interesting you know something else that that U my adviser works on is mut Mutant agents and I haven't really seen anything in the literature so far on active inference about mutation like between Generations yes yeah that could be really interesting like just lock in the schema and the understanding for the teamas and then do a lifetime where it does 100 teames and that's the fitness function and then have Rec combination I mean I I I I don't I'm not set up to Run net logo exactly right now but this looks like net logo so this just gets super far this gets like past 80% in a few minutes in terms of getting somewhere so that's that's Mega exciting for for a lot of reasons butan sorry did did Jeff yeah what uh did Jeff mention mutation agents yeah is there a paper somewhere yes I can link it give me a second cool but yeah f um fun times interesting chapter n um discussions one interesting meta repo would be if we made a repo that just I mean like literally I may do this tomorrow just brings in all these other repos but then at that point it might start like pulling context from like across repositories and it's not useful again so there's a lot of metaprogramming work and documentation that will make it more accessible and useful and and and vastly more unexplored than explored let see there's the paper cool yeah thanks sometimes I like like just just cing through okay so it's on the screen for you know like two frames at you know for a tenth of a second or half half a second or whatever it is future screenshotter will do better cool all right that was the first discussion on chapter n yep Susan uh yeah yeah I'm my brain's you going 100 miles a minute and so the the existing models that's in there are um where would you say the level of sophistication um what what would be the next level of sophistication that's not there yet in PDP yep in terms of yeah the the artifacts that are are are there now in terms of um of going yeah get going up into levels of abstraction for example um modeling um agents negotiating um you know which I'm assuming you know we're not even close to there yet but um but so beyond the yeah the rat of the maze what do you what do you see will be the next step in evolution of the models yeah like currently the main PDP package only has these several documentations and simple examples um like I know there's a THX more work not in the repo so I would like to see the next consolidating step to be many many diverse success uccessful simple examples and then the introduction of motifs like metac cognition and other things like that and then that provides like the pallets to be recomposed into these more composite simulations so we're in the game it's all happening yep and saying and asking and writing is more than enough so thank you all for this fun time see you next time thank you by see you next bye