[Music] [Music] hello and welcome everyone it's active lab live stream number 38.0 february 10th 2022. we're going to be discussing the paper the evolution of brain architectures for predictive coding and active inference welcome to the active inference lab we are a participatory online lab that is communicating learning and practicing applied active inference you can find us at some of the links here on the slide this is recorded in an archive live stream so please provide us with feedback so we can improve on our work all backgrounds and perspectives are welcome here and we'll be following good video etiquette for live streams it's going to be a solo stream though go to activeinference.org if you want to learn more about how to participate or contribute or get involved with any actinflab project and check out this coda link to see past and upcoming live streams the page looks like this so you can see events that haven't happened yet like 39 40. and then also you can look back and you can see who is participating and read the papers and all of that so check it out today in active stream number 38 the goal is to learn and discuss this cool paper the evolution of brain architectures for predictive coding and active inference the papers by giovanni pizzulo thomas parr and carl firsten from december 2021 and just like all videos it's just an introduction to some of the ideas it's not a review or a final word so go check out the paper to learn more and there's going to be an overview with first names and claims abstract and roadmap all right i'm daniel i'm a researcher in california the big question that this paper is getting at is what is the evolutionary neurophysiological basis of cognition and how do complex cognitive phenotypes arise so how do things develop and evolve how they think and how does that change over evolutionary time and shown here are three images representing three scales of analysis of looking at ant cognition so on the left is a representation of the synapse with the glia wrapped around it and the molecules and some of the mechanisms because changes in those mechanisms can influence cognition then in the middle is a 3d representation of an amp brain with the different brain regions like the central complex and the optic and the olfactory lobes and this represents the level of regional or micro or mesoanatomical variation and that definitely changes over evolutionary time just like the synaptic level and then there's this behavioral ecological level and that's where the ants are engaging in collective behavior and stigmargy and so how's this how does this all work how does this all work in today's ants and how has it evolved and then expand that to other species and other questions the paper was published right at the end of 2021 in december in the royal society of publishing and just to go over the aims and claims of the paper this is in the author's words there's growing consensus that the brains of humans and other phylogenetically derived or advanced organisms operate in a predictive manner across perception predictive coding and action control active inference yet the ways in which our advanced predictive abilities may have arisen during evolution remain unclear the goal of this article is to sketch an evolutionary history of brain architectures for predictive processing a central tenet of our proposal is that although prediction is often characterized as a complex cognitive function it is not a late evolutionary addition of advanced animals like us rather in distinction to a late-stage cognitive argument like saying language is what makes us an advanced cognizer or semantic language with certain types of syntax rather our complex predictive abilities eg planning and imagination emerged gradually e.g via phyletic gradualism smooth changes through evolutionary time or punctuated equilibrium sharp changes through evolutionary time but punctuated at one scale is smooth at another from simpler predictive and error correction loops eg motor and autonomic reflexes that were already part of the brains of our earlier evolutionary ancestors and were key to solving adaptive regulation problems so just like mike levin's paper was addressing the question of basal cognition from the bioelectric perspective here is going to be more of a predictive processing and action inference perspective on the functional aspects not on the mechanistic so the bioelectric was down here at the level of cells this is going to be approaching it from a little bit of a different perspective but we'll find out here's the abstract this article considers the evolution of brain architectures for predictive processing we argue that brain mechanisms for predictive perception and action are not late evolutionary editions of advanced creatures like us rather they emerge gradually from simpler predictive loops for example autonomic and motor reflexes that were a legacy from our earlier evolutionary ancestors and were key to solving their fundamental problems of adaptive regulation we characterize simpler to more complex brains formally in terms of generative models that include predictive loops of increasing hierarchical breadth and depth these may start from a simple homeostatic motif and be elaborated during evolution in four main ways these include the multimodal expansion of predictive control into an allostatic loop its duplication to form multiple sensory motor loops that expand an animal's behavioral repertoire and the gradual endowment of general generative models with hierarchical depth to deal with aspects of the world that unfold at different spatial scales and temporal depth to select which plans select plans in a future oriented manner in turn these elaborations underwrite the solution to biological regulation problems faced by increasingly sophisticated animals our proposal aligns neuroscientific theorizing about predictive processing with evolutionary and comparative data on brain architectures in different animal species and just looking ahead here's a figure that we're going to get to here's the ancestral state it has this structure it's a model and then it's going to undergo a set of different types of discrete operations that change it structurally and that's structure learning and it's going to happen over evolutionary time scale and it's going to be tied to functional architectures for predictive processing okay how do they go from here to there this is the roadmap after the introduction they introduce predictive regulation and control perception cognition and control action as basic design principles of the brain so kind of taking that embodied approach but making it very operational and functional so that it can be studied from an evolutionary function perspective introducing the brain as doing structure learning in generative models over evolutionary and also other time skills they then give three examples of simple predictive motifs in ancestral brains which is the homeostatic control the allostatic control and the simple simple behavioral learning then they introduce that figure that we just looked at and that's the evolutionary algebra of structure learning just like you can multiply and add these are kind of like operations on evolutionary spaces they then discuss a few finer points related to behavioral switching temporal depth hierarchical depth and then take a phylogenetic perspective at the end giving an example and there's a discussion okay so to go into section two and just sort of deal with the keywords and themes as they are needed here's figure one uh in figure one the reason why we can even jump in here without going to any keywords is it's biology we're talking about and we can jump in why not as good of a place as any to go in at the action perception loop and then connect it to some of the analytical or mathematical formalisms of active inference and the free energy principle so this is figure one in the paper in section two the action perception cycle and predictive regulation so here's our entity our agent on the left and here is our world state on the right the entity is engaged in prediction while they're making observations that are being emitted from the world that's resulting in some discrepancy either things are exactly as expected or not so an example would be in the visual field the brain is generating a prediction of what is in the blind spot of the retina and then if the eyes were to move there to use action changing the world in terms of the stimuli coming in through ocular motor action that would result in a different perception that could either confirm or deny confirm with a low discrepancy or be very surprising with a high discrepancy what was expected about what was in the blind spot which would confirm accuracy in a visual model so in this partitioning of action and perception which is just very descriptive it's not quite the bayesian graph that we're going to get to later it's kind of like a flow model and there's probably other flow models that could be used as well but it turns out that this partitioning or this way of thinking about flow at least conceptually leads to in the active inference proposal this idea of using a free energy minimizing function over some math that will get to a little bit more formally in the next figure and using a kind of combined metric that has two parts the red and the blue to make decisions about perception as well as action because it turns out that perception and action and cognition and metacognition are all part of the entities model that it's doing inference on in certain cases so just to kind of throw back to not so long ago here we have the f of q that's the distribution that's under the entity's control and y and so it's as a function of beliefs and data there's going to be some term and so just looking back to 37 we looked at the variational free energy and how that relates to perceptual inference where there's a penalty for overfitting as well as a penalty for failing to explain the data so it's kind of making a visual model or a perceptual model that in that snapshot given the priors and precision and all of that is not overfitting but it is fitting the data and it's kind of existing on that frontier and then it's using variational inference to solve that in a really tractable way and then when action comes into play a few things happen first the agent has to incorporate their own preferences because why care about action if you don't even care why it's going to happen so they have to incorporate their preferences which is a non non-arbitrary in a sense for action selection but it's arbitrary in a higher level as well as incorporating the fact that there's uncertainty over the consequences of action or just future states of the world not just like sensor measurement as in other cases so we have to take this variational free energy calculation that was just like snapshot perception and expand it a little bit to the expected free energy so here's f in the background and now there's this expected free energy term g which is over also an action selection policy z and now there's kind of similar like resonating or rhyming terms but rather than over fitting the imperative on the left side is to satisfy preferences on the right side the penalty for failing to explain the data is kind of transposed into this failing to surprise or failing to minimize expected surprise of future data so this is like fitting the expectations well on the right side in blue and then living up to your preferences and expectations in an optimistic way on the left so it's kind of like realism on the right and optimism on the left and that is what we talked about in 37 and that's the partitioning that's being done basically here the authors are setting that up as the action perception cycle and predictive regulation just wanted to kind of view 37 really quick because it was a fun discussion that we had it also really sets the stage for how is that similar or different than other action perception partitionings or models does evolutionary psychology or evolutionary cognitive studies do they have a fundamental action perception model at the root is that a good thing is it a bad thing section three goes into section two again was just about how this single slide and represented in figure one about this predictive so anticipatory but also embedded etc infinity loop cycle is the basic principle of the brain we can't take the basic principle of the brain to be um some lower level like just information transmission amongst cells nor do the authors jump in at a higher level like the fundamental unit of cognition is linguistic tokens that are being modified not discrepancies with multiple different kinds of things that are being predicted from this functional description of cognition they move to section three formulas formalizing brain design as structured learning in generative models so what is the structure of this model and then what does it look like to do structure learning in that model and why is it generative and then how is that formalized so here's figure two the generative model and the generative process so the first words the same second words different so they're different words and the figure on the left side has the entity the figure on the right side has the world state so it's the same action perception loop we saw in figure one and now this sort of conceptual flow single edge model like just only one arrow here no extra anything just sort of first pass it's compatible with this which is actually a bayesian graph but how do they describe it and what are all the variables we still have the same things happening we have the observations coming in to the cognizing entity that's the observations coming in the entity is going to infer some action policy based upon the observations coming in which is going to result in some change to the actual underlying system which is the generative process so that's like the actual birds and the beasts and the sun and stuff allegedly it does get into a little bit of a gray area with the realism instrumentalism and the structural realism but we're not even gonna go there in this discussion right now the generative process is the one that's handing out the observations as modeled the generative model to close the loop is the entity's inference and so here is x the entity's prediction on hidden state and then here is x star which is like the actual hidden state that is being alleged in the world and we've had some other discussions about how that's the sigma function that's like mapping between the two x's that's what's being minimized if the discrepancy is low there's other notation how do the authors describe it the difference between the generative model and the generative process nodes correspond to probability distributions and edges to their statistical dependencies so this is like a bayes graph mathematically a generative model may be formulated as the joint probability density p of y and x of observations y and hidden states x of the world that generate those observations i think it was just a copy error the latter are referred to as hidden or latent states as they cannot be observed directly the joint probability distribution can be decomposed in two parts the first is a prior p of x which denotes the organism's knowledge about hidden states of the world prior to seeing sensory data the second is the likelihood p of y given x which denotes the organism's knowledge of how observations are generated from states so that's the perceptual model and then they go on to describe how there's a difference between the entity's inference on hidden state and the actual hidden state which is the generative process versus the generative model distinction and then they introduce action and say action u that's this node that influences the hidden state even if zero effect is generated based upon the inferences made under a generative model action is shown here as part of the generative model oh sorry action is shown here as part of the generative process making changes to the world despite being selected from the inference drawn under the model so action is actually making influence even again the edge could be zero in some respect but it's making actual influence in the world it's like the active states interpreted in this statistical way so what does that have to do um with structure learning so the entity is going to either whether you're realist and saying the entity is doing structure learning or you're instrumentalist it is possible for us as researchers today to model that entity as doing structured learning because it's computationally efficient or elucidative or you go full utilitarian you just say disregard that whole realism instrumentalism it's a useful approach and i'll follow utility wherever it goes for any number of those reasons you might want to model the cognition of different entities without going into just the philosophy of what its cognitive process actually is and so one approach that's going to get taken is using inference either from the outside describing instrumentally or realism as if it were happening maybe with anatomical evidence as if the hidden state could include not just parameters that were continuous about the world but also structures of models however it's difficult to imagine that that type of cognitive or even extremely metacognitive thought or action selection could happen for example in some early however simple it may have been and so how do we get from that flagella changing bacterium to all the other kinds of cognition that we see today or should i say bacterium-like entity relative or ancestor of today's bacteria so how can we think about this model which is often described in the context of parameter learning and then approach this as if it were maybe about parameter learning sometimes but also could be about structure in terms of the good regulator and the requisite diversity that kind of um requisite variety those kinds of models okay the next several sections are where they get to the specifics and some of the contributions of the paper that i think will be really cool to continue the discussion on section four is just short and it's saying we're about to go into three examples of simple predictive motifs in ancestral brains because one of the main claims of the paper is that these motifs are very ancestral they're old motifs they're not johnny come lately to the cognitive scene these are features that one can think of as who knows how far back or how simple these cognitive mechanisms have existed but we'll evaluate that maybe when we get to talk together but first we'll just kind of go through how they define them and use them the three predictive motifs are homeostasis allostasis and simple behavioral control so first five generative models for the homeostatic control of enteroceptive variables they write the generative models shown in figure 3 which we'll look at after this slide afford the homeostatic regulation of a single enteroceptive variable which we call here body temperature for illustrative purposes much like a thermostat this model maintains the requisite body temperature by reporting the discrepancy between predicted and sensed thermoreceptor activation given bayesian beliefs about temperature triggering an autonomic reflex u resulting in for example vasodilation which resolves the prediction error so if the life of the organism were just to hang out on the beach and vasodilate to off heat when it needed to and then to constrict and to save more heat when it needed to that's the physiological task that this is going to be describing which is just one facet of an organism's biology but there are experiments that sometimes only measure temperature and so thinking instrumentally this single factor model this single variable model on body temperature may be sufficient for some experiments or it may be useful in certain cases so just because it's a simple model doesn't mean that it's not going to be very educational and provocative but also even be sufficient in a lot of cases but no one's even claiming it's realism that's why it's written this way they say see citation 20 for a fully specified example and that is a citation to chance at all in march 2022 so still in the future and they write we start from the presence premise and this is in the paper that again is from the future we start from the premise that the goal of enteroceptive control is to minimize discrepancy between expected and actual interroceptive sensations i.e a prediction error or free energy importantly living organisms can achieve this goal by using various forms of enteroceptive control homeostatic allostatic and gold directed so there's more details in this paper but here in figure 3 is where they're going to show it so keep in mind this generative model structure and now these are going to be in a different form and here in the caption i'll describe what they say this is that homeostatic the first most ancestral or just the simplest possible just go make it darker if it's too bright and make it brighter if it's too dark make it warmer if it's too cold make it colder if it's too warm that kind of first order cybernetic loop this generative model includes an enteroceptive thermoreceptor y observations and a belief about body temperature x so that's the beliefs about how the body should be and that's again the beliefs playing that dual function that the paper 37 drew out which is that on the left side of this equation failure to satisfy the preferences is dealing with this p distribution as a preference but then on the right side p has to do with expectations that are being either fit well or poorly and so this is where active inference has a slightly different architecture perhaps than some other theories the beliefs are about body temperature it's not an estimate merely of the external body temperature crucially the prior over x is kept fixed and hence it acts as a cybernetic set point well you can't just expect what's going to be best for you you'll die right if you die you die but if you enact policy such that your expectations are realized then you persist that's why we're studying things that are persist ant any discrepancy between the predicted thermoreceptor activity given beliefs about x and the measured y is registered as a prediction error that is canceled out by an autonomic response for example a thermoregulatory response this is shown as an illustrative plot of the expectations of prior and posterior observation and autonomic actions over time so here is like the action policy which is like be at the baseline level of thermoregulation and then kick in some sweating or um cooling mechanism and then here it describes how the observations start at about 37.1 and then they steadily start climbing and then the belief which is initially like things should be 37. the posterior the after evidence estimate starts creeping up and then it hits a certain value and it engages a critical threshold that turns on this thermoregulatory response and then that cools the temperature back down so this is a basic architecture for doing first order cybernetics and that kind of first order logic here in this figure the red circles represent the expected values of x which are used to make predictions about y these are subtracted red arrow with the rounded end so this one from the measured y to form a prediction error dark blue circle epsilon which is used to update the expectation and drive action light blue circle you here's you that changes y such that the prediction error is resolved what if it doesn't do it well then the system dies so we're talking about evolution where we've had like for the ants 120 million years allegedly for that to get pruned out and even longer at the cellular level note the lateral modulatory connections in the allostatic network which we'll get to in a second so just to take one little discourse they say c24 for details what is pape24 it is fristen par and devry's 2017 the graphical brain belief propagation and active inference let's just look at a few parts of this awesome paper so first they have a table with definitions of the technical terms so just to kind of read a few but it's kind of awesome to see the authors do this and this isn't great paper as well so how do they define generative model generative model or forward model a probabilistic mapping from causes to observed consequences data so from hyperparameter to the parameter it is usually specified in terms of the likelihood of getting some data given their causes parameters of a model and priors on the parameters so it's all relative in nested models but this is generating data like kind of cranking out like a music box possible or plausible data sets with similar summary statistics like similar mean and variance of some distribution or similar parameters if there's a whole vector that describe it and then the recognition model is related to learning where new data are coming in and discrepancy is being minimized if the generative is outputting the exact same mean and variance that incoming data are having the discrepancy is low the predictions which are about preferences are being realized successfully action policy is working well or better than expected flip everything and you have the opposite situation and then just to give one more definition here because the next slide will feature it though the others are also good to read factor graph a factor graph is a bipartite graph where two distinct sets of nodes are connected by edges representing the factorization of a function usually a probability distribution function formulating a bayesian network or model as a factor graph enables the efficient computation of marginal distributions through the sum product algorithm what does a factor graph look like and how does it relate to the kinds of bayesian graphs that we've been looking at so on the top is not the base graph that's distributed across this slide but another variant that we've seen a bunch of times which is the partially observable markov decision process so g expected free energy minimization pi policy selection is influencing b which is how s the latent state in the world is changing through time there's d the prior on the hidden state and then a the mapping of how the state is related to the observation and so depending on how the model is framed those can be learned or not but it turns out that because of how this is relatively sparsely connected within a time frame as well as across time frames there's a way to use this bipartite construction called a factor graph that splits up those unlabeled edges which are statistical dependencies and kind of interweaves functions which have a slightly different representation and it turns out that by interleaving these functions into the variables it's possible to make what's called a factor graph and that gives an order of operations to arbitrary or within a certain set any kind of base graph but it includes this one importantly and so here is the one two three time points and two policies are being selected and that's what this graph represents the organism comes in with the prior time step one two three there's two actions and then here's another figure from the paper where at each of those three time steps one two and three a little bigger at time steps one two and three there's the inference happening on time steps one two and three so time step one that's like anticipation and planning at time step two it's like short term anticipation as well as memory and time step three it's like memory and it's always now casting as well and so one can imagine that this is a really useful format because it's extremely composable on one hand so just like they said okay well we kind of have this motif for the three time steps and the connectedness what if d from the top level came down and was s at a lower level and we've seen that taken to a really elaborated extent as well as interpreted in for example the paper on mental action in live stream 25. and so factor graphs are awesome because they're basically needing to only be specified in the bayes graph format but then it provides not just a mesh connectivity but a process algorithm and a heuristic an approach that's actually tractable so we get the composable analytical and graphical component that's an attractable algorithm the next section is generative models for the allostatic control of enteroceptive variables so this is going to be the first real modification of the homeostat that's introduced in three this is going to be the base case but it could be something else other than body temperature the homeostat is simple but limited as they write it can counter sensed changes of body temperature but cannot anticipate predictable changes of body temperature or other variables in nature there are several regularities eg night day or seasonal alternation that can be easily incorporated to extend the above generative model as technically speaking empirical priors the obvious advantage of predicting how our bodily and enteroceptive variables will change is being able to exert some anticipatory or allostatic control and so this is kind of getting into the second order or anticipatory cybernetics also related to rosen's anticipatory ecology so here's figure 3 c in a and b there was just the homeostat returning us to a set point after something got triggered and now there's going to be the affordance for anticipatory control this generative model sketched out with the same scheme as the previous slide this generative model extends the homeostat by including a second set of exterceptive variables that correspond to light intensity white y2 and a belief about sunrise x2 that's the sun visual side on the right furthermore like the visual system and the left side still the temperature and terraceptive system furthermore the model includes a predictive relationship between sunrise x2 and body temperature y this edge isn't saying that the sun warms the body it's saying that they're in this model there's an edge reflecting a statistical dependency and that's where there's the degree of freedom with respect to the realism and instrumentalism etc in this way inferring a sunrise can trigger the autonomic response u of thermoregulation in an anticipatory manner that is before the sunlight actually increases body temperature the upper part of a and c are bayesian networks highlighting that y is conditionally dependent upon x with the directed arrow between the notes with more than one x and y in the model for the allostat the lower parts show the form of neuronal message passing that could be used to solve these generative models so the bayes graph is represented on the top and then there's the message passing with respect to the neural population so that's kind of the second [Music] aspect of figure 3 which is just bringing in multi-sensory integration or even it could be like two pixels for example with beliefs about each other or something like that but that's what allostasis is going to be enabled by is just by this duplication of the column and then this connection in a different way and then here's the third section of four seven generative models for simple behavioral control and so they write the homeostat and the allostat permit the control of simple forms of swimming locomotion reaching and other movements one biological example is provided by the zebrafish virtual reality study 30 which identified the neuronal underpinnings of error correction during escape behavior in the animal's telecephalon to brain region an evolutionary conserved set of brain circuits involved in action selection in other vertebrates including mammals such as the corticobasal ganglia circuit so that's about the evolutionary homology of the brain region and then here's just some pictures from the paper um by torygo at all21 zebrafish capable of generating future state prediction error show improved active avoidance behavior in virtual reality so they did a learning task that involved the fish being able to differentiate a signal and then they studied the role of anticipation in that and the authors in this paper use that as an example maybe we could talk about that or other examples in the dot one and the dot two section eight here's where we get to the um very interesting operations that are going to bring this sort of descriptive model of different kinds of homeostatic allostatic and intermodal and then behavioral regulatory elements into the evolutionary context so our central argument is that evolution proceeded via gradual elaborations of the predictive motifs illustrated above under genetic constraints and opportunities and the selective pressure of novel problems to be solved such as the control of more sophisticated bodies in the presence of richer ecological niches eg when vertebrates began to establish life on land some 400 million years ago over excessive generations generative models can remain stable or be elaborated along four key dimensions strongly limiting the space of what is evolvable so what are the four kinds of dimensions that are going to be changed that is going to be discussed in terms of the changes that can happen to the specifics of the generative model we have introduced the first kind of elaboration from the unimodal homeostat to the multimodal allostat so they kind of secretly introduced this transformation between figure 3ab and figure 3c so that was secretly like one of the transformations a second kind of elaboration is the duplication of predictive motifs which enlarges the animal's behavioral repertoire the third and fourth dimensions equip the generative model with temporal and or hierarchical depth respectively these two expansions enable richer predictive motifs that endow a cognitive sophistication such as the possibility to plan or consider events that change on multiple time scales so it's the evolutionary algebra on structure learning because we're outputting a structure this graph g which is going to be like as if the species over evolutionary time is going to be implementing some graph in terms of the structure of its model like if there's a case where the ant is not integrating the polarization of light with the olfactory system and then there's some change in the model that actually integrates them and then some relationship is learned whatever that means from a realist or instrumentalist perspective and that is going to be like an evolutionary algebra so it's not going to be like 2x minus 3x but it's going to be more like that than not because there's going to be operations and they're going to happen in order so here's figure 4 where they represent their evolutionary algebra figure four the five main dimensions of elaboration of generative models introduced in the paper so it was you know four dimensions then it's five dimensions there's evolution in 4d by jablonka and lamb that would have been good to add to um the five main dimensions of elaboration of generative models introduced in the paper illustrated as operations of an evolutionary algebra so here's the five operations and so we're starting with on the left side that homeostat that simple corrective calibrative first order cybernetic model either what the system is actually doing or model of then there's going to be five transformations that can happen and then it's showing there's a second round like once you go h you could go h t a i plus i or i so you have five discrete options at the first time step but one of them is no change so it's kind of like no change or four different layers of um excitement of the electron like for quanta but they're for discrete operations like a deletion or an insertion in genomics and then from there it's just the state for the next time step of the model and then something else happens so what are the operations the bottom is i which is the identity operation that leaves the generative model as is so that can be interpreted as like a non-mutation or just a conservative mode which is how most inheritance works then the second one is the duplication operation i plus i so it's like identity remains the same but then there's a duplication literally it's like a genomic duplication but in this functional space replicates existing predictive motifs to form parallel sensory motor loops a is the operation that was described in figure 3c the allostatic operation endows the generative model with horizontal predictive relations between different modalities and so the duplication would be like going from one sensilla one antenna to two antenna or from going from one photoreceptor to two photoreceptors but the actual architecture of the column of the photosensory transduction cascade would basically be computationally or statistically unchanged and then the allostat is actually bringing in this horizontal aspect it's not just two um duplicated systems next to each other now there's actually connections between them and of the possible kinds of connections across columns one of them is like this classic allostatic motif then there's the ones that we haven't gone into as much which are t the temporal depth operation extends the generative model with separate variables for past present and future states so it's kind of from a graphical perspective what we looked at in the difference between the first factor graph which did take action at three time steps through time three time steps like the thermostat does to the one that actually has either prospectively looking anticipation about future time steps or retrospectively looking memory but that's how the factor graph comes into play that's temporal depth then the hierarchical depth operation h extends the generative model with separate variables for states of affairs that change at different time scales faster time scales at the bottom levels and slower time scales at the higher levels hence modeling narratives such as music and language where nested time skills are relevant so to kind of split that idea of temporal depth into two pieces there's incrementing the number of steps you're looking in the model that's increasing the time horizon on policy selection and increasing the temporal depth within a level and then there's this notion of nesting levels within each other that's the nested generative model and therefore nested markov blanket discussion that we've been having and that is going to be connected to cognitive activities like narrative and the the reason why they're very similar is that the time scales can kind of blur into each other and so it's all about the model's structure as stated like this one is hierarchical and it has a depth of three it's a two layer model and it has a depth of three three time steps are included and it could be different if there was always looking to a head and always looking to in the back then the model in the computer would need like a minimum of you know five time steps but the entities model could still be restricted to s minus 2 s minus 1 and then s plus 1 s plus 2. so um those are the two ways that it can expand in these two temporal and hierarchical ways which is to nest hierarchically or to become temporally deeper with a longer horizon given the nesting structure so these are all structural changes that's why there was the whole piece about structure learning because it's as if or actually like over evolutionary time there's the structure learning happen and then if we use this partitioning and bayes graph approach then hypothetically any kind of evolutionary starting point if we go back far enough and then final state if we have all the transitions could be modeled within like a native active inference framework section nine they're going to go into a little more detail about duplicating predictive motifs and enabling multiple behaviors so they write how does this um the writing on how does this duplication of the model um looking at it from the outside it's like as if they're acting as if there's two models looking at it from the realism and the inside it's kind of like thinking about the real duplication of a cognitive function that's functionalism or like even a neuroanatomical region like the earlier examples with the retinal cells and that's like an anatomical realism so generative models can expand by duplicating simple predictive motifs to form a larger repertoire of species-specific behaviors such as approach avoidance the control of the vibrasay and visually guided grasping classic the operator i plus i in figure 4 illustrates a generative model in which the same predictive motifs are duplicated and specialized to form a behavior-based architecture composed of multiple parallel sensory motor loops so they're suggesting that because these are your affordances your operations in your evolutionary algebra you can go from this starting point it's kind of like go to lesser block starting point and then doing operations to it because you have the starting point and the operations to it it allows you to get to even relatively advanced um motifs like approach avoidance etc but a key piece is duplication because duplication of something without changing it is how you are able to build more land to experiment in so to speak build more space and um i copied some images from genetics specifically in the relationship of how gene duplication and divergence in the early evolution of vertebrates this paper um and there's a huge amount of genetics and genomics works on the duplication and divergence and the neo-functionalization the sub-functionalization because if you have like an enzyme or a essential gene a not to go into the whole gene thing totally another time though um you could have the function of the second copy in the genome be lost and then there is still like a continuous line of function so if you only needed one copy of a then this would be sufficient and then other times when you have a and it's dual functional like it binds to two different not exactly similar molecules then when there's a paralogy when there's this duplication it allows sub functionalization or new functions to arise so that's how people talk about it and link it to realism in genomics and this is kind of approaching that from a cognitive perspective um there's probably more to say but we'll talk more about the duplicating of predictive motifs so how is duplicating predictive motifs enabling of multiple behaviors okay they write from a structure learning perspective duplication is an efficient way of building generative models and that's what it's all about in the sense that the dynamics are conserved over different sensory motor domains this conservation is mathematically akin to factorizing probability distributions on the generative model that has been discussed in terms of modular architectures and functional segregation as a principle of functional brain architectures in bayesian statistics physics this kind of factorization is ubiquitous and known as a mean field approximation indeed the free energy bound on model evidence is defined in terms of a mean field approximation that affords an accurate and minimally complex explanation for sensory data and so what are some of these citations 484 modular architectures for factorization of probability distributions in the generative model par sageed and firsten 2020 entropy so here's kind of a cool figure nice graph and then there's the message passing and then citation 48 the mean field approximation what is it here's a paper from 2001 and they wrote algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of local interactions each of which depends on a subset of the variables such a factorization can be visualized with a bipartite graph that we call a factor graph dot dot a wide variety of algorithms developed in artificial intelligence signal processing and digital communications can be derived as specific instances of the sum product algorithm including the forward backward algorithm the viterbi algorithm the iterative turbo decoding algorithm pearl's 1988 belief propagation algorithm for bayesian networks markov blankets the common filter and certain fast fourier transforms fft algorithms so it was 21 years ago when this was happening and now we're here okay section 10 endowing generative models with temporal depth supports prospective and retrospective inference so just like we looked at with that factor graph giving this operation over evolutionary time enables that factor graph to arise from something with the lower time horizon the generative models discussed so far only consider present states and observations however they can be expanded into temporally deep models whose variables explicitly represent future and past states and observations so this is what the operation looks like it takes x t and then at x t plus one or tau depending on how it's written and then now there's another time step appended to the end of this model either actually or as if here's something cool that they wrote they wrote various researchers have speculated that a major driving force for the development of deep temporal models was foraging so why would this happen functionally which is to say why does the mutational spectra which does allow for this as an affordance end up selecting for and retaining and enriching for temporally deep models otherwise we wouldn't observe it to exist and they're connecting that to foraging intriguingly this is a vertebrate example the same hippocampal circuits that support spatial navigation and foraging are also involved in prospection and imagination this has led busaki and mosser to propose that prospective functions have leveraged cognitive and predictive maps in the hippocampal endorinal system and hence mechanisms of memory and planning have evolved from mechanisms of navigation in the physical world so what are the cognitive demands of foraging how about information foraging how about mental foraging here's some awesome papers by hills and cuisine and others foraging in mind and foraging in semantic fields how we search through memory so what about mental foraging what about individual and collective foraging this is an awesome paper by finerman and corman in 2017 and they talk about the continuum and the complementarity of individual and collective approaches to cognition and so implicitly like foraging as a phenomena some of the affordances and the neurophysiology of foraging in ants it's the same materials and mechanism that any other insect that's not eusocial has so the detection of light the intensity the wavelength polarization sometimes the ability to do chemo sensation like taste and smell mechanoreception etc and the same action affordances too like movement and so there definitely is nest mate level cognition in ants but also there's things that are of a few different interesting types one of them is mesoscale like small group dynamic stochastic teams and larger scale like colony and even colony niche stigma g and ecological scale cognitive processes like these two ants are interacting and modifying each other's foraging behavior mechanistically and statistically but also it wouldn't happen unless the niche were exactly this way which they have also in their extended selves established for themselves so how do we think about individual and collective foraging and stigma g and complex systems and mental foraging and cognitive demands and cognitive security what about section 11 endowing generative models with hierarchical depth affords multi-scale inference so now we get to the hierarchical operation that is going to give that multi-scale inference so far we have described generative models that can deal with aspects of the world that unfold at single time scale so plus one plus one plus one time scale is temporal depth but you're getting still only one extra per transformation however they can be expanded into hierarchically deep models whose variables at different hierarchical levels encode latent states that unfold at different time scales one example is a song melody remains the same even though the notes we hear or sing change rapidly and speech similarly a movie or narrative remains the same for several minutes scenes remain the same for several seconds but visual stimuli can change over hundreds of milliseconds such models permit hierarchical models permit modeling of narratives songs movies and other events that change at different temporal scales by encoding variables that change more slowly eg melodies or movies at higher hierarchical levels and variables that change more rapidly eg notes or visual scenes at lower hierarchical levels two neurobiological examples of hierarchical organization are visual areas in mammals and areas that control vocal gestures in birdsong which has been studied in active inference several times and so here's another quote from the authors in more advanced animals the hierarchical control of action may have expanded into sophisticated forms of cognitive control and executive function layer 1 scare quotes which help prioritize distal goals while inhibiting immediate affordances so it's not just about seeing deeper within a time scale but it's about being able to pull up to a higher time scale and then from there after the h operation it can be followed up with a t operation so here's the minute scale and then there's a hierarchical duplication that allows for the hour scale and then that can go into two hours and now two minutes so now there's a two hour and two minute long model instead of a one minute and it was just two mutations but if the two mutations had been um or the three mutations had been just going deeper within the minutes it would be a different outcome how is that um functional so what is the function and the cost of temporal depth just instrumentally when we're studying diverse cognitive systems how can we detect temporal depth and slash versus hierarchical nesting then what is the meaning and the role of narrative in cognition how does this relate to narrative information management all right section 12 getting towards the end in the above which was again the description of the simple motifs in four five six seven and then the evolutionary algebra in eight and then several of these finer scale discussions on 9 and 10 and 11 we then get to 12. in the above we formalize brain designs in terms of generative models that include predictive loops of various complexity red and then discuss the five main ways in which generative model designs can be elaborated green or the five main operations of an algebra of evolutionary structure learning figure four this means that one can describe the evolutionary trajectory of brain designs in terms of a limited number of mutational operations over generative models blue so here is a phylogenetic tree on the right side with the tree of life one of the tree of lives what are alternative complementary or traditional ways to think about phylogenetic trees in evolutionary biology are phylogenetic trees interpreted instrumentally are they interpreted under a realism framework is that what really happened to those species or is it our model inference about what is the relationship between active inference and the free energy principle and evolution okay they have figure 5 which gets at their phylogenetic model so this is a phylogenetic tree of generative model designs and putative correspondences with animal brains so here's the implied ancestral state and then i is going to be the identity operator so here the orange species has not mutated at all now sometimes this is um conflated with simply being an out group it just because it is that way doesn't mean they're making the conflation but sometimes people will make the conflation that because a species is an out group to some other clade that has been included in the analysis that it is the basal or primitive form and so it does happen to be that way in this example that the basal is the so-called least derived or most primitive or basal form but my personal thought is that it should not be described and tim link's fair and others have awesome writing on that evolutionary fallacy so in the rest of the tree which is being focused on different kinds of operations happen so here's that i plus i duplication and then there's no change after that and then this one has a and so on so just like you could trace the phenotype changing through time on a tree inferred from trait or genomic data which is just another trait this maps up to certain changes that are seen neuroanatomically over vertebrate evolution and it reminded me of this paper which was um chakraborty and jarvis 2015 and so that is the paper brain evolution by brain pathway duplication so they don't connect it to um in the exact same way the neural cognitive and the functional and the active inference and all that but this paper does get out some of the very similar ideas about the functional duplication arising as a result of pathway duplication they have a section on brain complexity and pathway evolution they talk about some alternative hypotheses and then talk about distributed and duplicated morphological structures so it's a kind of interesting paper from about seven years ago another paper that's very related to this idea of doing like an evolutionary algebra with combinatorics but also a path dependence is this paper pretty recently just a couple days ago by ryan smith maxwell ramstead and alex kiefer the paper is why bayesian brains perform poorly on explicit probabilistic reasoning problems so look at this tree that they have the starting point and then three actions so here it's like divide divide multiply divide add divide and then they study that in the context of bayesian brains and doing calculations why is it hard to multiply numbers together sometimes so then the authors of the paper 38 right interestingly the mutational operators are commutive the same generative model design can be obtained by executing the same operations but in a different order the commutative property of mutational operators potentially sheds light on the convergent evolution and the process by which unrelated organisms evolve similar traits independently and via different evolutionary histories when they need to adapt to similar ecological niches that's pretty cool all right so just the discussion and then a few last points so discussion and the authors summarize it in this article we suggest that brain structure or design could be formalized as generative models agree disagree that the brain generative models of our evolutionary ancestors included simple predictive motifs agree disagree and that the evolution proceeded via successive elaborations of these predictive motifs into more complex architectures that we observe in advanced animals they then talked about the ways that that can change through time functionally and then they write while the evolutionary trajectory of designs for predictive processing proposed here is certainly tentative and incomplete we consider it a first step towards the alignment of predictive brains and evolutionary studies of neuroanatomy in different species so if this is the first step where are we headed and why do we prefer and expect ourselves to be there or go there just a few more topics that we could talk about like in the dot one and in the dot two um first would be they write that the error correction mechanisms in their view encompass the simple and the complex forms of adaptive behavior hashtag integrative theory and they're going to argue that that differs significantly from prevalent perspectives in psychology and neuroscience which tend to separate sets of mechanism for sensory motor processing and simple cognition so how is active inference similar and different to other frameworks for behavior what are the building blocks of adaptive behavior what are the basal blocks of just any kind of behavior where does sensory motor integration come into play how about mental functions and cognitive functions like memory anticipation counterfactuals etc okay another point to kind of think about or write your questions down and reflect on is the perspective which is still speculative and not unchallenged suggests that the complexity of the ecological niche determines the level of complexity that the brain needs to have in order to be bayes optimal in other words brains only increase their complexity with sufficient ecological demands so not necessarily just that mutational direction and intensity will go towards increasing brain complexity from ecological demands the so-called anticipatory evolution that cognitive entities can have through self-modification and niche modification but even for those that aren't actually doing anticipation still it could be the case that when the ecological demands are such that a behavioral model increase in complexity is selected for and retained then evolution will go that way this is because having a more complicated brain does not help if you live in a simple niche so that's like a very costly model that's not giving you any more return on investment they then talk about how social brain hypothesis states that the necessity to predict and deal with sophisticated social dynamics was a main driver of the evolution of large brains and sophisticated cognitive abilities in our species people in short the gradualism expressed as a progressive increase in complexity rests on the circular causality implicit in the modeling of an echo niche that is itself constituted and constructed by increasingly complicated phenotypes so because it's so important to think through other minds first just how you're going to materially avoid a spatial collision but then so the social brain hypothesis goes includes increasingly recursive levels of game theory market theory and all this kind of stuff and related indirect cognitive phenotypes required like memory and recognition narrative understanding rhetorical understanding governance etc that is being posited as compatible with the models the authors have written and a hypothesis that others have written about not from an active inference perspective though in most cases so what is the cognitive niche for social entities our material niche and our social cognitive niche what is the social brain what is the you social brain how are they related so for example the social brain is saying that the more social things are the more sophisticated the brain has to be well you need more narrative understanding and more memory but what if in the eu social case the brain is simpler on board for example it's more role-based or temporal polyethylism has allowed more reduction in the each phase of the life cycle's brain so does social lead to you social how does your sociality arise and how does it elaborate how do different kinds of sociality arise and elaborate and how is that associated with the different kinds of models structurally changing that we've been discussing in this paper and then just genomics all the other stuff gene expression and then just one last point which is the closing piece of their paper too finally it is important to acknowledge that brains design bodies ecological and cultural niches co-evolved independently not sure if that was dement it's kind of like they are codependent in their co-evolution but they co-evolved they were alone together given that here we were interested in the evolution of brain designs we assumed a brain-centric perspective and conveniently focused on generative models in the animal's brain hashtag realism in the brain not modeled as in the brain however cognition does not need to be confined in the skull to be it can be extended outside it to cover for example tools and social dimensions epistemic niche niche modification digital stigma she furthermore the body design and not just brain design plays an important role in solving control problems acknowledging that cognition can be extended and embodied and in cultured etc all the e's all the other letters suggests that not all aspects of control need to be solved by or represented in a central generative model tale of two densities all the discussions we've been having about representation and so it was x and x star in the simple version that was presented in this paper where was actually trying to track x star in the world with the internal inference but this is the discussion that we've been having do those representations have to structurally resemble the world and there's other papers that we've discussed in the last several weeks that really touch on that point so how do we think about generative models and factor graphs for extended cognitive processes so a couple books to check out about extended mind and embodied cognition and then here's a nice figure from touch points with the brain the organs and the body the world and the tools and the epistemic niche and the computers like a calculator and time chronos and food and then other people social so that's like cognition is like a holistic integration of all these features what does embodiment this perspective have to do with realism and instrumentalism and utilitarianism and other philosophical positions are people really taking those positions or is it just as if they're taking those positions and then what else are you really curious about and motivated to explore and how will you modify and improve your epistemic niche so hope you enjoyed this kind of solo 0 video i think it's been a little bit since the solo.0s but just want to close as always with what might a good understanding enable what are the unique predictions and implications what are the next steps for free energy principle and active inference research and application what are the goals of this research and what are you still curious about we're going to be talking about this paper in the coming weeks on february 16th and february 23rd and so if you'd like to participate in those discussions through live chat or by joining the discussions live just get in contact with us hope you read this paper because it's very thought provocative and uh interesting so enjoy the paper and working through it i hope to see you in other acting flap activities thanks for listening in your regime of attention goodbye