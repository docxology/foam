hello and welcome everyone to the active inference Liv stream it is active inference Liv stream 11.1 on 12 22202 December 22nd 2020 this is going to be a really fun discussion and hopefully we'll see if anyone else joins us other than that we got a nice small group and I'm really looking forward to talking to you all about this paper welcome to the active inference lab everyone the active inference lab is an experiment in online team communication learning and practice related to active inference you can find us at our website active inference dorg on Twitter at email or YouTube channel or our public keybase team and username this is a recorded and an archived live stream so please provide us with feedback so that we can improve on our work all backgrounds and perspectives are welcome here and as far as video etiquette for live streams mute if there's noise in your background raise your hands so that we can hear from everybody who wants to speak and we'll use respectful speech Behavior Etc so just a couple points of process today on December 22nd we are in 11.1 and next week will be the last act imp stream for 2020 on December 29th 2020 and that will be at 7:30 to 900 a.m. PST on the same paper that we're talking about today and everyone is welcome to join then then we are very happy to announce the active inference stream schedule for 2021 which can be found at this rb. gy link going to this link you'll be able to find out which papers we'll be discussing which week and how to participate if you are so interested and also all these sessions come and join for however much you can so if you have to join late or leave early it's all good we just want to have participation and your perspective this is what the calendar looks like so looking ahead to some of the first paper we're going to discuss the first weeks of January we're going to be discussing um in 13 a paper by Adam saffron and Colin D young uh in the second weeks of January we're going to be talking about Mel Andrew's paper the math is not the territory so everybody should be finding exciting papers and letting us know when we can read them for AC infam also just one last note if you go to active inference dorg you'll see a call for collaboration for the active inference lab 2021 so check that out if you'd like to get involved in any way okay thanks for all that here we are in active inference stream 11.1 and today first we are going to have introductions and warm-up questions and then we're going to turn to the sections of 11.1 the paper we're discussing is sophisticated affective inference simulating anticipatory affective dynamics of imagining future events by Casper hesp at all in 2020 from the iy proceedings we're going to talk about the aims and claims the abstract and the road map and then we'll go through the figures and maybe even some of the citations that are referenced in the paper next week we're going to be discussing the same paper so save and submit your questions and get in touch if you'd like to participate okay here we are in the intros and warm-ups so let's introduce ourselves we can each give a short introduction or check-in and then pass to somebody who hasn't spoken so I'm Daniel I'm in California and I'll pass it to Sasha hi I'm Sasha I'm also in California and I will pass it to Blue hi I'm blue I'm based out of New Mexico I'm an independent research consultant looking at um bioinformatics a lot and a lot of agent based modeling mostly and I'll pass it to Stephen hello I'm Stephen I'm based in Canada in Toronto and I'm interested in um the ways active inference can help inform the ways groups and communities understand their place in the world and I will pass it over to Ian let's go to Alex actually oh sorry I yeah hello my name is Alex I in Moscow Russia I'm a researcher in systems management school and I'm trying to find interconnections and possible ways to connect with uh systems engineering and system thinking Frameworks awesome and have uh we a new fellow jiter it could be Ryan so anytime that Ryan or anyone joins we'll just hop in and go from there um okay I just want to check these messages all right thanks okay let's go to the warm-up questions so for the warm-up questions we can each just raise our hand give some thoughts and we'll have plenty of time in today's relatively small discussion to get through everyone's thoughts on the paper and on the associate areas so first just an introductory question is what gets you excited to read and discuss this paper so thanks everyone for showing up and for those who are listening live and in replay and I'll tie that to the second question as well how can we learn and communicate the technical aspects of active inference in an accessible fashion so it's kind of like intention setting as we head into this relatively technical paper and indeed relatively technical area of active inference that draws on mathematics and computer science and a few other areas so again anyone can raise their hand but I'll give a first answer just think about what's something that gets you excited uh in terms of the content and then from a process-based perspective what is a way that we can learn and communicate accessibly so what um let's go with Stephen first Well I this is interesting because I think this discussion came up on one of our conversations on our chats I think finding different ways in um will give you different ways to communicate to the different people that you're talking to so I think active inference needs to be connected to some process that people are familiar with in terms of how they make meaning in the world um otherwise it's a big big jump to build it all from first principles yes so definitely it's exciting to hear about things that we've heard about in A New Perspective so I agree when we see keywords in an active inference paper and we know that it's going to be like familiar territory but approach from a different angle that's exciting uh any other thoughts there Alex yeah thanks uh for me it was interesting how uh provide an example and the the case for defining agent and generative model for this agent and so as a result to have simulation as possible ways way to in a more practical way when we usually discuss on papers here is like exact case for simulation thanks okay blue so I think a lot of things were exciting to me but like computational Psychiatry that's a field like what is that about um but I mean it it really just kind of hones in on like maybe are we like a sum of input output like is our effective State like just direct result of our input and if so like I don't know that it feels a little bit like Brave New worldish like are we going to move toward you know control theory and optimization of affective State it's kind of um just like crazy and a little bit scary to me yep from implicitly to explicitly steering others behavior and veillance and affect Sasha um yeah I just remember this reading this paper when it uh came out earlier this year and thinking like what does affect have to do with uh agents and and why is that important to model or to include um mathematically and so that's been something I'm still thinking about um and um yeah very interested in the aspects of uh you know computational Psychiatry and yeah I guess just on a deeper level reminds us that um affect and mood are really important aspects of The Human Experience and not something to be um ignored uh in favor of like bigger decision aspects um that it really does matter yeah one thought on that is that in active inference we're always talking about how everything is prediction and then we're always talking about how prediction isn't just a point estimate of what will happen it's actually a state estimate and an uncertainty about that estimate so you know I predict the Giants are going to win the World Series and I'm this certain about it or I'm not certain about it so it's always the state estimation and the uncertainty and so that uncertainty is the risk or the ambiguity depending on the context and then the state itself good versus bad is the veilance and so it's sort of like the affect which is multi-dimensional contains something about how good or bad it is and then orthogonally or independently whether it's good or bad is whether you're confident or not and so you could be very confident about being happy or very confident about being sad Ryan we see you joining can you hear us not sure while Ryan is is um figuring out his setup but thanks Sasha for bringing up the computational Psychiatry angle and I hope that Ryan will be able to fill us in soon Stephen yeah I think this is a really important point because when we think about how things happen over time in this process how that gets integrated how we make sense not just in some sort of snapshot about a situation I.E we think this is a problem situation and then suddenly there's this emotional churn that's somehow a byproduct of that but actually it's not a snapshot this ongoing process which seems incredibly impossibly complex is made all of it's made sense of because of affect and emotion it's not some Freudian sort of repression that's sitting there in the background as a as a as a mistake but it's actually like the big game in town which is pretty revolutionary really interesting and also uh yet another transformation or sort of Paradigm Shift associated with thinking from a free energy perspective is rather than prioritizing the veilance the Plus versus minus and then having risk or ambiguity as a secondary layer we can actually think about the ambiguity reduction as the primary drive and then the plus and minus as falling out of the quest to reduce uncertainty rather than uncertainty being an auxilary factor in the to improve outcomes so it just shows how there's these two related dimensions of prediction which is the state and the uncertainty and then we can think about how prioritizing one or the other is going to lead to different outcomes Ryan we can see you raise your hand can you talk okay how about you can raise your hand and lower it in Morse code and we'll communicate with you that way but Ryan thanks for trying and if it's not working with your current browser setup for whatever reason today then we'll make sure to work it out with you in the interm and for next week and for following discussions will have you on unabated all right and here's our last warm-up question which is something that you are wondering about or would like to have resolved by the end of today's discussion blue so I don't really expect this to be resolved but I wonder instead of um modeling you know to predict like positive or negative veilance like if there is a way to model um like equinity in this in this sense like so neutral veilance like is that um I mean what what would drive that force and so I'm just kind of wondering as as we dive deeper into the model if that's going to become clear or not can you um explain what you mean by that and what types of models might exist to think about that um so just like how you know the results here were geared obviously toward um you know pushing a affect towards either a positive state or driving away from a negative State I mean that's I assume the idea so what about driving toward a neutral State like is is this something that's been considered right like so you know overthinking tends to lead like overthinking like supposing about the future leads to like you know these supposed negative thoughts that and so then it's anxiety producing because you're worried about these negative thoughts like so that's overthinking or thinking like worst case scenario perhaps right so people do like a lot of thought redirection in this cognitive behavioral therapy like people do thought redirection so that maybe you're thinking in not such a Negative state but but in a more positive way like well it could also be great right like so there's that but what about like the non-thinking so if you non-thinking a veilance neutral like veilance equals zero to just have this kind of equinity Baseline that's like something maybe medit meditation achieves right so like can you can you work towards like non- think maybe non-thinking is that that veillance neutral right like so I don't know how how um how can that factor into computational Psychiatry and it has that been thought of before I don't know cool great question and so it's kind of like if we were going to be doing modeling of a car there's probably a lot of different ways that you could set up car crashes or cars that drive off the rails and we just want to know about what does it look like to have a computational Psychiatry model that isn't just capturing a negative spiral as overthinking progressively sort of accelerates but rather something that returns to a neutral attractor state or something that's related to mindfulness or attention to detail or abstraction but not hyper abstraction rumination but not hyper rumination so could the strange attractor be a neutral or even a healthy one not a delusionally positive or negative Stephen I suppose you could say that like there's thousands and thousands of Dimensions which are kind of sitting there as neutral and you really notice it when you you're not there and you got to reestablish it so that's what they talk about in sense making is when you're immersed in something you don't do sense making but once you Sonic jolts you out of it certain consciously you might be doing unconscious sense making but at more of conscious level is when you're surprised basically when things aren't going the way that your habitual understanding of them are and then suddenly your cognition is got to kick in and say okay how do I work out what is the sense of what I should be doing at the moment and that's when everything becomes transparent so it's it's quite interesting to actually then see this now that the again taking that that thinking and and that sort of abstract and bring it right into the body and the and and the emotions as the kind of like the way of really knowing I mean in some ways is your mind checking in with your body or is your body checking in with your mind cool very interesting about the mind and the body and always an important take um any other thoughts here or can we continue Sasha um yeah another aspect of this paper I really liked is discussing the um like future clinical applications of understanding the mechanism of how certain existing therapies work because there's a lot of different kinds of therapies out there um and namely I'm thinking of like art therapy and but of course all other forms included um to understand to start to understand why they work and by what mechanism um they might be tapping into uh this kind of affective and predictive coding um so I I think that's really exciting and I also wonder who is fit to address those kinds of questions is it medical professionals um is it uh psychologist um who is best suited for that role because um it's a very you know uh challenging subject to talk about without um giving people perhaps uh incorrect medical advice or false hope and so that that's just something that um I'm curious about but I don't want to step on any toes cool let's keep that in mind and as Ryan joins and rejoins but no need to send the jitsy messages because we can hear it very loudly so let's just hope that Ryan can figure it out otherwise we'll take care of it for next week cool here we are in the paper for today which is sophisticated affective inference simul ulating anticipatory affective dynamics of imagining future events and this was from October 2020 in the first International workshop on active inference or iy and I believe that more recently like in the last couple of days this has been codified into a book so um we're using the research gate version the aims and the claims of the paper were a bit rehearsed in 11.0 so go and check that one out if you want a deeper dive into what the aims and the claims were but the big point of this paper was to take two bodies of previous work which was the sophisticated inference which is sophisticated meaning deep through time and then affective inference affect being related to emotion and veilance and fusing these two threads into sophisticated affective inference so deep through time and also involving aect and the big question from a non-active inference jargon perspective is how to model affective and anticipatory agents of course we're going to be thinking about that within the active inference framework and then we're going to be asking what features do these simulated agents display and then how does this carry out or connect to areas that are like Psychiatry or cybernetics control theory all these fun things that we've been talking about in previous actm streams how are we going to connect what we're learning about today something that's a recent development in only the last couple months this is the current developments so let's have fun let's um treat it as just an initial inroad and a connection between these two different areas here's the abstract and again it was read through in 11.0 and we're going to just go more discussion oriented in the panels that we have but fundamentally in the abstract they describe what I just said that they combine those two different types of active inference models sophisticated and deep parametric models and then they use a augmented marov decision process please know jitsy chat if possible thank you Ryan we'll see you soon um and uh then they give a minimal simulation at the end of a ruminating agent and that is where blue was talking about the negative agent that sort of spirals off into negative affect okay um the road map of the paper there's not that many stops not that many gas stations along the way it's also a short paper and I have it in this other tab if we want to um go through it as it is as a paper because it's so clear and concise but what they do is introduce the ideas then show a couple figures that just summarize the model and show a table with what the uh formalisms were at this point does anyone have any thoughts or where do we want to go like what was something that somebody thought structurally or from a topical perspective that they wanted to bring up or it's okay if not all right let's uh look at the figures and then use the figures as our scaffold for kind of understanding what they are up to in this paper and then understand why they did some of the things that they did and then what some of the next steps could be so here we are in figure one and figure one does anyone want to point something out that they see first so feel free to just raise your hand any time um in figure one I've put red boxes around two pieces these are the two pillars that things are being built upon here is the aect of inference part which we'll get to in a second and then in the the middle is the task specific sophisticated inference so that's deep inference here and then as with a few other figures we've seen time is moving from left to right now in this model there's several boxes that are shaded and that's because there's this recursive embedding of the models so we start with one single time Point that's this up here on the top level of the model this is like the outer layer of the model it's kind of like the hour hand of the model you can think of and what's happening at each time point of the model itself is that the agent is doing a forecast through time so it's kind of like in the year 2000 you're doing a forecast for the next 100 years and then it's a recursive string because at 2000 you do a 100-year prediction and then 2001 you do 100-year prediction so it's like at each time Point each big hour tick of the big model we're going to be doing this recursive uh rolling out of predictions through time so that's the biggest structure of the model is top level is the actual time that's the real what's happening in the world we can think but then the agent is involved in this recursive of anticipatory simulation and that's the Deep or the sophisticated inference now there's a few other elements to highlight and again anyone can raise your hand at any time the first thing is that within this prediction through time we've seen a couple elements here we've seen s the states a how the hidden State estimates are mapped to observations we've also seen b which is how the states change through time or are predicted to change through time again this is like happening with within an instance of the agent we've also seen U which is how actions how policy maps on to the way that states change remember that policy enters the B Matrix so states are being inferred and then we're inferring the B Matrix which is basically how our policies affect how States influence uh how States change Through Time Another notable feature here and slightly outside of the blue box but in the gray box is this gamma or a Precision parameter so as we do this roll out at a given instant and think ahead Through Time how things are going to be we're not just estimating the state roll out through time we're also estimating our actions through time and how that influences States and how they change and a layer above that is this gamma which is how sure am I about that that's this layer of precision in the estimate and that's coming through this G which is um related to the estimate free energy so again for each moment of the roll out the agent is estimating a bunch of things inside this model and then Steph I'll get to you after I finish this last little bit and then in the moment in the actual timeline of the agent it is having aect and so these are the ways that these two models are combined and we can look at some more um unpacking in other slides but I just wanted to start with the actual figure used in the paper itself before going to another citation and the sophisticated inference is capturing this deep roll out at an instance with a Precision estimator and the affective inference is capturing this affective state that carries forward in time and so combining affective and sophisticated inference is quite literally structurally combining the patterns of affective inference from this hesp at all citation with the topological model structures of sophisticated inference we'll stay on here and continue thinking about it Stephen so would I be right in saying that the the effective inference over time is is kind of looking at the shape of how actions look like they're going to turn out over time and and sort of put in a feeling to that in a simplistic term it's like there's it's not so you've got all these fairly discret moments being looked at or assessed over time and the sort of the shape of that is what the feeling is about that makes sense it's like is it going is is is it like am I predicting this to be a roller coaster ride of uncertainty over the next few minutes or am I expecting it to be smooth you know because that would be the kind of the shape of the observations and the expectations as I stretch it out over time and that itself becomes something which is abs you know has a generative model um tracking it would that be a one way of saying it great and thanks for phrasing it in the wording as it appears to you so let's start with that shape of the prediction that shape is actually the shape of a probability distribution it's the shape of the probability distribution that is a generative model and the shape of that it's kind of like a cloud of points or the bubble that encloses the cloud of points it's a a shape that is existing let's just think initially in two Dimensions so like a piece of paper and on the y- AIS is going to be how rewarding is it lots of reward or negative reward and then the x-axis is precision from low Precision to high precision and so you could imagine that the shape could be all the way clustered up on the top right corner so that would be high expected reward but High Precision that's the best state the lowest state would be like the bottom left where it's like low expected reward and low Precision so again the reward prioritizing mindset says the agents State Should correspond to their state estimate the active inference perspective says no no no the agent's affect is going to be related to their uncertainty estimate more so because if you have a small positive State estimate but you're very precise I'm going to give you $5 plus or minus 1 cent you'd say great and if you say I'm going to give you $5 plus orus $25 you say wait a minute you're going to maybe take $20 from me even if it's a very small chance that isn't as good as getting five plus or minus one and so this is where the state estimate and the Precision estimator are orthagonal and so that's what delineates the shape of the distribution that is the generative model of the future now in a traditional computational psychology model again agent affect would be tracked by the state estimate if it's a above zero expected then you're good if it's below zero it's bad whereas in the active inference framework good affect is going to be associated with precise estimates and anxiety negative affect is going to be associated with high uncertainty and so as this agent runs simulations going forward and rolling them out we can look at what that looks like even if the expected reward is positive if the ambiguity is high the uncertainty is high it can be anxiety producing so that is what we're really tracking is there's the structure of this model which is like the topology or the connectedness of how different variables influence each other in the model but then the outcome of all of this is the shape of the distribution of the prediction of the agent and that's respectively just like all predictions are about State as well as uncertainty so estimate about the world States the hidden states in the world and then a metacognitive estimate of our decision and so it's like this is one click through time and then the agent acts but it's simulating its future actions at this moment and then the actual model clicks over and then it's in the next time step for the agent and it starts simulating from that moment going forward and so that's one of the features that is uh something that's a Hallmark of this model is it's like the game that's being played has a net positive return and let's just just assume that we had a degree of agency we could probably choose small winning outcomes within this game that we're about to show however by spiraling and by ruminating Deep through time the agent starts thinking about potential roads that are highly uh rewarding as well as a small fraction of paths that are very negative and then the uncertainty in that distribution the spread on the x-axis or the higher uncertainty on the x-axis is actually leading to it being anxiety producing even if the state estimate is positive Stephen yeah I think this is this supports some of the challenges we also find with you know if you you see the the numbers for the stock market you can get this sense of full sense of certainty that we all know what's going on and it gives this for some people that can make them quite relaxed and confident and here I go you know um bullish as we might say and this this would sort of support that sense of like um if you're given this high level of supposedly precision and um supposed um accuracy and reliability you could get a full sense of of of that and and that could be where you know at the same time people challenge that and look at like we need to blow that apart because you know if you if if the confidence in that suddenly disappears and you see it as not being as precise as you thought the anxiety Rises greatly and you know otherwi ways of thinking might need to be thought you know come into play cool good connection there with decision making in markets which are very related to not just estimates of value but estimates of volatility and uncertainty estimates about value and about volatility and so then you have people trading vix you know trading the volatility index or leveraging that and so these are like higher level ambiguity about ambiguity or risk about risk and then all of that is associated with veilance is it a good trade or a bad trade and so that's like coming back to Sasha's question about veilance and affect it's sort of like well there's so many layers and ways that you could leverage trading but then in the end it's like right but am I going to do action a or not is it going to be a or b is it a good trade or not and that implicitly entails preferences like I want to see my number of Bitcoin go up not down but if you didn't have that preference which is part of the C Matrix which is not shown here it's part of the G if you didn't have a preference then you wouldn't know which policy to partake in like if you don't know where you're going every step is a losing step but then with a preference Vector C you can actually ask is this trade a good one or a bad one and that is not just is the expected value above zero again that's reward landia that's reward first uncertainty as a satellite we're taking uncertainty first and we still want to partake in in preferences uh in preference guided policy selection so instead of doing preferences to reward maximization and then we'll deal with the uncertainty later it's like let's go from preference to policy selection with ambiguity as the heart of what we're doing and reward will fall out as a function of reducing uncertainty about optimal action in the world given our preferences and affordances so this is sort of the simple uh rearranging of ideas and reconfiguring that leads to some of these Innovative insights in active inference Stephen just adding something into that is also shows it can work the other way I I know someone who does trading and he has to sort of monitor his heart rate they do a whole thing where he does like some relaxing and measures the heart rate and that before doing the work so that the state of the body doesn't mask what's actually going on you know so this also shows that you know if your physical state and your you know emotional state is is is out of whack in any way your your ability to to do this deep inference might be skewed or even you know uh lost because the the top level in the diagram is not necessarily tapping into the real data it's just tapping into the the the the values about context arous or Etc that is just in the whole system for the person correct and there's a lot of Behavioral research not done in the active inference framework that shows like when people are in a pessimistic framework they might be more willing to satisfice with like a smaller gain in the short term whereas when somebody's feeling like abundant or optimistic or confident about their success they might be able to delay gratification and partake in larger gains in the future and so if you have somebody who's carrying over from the other tab quite literally negative affect or adversarial affect about the world and they flip over their trading account they're going to be making different kinds of decisions based upon their affect of state that's going to carry into their estimates of precision which is related to anxiety higher Precision lower anxiety those two are negatively correlated and then again in this caption the um imagined action model Precision actions States and outcomes everything inside of the gray and the blue box is inside the mind of an agent at a moment and so this is the roll out inside of the mind of an agent at a moment let's look at figure two and talk about this game that they actually simulate out so this is Four State game um it's uh there's a lot of games that you could simulate but this is just one game and each of the edges reflect transitions that are possible so you start on like square one and then you can either move to square two or Square three with some probability and you start out with gain of zero it's a neutral State you can go to a safe small gain so if you're just wanting to play it safe you could hang out and go between one and two however also you can go to this High Gain three now three you're getting twice as much money however there's a one and three chance that you're going to or depending on how these edges are parameterized I should say there's a chance that you can move into this absorbing State that's painful and so the two adjectives there are painful so it has a negative reward of negative -2 and it's absorbing because you see that it can also uh swallow your trajectory like once you end up in four it's sort of like a negative State and so there are absorbing states in the world like death let's say once you hit this state you're staying in that state and so the agent is starting here and so it's like which Square should I walk on to get um you know the most money or something like that and so if it just walks around it's going to end up here really quickly and get into this painful absorbing State and so it's thinking okay there's some paths I can imagine where I just walk back and forth between one and two there's some other paths where I walk around on one two three I'm just getting money or neutral on every step and so what it's doing here is time one it's saying well on my next move I could go to one two or three and I could go to four but actually this Edge isn't there so it's it's like not likely so the first step it's like it's literally all good your expectation is either one or two so your kind of estimate is a mean of one and a half with a small variance okay but now here if you stay on one and then continue on one now you're getting this path at time point three would give you zero here you'd have $1 total 0 01 here you'd have $3 total here you'd have plus one Z so 1 2 4 here you'd have 2 + 2 is four so you're getting all these estimates now you have some fours but you also have some two negative twos and some uh negative fours so as you're rolling out this simulation at each time Point actually the expectation is getting higher because if you think about it you can get -2 or plus two that cancels out and then plus one so each game you play each step the expectation is going to strictly grow however the variance is also going to strictly grow and so this is related to a few other probability games where it's like will you play this game will we Gamble and then it's like double or nothing uh uh following double or nothing it's like the St Peters St Petersburg uh Gamble it has another name as well and the reason why people don't pay infinite money to pay these uh to play these games with an infinite expected value is because the variance is so high and so what's happening is as the agent is rolling out in its mind these possible trajectories and this could be like chest trajectories or it could be like action selection policies or trades as it's rolling these out the variance is increasing and so that's making it anxious um that's sort of the heart of what's happening and then as we Trace out the time steps of the model this is again just one trace of the simulation they're not exploring every parameter but this is very illustrative what happens is that in the first couple of hundred uh time points of the model the veilance is good the agent is feeling good it's feeling good about ending up in large reward States and it has a fairly precise model on action and a small fraction of an of the imagined events are negative 04 but then what starts happening is because that negative state is absorbing you get more and more trajectories lining up on this right side where it's like four as an absorbing State and so that is making that uh making the uncertainty strictly rise so around 500 we have this phase transition where the Precision on the agent's estimate drops rapidly it's like yeah I'm not sure what's going to happen after 500 time points because there's some paths that are just super bad and there's some that are super good so when it was one time point I was like pretty sure I was going to get $1 or $2 and I felt great but now that you're asking me to predict 500 time points out I don't know if I'm going to have $100,000 or be $100,000 in debt and that's actually getting me anxious that I don't know the Precision and so again if someone said hey don't worry about the future because the expected value is going to be positive $1,000 that's not $1,000 in my pocket that's a precise ,000 if somebody says the expected value is $1,000 but it has a huge variance it's going to be anxiety producing and so even though the threat perception is inching up from 0.04 to .1 so it still is not more than a 10% uh barely chance of these highly threatening events happening it turns out that um the uncertainty is what drives the veilance not the percentage of negative events and then also interestingly and this could be over reading into one trace of the model but the phase transition and the Precision and uh veilance happen at exactly the same time around 500 right before 500 interestingly the threat perception is going down over overall leading up to 500 and then it starts kicking up again that's sort of like okay I drank all the coffee I'm feeling great it's like oh no I'm starting to get a little tired that coffee is's not going to work that quantitative easing is not going to work and so even though the threat perception actually isn't as high as it has been the Precision being so low leads to the veilance being negative because the veilance is being derived again from the anxiety from the uncertainty not from the expected value this is like a point we can always return to because it's a great example of the complimentarity of traditional reward Centric understandings of reward learning and this more Precision guided understanding of action selection in the niche okay any thoughts on those figures that's sort of the contribution of the paper in many ways is just to make this combination model that features the aect of inference of the agent in their timeline and then at each moment this imagined roll out and um yeah it's a discreet time model and uh yeah any thoughts or questions or there's more stuff we can continue to look through cool so just to put it up there and anyone can raise their hand table one has some of the mathematical details so hopefully with Ryan and any other authors next week we'll be able to talk about these details and uh here is that that gamma which is one over the Precision so sometimes you'll hear about it as Precision maximizing other times you'll hear about it as uncertainty uh minimizing and those two the Min and the max are related by this one over feature just one point so it's kind of like um on network uh networks there's one type of problem called the max flow like you want to have flow through a network internet or water or resources and so you might want to know what the uh cut is that's going to be most damaging or the least damaging to the network so sometimes the most and the least are related by this one over feature um okay any thoughts because there's a lot of formalisms we can continue to walk through and we have a good amount of time but like maybe just pausing here what would be something you would say to somebody who had never heard of active inference and just what is something that it captures that other models haven't captured or something that you'd be excited to see it head in the direction towards Stephen thanks well I think the counterintuitive nature um and the ability for things to be unexpectedly stable and unexpectedly transitioned um is something that I don't know of a way that traditional models of the world would show you you know because you know you could be like oh people would normally either just take one of those moments and then that gets extrapolated for everything but actually you need to follow it over time because it matters a lot it does and it needs to be um kind of through time in two ways the actual agent needs to be progressing through time but at each time point the agent needs to be simulating time points of the past present and future and so that's this like double timeline that's happening with the models topology here is you could have another pink box right next to this one and that would be like the next time point of the agent but it's like right now it's 10:00 a.m. and I'm looking ahead to 10 11 12 and then it's 11 and then I'm thinking ahead again but I'm also looking back and all of that is being spun out of a generative model of a trajectory Stephen yeah that's and I thought it was interesting I haven't seen a positive veilance and a negative veilance I haven't seen sort of two Dynamics mapped alongside each other simultaneously normally there's just the one so I thought that's something that's kind of uh the good and bad as two you know it's not just about good it's about the blending of good and bad I thought that's so I mean theoretically you could have loads of V variants of that you know you could have good the bad the ugly yep yep veilance just like uh an electron or proton you know veence of plus or minus that's plus to minus positive to negative veence but affect is a multi-dimensional landscape and so that is something that could be explored in a higher dimensional way but again let's think about that trading example there's so many ways oh it's an elegant trade it's an ugly trade it was a clumsy one it was a uh uh one with very much foresight or it was a retributive trait all these adjectives but then what does it boil down to given my preferences and my affordances was it a good trade and that if your preferences are hey I have too much money I'm trying to sponsor a couple people who have less crypto than me then a quote good trade given that preference Vector might not look like a preference uh or a policy selected by somebody with a different preference so that is where agent specific preferences come into play is you're never going to get away from that the agent is not doing this neutral calculation followed by a secondary step of policy selection the preferences for policy and for outcomes are entrenched within the kernel of this model at every single time step Stephen and and that gives a plausible basian route to your gut feeling I mean some of those emotions like you're saying the An Elegant trade might be kind of a cognitive process and uh and some other type of part of it might be kicking your deep you know there are certain times when you're thinking about stuff and then suddenly you get a sinking feeling in your stomach you know and it's like well that that um that who knows where that's coming from but this gives a you only get one overall sort of gut feeling you only get one overall sort of um route to actively infer how to take action in the world and all these different things they only become available to you when you maybe reflect on it later and you have to describe what why you had that gut feeling like you just mentioned there could be hundreds of different things all being basly integrated exactly and that's this go noo hey I'm just not feeling good about this this whole vacation or I'm just feeling really great I don't know what's behind the door number four but I'm feeling great about it that veilance aspect of prediction for the future is like the highest level control summary statistic it's like are we going to accept this person into the college or not there's so many other dimensions but it gets distilled into the choke point through the marov blanket of action it gets distilled into go or no go on that specific person or that specific policy or that specific outcome and so that's actually the justification for the use of veilance as a simple positive to negative even though there's so many other dimensions to affect overall it does get distilled into this gut feeling which you can go into and and uh you can cognize you can add adjectives on top but it's sort of interesting it's like is the gut feeling just positive versus negative and when you introspect do you get higher and higher levels of abstracted polysyllabic emotions or do you get deeper and deeper into your body and into increasingly summary statistics like go no go um freeze fight these are things like go and noo let's look through a couple oh Sasha go ahead that's kind of what I was thinking is with this model of veilance would uh a human participant let's say um be able to self-report in the similar way about um their veillance during an experience or is this kind of like the you know hidden by the marov blanket and um we can have these models to help explain what was happening at the time but those States might be unaccessible to uh people actually experiencing this you know decision-making process and um yeah it just reminds me of I guess how people spend money and thinking about economic um economic decisions that uh people make that are you know either logical or not logical and that it really um has little to do with the money that we have and then the mindset that we have about the money and like how we ought to be spending it and um you know who we want to be supporting or not with our uh investment decision and yeah it just really uh I don't know it it's at such a higher level than um just thinking about someone's salary it's how they interact with the economic system and um what role they might play in it and just especially in the holidays like all I can think is we're so deeply influenced by um times and like season and tradition with how we choose to uh how and where we choose to spend money right you send money you literally give money away to people on their birthday on their biorhythm or you know in the holiday season as then also what you just said Sasha reminded me of like course graining estimates and why it's so important if your economic estimate that you're making is will we have enough or not you might be very confident that you'll have enough say I don't know the details but I'm confident that we'll have enough or even I'm confident we're not going to have enough and we're going to have to do XYZ policy okay we can work with that but if you're trying to do a estimate down to the scent you might have a very noisy estimate and then apparently people can get quite anxious about relatively small amounts of money that are way up there in the big salary range is it going to be this number or a slightly higher or a slightly smaller number so there's this jockeying and uncertainty up there at the high level because they're doing a nine fig Precision estimate with a large variance whereas there's something to be said for coar graining and simplifying and functionalizing it and actually not just reducing the cognitive load but increasing the Precision of our estimate even if the state estimate is inferior so there's so much there to continue exploring let's just walk through some more of these formalisms because most of this paper um we can just scroll through it just to you know show you but it's 10 pages long including references and basically they introduce give that figure one that we just looked at give figure two that we just looked at give the table we looked at show the results for figure three and there's the whole paper so it's short very very short so let's go into these two citations underlying the Paper Central and then just find out what they might show us and we're going to be talking about deeply felt affect in April I believe so again sophisticated affective inference is drawing the affect from this left side and the temporal depth from the right side three areas we could imagine this area of research heading towards would be more advanced simulations so agents that are simulating in continuous time or with higher dimensional action policies just like we've seen from actm 8 with scaling active inference or towards the computational Psychiatry angle something that Ryan Smith and others have written review papers about and a lot of empirical work as well so we'll hear more about that next time and then there's this angle of the models for robotics which is like what if the Drone had a top level summary statistic that's just like is this Mission going well or not and if not then that might engage some um policies like head back home or pause or land or get to safety but that's a top level summary statistic that even robots might be able to utilize and I know that some people are doing that kind of stuff so in sophisticated inference and this is to bridge the gap between the formalisms and the actual sentences that are driving us we're going to kind of write it in a little bit of a hybrid script like a Rebus so the big question that agents are trying to answer in the world and in F sophisticated inference is how can we have the best policy over a given time Horizon so not what's the best chess move now it's what's the best chess move over the time Horizon that I'm considering and tied up in that question about evaluating the best policy over a given time Horizon is the question of what are the consequences of policies through time and how do estimate that what is our estimate and what that is related to how we how we Benchmark how we compare policies and their consequences is specifically related to how we understand observations being mapped to Hidden States and our policy which is how our actions are influencing the way that hidden States change between each other that's that b Matrix and the generalized free energy which is this par and friston citation so another citation link away from the iwi paper is that the generalized free energy basically consists of one model that conditions on policies and then asks about how State transitions occur so conditioning on me exercising every day what kind of state transitions can I expect to see in the world and then the second part of the free energy is conditioning on States What policies should be selected so this is the two-stroke engine conditioned on what I know about the world world state and causal model of the world generative model of the world what is my policy selection that's the control theory that's the cybernetic side that's the action side um action looking side and then this first part is again conditioning on my policies in the world what are the state Transitions and how did those change and there's more Nuance because of course we're just describing it in natural language but this is sort of the broad outline one half of free energy conditions on policy the other part um selects policy and basically vice versa with State Transitions and so here's related to this q and P which we saw in Tale of Two densities we talked about it again in integrating internalism and externalism Q conditions on policy that's a vertical line P your estimating o and S through T through time as conditioned on P and then uh p is conditioned on States so again we're conditioning on two different parts and uh that's also uh how we end up using this two-stroke engine to do inference in complex settings we also talked about amortized inference but don't want to go into that here blue this is the slide that uh always makes me think about you with uh where's the information gain and could the pure information gaining agent get reward or does the pure reward Seeker gain information and like where is this play interplay between the intrinsic values or the salience and then the intrinsic value in the novelty so the way that these two and all all these different features and the different representations I mean there's so much to say about and think here but Stephen and then anyone else yeah could you just go back to that the one where you put those two terms between action the generative model and the that one yeah see that's kind of interesting that generative model says State transition policies and policies final States so policiy final States is probably a bit more action and like least energy rout and the other one maybe is a bit more generative model is a bit more processing sensory data it's a bit more cognitive sort of fely cognition if that makes sense I don't know if that if that if that's correct but I is it like you've got like a perception action part to those two in a way one's a bit more perception heavy one's a bit more action heavy or let's return to that in a second blue so I just wanted to comment while we're here about like what you had said in the um in the introduction video um related to like why are we always trying to you know estimate the states when really we should be trying to estimate the best policy right like that's what we should be predicting over not trying to predict the states like with the bring three jackets instead of one jacket and then you'll always be at the right temperature like if if we prepare versus trying to predict the the state of of what's going to be I think that that's a just was a neat thought that occurred to me exactly um when there's too much emphasis on precise estimates of world States it's implicitly like we're focusing so much on precise estimates of world states that we'll just know what to do when we have that precise estimate it's like that's not true it turns out that maybe again a on digigit of precision or even uh to the nearest 10 of the temperature from a policy perspective you'll be fine if it's um 20 Celsius plus or minus 10 you might be fine within a broad range of world State predictions from an action selection policy because your action selection could be cool I'll throw a jacket in my backpack and then I'll be fine whatever it is and so that is this um two-stroke engine this handoff or handshake between co- estimating states and their transitions like weather in the world and the transitions between different weather states in the world given what you know about weather we're not on Mars it's not going to do a you know acid rainstorm at 400 degrees so it's like given what we know about the distributions of the niche the statistical regularities of the niche we want to be co- estimating States and our action action and perception and we want to be doing that in a way that suffices that's adequate to remain within our preferred areas our preferred strange detractors where we're able to basically have reduced uncertainty about the things that we care about the physiological variables that matter like our temperature and okay so it's it's it is very cool and again just for those who haven't seen these kinds of equations that much the vertical line means conditions on and then whatever follows it you can think of is like fixed so it's like you have a spreadsheet and let's just say that the rows are policies and the columns are like State Transitions and so when you fix on one it's like you pick out you fix a column and then you're asking about the distribution of that Vector fixed on that column and similarly you could fix a row select one row condition on one row and then ask about the distribution in that um line going across and so that's the full Matrix and uh also so that's related to what's called marginal likelihood in basian statistics the margin is literally the margin of the page when they used to do it with physical pages so it's like rows by columns and the marginal likelihood is related to the margin of the page which is just so fun it's kind of like a floppy disc icon but for statistics um here's another cool piece of the sophisticated inference paper and I think there's a lot I'd like to learn and ask here to Casper and others but this formulation of policy P Pi selection can people people can see my red thing right Pi is related to the argument minimization of free energy of policy so this is saying the policy that gets selected Pi is going to be like a free energy minimization of G as a function of all the policies that could be done so of my affordances we're going to do a free energy minimization and that's how I'm going to select my policy okay well what is g of Pi G of Pi is related to the expectation of what risk minus ambiguity so high risk is going to be a higher number and that's worse in this case we want it's like golf we want to minimize the free energy and so we're jointly trading off and there's some natural logs and some negative natural logs so it's sometimes a little bit hard to see if you're going like up or downhill which is why it's so important to have it phrased like this but basically risk is bad and ambiguity is bad but it turns out with the natural logs that you can just think of them as being combined so it's like if we seek to maximize um our Precision minimize risk minimize ambiguity what we'll be doing is actually a strict bound on the intrinsic value and the extrinsic value so this formulation of search of Information Gain related to risk and ambiguity turns out to be strictly bounded by this value driven process so worldview related to reward you see that agents are reward Seekers and uncertainty is something that they just simply deal with or they figure out or they Thrive despite in the active inference perspective agents are uncertainty reducers who obtain rewards and if they don't they die that's evolution and so we're putting risk and uncertainty first and so instead of saying like well the agent predicts value and that ends up reducing its uncertainty about the world we're actually saying no it's a way more tractable calculation for the agent to be reducing its uncertainty about action again not just about states of the world but the agent is reducing its uncertainty about action through action it's performing optimal foraging experimentation to in order to reduce its uncertainty about best actions and it turns out that that is going to have a bound it's always going to be converging towards this perfect tradeoff between intrinsic and extrinsic value and special cases fall out of this where certain variables are basically uh fixed to zero so if you have no prior at the beginning and you just um let it start uh kind of draw from your first observations you take those and you use that as your first hyper prior that's like the parametric empirical Baye and in this case you end up recapitulating several things from basian statistics like Optimal basing design or just surprise and then similarly if you set the ambiguity to zero so like the case in active inference 8 where the states were perfectly observable like the pendulum and the mountain car it wasn't like it was getting a noisy estimate of where it was on the mountain it knew exactly where it was on the mountain and in the case of of no ambiguity about States again ambiguity is the the P distribution of observations given States so that's like given that it's daytime am I seeing photons so if you have no ambiguity about that then this term is zero right which makes risk minimization the imperative and that's why when you get no ambiguity you find that this whole framework collapses into risk control whereas if you had risk collapse to zero like it's a no risk situation the only imperative would be reduction of ambiguity so now let's think about that in reward land if you didn't have to seek value it could be purely novelty based search whereas if the only imperative were to obtain short-term value you would not expect that kind of agent to be engaged in a creative search so it's sort of like each of these are um phrasings whether risk minus ambiguity or intrinsic minus extrinsic value you can see how either one of them could be like zeroed out and what that would do for the other side or you could imagine in realistic situations where they're sort of like tied up in a specific way so again you could imagine a no risk scenario a no ambiguity scenario no intrinsic or no extrinsic any of these combinations we'll do Stephen and then Sasha yeah this is really good the way you're putting this together here and explaining it I think also this the obviously these things um sometimes they become really clear when it's an extreme case and then you've got this blending that's going on um you know it's not fully any one of these but I I think that no ambiguity piece is is is is a useful one to think about what happens sometimes when um well you could say I don't know if you'd say Trump but the when when in the politics when something is if people say these people are bad and you know you often see that even at work and it's a no-brainer things are said to be a no-brainer then suddenly everyone the the the intrinsic value of trying to explore other options is can be collapsed in people and they just go with the extrinsic value of gain because there's no there's supposedly no ambiguity and I think that that could be interesting social y yep like we know exactly how dangerous this virus is there's no discussion about what the risk minimizing policy is oh wait a minute is there Sasha okay very leading questions um in hearing this description um just really thinking about using this to Define play um and really seeing play as the combination of factors that has um very low risk but like high uh value of exploration and so setting up um things that have low risk but High opportunities for curiosity that would be I guess for me fit into the category of play so that's that's a good way to think about it and and another fun part there is like when value is the imperative it's difficult to be exploratory and creative it's like maso's hierarchy of needs but then when there can be the space where you can actually engage in a novelty or a curiosity guided search kind of the prerequisite the enabling feature of that is sufficiency at a material Level so that isn't simply related to reward we don't just give people reward kind of dial up their dopamine and then they'll be acting creatively it's actually like we need to scaffold the agent in the environment in a way where it can reduce its risk so that it can tolerate higher ambiguity or reduce ambiguity so that we can engage with higher risk scenarios so sometimes these combinations of features even though risk and ambiguity they're just English words so really it is a about the formalism but it helps us reimagine and repartition and fluidly move across partitionings for how to think about these Nuance control problems Sasha um also it makes me think about how this is calmly studied like in Psychology uh lab spaces and yeah really thinking about like how using this framework to figure out what would make the participants what's state that would put them in um as well as how uh they feel about the risk and ambiguity of the situation that they're in because depending on how you feel about participating in research um that would change what state of exploration or curiosity um you might be in and that I don't know it just really makes me rethink a lot of um research in this field because it's ignoring or I I guess excluding one of the key variables of this process yep and it makes me think about safe spaces but we could also say how risky is this space that's sort of related to safety those are like one over each other you know risk equals one over safety but also how ambiguous is this space we want this space to be safe so not risky but we also want this space to be not ambiguous we want to be clear and communicating about what this space is however we don't want to make it so unambiguous there's no room to play so we want to have the optimal level of ambiguity in Risk that's controlled novelty that's parto optimality that's free energy minimization that's living on the frontier between performance and Innovation so that's where all these models can take us and that's why it reimagines the bottom up versus top down the explore versus exploit the maximization in the long term versus the short term those are all coming from the reward mentality and when we think about the situated agent reducing uncertainty about action through action we have a whole new set of ways to talk about these questions Steph and then blue and bring it back as well with this paper and you know the way it talks about Temple depth and and is it it can also combined with this give a way to think about what they call stages of Readiness because people sort of think oh you know could read this and like okay we' made it safe I've said it's safe I've told everyone it's safe well it might be you've told them it's safe and you've demonstrated it's safe and the environment's been safe but it might be five minutes it might be three weeks of training before people start to bring that safety into the way that they balance these different parameters you know so the way that there and it could be that it crashes quite rapidly positive or negatively um as we saw earlier with the the way that the uh the Dynamics work and that that's quite um that shows that the importance of facilitation and the importance of the way the space is set up the safety between participants and all that sort of stuff cool blue so I know that you said like we're not going to unpack the formalism of the intrinsic value and the extrinsic value or at least you said that on the intro video but um those two things like it makes me think the special cases really like you know they talked about no intrinsic value but what about like no extrinsic value like it just always reminds me of like what about just exploring for you know info gain or um you know just out of curiosity to satisfy that like for intrinsic value I did note that I was like waiting for I was like okay no risk no ambiguity um then no intrinsic it's like the next one and uh I wondered if that actually was related to maximum entropy so it's like given a distribution if you have no preferences for value then you're just sampling your preference is to sample the distribution unadulterated and so that is like Max infog game Max ENT sampling neutrally without preference across a distribution and so that's very related to statistical sampling techniques because those computer algorithms have been designed actually without a preference Vector in mind just to sample distributions like Monte Carlo Markov chain methods and so now we're taking a sampling agent you're sampling temperatures but you don't want just all temperatures for that distribution you want to sample repeatedly from body temperature however there might be another distribution where you do want to have a very very exploratory sampling pattern let's just see if there's any other interesting stuff so here is from sophisticated inference uh another kind of roll out and here we can see observations and then there's different actions that can be taken and each of those actions would lead to different observations and so on and so it gets exponentially large and this is just like early chess algorithms they used to do if this then that if this then that and they would do these roll outs and then they'd prune this Branch oh that doesn't look that good so I'm not going to explore that way and since those sort of tree pruning chess algorithms there's been many developments in chess and other algorithms for this kind of decision-making and so here's the structure of the model and here's that roll out and then one big question is how can we look down the branches that are most informative not just fantasize and dream about the one in a billion branches that's the best not negatively ruminate and get dwelling on the one branch that's the worst but how can we sample information across this branching tree pattern in a way that leads to effective action in the world and then here's another integrative plot that they made which is showing that basically uh there's a few ways to think about active inference what it's doing here it's minim minimizing risk and minimizing ambiguity okay so that's related to the this phrasing on the top minimize risk minimize ambiguity okay make it safe make it clear positive way of saying it the negative way is minimize risk minimize ambiguity so policies States observations states are the hidden part of the world observations you know photons on my retina policies where my eyes move and so the risk framing is you should be minimizing free energy in a way that red reduces risk and ambiguity about this chain that connects policy states and outcomes another branch of active inference is actually sort of like a yin and yang this is like a push pull it's saying minimize the entropy of the distribution of outcomes so achieve predictable outcomes reduce big reduction on there and expand here with the information gain and so instead of hey do something that's like creative but FYI don't be risky and don't be ambiguous here is like be as clear as you can and predictable as you can the outcomes while being as infog gain and creative as you possibly can and so I like this because it's sort of like instead of two things that you want to run away from and then hopefully you become creative in the Gap this is like something to run away from and something to run towards so it rephrases that risk and ambiguity minimization as actually a push pull of a minimization of surprise about observations and a maximization of the Information Gain given the um policies that can be carried out so I kind of like that graphic and then um just in the last couple minutes um Casper and several other authors will be on in early April hopefully before then as well for active 19 and that will be pretty cool but here's where they walk step by step M1 at each time step the agent is inferring how hidden states are related to outcomes then we see that sa AO mapping and now we have this and D is the initial States now we're going to take this single time Point model and use B to ask how States change through time then we're going to take M2 that States changing through time and put it within a bigger model of M3 which is action so policy is influencing how States change their time the B Matrix policy is being selected by what minimization of free energy G how do we calculate minimized free energy including a preference Vector C and then we have a prior over policies this is related to the affordances so now we're not just doing State prediction at a moment but through time M1 and M2 and we're going to be doing policy selection on that right now and then where we got to in sophisticated affective inference was this M4 layer which is State observation mappings through time or at a given moment and Through Time with the A and the B and choosing policy using our C preference vector and G the minimizing of free energy and about that free energy we're going to have a Precision we're going to have a prior on our Precision this is our metacognition and here's where veilance enters the picture which is anxiety bad anxiety comes from high uncertainty so if you have high Precision on free energy you're going to feel better if you have low uncertainty or low certainty about free energy it's going to lead to anxiety not because the expected value of the outcomes is negative so not within that reward first mindset but in the Precision first mindset even a positive expected value where the high variance can be anxiety producing so we kind of uh return to the paper as being the summation of these two citations building before just like so many other papers are building on citations it's always just like tips of icebergs all the way down Markov citation blankets all the way down and we can ask our kind of usual sets questions and people can provide their closing thoughts or questions or what would they like addressed in 11.2 next week just what's something fun that anyone or each of you thought about today and then also to kind of maybe even close on a note about how we can have accessible formalisms for active inference and include people in the discussion who speak math or not who speak English or not so how do we communicate it make make it exciting build those bridges to other areas any closing thoughts on that Stephen lots of really good stuff I mean I suppose there's there's some elements of this where I'd love to find a way I'm trying to find a way to take people into an activity where you know well I suppose some of us do that you know with play or with an exploration different types of exploration activities that maybe illustrate some of these and then they get unpacked after um because it maybe just some of this stuff is in its nature pretty involved but that's still good um so I like the way you've been describing it but maybe there's um yeah maybe there's something then that this now Bridges with something else that's experiential cool anyone else have a thought on that yeah I think that the questions I would like to have the authors or anyone familiar with the formalism help us on would be how how can we um communicate and understand the differences between partitioning risk and ambiguity this way or that way how do we know what to apply in What scenario how does it change how we act how does it change how we model systems how would we infer it in a system how do we disconnect the qualia the experience of surprise uncertainty ambiguity risk veilance how do we disconnect from the qualia so that we can apply it to systems that are um on the other side of our marov blanket systems that are we are not experiencing but are acting in a way uh in an intentional stance way they're acting as if they had these kinds of attributes well um if there's any other thoughts we can definitely hear it but otherwise very excellent discussion wait Stephen do you have another point oh so everyone thanks for the awesome discussion there's a uh feedback form in the calendar invite if you'd like to take a look and fill that out otherwise people who are watching it live and in replay thanks so much means a lot to us and we hope to hear your questions hear your thoughts so that we can address them in 11.2 and thanks so much for a great 2020 we are almost there this is the pen ultimate active Stream So everyone thanks so much and we'll talk later