all right greetings it's March 22nd 2023 we're in cohort three and meeting nine in our second discussion on chapter four of the textbook so last time we went through some sections and we have um also a lot of questions that have been addressed so before we go back to the text or to the questions does anyone who's here want to just like give any thought or reflection yeah what what um what are you still looking to reduce your uncertainty on or whatever yeah I'm just finding a lot of the mathematics um it's just not explained in a way that disambiguates what you know what a particular expression might be um I've got certain uncertainties about um some of the mathematical objects themselves um and then particularly on the section on Taylor series and I feel that I have a pretty good grasp on Taylor series um that's feeling particularly opaque to me which feels surprising um yeah I I'm finding it a slightly frustrating chapter which sort of dives into the maths but in some sense without enough detail for me to really deeply understand it but maybe that's just a matter of time thank you well definitely when building on a sort of meat and potatoes mathematical concept someone with your expertise should not be overly confused it should feel like you have already been on the on-ramp to understanding where this is going because it's hard to imagine it'd be clearer for someone who is less familiar with uh foundational pieces so let's definitely keep that in mind when we move through okay um anyone else want to just like give any overview thought on a section of four or anything else on how there's thinking about any aspect of it since last week then we will look at the questions and then continue to move through the text I'm just looking at the previous video to see where we ended 410. okay any other comments otherwise we're going to go to 410 and continue or a little bit before okay all right let's pull back to four four and just please raise your hand or um write in the chat with any thoughts or questions so just looking at the the questions that were submitted in this uh cohort like many of them involve the equations um for seven eight ten and so on so these are ones where like we can um look at at what was written for those where things were written or otherwise just like kind of um given the constraints on what we can do in 50 minutes just recognize these are like important areas for there to be asynchronous development on but this looks like a great um answer whomever has written this and it's like a an example of um how to address it asynchronously yes Jonathan yes this was my my contribution here um the the explanation underneath um I I still have some some questions about it um despite the fact that I think I Now understand the the sort of the the vector aspect so I I've created a an overleaf document that sort of explains all of this um I'm I'm still slightly confused by something quite simple here in the expected free energy because there are these um Tau um indices floating around and Tau indicates I think the the time the moment in time so for instance s um of P subscript uh Pi tau is the probability of being in a given State um at a particular time given that you're undertaking some policy pie um and so there's a there's a Tau index floating around but it's still not quite clear to me in the calculation of the expected free energy um what you do with that Tower index are you are you summing over all of these terms um are you integrating over them it is an expectation value over all of the different time steps so that that was the the one thing that was sort of least clear to me here foreign yes great point is it expected for energy as an expectation of snapshot free energies is it a expected free energy as the sum of the expected futures or is it even the expectation at that last time step alone and the other ones are discarded good points in figure 4 3 we have the discrete time partially observable Markov decision process pomdp and the continuous time cousin in the discrete time case past present and future time steps hidden states are explicitly predicted and action sequences are explicitly intervening in how hidden States change their time in contrast in the continuous time model rather than predicting or even explicitly mentioning past present and future we see like x x Prime X double Prime so the value of x and then the higher derivatives also known as the generalized coordinates of motion and so this amounts to making a Taylor series expansion which is continuous around the current time step two different ways of dealing with temporal depth and the way that action selection relates to temporal depth and they have some in principle and in practices strengths and weaknesses in different settings in 4.4 they're going to focus on the discrete time model the discrete time model has been especially applied to categorical cognitive decision making whereas the archetypal case for The Continuous time generative model is continuous perception and action of like a motor unit and they can play well together as we'll see in chapter 8 with Hybrid models we could go slower fast on equations but we'll just try to like move through the whole thing but many many of these the work to be done is making sure that we have [Music] um high quality descriptions verbally which we do for for many due to many people's great work but making sure that we have verbal descriptions in the active inference ontology that are faithful to the symbols and then where people have questions about what does this mean why is that that way what if it were this way what are the implications here those are all great questions and they can all be included in the notes section for a given equation or in the more General notes table but for for many of the equations including some of the super challenging ones [Music] um we have things written out which is very good um but just kind of at the um skim level cat is a categorical distribution so in this section we're in a discrete setting so like the light is on or off the continuous setting would be it's a continuous variable between zero and one but in the categorical setting we have categorical distributions and so we have certain um ways of summing across them for example instead of taking an integral over a continuous distribution um action selection ply policy selection is going to be guided by which policies are most likely most self-consistent most self-evident most probable lowest expected free energy we're not proposing a reward or utility function and then evaluating policies based upon their expected reward we're evaluating policies based upon their self-consistency and in fact the most probable ones are the ones that lead to the lowest expected free energy so more equations G is expected for energy and even just looking at which variables go into this we see a probability distribution over policies that is defined through and expected free energy calculation and this G of Pi it's a it's a function of policy and it is going to have this expected free energy Construction and we've seen expected free energy before in equation 2.6 where the part that's an expectation that only involves preferences and observations is pragmatic value so natural log of a distribution expectation of a log of something only involving observations and preferences here we have y tilde here we have o tilde Y is sometimes used for observations more in like a linear regression setting o is like observations but they're identical and then the other component is a and so it's pragmatic value because that is the alignment between the observations and the preferences or expectations the other component in this decomposition of expected free energy is a KL Divergence expected KL Divergence between two variational distributions two distributions that we control Q they're both x hidden States Through Time X tilde conditioned upon and then they're very similar here we only have Pi here we have pi and Y so this is the Divergence with respect to whether adding observations updates are prior if these two cues are the same that's equivalent to saying there's no space between the distributions where we've parameterized x with or without getting any observations in other words the observations were valueless if the Divergence here is zero whereas if the observations are really impactful on moving the distribution then this KL Divergence is going to be big divergences are always non-zero and then there's a negative here so the more information gain the bigger the KL Divergence the more that the observations matter the more this first term is going to go negative and so that specific policy will have a higher epistemic value Ali uh yeah I just remembered a clarification made by Ryan Smith in one of his lectures about uh two concepts of or rather two Notions of time used in active inference literature uh one of which is denoted by Tau and the other one is denoted by T So a Tau is used for the time about which we have a belief and the examples he gives is for instance I believe I am now in my car so that would be S of Tau but I believe I was in my kitchen 10 minutes ago would be S Tau minus one where I believe I will be at work in 20 minutes or something would be S Tau plus one but on the other hand we have t which refers to the time at which a new observation is given so for instance as an example and after turning on a light I now in other words essential believe that I was in the kitchen for the last five minutes right so we can update our belief about all uh all Taos or S of towns with each new observation at each tease or at each given observation times so uh briefly one is the belief time and the other one is the observation time so tau is used for leaf times or the time about which we have leaf and T is used for observation times thanks that's very helpful is it accurate to say that T is like the Click of our simulation that's actually handing the new observations in at a given moment T after T but then especially in sophisticated active inference where we might be considering like the past present and future at every t we are reevaluating Towers at each tee yeah I think we can reframe that in the in this way as well awesome so here we reach yes potentially with some um Bumps and Jumps the expected free energy for a policy in terms of the pragmatic value alignment of preferences with observations and the expected Information Gain the epistemic value in terms of how much adding in observations updates are variational distribution about hidden States conditioned upon that policy here is more Focus on how we get this KL Divergence so here we see that KL Divergence and there's just a few different expansions and relationships around it Jonathan yeah so just zoom zooming into that equation there um there's an expectation um over Q of O given pi um and I I couldn't figure out how that's calculated because I I understand how one can get um Q of s given o and Pi but it seems that to calculate Q of O given Pi one needs to marginalize or sum over the states and I thought that that was the whole reason for introducing Q in the first place was because we we can't um we can't same overall all external States the subscript notation may be used in an unconventional way but I I agree with you on that here in the inner queue we have it about s conditioned upon observations and policies this doesn't seem contentious yep that's fine yeah but the subscript in 4.8 and I think that was probably one of your questions yeah yeah that's the one sorry with the terrible latent yeah yeah yeah um yeah we should look at the the Matlab code for wherever that comes into play to see how it actually is done or is a separable variational quality yeah like this is the just the inner value is the KL Divergence of how much observations update um uh add in to your changing beliefs about s but we're taking an expectation of that over expected observation sequences which then begs the question of needing to know the distribution of s that would generate those probabilistic envelopes of o exactly yeah well one answer is these are the analytical um ideals for which there are strong analytical guarantees and then any given computational implementation is going to use different methods to to implement this just procedurally but that doesn't make the notation clear and I I think these are some of the kinds of artifacts hopefully cohort after cohort we can craft like a lookup table and we've done this to a limited extent just starting it but having a lookup tables for all the different [Music] um shapes and squiggles But continuing on site I hope that we can at least see the rest of it um variational free energy F and expected free energy G variational free energy which we'll recall from equation two to five is a functional of Q the distribution we control and Y the incoming data so variational free energy is like the real time unfolding model fit and this is a quantity that's widely used in statistics expected free energy uses similar structure and positioning but it explicitly brings in two pieces that aren't present in variational free energy and those are observations which haven't happened yet because we need to talk about how informative we expect observations that haven't occurred yet to be Information Gain epistemic value obviously variational free energy is only concerned with the actual data point being acquired at the moment and then secondly the fact that we can take different policy choices and policy choices end up conditioning for example what pragmatic and epistemic value we achieve or expect to achieve so free energy can have a variational free energy formulation real time unfolding model adequacy or projecting free energy into the expected future we need to invoke observations that haven't happened yet and our agency in selecting alternative policies which then of course bear on the epistemic and pragmatic value we accomplish here in 4 9 there are more decompositions of expected free energy that help see previously recognized dialectics or decompositions or trade-offs as actually decompositions of the unified imperative expected free energy so epistemic and pragmatic value decomposition and an ambiguity plus risk no one can kind of walk through and see what those mean or look at the natural language we can rewrite 4 7 in linear algebraic form here's four seven here is for the categorical distribution we can sum over policies about the policies and the hidden States Through Time um more details and calculations of variational free energy factorization and the mean field approximate mean field approximation these are some mathematical technicalities but but um they are simplifying assumptions or ways to approach this in the general case this factorization is one of many possibilities in variational inference and as we talked about last time variational inference is just one way to do these calculations and represents the simplest option and in practice it's nuanced slightly and there's like other approximations and it's a whole thing more information on the letters that we know and love a the tale of two densities B how hidden States change Through Time C prior beliefs about observations which are preferences and the simple prior on the initial state to kick the hidden State chain off a little bit of policy and belief updating few more technical details into active inference in continuous time Box 41 on Markov blankets a markout blanket for a given variable with just those words the map territory question is addressed Markov blankets are about variables comprises a subset of those that interact with it if we know everything about the subset knowledge of anything outside the subset does not increase our knowledge of the variable of interest there are several Bayesian message passing schemes expounded on a lot further in other work with fristin parts of rise at all probably not the most relevant to delve into right now but the important takeaway is that by using a base graph so by making a commitment to the figure 4.3 Lego set if we choose to have nodes be random variables and edges reflect relationships amongst variables in a certain way then we gain access to message passing techniques that make even large Bayesian graphs with different parts of the graph updating at different speeds and so on there are software packages that are able to in a defined computational complexity setting run inference on those base graphs so yes bigger models all things being equal take more time and more computational resources to run however there are some tremendously scalable high performance ways to computationally implement computation on these graphs and they have interesting analytical representations and they have a growing stat of tool kits like reactive messagepassing dot JL by the bias lab with Bert DeVries and um his lab this is like really cool current work that's not even outside of their lab and colleagues not heavily used in even active inference Publications but they have incredible recent work and you can see how they're using variational free energy in these um advanced settings pulling back to consider message passing qualitatively in the chapter whereas it was introduced in this Markov blanket box um message passing they'll be totally looking oh thank you I will yeah uh there's the bioslab site and I'll add it to the figure four the reactive message passing is like one of their new pieces where um let's say you had two sensors and one of them was being updated every second and one was being updated every hour well if you only could turn the clock if you you might get into a situation where you would either say well should I update my model every second and then over sample the slow variable or should I sample my model every hour and under sample the fast variable and reactive message passing navigates that by actually having nodes update on demand so you can have one node that's just getting pinged every second and another node that's getting updated on a different time scale and the computations on demand so that allows you to have like lifelong online learning for base graphs flexibly with different rates of sensors and and so those are the kinds of toolkits like like um these models are not just being proposed to promote theoretical unity in the cybernetic Sciences also there are powerful software toolkits that using these kinds of architectures enable so epistemic value pragmatic value um message passing schemes um if anyone knows any takeaways from this image please feel free because certain things are like omitted and also it uses like a lot of squiggles and ease and different variables um but here we have a representation of a hierarchical model so you can tell it's a hierarchical model because you have like I and you have this kind of cluster of four and you have I plus one and you have errors getting passed up and hidden State inferences getting passed down and so this would be like the sort of Timeless representation of that modeling hierarchy hierarchical base hierarchical predictive processing architecture um tilde through time so we're just describing timelessly here is the hierarchical Bayesian model this can be rendered or unpacked through time now we see that Tau minus one Tau Tau plus one as a function of time so instead of just seeing it as like o tilde like a sequence and seeing this as like a skyscraper this can be unrolled in a procedural way using message passing techniques um okay are the rules for message passing on a convoluted Bayesian Network known yes this paper that I have just put in the chat here we see figure 4.3 discrete time again and again and here is a alternative representation of this base graph with what is known as a Forney Factor graph and so in this paper they show that [Music] um any base graph can be represented as a Forney Factor graph and any phony Factor graph has a defined procedural message passing algorithm so actually a quite incredible synthesis even in this 2017 paper because it means if you if you can build with these Legos with this semantically interpretable setting then there will always be a procedural technique to calculate it no matter how convoluted this graph is which is very important because you could make um um you could just add linear model layers but then you would start to lose analytical guarantees very quickly here now we're in the continuous time so section 4.5 is a lot like 4.4 except it focuses more on the continuous time model just to only describe more on 4 15. here we have our observations Through Time and that's a function G little G not expected free energy it's an observation its observations are being emitted by a function of hidden States and slowly varying causes V which kind of plays the role of policy in continuous time and a noise term so this is our sense of reading here's EEG measurements SPM measurements as a function of neural activity and sensor noise and then the rate of change of neural activity is a function of neural activity at that time and slowly varying causes so the mapping between uh data and hidden states which is kind of analogous to the a matrix is timeless and then the rate of change of the Hidden States x dot which is like X Prime is defined in a certain way and this is like familiar structurally to those who have looked at physics generalized coordinates of motion related to the Taylor series approximation so the the black line is the function true underlying function here's our first pass approximation at this time evaluate the function and then just that's you know y equals 4 is this line then we have the second term approximation which is the value for I'm just making that up and then the slope instantaneously the third order approximation is going to have three coordinates of motion the position the velocity slope and the acceleration and then if you were to have another term taking it into another level of exponentiation you would end up like kind of probably coming back out so that's how smooth approximation of functions Works using the Taylor series by evaluating higher derivatives around the point of focus what is the difference between the dot and the dash yeah the X so in in principle nothing in principle they both mean rate of change here x dot and dash are being used because x dot is the change function on hidden States neural activity changing through time is x dot so here is our estimate of neural activity changing Through Time here's the rate of change of neural activity changing Through Time x dot Prime but that is not necessarily X double dot I hope that that's accurate Jonathan yes I think one of the things that confused me most here is that he we've got an F Prime of X Prime V Prime um so certainly in figure 4.5 the prime really does represent a derivative with respect to Tau and then within the equation here it's just not quite clear you know what what one is taking derivatives with respect to and how many times like f double Prime of X double Prime V double Prime it's just one it's one does not need these two um well that that's what I'm so to calculate the Taylor series here you would want to include derivatives but it's derivatives with respect to the variables inside like with respect to X yeah yeah yeah and you have to be confused by this no that that totally makes sense I um I agree anywhere where there's a derivative or an integral there should be clarification of what it's with respect to and that's sometimes done but here Prime is being used just to refer to the generalized coordinate of motion at that scale okay then writing down the variational free energy with generalized coordinates LaPlace approximation this is something where there's a lot of technical detail but what the LaPlace approximation does broadly also please correct me is finds the single maximum likelihood estimate for a distribution and then parameterizes a negative quadratic with the points being at the maximum likelihood estimate so for distributions with a central tendency LaPlace approximation can do really well for distributions that are bimodal like with two humps LaPlace approximation is going to identify the slightly taller hump in its maximum a posteriori estimator and then either draw a pathologically narrow or wide quadratic around the taller hump Ollie oh okay and more details on that quadratic expansion around the posterior mode mode most likely point of a distribution quadratic expansion drawing an upside down parabola around that point expanding some of those discussions from the above into hierarchical models re-viewing the message passing that we saw previously skyscraper on the left unrolled Through Time on the right in the context of generalized predictive coding schemes and a short summary so definitely an interesting chapter the mathematical details Beyond way back when basically Beyond this point really escalate fast and there's also several boxes and asides like this message passing generalized coordinates motion and LaPlace approximation all of which are significant technical Concepts so a lot of challenges and trade-offs with writing such a chapter especially because this is like active inference chapter one overview chapter two low road this is how we're gonna do it chapter three High Road this is why we're gonna do it chapter four generative models of active inference figure 4.3 discrete and continuous time generative models and then there's a lot of technical details so anyone have any just overall thoughts or questions on for Jonathan and then anyone else yeah I think I'd just to get more of a sense of it I'd still be interested to know more about the the Tau in G um if anyone has any insight into that when you calculate G um yeah does g still have a Tau index or or is something else happening to it yes good good that is noted if anyone has a link or a thought go for it otherwise that is definitely something that we will need to revisit and improve for for future cohorts Kate um they're just a very general comment like this was way over my head overall but I was just wondering if in your experience um the the textbook that you are kind of working through with um mispronounced his name name Joshi but the fundamentals of active inference do you think there will be some help in any of these areas Ollie what's your what's your first thought on that this is in reference to sanjiv namjoshi's fundamentals textbook that we are um like working through and evaluating during 2023. so Ali what would you say to Kate's question uh yeah in my opinion I think it is way way more helpful in understanding the mathematical details and uh also in fact uh the conceptual intricacies uh that have been somehow uh glossed over in this textbook uh but uh on the other hand it is estimated to be about 600 to 900 pages long so uh yeah it is much more expanded than this textbook and it goes into uh into a very very helpful uh detail um expanding upon these um mathematical derivations but at one point I wanted to make is that sanjeev's textbook is not strictly strictly geared towards uh somehow somewhat mathematical derivation of these equations but its main objective is to use it as a practical tool in order to model these kinds of agents and in fact he also provides some helpful Jupiter notebooks in that regard but yes I think it can be really helpful in Bridging the Gap between this textbook and the Practical side of doing things yeah thanks ali um if anybody so the book is not available yet it's not even finished in writing if anybody wants to be added to view chapters and the code which are all in Python which also increases the accessibility relative to the Matlab of this part hole these chapters in a way that has not appeared in our space before are tackling the these statistical questions so it is still like very much an accelerated statistical learning curve but as Ali mentioned it's less focused on like well here's how you get from here to here as just like a as a analytical derivation consideration and it's a lot more like we're going to go step by step with building stochastic simulations and um so this is gonna it's gonna be a great compliment and and Fields have many textbooks so there's not just one right approach um but it's been really encouraging to see his work so if anybody wants like even just access to the coda to review the chapters um please feel free to email us and hopefully in the coming year we'll have more details on when it'll be available um let us look ahead quickly to chapter five chapter five is the last chapter in the first half of the textbook which is the epistemic half of the textbook so congratulations to those who have continued on especially through that second half of chapter four which is definitely like intense to a comical degree um and so carefree and Whimsical in its writing style which which um has its own kind of Comedy but we're gonna have two weeks on chapter five which is going to be a great return to reality and then um the final meeting will be on feedback project ideas Terry I think we need to approach to the maths pitched at a seven-year-old yeah many angles on that one is in the math learning group we've explored these kinds of questions and another approach is a non-mathematics approach which several people have investigated how important will it be if we didn't grasp all the details of chapter four when we get to chapter five irrelevant chapter 5 picks up on a very different note remember that chapter four they even said you could skip said if you don't want to know the technical details you can skip chapter four which was again like it was like wait but we just took the low road and the high road to our city and then they're like you don't have to go on the tour if you don't want to chapter 5 message passing and neurobiology um Bayesian message passing comes back so again that box that we looked at earlier the idea that every base graph is sparse not everything depends on everything because of the sparsity of the Bayes graph especially there are some computational procedures that are extremely effective and interestingly real biological systems also have sparse connectivity whether it's the neural architecture in the brain or whether it's the interaction patterns in an ant colony in distributed systems connections are sparse they begin at the microanatomical level with looking at neurons and their connections they focus on one of the most well-studied neural tissues which is the mammalian cortex and the mammalian cortex has what's called a columnar architecture which is these six histologically distinct layers of tissue so they look different under a microscope and the connectivity patterns in terms of what actually sends axons where are also essentially completely characterized and so in here we see the tantalizingly realist alignment of the histological columnar microarchitecture with Bayesian graphs that have similar structure in figure 5.2 they're going to generalize and kind of coarse grain the columnar architecture and now look at how different columns communicate laterally so we have like hierarchical communication within a columnar unit and connections across units this is kind of like um numanta thousand brain hypothesis like a lot of work that is using the neocortical architecture in search of intelligent machines so that's the neocortex scenario we're going to switch systems to the mammalian motor chord here we have incoming proprioceptive data y and descending predictions those predictions and observations are juxtaposed to form an error signal which gets passed forward so this is a continuous time setting and here we can see action as resolving discrepancies between Target set points and proprioceptive input now we switch to another mammalian neural anatomical system which is subcortical and the basal ganglia in particular which is a dopaminergic region this region plays a role in policy selection check out the Oliver Sacks book or Robin Williams movie Awakenings it's really interesting and funny here we see two different ways that the dopaminergic tone tilts the balance towards either action selection which passes habits forward or that kind of type 1 indirect policy selection pathway can tip towards a type 2 in economon sense deliberative free energy updated policy posterior but we'll talk more about it they talk about different neurotransmitters inactive they talk about how continuous and discrete models can come together and then they end the chapter with bringing together those three systems that were previously described the columnar architecture in the neocortex the basal ganglia dopaminergic decision-making architectures and the spinal cord reflex proprioceptive continuous time model and they show how those kinds of models can be integrated to address some of our favorite topics so it's a shorter chapter it doesn't have equations like the previous ones do so again congratulations to everybody who made it through the more think of it chapter four and chapter five we're going to have a lot of space for conversations about like neurophysiology and the body and it's just a good close to the first half of the textbook so thank you all for joining see you next week