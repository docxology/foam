hello and welcome this is active inference guest stream number 86.1 biological neurons compete with deep reinforcement learning in Sample efficiency in a simulated game world with Faro Habib and mo kaj NAD and thank you both for joining really looking forward to the presentation and take it from here thank you very much yeah thanks Danielle um I guess I'll just uh open up hello everyone thanks for joining I hope this will be interesting and fun for everyone uh so today uh we are going to talk about uh a collaboration between cortical Labs here in Melbourne and mes University uh we will mostly emphasize on the details of the project as titled biological neurons compete with deep reinforcement learning in Sample efficiency in a simulated game world but before going into details of the findings that we had in this study I'm just going to uh talk briefly to uh our setup our system of invitro neuronal cultures that we are interacting with and we are embedding them in simulated game environments to be able to do all these cool tests and uh well which has led us to these findings so to start with um I'm going to just tell you what were our motivations in cortical labs and what led us to where we are here today uh without getting too philosophical though uh we can say that we as humans need they froze I'll just wait their own uh shortfalls if you would say for example yeah oh yeah sure okay so uh reshare so it's stopped sharing oh no no that's okay um so stop share yeah uh so yeah without getting too philosophical here uh we can say that us as humans we need intelligence in some form to be able to disal me meaning from the phenomena around us but to be able to make more Intelligent Decisions by Computing more data faster and with better outcomes has actually become one of the major goals and the holy grounds of machine learning and AI in the past decades uh now in search for different ways of uh intelligent Computing uh one way for us to C categorize all of our recent efforts could be to talk about these categories like machine learning and AI Quantum Computing or neuromorphic chips obviously there are other ways of looking at these and uh other tools that we've developed uh and they are all the right tools for the right purposes but uh they could all also have their own pros and cons and what motivated us for to look for new alternative ways of computing was that for example in machine learning and AI we are facing challenges such such as their high computational power uh high power use their uh catastrophic forgetfulness or the fact that they require very large samples and very long training times and they are also uh very susceptible to errors or if you're talking about comput Quantum Computing uh again we have extremely high power usage uh these are very isolated from the external world and uh very prone to errors and they are not very adaptable uh and also if you're looking at the neuromorphic Computing uh and the whole You Know Field around it there's also uh limited error correction capabilities uh variability between circuits and also they still require some sort of programming to some capacity to be able to do what we are designing them to do so basically in search for this alternative intelligent Computing system uh that could actually solve some of these challenges that we have in these other categories we thought that why not use the brain and the brain cells themselves which are the most advanced intelligent uh systems that we know of and uh there's actually no need to prove that these brain cells are capable of doing very high order of computation uh so I'm not going to go into tooo many details of our setup because I think many of you might have heard or read about it but just to recap firstly what we do in cortical Labs uh to basically design and develop our system is that we use human ipsc cells which are then differentiated to a neuronal phenotype for the studies that we're going to talk to you about today we also had primary cortical neuronal cell cultures from mice and all of these cell cultures were then plated onto Maxim one high density multi- electroid Aras which basically enables us to stimulate the neurons and also record from them at the same time from the same cultures and uh well we see that we saw and we showed that these cultures could actually survive for even more than six months on these multi- elector arrays uh with our new products new systems in this brain we can go even Way Beyond six months and keep them healthy keep them alive keep them active which gives us capability of studying them for longer terms and for example here is just a sample microscopy Imaging but you can see the dense interconnected population uh of uh these neurons that have been cultured and are active on the m electrod so then we designed what we called initially dish brain which is this Clos Loop real time system to interact with these neuronal cultures and embed them in the environments of the arcade game of pong which you can see here on the right hand side uh this is a famous arcade game you have one padal and basically the paddle is playing against the wall trying to hit the ball accurately uh and uh the first published work that we uh explained the system and we showed you know basically uh all our findings of the system uh uh you I think you've seen it and you've talked about it before but but it um basically explores the system in extensive detail which I will not bore you with here with all of those details but because it's important to know what's this closed loop system that we're dealing with I'm just going to briefly talk to talk you through how uh it works and how it's designed basically on each culture which is integrated onto a multi exor array we first predefined separate regions one uh sensory region on top and two model regions on the bottom of this uh cartoon image that you can see on the left hand side and the right hand side first using the sensory region we feed information about this hypothetical balls X and Y AIS location so imagine that game environment you have the ball moving you want to know where it is in that frame so the x-axis location is actually uh encoded by rate coding between 4 and 40 htz depending on how close the ball is to the paddel on the x- axis and also we use Place coding uh where uh where we encode where the ball is on the y axis by only simulating one of the eight available sensory electrodes within the sensory region and these eight electrodes are actually evenly distributed along the y axis so whichever part or segment the ball falls into that sensory electrode is activated then we record from these two again predefined motor regions and compare their activities of the all the channels in those regions which are some of them are representative of the up movement as you can see the arrows on this uh figure and some of them are responsible for downward movement of the paddle uh and then obviously comparing the activities of these two uh sub regions we decide where the culture is moving the paddle in what direction and then we need to close the loop by applying feedback to the same sensory region as we defined again this is another schematic maybe it to make things a bit more clear uh but basically to explain our feedback loop what happens is that if the ball is missed by the paddle random unpredictable signal is applied for like 4 seconds at random sites in the sensory region and then if the ball is hit accurately a predictable repeated stimulation for a shorter amount of time is applied to all of the sensory electrodes so we then again uh record from these cells on top of the silicone chips both during the rest State spontaneous activity for comparison reasons and during their embodiment in the gameplay environment and I'm just going to briefly touch upon something you might all have been thinking of now that I have explained our feedback loop here that um after designing the system and finding actually evidence that this particular type of feedback loop is actually enabling the neurons to be learning the game or to be performing the game better as uh we go on in time uh you could think of this clearly as some evidence supporting um free energy pre that we've been talking about for a long time now uh the fact that uh these neurons don't like surprised don't like the unpredictable sensory feedback that they receive when they miss the ball is what seems to be driving them towards playing the game better and towards performing better in the game so this was really cool evidence that we found that could be actually explained by fvp as we all know about uh we could definitely talk more in detail about this but uh I'm just going to uh just going to go to our basically most newest findings this is again a quick uh illustration of the actual gameplay environment on one of our meas this is obviously the simulated environment you can see the game play uh in the corner top rights and how the all the channels that we have on the mea have these activities that we recording from and then we are comparing the two sides of the motor region to actually decide uh what the culture is doing in this gameplay environment uh yeah and then we evaluated their performance and whether these are learning using several metrics this is a very very short summary uh of how the my cells and human cell cultures which we call MCC and HCC compared to our media only controls to our in silicone models and to our neurons at rest and they all show that they perform much better with more significant improvements in several metrics including their average rally lengths the percentage of Aces or Ace here is actually a bad thing so Ace means a ball is missed after the initial serve so the lower the number of Aces gets the better they're performing and also they showed a significant Improvement in the percentage of long rallies which we defined as rallies that have more than three accurate hits again we've got uh you know much more nuanced you know results and details that we have figured out from these systems but here you can see the comparison between the first five minutes in green and the second 15 minutes of each gameplay session in Orange and you can see that's basically the only significant Improvement occurred in our human and mice cortical cells uh now in our obviously never ending search for the underlying mechanisms that could drive this Behavior Uh in one of our more recent projects uh we first wanted to compare the gameplay and rest sessions in terms of their connectivity so the connectivity between the different channels that we are recording from and how actually these connectivities are changing over time and whether the evolution in these connectivities can capture uh parts of this learning or this basically the plasticity we assume that is happening uh during game play and mo is going to take on from here talk about all fundings from this functional connectivity study and then we're going to spend most of the time on the comparison with the reinforcement learning methods that we did in terms of their sample efficiency okay great um hi everyone again uh now to do uh this task that F mentioned uh first we the challenge was that for U every recording and for each Channel we have a very very large time series of spiking activity so to make these sparse U sparing patterns more interactable and easier to work with um first we decide to we decided to use a dimensional the reduction algorithm to bring each channel Time series uh to a lower dimensional space we used and compared uh different um algorithms including tisne and ISO map that you see here and as we can observe interestingly uh even in in a very low dimensional space such as uh a 2d space here um the the first and second half of the uh of each recordings were easily distinguished during game play but uh not uh clearly in the rest these figures are for uh sample cultures and the two colors represent um all the channels in each half of the recording so we were motivated to continue this study in in this lower Dimension uh dimension for higher interpretability and lower computational power use but then also having 1,24 uh rep recorded channels still meant High computational complexity in our problem so we have this hypothesis that most probably a lot of these channels are highly correlated and uh we might be facing redundancy of information when looking at all the availab channels in the recording so for that reason we designed this pipeline uh to eventually study the functional connectivity of channels and um compare between gameplay and rest very briefly we first use uh tne algorithm to map all channels according to the lower Dimensions which is selected to be Tre here uh then to select a uh smaller set of channels uh which are good Representatives among all the recordings we stacked up the low dimensional representations of U all game play sessions and using a Tucker decomposition uh followed by a kid um clustering algorithm we chose the centroid of the channel uh clusters in this low dimensional space as uh the mutual representative channels we tried different uh numbers of clusters and got the best results uh by choosing 30 clusters and higher numbers of clusters show no significant Improvement uh in the results uh finally we built the uh functional connectivity networks uh using these 30 channels as notes and the pearon correlation of their spiking activities as the weight of the um ages between each pair of channels but we were also interested in track tracking the connectivity Dynamics and changes in time as learning occurred in the culture so what we looked at here was the changes in uh correlation between purs of notes from the first two minutes to the last two minutes of the recordings uh [Music] and what we see here um on on on the left um and right are uh the average networks from all of our recordings which is around 300 Gameplay sessions and about 150 res sessions first of all uh the extracted representative channels which come from the sensor regions are um in uh green circles and the ones from motor regions are are in blue squares now the color of the edges indicates an increasing or decreasing correlation between nodes in red and black respectively and the ede thicknesses are related to to the magnitude of these differences simply by uh visualizing the data uh uh we saw significant differences between rest and gam playay where we observe uh many more positive edges or increase in correlation between channels um and finally to give you some more statistics of what we found um happens as the network of channels evolves in time um here we can see the same five measures of network Dynamics um compared between the first and last two minutes um in in pink uh and green and also game play on top um versus uh rest rest station yeah the game plays are in pink and and the rest are in uh uh green first uh we have the average weight of the functional connectivity networks uh which shows a significant increase during game play but not at rest next the modularity index uh that decreases significantly but only at game playay uh that basically means that the different clusters or modules uh of the network become more interconnected during the game play as time goes on the clustering coefficient also shows a significant increase only in game playay meaning that uh the neighbors of a given node uh become have become more strongly connected between themselves and finally um characteristic path lens or the average shortest path between any pair of nodes in the network decreases significantly after 18 minutes or game play recording now that we have found even more evidence of the Dynamics of these networks which could potentially give rise to emergent learning that is observed in their behavior in the in another study and next study we were also interested to do a direct comparison between uh the Deep reinforcement learning algorithms and our noral cultures in the same g game environment of P but clearly um only during the game play we all know that uh RL algorithms that use deep neural networks uh in their structured have been developed to beat human experts in various games such as Atari games and have proven to be very strong players of these games given uh they have enough training but these algorithms uh suffer from different issues uh such as modeling the reward um structure sample inefficiency reproducibility as well as requiring high levels of uh computing power and these issues um suggest that deep RL algor GMS might actually differ fundamentally from Human learning mechanisms and not be efficient to be a plausible model for human learning that's why we were motivated and interested to do this research and comparison um in our work we used three deep RL algorithms dqn um a2c and po which are established to have good performance in Atari games and our robust Tools in re enforcement tasks particularly in games where the input is an image but apart from uh the traditional gray scale image input of the game environment we also take a step further aiming to account for potential adversaries resulting from The increased dimensionality of the image input to the de parl algorithms or so-called Cur of dimensionality in U machine learning terminology we designed two additional types of input information first paddle and ball position design where we obtain a four dimensional uh Vector encoding the X and Y coordinates of the ball and also the Y coordinates of the paddles top and bottom and also the ball position design where uh we divide the uh y AIS of the gam playay environment to eight equal statments each mimicking one of the sensory electrodes in the biological cultures that place code the information about the ball's y AIS uh then the ball's uh xais position is used as the second element of uh this input Vector uh similar to the rate coded component of the stimulation applied to the B ological cultures uh that we had uh this design is the most uh similar one to the cultures with the lowest dimension of the input vectors um also we found that using the same number of training game episodes for uh biological neural networks and deep reinforcement learning algorithms in the image input design the average rale lens is highest for the human and mice cell cultures uh here in uh orange and blue uh while uh they also achieve the lowest percentage of Aces uh and highest percentage of long rallies may I just add here that uh maybe it's if it's not been clear uh we are training all of these for the same number of episodes that the biological neuronal networks had to be trained on which was on average 70 game episodes in 20 minutes so just to make things as Fair as possible we train these RL algorithms also only for 70 episodes and that's why we're talking about sample efficiency here because we're going to show you and we know that training them for uh very longer time would result different obviously performances in these deire algorithms yeah thank thank then comparing the uh first five minutes to the last 15 minutes of the game um here in the third row um in green and orange we see that only the biological cultures show significant Improvement in these metrics next we repeated all the analysis for the paddle and bulb position input design which revealed the fact uh that or algorithms performances were not suffering uh from the Cur of dimensionality and all the previous conclusions still hold and finally very similar comparisons were observed when using the last input design which was the most similar to the biological cultures uh input information structure once again uh the RL algorithms are outperformed or rarely match the biological cultures performance at their best and lastly we directly compareed the relative Improvement in the average lens of different groups over time um and these plots show that um in all the Tre designs um human cell cultures uh show the highest Improvement uh usually followed by the mousee C cultures we also compared the relative Improvement in the average uh it counts or average rallies between the first 5 minutes and the last 15 minutes for all the sessions as well as the postto test in each separate group for different batch sizes and different hyperparameters as we can see in the first two rows and additionally as BR mentioned we'll look at the mean total reward of the RL algorithms with only the image input design using the same um hyper parameters uh for an extended training period of uh 11,000 uh game episodes in the last uh and or third row here and it showed um improved performance across an um Extended number of training episodes this is well as it anticipated 70 game episodes or 20 minutes of recording uh which is the same number used to train the biological cultures but not sufficient for um any of the algorithms so we could eventually conclude that the RL algorithms uh showed the lowest sample efficiency having the lowest improvements in learning given the same number of training episodes provided for all the groups and this was even the despite the fact uh that these methods receive a higher information density compared to cultures finally we also explored a biologically inspired algorithm implementing an active inference agent that uses counterfactual learning um improved learning rates observed in this biologically inspired learning protocol supports the potential of active inference agents to provide valuable insights into optimized learning strategies so um and and they can enhance our understanding of these Dynamics however these active inference algorithms are um still highly dependent on on the chosen hyper parameters and um require relatively higher power consumption compared to biological systems however these results highlight the value of uh further exploring biologically inspired systems of learning and support the notion that uh synthetic biological intelligence systems may offer a useful Pathway to do this um in in the future so yeah I think I stop here and uh let us thank all of our internal and external uh collaborators both in Monash University and cortical labs and and in um other institutes thank you yeah can C thank you awesome okay many places to jump in well thank you for sharing the results maybe just while we're on this slide uh with the active inference H how was this agent constructed and and how or was it the case that the neurons consider counterfactuals or how how did the counterfactual come into play want to uh so here maybe this is actually a bit bad uh naming with you so C here is actually our contrafactual learning agent and the number you can see in front of it is its uh horizon horizon horizon uh which is one of the parameters we've adjusted then uh for our uh search space uh we have tried to mimic as much as we could um I should mention also here that ashin ashin Paul was uh the person who has helped us with this analysis worth mentioning again so for the search space we try to mimic what we have in the biological cultures so so the x axis which location of the ball which we encode using the frequency values between four and 40 Hertz in our dish brain uh we're mapped into basically a space of 37 that would be 37 different values along x-axis and our y- axis eight different uh values which could be uh given as inputs uh so this would be our uh search space or environment uh and uh yeah so the we explore different values of the hor memory Horizon we could obviously go even further but we were trying to find a model that kind of matches the biological cultures the best because as as you all know uh we are thinking of active inference as a plausible and possible uh you know model of what is actually happening in our brain uh so we wanted to see if we can actually uh reconstruct uh a model that is very close to the performance of these cultures so the Horizon memory of seven uh basically having the seven frames prior to the current step was what gave us the closest results yeah I think yeah uh just to add I think a recent active inference scheme is shown to be mathematically equivalent to a part particular class of neural networks accompanied by some uh neurom modulations of synaptic plasticity and um it uses counterfactual learning to accumulate a measure of risk over time based on feedback from the environment and a subsequent work that validates this scheme experimentally using invitro noral network has also appeared recently in um Isam ra at Al paper uh in 2022 yeah uh so yeah just to I think more clearly answer your question this was just a uh contrafactual learning uh model on its own it is not uh we are not using the neurons or the input from neurons in the model this is just a model Standalone model on its own trying to mimic the performance of the invitro cultures cool like really interesting how the same kind of functional play or differing might arise from systems that are explicitly comparing Alternatives and systems that at least are appearing to simulate counterfactuals yet somehow the instantaneous firing rate and the response comes to act as if there is a counterfactual in the sense that the gradient is being compared and the gradient is more often than not going in the direction that is leading to less surprising sensory outcomes yeah exactly yeah okay I'll ask a question from live chat um Jeff asks is there a noise or density limit to The Matrix culture interconnect uh so by matrix culture I am assuming they mean the multi- elector array yeah that's very yeah uh so for the results that we have uh talked about today and most of our Publications up to date we're using a Max one high density multi and maybe we didn't State this clearly we have 1,24 channels that we are using for our design uh there are thousands more channels but uh we are only interacting with 1,24 of them so maybe our limit we could say was 10,24 channels but we are designing new systems now that are actually less dense so we are using a 64 channels in our own chips designed at home at cortical Labs uh this will yes uh limit Us in the sense that we don't have as many channels to be working with but also we are hoping to be able to get more interpretable uh results and uh let's see interact more efficiently with the cultures with the 64 8 by8 Matrix yeah oh noise yeah they also asked about noise uh yes obviously uh we are facing noise in any system any experiment that we're doing we do have the human IND IND noise we do have uh noise when obviously recording from these channels but we have have taken uh as many measures as we could in order to clean uh the recorded uh signals first obviously we do filtering we do Spike sorting uh we have tried to do template matching with the waveforms with the spike waveforms that we extract in order to make sure we are not picking up any false positives uh and uh then after all these steps done we are facing these rather sparse spiking time series for each of the recorded channels cool um another question how would you characterize why catastrophic forgetting catastrophic forgetting happens in RL and how do you feel that active inference generative models Andor the embodied dish brain averts that or does it ever do forgetting or what kind of forgetting and how how does the Dynamics there differ from the reasons why those phenomena happen in RL yeah this this is a yeah this is a great question um and one part of the uh ongoing project that we are doing now um regarding this question we are using lifelong learning or continual learning we are trying to teach the dish brain and train the dish brain different tasks multiple tasks instead of only one task so far only Pawn game but we are planning to train the system on different tasks and see uh how they act um in different consecutive tasks and without forgetting the previous Mones um we are still doing the recordings we don't have the all the results yet but yeah as as soon as we got the recordings we can start the analysis and see what happens Yeah so basically yeah we don't have uh evidence in our dish brain yet that catastrophic forgetting is not happening that is on our plan uh but uh just in terms of comparison to RL like why catastrophic forgetting happens in RL do you have any insights on that um I'm not sure maybe um just one answer that I can say now is that because most of the orial algorithms use back propagation in their optimizations and maybe because of I'm not sure but maybe because of the gradient Vanishing and uh something like that happens in their training we can relate that that's the the catastrophic forgeting to uh a and because of the these these matters but uh which is again exactly the point that is in contrast with what's what we have in an active inference model and the generative models that we use active inference but when we have the multiple tasks in in our framework I think we can answer this question much better in in terms of what's happening in biology and IND dish brain yeah yeah just just to kind of highlight that when there's a training loss gradient in a neural network then different tasks can have performances that are at odds so even if you did Epoch of training task a and task B you might end up following the gradient for task B so much that it deteriorates the performance on on task a um so then the active inference angle would be well if you have a joint generative model and you're going down down the free energy gradient on the performance of both at least you'd have the explicit Frontier and you could explore like is there are these gradients at odds like will there be a trade-off with per tuning it one way or the other um or is the architecture such that it could sustain the the the both functions at once and then that would just be how the generative model was parameterized it wouldn't have invoked any kind of reward model which especially as more and more tasks into play becomes more and more arbitrary to specify exactly and the huge amount of hyper parameters to be tuning which can be again at OD with each other when we're try training on more than one test yeah cool so about like the sense in the action cells that is spatially fixed on the chip so like how do those come to be Associated is it just giving the sense region what and what is given to the action region such that it does self-organize into that kind of dynamic yeah so again the sensory and regions or action regions that we have were predefined during design of dish brain By Us by the founders of this Frame mostly I would need to acknowledge here again Han Andy and Brett uh but uh what the challenge that we were facing obviously is that we do not have any ground truths or any uh map or layout that the neurons give us to say okay yes we are responsible of sensing we are responsible of making an action uh so because these are all the same cell types so during the design of dish brain what we did was we did experiment trials and errors with different layouts predefining different regions having uh different roles and this is the design we came to just because of the fact that it showed better performance in the game uh the sensory region is the region that is receiving all the sensory input and feed back and all of that there is no input fed to the motor regions or the action regions they are only being recorded from and uh this is actually what we are searching for to be able to come closer to an answer of how these are self-organizing themselves to be acting the way they are acting one uh way of looking at it was looking at the functional connectivity networks which we very briefly talk to uh to you about here but in another project that is ongoing here we've actually implemented a framework uh which uh which actually showed us that looking at different game episodes when the cultures are doing well or bad in the game and comparing uh an embedding or a lower dimensional representation of all the channels in these different uh episodes showed us that during the better episodes when the game performance is High uh there is actually a nice uh Association or correlation between the activities of the sensory region and then the motor regions which are responsible for up movement and the motor regions which are responsible for down movement so they actually do make these nicely uh separated clusters when this does not happen during uh bad game performance which was actually very nice for us cuz um it showed us maybe these pred definition of regions was towards the right direction and more importantly for our future designs we can actually use this framework beforehand to see what are the uh channels that are clustering together self organizing to be more Associated together more correlated to then Define the uh different rules roles for them we also looked at uh the criticality metrics actually in these cultures when they are doing well in the game in terms of again how maybe they are self-organizing themselves uh in a specific matter that helps them process information better have higher storage capacity which is all that criticality is actually showing and in one of our recent uh studies which is already published we did see that during game play the whole population is actually self-organizing near a critical point and the sub regions separately as well uh which is actually a Hallmark of criticality being uh scale free right so we did see this scale free pattern in their activity as well the motor region separately and the sensory region separately both also self-organized near criticality which could be arising from a nice balance between excitation and inhibition but again there's lots to explore and lots to look at still wow very cool with the multi scale criticality as those are the kinds of like empirical patterns that in the biological systems maximize the signal intensity and and it's kind of first principal statistical properties like it wouldn't be using the dynamical system to the full gain if it were falling far on one side or another and then to show that even absent Gia and all these other forcing or buffering elements that that probably do play important roles in the criticality being like maintained or useful organism but then even stripping out just the cells still has that pattern just for what they expect and prefer yeah exactly and we do hope in our future iterations of the system by the introduction of glal cells asites we hope that this will actually be again helping enforcing the how they are self-organizing your criticality to be performing the tasks to be processing information however we want to phrase that what kinds of like computational or or system specific challenges do you think this kind of system would be useful for in like short and longer terms but what what do you think and how how does that work with plugging in and co-evolving all of these like very material details with the kinds of settings that are useful uh yeah so we do have this uh here as a short list of what we are thinking of as our short-term goals long-term goals uh so as what we have uh ongoing as ongoing projects uh would be like what M mentioned so we are as a first step because if we are aiming to have these computational units or biological intelligent units we do want them to show memory yeah to have the ability to show this lifelong learning or continual learning which we haven't uh ful shown yet so that's one of our ongoing projects to be able to uh train them in different tasks U we are working on different applications in drug Discovery meaning that we can have invitro models of different diseases such as epileptic models for example and then uh testing the drugs uh on our cultures to see not only how the activity patterns are changing uh but also even compar between drugs and how effective each of them are uh then um a recording capacity actually uh with with these projects the our previous recordings were just 20 minutes but now we can have recordings up to in a month hours and hours and yeah we have disability to record from the cultures for I don't know up to 60 days oh way more than that which go up to even 8 9 10 months and ongoing uh but definitely it's going to be new challenge because we have a huge amount of data to analy but at least we have a good source of recordings and yeah yeah again in terms of challenges yes the just analyzing the data the data storage for our purposes is going to be a challenge but it's really nice to keep in mind that although it is a challenge for us to maybe record have all of these recordings and analyze them computationally but these neurons these cultures are still using very very tiny amounts of power so the power consumption by these computational units if you want to call them is it still very efficient which will hopefully in the future enable us to potentially uh use them as these Clos Loop uh intelligence systems with these input and output obviously uh design and I think we we can go wild in our imagination maybe someday they can even replace silicone chips interesting well okay one question I guess to that is how how do you think about the resourcing and the benchmarking like you could take take the thermometer and give the temperature reading that's kind of cool that it it does have this fundamental physical energy balance too so that's very interesting but in terms of the computation so here you explored some of the sample efficiency like how can these different Computing substrates be compared when it comes to like thinking about speed but it doesn't have a clock speed it's just unfolding or it doesn't have a RAM memory or GPU measures for parallelization so what what are like promising or useful ways to understand what these systems can do yeah so uh one uh way that we are exploring now again is that if uh we are able to uh understand at least parts of the mechanisms that that is driving this learning that's happening or the information processing that they are doing one Avenue could be actually to use those mechanisms Implement them in uh what we know as machine learning or AI methods and actually help to improve those methods uh using these more biologically inspired uh and more intuitive mechanisms that we will be hopefully uncovering uh but in terms of just comparing uh this was our first effort comparison to RL in terms of sample efficiency it was challenging to make the comparison Fair we did have suggestions we did have criticism in terms of as you saw it showed results that if they are trained for longer durations of times the AR methods obviously they can even outperform our cultures at this state but uh we all know that the PO consumption now uh is like a huge issue right even in these llms new Hot Topic that everyone is talking about uh if you just think about how much power they use uh I think just comparing in terms of features like this their power consumption that could give the biological cultures a huge Edge uh and a huge motivation for us to follow up on you know on our designs and just continue with what we're doing uh do you have any ideas on how to compare at this stage uh honestly I think again the continual learning the liftime learning will be able to show us the actual capabilities that that these biological neuron networks can have uh the memory if they show the memory that we expect them to show uh could could be another point of comparison between uh whatever technology we have available now but yeah lots to explore still cool I guess to a different side of it it says ethical considerations like ongoing I mean even broadly what does that look like or how does that really come into play and get stewarded in the research uh so uh when we started the research like the start of all of that uh first of all one of our challenge challenges was always um just to put into wordss the phenomena that we are seeing we are observing that what is happening uh because if you're using terminologies like learning cognition sentience and all of that this uh could by itself be a huge area of discussion and even dispute in some cases uh but to start with our reason uh to do this was that there is no terminology like there is no set language to talk about predefined terminologies or language to talk about these systems or these phenomena so we decided to go with okay choose whatever best describes them but then as we moved on we realized that even the terminology that we use could have uh could have huge you know ethical controvers controversies or cause uh people to think about lots of ethical considerations of are they sentient do they feel and all of these so all of our analysis that we're doing we are using different metric different measures of for example measures that have been introduced to quantify Consciousness like for example the PCI metric right uh we can have all of these implemented for our cultur which we are doing now and then compare them against the findings the state-of-the-art research that are being done on Consciousness on cognitive abil abilities and all of that and so far to show that while these are capable Computing units they do not necessarily show or have the features that would qualify them as uh conscious features or units so these are things some parts of the things that we're doing we are trying to address to move in parallel with all of our computational studies in parallel do all of these uh basically analysis as well uh to make sure that we are considerate enough of a phenomena that we might not be aware of it happening underneath all of this but so far uh we are happy to say that we have published everything that we have found we have been very open with uh our findings and open to discussion open to everyone's opinions about whether there is an ethical angle that we have maybe missed wow very interesting like how is that Vector of different cognitive performance on different tasks associated with the different measures of Consciousness and are those like maybe some implicitly or explicitly believe those are like the same vector or that they're orthogonal to each other and there's some other kind of dimensionality where changing the the cognitive capacity like on any given t task ends up not or even diminishing the performance in other ways so it's like a whole portfolio of evaluations because there's tasks but then these are other measures and yet it's like an opening up of these measures into the empirical whereas even before that it was from the qualitative to the formal but then all the equations on the piece of paper don't get get to the sensor reading so that will be quite an exploration okay I'll just ask like one or or any last questions um Jeff writes have you compared results from cultures from different brain structures EG prefrontal cortex versus visual cortex uh no that we haven't done all of our research is based on these uh ipsc cells which are differentiated into cour IAL cells again in our future iterations of the system we are introducing glal cells Asos sites and all of that and we are trying to also move to 3D organoid uh intelligence systems or organoids but uh we have not implemented or compared between different brain structures yet what what attributes or were there any other things that correlated with like the human the mouse difference I mean do they are they different sized or do they have different branching characters uh so they uh I'm not sure about the size to be honest uh I would love to have one of our biology team to be here to answer that so I don't want to mislead anyone but in terms of their characteristics uh we did study them in terms of their connectivity patterns like the study we showed you about and the the Dynamics of the connectivity uh and we do see maybe we could call it slower plasticity mechanisms happening at a slower rate which is what is uh we saw in comparing mice and human cortical cells which could explain parts of the difference in the performance that we saw but still we shouldn't forget that even the mice cortical cells were performing quite well uh in the context of the task that we defined for them wow very uh interesting do you have any oh go ahead they're quite smart yeah even when alone it's like it reminds me of kind of a lot of the laboratory experiments in ant colonies where even taking a nesme out of its usual Collective Niche which is kind of it's anous like other nestmate interactions that's like other neural connections um but with a more Dynamic topology and then the GLE Niche is kind of like the nest architecture and then even stripping them of all of that and the phermones and the tunnels and the nest mates interacting and then it's like still they could do the t- maze um okay one one last question from the live chat Jeff wrote could you see scaling this from a 2D grid to 3D Matrix emulating cortical columns and interconnecting them yeah I think I briefly mentioned that yeah but we are actually doing it right now we are uh working on organoids which is basically the 3D structure that uh Jeff is talking about uh one major challenge of organoid the studies is always recording is yes exactly how do you record from the cells on the outer layer how do you make sure the inner layer cells are still alive and functioning and how do you efficiently record from them without causing any damage or major Interruption to the activity of the organoid of of the other layers but I think those are challenges that everyone in this field are trying to solve now are facing we are also trying the same but we are doing that we already have some recordings of our organoids which are comparing against our two is right now uh no results to show unfortunately that is very new but yes that is on our to-do list cool do you have any last comments or questions or like anything else you want to add no I think that was pretty much that yeah I wanted to discuss and talked about what could what could someone who's learning and applying active inference do in terms of their research and learning to kind of dovetail with these [Music] directions um to model them more biologically inspired yeah yeah know yeah so maybe if if you would like to because of it's still an open question for us to to understand and realize the learning mechanism Behind These biological cultures and we need to find a way to somehow model the learning we were thinking about yeah active inference for a long time as a biologically inspired algorithm but definitely uh there's a long path and uh lots of things that we can do yeah and for someone who is interested who's starting up I think although we have done this comparison that we showed you already but uh still we are looking for uh proof or stronger evidence of these for example biological cultures actually following an active inference kind of framework if you want to say so it could be a very nice starting point to actually model the exact game environment that these cultures these biological cultures seem to be handling quite well in an active fence uh and and later on very soon for lifelong learning actually we we need a mathematical analysis to model the system yeah to start so to start with with an environment or with a search space exactly similar to what the cultures are facing trying to build uh a model upon that which matches the activity of our neurons of the biological cultures as we did but still again starting from that point done they will have a lot to explore we're happy to uh discuss with anyone who's interested to contact us via email in calabs we have Discord Channel we have all the means of communication that you can think of so if they're interested to you know get a sneak peek or have some some sample data to work with definitely happy to stay in touch with them awesome thank you both so much it's really fascinating so hope people enjoyed it and learned it was great and good luck thank you very much for inviting us it great and pleasure yeah thanks a lot for the invitation hope we had some you know new stuff to show people some good takeaways for the audience thanks a lot thank you see you bye see bye e for