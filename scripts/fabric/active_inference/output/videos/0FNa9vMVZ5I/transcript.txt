all right welcome back cohort 7 we're in our second onboarding SL chapter one slash Etc and Andrew go for it however you want to begin yeah uh great so I know that today we're covering not just chapter one but just a more General like introduction to to the group and active inference um sort of meeting uh I will kind of quick quickly give like a rundown of this first chapter it's not very long there's not too much to say but um that said I thought it'd be useful just to kind of kind of wrangle together all these different themes here um that we're going to be seeing in chapter one but also going forward for the rest of the textbook so in chapter one we're very quickly introduced to this general idea that a we have uh agents which could be seen as living biological organisms or other kinds of self-organizing systems um but they conceptualized as agents and so agents take in sensory observations and elicit actions to either realize their desired outcomes or goals and Andor to make sense of their world by gaining information about it this leads to the development of adaptive behaviors or strategies that agents use for navigating their environment uh this process plays out in a recursive action perception cycle where observations and form agents decision making regarding the next action they should take uh we also learn that this this whole process occurs at various levels of complexity and differing time scales ranging from the simple and rigid moment moment by moment strategy I of nutrient seeking bacteria up to the more complex and flexible strategies of humans engaging in planning to realize their goals in the future active inference occurs at different physical scales as well as well from microbiology to Broad cultural and development developmental learning in collectives or human societies uh one way to frame active inferences approach uh for example is through the neats versus scruffies discussion in this chapter uh while so-called scruffies lay emphasis on the idio sequencies and specificity of various phenomena of interests for example different biological adaptations neuronal Dynamics or cognitive mechanisms uh each deserving of their own separate bottomup research from empirical data the so-called Meats aspire to a set of first principles for explaining and relating these diverse phenomena in a more top- down fashion while still engaging in empirical analysis for validation and so active inference also identifies with needs as it lays the normative framework for understanding the brain and mind and their biological and cognitive implications alongside model design and testing for empirical analysis um we're given a kind of General schematic of the rest of the book uh it's separated into two parts s the first half will focus on Theory the second half on practice so I'm just going to speak about the rest of the first half um the first half basically presents active inference as a normal normative framework with its distinct Concepts and theories um we're shown a kind of conceptual road map at how to arrive at active inference uh in you know your respective Learning Journey or however you would like to view that um and there are kind of two roads to reach active inference there's a low road starting with bases theorem uh which basically supplies the mechanics of active inference uh in its relation to what would be called the basian brain hypothesis uh it's basically a way of viewing uh processes or computations in the brain is playing out Thea basian principles where there's prior information uh new observations come in there's some kind of likelihood that relates uh prior information with new information and then uh produces a kind of posterior uh result you know a prediction about what's going on in terms of uh inference right inferring what is going on based on what you thought before as well as what new information you've received and then on the other hand the high road in chapter three uh coming much later begins with the fre fre energy principle or the necessity for agents to minimize free energy as a proxy or upper bound on surprisal uh in order for these agents to survive and adapt to their environment uh for the rest chapter 4 we'll just go a bit more into detail about basis theorem and we'll actually be presented with uh major kind of Exemplar active inference models uh those that are used for discrete time scenarios as well as continuous time scenarios chapter five uh the final chapter of this uh theory part of the book we'll then uh discuss the neural process theory of active inference uh which you know again begins with the free energy principle but then also rate how the specific quantities we find in active inference like predictions prediction errors Precision signals and so on which we'll we'll discuss much later how all these map to cognitive functions and their constituent physiological substrate and ronal computations so uh through the course of the first part of this book these first five chapters we just repeatedly returned to various themes uh perception as changing one's mind action is changing the world learning as actually being very similar to perception but operating at a slower time scale with longer term impact on the inference process going forward thus learning uh planning is a means of selecting actions and sequences to realize not just current but future goals by uh kind of kind of uh predicting forward into the future to decide what you should do later not just in the here and now uh some other things like uh how to define exploratory versus exploitative behaviors it's a common distinction made in various uh Sciences Behavior Uh and and I especially wanted to note those because an active inference claims to kind of uh include both kinds of behavior within the same optimization function for energy minimization um as opposed to treating them as uh separate and needing to be manually defined uh as we'll find in many other kind of computational approaches like in reinforcement Le uh agents for example um and that is about everything that I kind of put together here for describing the first part of the book um you know feel free to obviously read the rest of the chapter it'll talk about all the uh other chapters in the book as well but just focusing on part one for today so um I guess I'd like to open up the conversation I know that there's some introductions at the very beginning of the meeting so I'm not sure if we want to go back into those but uh usually how we do it in the textbook is just anyone who has uh something of interest uh about this chapter or a question they have um they would just like to throw it out there we could uh take things from there there there's things that um I have to say but I'm look in my not I I I make notes on my trell board so if anybody else has anything to say before I I get to the notes I've taken on this chat on um I guess they could feel free I'm just looking for my notes sure uh Jorge you have something yes basic question uh what is free energy itself like not the pr principle but free energ yeah so it's uh For Better or Worse is somewhat uh complex concept but um it's it's basically it's you can relate it to information Theory it's kind of like an information theoretic quantity if that makes any kind of sense that Mak sense yeah so it could it could be measured in NS for example um and kind of the the importance of it here is that it acts as a kind of proxy more specifically a kind of upper bound on another quantity that organisms are theorized to be trying to minimize called surprisal and the reason why we're not um try saying it's surprisal minimization as opposed to free energy minimization so surprisal as far as kind of the basing computation that's being played out here surprise is typically like intractable um it's just a a lot of um kind of factors that need to be marginalized along the way when when Computing surprisal there can be kind of this issue with integrals and so on and so free energy in kind of mechanical terms is just yeah an upper bound on surprisal that is tractable so we can compute it then on the other hand um it still relates to something like something like a kind of biological realism that is you know uh organisms have limited uh resources in the Moment by moment inference processes that they undertake right so they're biological and metabolical um kind of constraints on on what they're able to do hopefully that was helpful yeah let me add one more by by analogy here so from chemistry one free energy type that people might be familiar is the Gibbs free energy so this is the thermodynamic free energy and so it's like ball rolls downhill is the um Newtonian mechanical path of least action given gravity candles burn given the activation barrier is the thermodynamic equivalent so put putting aside this the activation energy question going downhill means energy is dissipated as heat but then there's some floor where there's no more liberable energy from that floor so free is not in terms like free like beer free like software free a synonym for it is like liberable or like releasable as heat so then 1900s are happening information and thermodynamics are coming closer in info thermodynamics with in a lot of different like kind of really mechanistic ways like Land hours limit how much heat is related to like erasing one bit but also like realizations that at even deeper levels that there's these um way to think about information in terms of also a path of least action in an arbitrary State space that's called basy mechanics so the ball rolling downhill in this case is like explaining the data better or better is given a specific like form of families of equations such that there's kind of a signal to noise and the signal is kind of like the the floor and the noise is more like a heat or an entropy so it's used as an approximator that bounds surprise minimizing surprise is maximizing model evidence however maximizing evidence you don't know how high that mountain is going to go but minimizing surprise is often more tractable but then it itself is intractable for another reason which necessitates in the approximate basian setting the usage of variational methods because that gives an analytical approach that's optimizable incrementally whereas in alternative approach to variational approximation is Monte Carlo or sampling based methods those are also Limited in large State spaces but they don't require you to compute a free energy to balance a prial you just sample from a distribution and then use that as your kind of empirical data David uh yeah I was wondering if we could correlate it to to um free energy in in terms of tradeoff so like how much how much weight is assigned to you know the predictive nature of tradeoff itself and how much will you gain or lose by being right or wrong you know depending on the the data itself and how it's fit the accuracy minus complexity decomposition of variational free energy energy energy minus entropy is kind of like the physics e flavor accuracy minus complexity is the statistical flavor which is that you want to reward model fitting but penalize more parameters so now your kind of your risk tolerance like whether you have a preference for smaller and you're willing to like your point of diminishing returns is a smaller model or whether your point of diminishing returns is a larger model there's like this parto Optimum optimality manifold where if you're off this manifold you just could simply be doing better but then there's like a manifold Frontier in terms of model fit where it's like it's like a a hyperparameter manifold where you're doing as well as you kind of could on that trade-off Frontier but off that crease you're just leaving um explanatory power on the table with the parameters you have or or from coming from the other side well that's kind of the statistical and then this is part of the whole theme with things the the the most likely thing is what happens like things are doing what's likeliest rather than what's most rewarding because the proposal of a secondary reward function is not even something that seemingly Advanced cognitive systems necessarily do but that's what gives Unity with the dust particle and The Rock and cognitive modeling but then the question is how do you explain higher order Behavior chological Behavior Etc in terms of novelty Aesthetics in Surprise minimization terms right so I mean I guess sorry my my approach to it you know in terms of like I come from more of like the quantum side of things so I don't want to inject too much of that into it but um if you know you have a coupling with like a bit flip right if you have a coin with two heads like if you're just going off the randomness of the coin flip if you're a blind Observer you don't know you know heads or tails what the trade-off is going to be I mean if it's given the outcome is always going to be heads how can you then minimize that into free energy well if you're never getting an observation then you're never able to calculate a free energy because the free energy is C equation 2.5 for variational free energy it's your beliefs and an incoming data points so if you don't have a data point you could do descriptive statistics on belief but you wouldn't calculate a free energy quantity right so I guess the I guess the primary question there is if a system is determining how you're going to answer something because of you know learned in Behavior due to an assumptive prere is it doesn't that kind of end up being deterministic and becoming a trade-off in the long run I'm sorry can I um make comment regarding like my the way I think about free energy and how it makes sense to me like I like to think about Fields I'm assuming everybody on everybody here knows what a field is and I think about the different combinations of ways that perception and action can unravel with perspective prior thinking about feels from the physics point of view and translating that to the cognitive and Behavioral or psychological point of view um and you can get really more into the woods with this in terms of like you know mechanisms in the brain where neurotransmitter interactions are happening and neurom modulor interactions are happening but um I I I'll get into like certain points that I made about comments I made about the chapter in a moment but I just figured that what makes sense to me about free energy and just thinking about like potential energy in from from a a the point of view of like how energy can be utilized for it's utilized and think about the degrees of freedom that's that's there and thinking about modeling agency and how organism um engage their environment but also um a number I've had a number of com conversations regarding free energy being generalized beyond the scope of thinking about agents or organisms but also in their objects and how they take up an environment and how you can estimate the space over time that's taken up by those objects and then you can encode the marov blanket and what have you have a field you can envelop a field uh of like the possible interactions that can happen even from inert objects to um systems that are capable of agency that can actually properly infer and estimate over time um uh their environment and their circumstances leveraging things so I uh to me that that it makes sense from that point of view and not to not delving too much into the details of the physics but acknowledging okay there's the concept of fields and I could take that in the combinatorial options in which me as an agent can perceive and act on my surroundings and develop priers but hopefully that that that that kind of uh is applicable to addressing this like potential energy free energy so and what have um mean to ramble too much but I I I was like sitting on that thought for a few minutes and like oh I want to say something and hopefully it helps make a more sense yeah I mean it's I mean not to heavily I'm really just kind of simplifying and abstracting certain parts of what you said so apologies for that but I to kind of bring it back I think I mean if I understand David's question right um like isn't maybe part of the idea is like isn't supplying some kind of Prior that's already heavily conditioning the the process that ensues from there such that there's a kind of almost determinism based on your initial starting point because we're requiring that you have a starting point given this is like a basian process where have prior information necessarily involved and I mean it's from my understanding it's just kind of like a description of how the process plays out and I like the idea of a field whenever we just look at it as like this is a kind of space like how you describe like like objects or beings in their environment their you know uh affordances within that space or field or environment and so on and it's like well if we were to study that as you know scientists researchers however like we already have a lot of starting kind of prior there and we're going to start trying to model it to predict what will happen next so I mean it's not to sound so abstract or conceptual but it's like we're always kind of working with from our standpoint kind of you know external uh position a bunch of Prior information and we just kind of start there um just a couple tangential points that uh when setting up an active inference model um you know there there's of course like fitting models to empirical data but then there's also just during the testing phases I mean it's very common to just initialize with say very uniform uh priors you know B basically entirely uninformative priors and it's through the capacity for like learning or updating model parameters that the the agent can actually adapt to the situation and then it's it's it's its own parameters change such that you know it's kind of starting with new priors in in the next round so to speak that may be better hopefully through Min free energy minimization better match the environments around it um if any of that tracks yes and just like dynamical systems or linear aggression you can pull back to like univariate linear regression or single sinusoidal oscillator dynamical system those are kind of like the doorway example but then you might run a statistical script and it does a linear aggression on thousands of data points or it h it has more Dimensions than a single dimensional form so in the textbook much as it is for for for again the kinds of um topics that are addressed um in the appendices linear algebra dynamical systems probability information Theory those are also like their principles are shown in the textbook but then when it really comes down to anything like a system of interest it's the shape and the specific variables you use so these are like some of the moves and some of the generic cues and then like it's all about making that jump or path from okay listening to music in chapter 7 to here's this music data I have yeah that makes sense I I guess I'm thinking in terms of Weights as well like if we're waiting that data um like how can you avoid overfitting on something that's assumptive like for example like some of the things covered in chapter one like do go into I guess some of some of the things I see as um like in terms of like not just tradeoffs but in terms of how we approach as you were saying like just with sensory response right like our priors are also based on our limitations in terms of how we can measure how we can even understand to measure where you know there might be extra sensory kind of abilities that we have from a cognitive standpoint that we're not aware of in terms of even just in the way our brain interacts with itself with neuron interaction right so um I guess it goes back kind of to the pheromone response as an example of something that we can't detect but should be able to be weighted in the data yeah I mean just as a a brief like like one of the key a key Concept in in active inference whenever it comes to modeling is the notion of like precision as a kind of like inverse variance uh term and that that can kind of be viewed as a weight or waiting system there are a variety of different kinds of precisions that are applied to different variables as far as the neural process Theory goes they're kind of related to synaptic gain and and neural trans transmission um but uh yeah the general sense is that there's a kind of waiting process going on in addition to that again active inference uh agents who engage in learning like many things can be learned including like how to adjust those precisions uh in order to say weigh upweight or down weight the impact of new incoming information um you know there there might be an agent who uh has a likelihood model that that Maps observations to its own beliefs about what's going on is that kidden states and so it it might it might have a lot of really imprecise mappings like relations such that even though it receives new a new observation it kind of downweights the impact of that new observation because it it can't it can't find a good way of mapping it to a to a belief State such that it can confidently update that belief State giving them observation so so there are these kind of mechanics yeah great point with gain that can be thought of like people with audio editing experience probably have a very embodied sense of this but there's a way to tune the Precision such that even a variable signal gets collapsed to basically the extreme case is the dero Delta function which is just like a line it's a it's a special distribution that is zero everywhere and then it's infinite in one spot so there's a Precision setting that'll take a range of values of thermometer readings the height of the children in the classroom and do something like collapse it down to its central tendency and then also there's gain settings that can take even closely related data points and flatten the distribution the hyper priors and some of the parameters that that come into play in empirical basian analysis and then like unless otherwise specified it's like the temperature is one but then sometimes you do write it out more fully and then H learn or manipulate the hyperparameter related to the temperature and then about action that's the shaky hands so it's kind depending on where it is but but that does basically like sharpens or blurs okay yeah I mean that's how I was thinking of it in terms of like gradient descent um because those are some of the formulas that I've been you know working on where I also have run into a few things that I need to check where it is zero like you were mentioning but it also expands infinitely at that point and contracts infinitely at that point so that's kind of my prior that I'm trying to work with in terms of like if the math is correct what inference does that have if that collapse point will always be zero and one right you have a binomial distribution at that point where it's still a choice but if it's predetermined right you end up and I want to get too far into the woods on that but it's just something I wanted to kind of highlight from what you mentioned I want to um bring up so there is one statement on page 10 that I think I have some confidence that's that that that uh the rest of the book kind of mix up for for for the generalization I found which uh is the this the the the the bullet I think it's U it's the second it's the last bullet on the on page 10 and and it's it it's a bol that says under active inference both perception and learning are active processes and I quoted the part the brain is essentially a predicted machine which constantly predicts incoming stimuli rather than passively waiting for them and the comment I made about this was that I thought it was a it wasit it was kind of a naive assumption to assume that there's never a situation that the brain is passively engaging with certain stimuli instead of constantly predicting and this can help differentiate between noise and relevant stimulus to be interpreted as information so I think that the rest of the book gets into better detail about this but um I made a note of that as like kind of um a naive assumption made on page that I I found on page 10 that um well is the brain predicting everything coming in around it's predicting relevant information but I I guess I'm assuming that the book gets real uh it seems like I I Peak that chapter to little but it seems like it's it's get it does it better at spe better job at specifying and I think that overall chapter one does a good job providing a nice General overview even though there's there's some assumptions made that I think are clarified better but um I also sorry about that yeah point I made about what I found on regarding predictive processing happening in the brain yeah two two quick things on this the first is as so so so many times there's slipping between realism and instrumentalism if they said first we choose to model the brain as a predictive machine they couldn't be wrong because they're talking about their position to modeling but then it slips into what the brain is so that's that's one piece and the second thing is it hinges on what is meant by passively waiting that could be hanging out on the couch but hanging out on the couch even if your eyes weren't cating still you would be actively generating the periphery the sharpness and so on so in that sense there is this real time like now casting a vision even if it's not cating and moving its head and all of that but then is that passive or active yeah I mean how does that speak to a dream State as well where if you have a hyperreal dream state you know where there's you can affect your surroundings in the dream state not realizing you're in the dream state versus awaking state in the same kind of notion of sensory yeah well that I mean that's an interesting question I the way I would take them is that it still be similar to a waking State and that you're still a bunch of sensory information is still kind of being delivered to you presumably there's something going on that is kind of actively leading you to make the decisions or inferences that you're making during the the dream um but I've never actually I've never really followed that full thought through on thinking about how this works in a dreaming state but that's just my initial guess at at an answer to that question um I think for this particular quote yeah same point that Daniel made earlier the flipping back and forth using instrumentalist language sometimes other kinds of language other times but I I just wanted to say I think it still relates back to kind of that you always have priers right there's that there's that kind of like you have prior there and then there's computation going on if you didn't have criers then maybe it'd be easier to say like like you could passively take something in but the idea is that you're you're coming to a situation figuratively with information that's going to get computed so it's like you're involved in the process as it work and and to make this like really clear and be be clear about what the alternative hypothesis to a basian approach would be frequentism would say okay we're getting this wave of photons hitting our retina and we're going to do the maximum likelihood reconstruction so then we'll use interpolation gaussian blur convolutional neural net etc etc etc all these techniques that are these inbound processing techniques to reconstruct a get a snapshot of the maximum likelihood image so that is implicitly saying all pixels have a uniform prior like I don't know anything and I'm just going to take one snapshot of pixels and then reconstruct the ml um the outcome but as soon as you start to leverage oh well but I think it should be like the prior one prior frame that's literally basian analysis then that's the Colman filter where on one extreme it is the special case where you're frame by frame doing a total reestimation The Other Extreme case is you're just making a longterm running average blurring over all the times so then you have this basian hyperparameter search question how responsive should my Colman filter be and then you have another model in this portfolio you know how fast should I be learning how fast to change that all of those basian models can be evaluated with basian model selection using accuracy minus complexity basian information criteria so it's like oh okay well I'm getting I'm still getting bang for the buck to three but four always you'll fit better and better but then you're past the point of diminishing returns so that's like kind of the meta with basian which comes back in chapter nine as well is selecting amongst basian models even with totally disparate architectures is a basian model selection question whereas in frequentist parametric statistical methods you can really only compare model likelihoods using strict Al nested the hierarchical likelihood ratio test like Anova but you can't test non strictly nested models so for all the limitations and peculiarities of basian analysis it's super useful to compare it to frequentist and to non-parametric statistical approaches like bootstrap jack knife resampling but those are three of the major lineages in statistics overall and and those are some of the major toolkit areas as well and the SPM textbook earlier work by friston go goes into this and kind of compares the methods a lot so is the stacking kind of like logarithmic in a sense or is there any point where it becomes exponential and then just falls back through the stack to the base what stock well so you were saying like if you're using basian to calculate basian right so you're still you're kind of using an exponential formula in a way right but it must be within a certain range so once you hit a maximum does it reduce back into the root you know it's still basian inference like you were saying right as a four function or would it reduce all the other layers that you've gone through to iterate up into a certain point right back into the initial if there's no priors in the set okay is an interesting question so this is like asking what should your prior be over structurally variant models like I I can do the one layer temperature model just try to do a fit I could do a two layer temperature model three for but then am I a frequentist which is to say naive over structural parameters okay so is it like is the whole basian game nested within a frequentist navity about model structure and you could do that or you could explicitly have a prior on structure learning so then if you were saying I'm making structural models of this condition in the genome and I I think it's it's not possible for there to be fewer than five or more than 50,000 low side and then here's my distribution of of structural parameters within 5 to 50,000 it's uniform within 5 to 50,000 or it's gaussian around this number then your structure structurally differing models would be weighted attentionally by your prior Distribution on that okay whereas if you have a uniform distribution across structurally different models that's like a fair test across the all okay that makes sense thanks yeah I had a one more comment on the chapter on page 10 the second bullet where it starts with various cers of active inference have possible biological analoges in the brain it makes they claim that Precision of policies corresponds toil fil minerc activity so I think again that that's a pretty big assumption and there's a lot going on with the regulation of neurotransmitters and other main neurom modulators like neur epinephrine and serotonin so the regulation of arousal in the brain and um the coupling the moments of coupling between serotonin and dopamine for for different reward and uh learning circuits that are that are chained together as well so and I think this also relates to uh the capacity to become aware of and pass on stimuli as Sensations and acting on those Sensations that impacts perception and action and priors so I I figure I I throw that out there too but I I'm not sure totally if the if other chapters in the book press on the importance and role of other neurotransmitters and neurom modulators from from the top the of the stack in terms of the of how cognition is uh uh is regulated within the agent yeah here's table 51 acetylcholine nor adrenaline and it goes it here's the citations with some other neurotransmitters and and um agreed it's like it's like but there's there's so many subtypes receptors Downstream signaling it's like how could one single parameter and it's like it's a course graening it's a map it's not a teritory it's not that it is a parameter in the brain and then models that make unique predictions and explanations and have explanatory value those are leading models and then when they when they are fit with one data set and then they have predicted value in a different Paradigm again that's evidence for that it's capturing an informational aspect so yeah I mean thinking about that in terms of like descending versus ascending and deep versus superficial I mean that's kind of the coin flip again right where you have like at what point in that chain of the structure can you Det determine whether or not the Deep has flipped to a superficial kind of state if we're thinking of temperature right it's going to be a constant right or are we talking about interval in this case temperature could be constant or just like from reinforcement learning and and other basing approaches a common method is to have a high temperature beginning and then turn down the temperature and then people say well let's do multi-chain let's have them do let's do five parallel chains with different temperatures and then have them swap positions like then there's all these higher order questions about how you best leverage your Computing resources but that's not changing the analytical formalisms those are more like computer science and engineering methods to Implement variational basian methods okay like that doesn't change the equation of 2.5 or 2.6 but like different approximators they may give different results but it's like that's like how many layers back do you pull back in your investigation right question which what what's the name of the book that you mentioned about by friston on the SPM I think it was earlier what's the so the last um printed version as far as I understand was 2007 it's purple book okay but then there the the SPM online documentation goes up to 2012 and there's still a totally live Community with people doing fmri Imaging so I found this I found this book to be extremely helpful background information for several reasons first off it's like a speed course on the trifecta of classical parametric statistics non-parametric statistics basian statistics so it gets all those in play all the time and it deals with what we might call the a matrix the mapping between observations and hidden States in a setting where the observations are of a well-known form like EEG or fmri sensors and then the hidden states are neural activity and the blood oxygen flow dependent signal the Bold fmri signal or neural activity signals so it's like a defin system of interest and sensor type clarifies the setting it's not about um multiscale um considerations but there's some some ways towards that um so it really hammers down the statistical and the partially observable part and then action selection is just selecting a different index card in the transition operator and changing how the hidden State unfolds and and that is kind of approached towards the end of the book in certain analyses and it highlights the empirical basis from your Workshop presentation Andrew what what questions did you receive or what did you feel like what what what would welcome people and um like what what did people ask and what were they wondering when you showed them what you made yeah sure um yeah you know it's so again the the conference was uh it's it was like the big like International uh like computational social science conference and so many people there are like familiar with machine learning and and empirical data and so on maybe not know so much um kind of like say foundations of Concepts in physics um information Theory and so on um not in a way that they firmly needed uh and so I think a lot of it's just attempting to answer questions of like why use active inference to try and explain human behavior can we not approximate human behavior through you know iety of other methods um so it's it's a little different from the conversation we've been having right like there's a lot of questions of like scalability like oh how okay great one person one individual entity is minimizing their free energy but how does that allow us to make claims about what's going on at say more Collective you know level like like 30 agents in a network or something like that um you know so it's kind of just um it's more about kind of describing the mentality here of like okay we're we're creating something like an agent based model that has an agent and its environment and then from there it's just you as opposed to using like net logo which is kind of traditional way for scientist social scientists to do this where you have much more rules-based logic like the agent does X if it observes y the Z if it observes a um you know and said it's kind of like we have a models in a model so we have an agent based model where each agent is its own generative model um so yeah it's it's just more like kind of conceptual in that sense how to relate it to agent based modeling human behavior especially um let see what other you know it's per usual there there was a quick question about like okay so why the is this a theory of Consciousness Etc you know that they kind of open up into other discussions um let's see yeah I think sorry about those massive cells there but yeah those those outputs are like you know this is Agents engaging in something like Collective problem solving so exploring an enk landscape where they can either uh explore which is where they change a bit in their own solution or they can exploit meaning take their neighbors one of their Network neighbors Solutions and so the these are just like the output results for running that over T time steps right like how how what what's the best solution that they managed to collectively come up with did all agents arrive at that solution is it separate you could try and use this to study something like the the diversity of ideas in a more General way too of like right because you know there are fewer and fewer unique Solutions if all agents are just jum in to stealing the best one um so that yeah Falls over time and then what I was attempting to demonstrate that because this is recreating a simulation of more famous kind of Paradigm uh from a decade or so ago where they try and describe like team performance between um you know within groups like a group of researchers or a group of you know employees or something all working collectively on a problem maybe it's a group of students right working on a group project um but what they don't you know it because it's all done in this kind of like more traditional rules-based way we're not able to look at like okay well what about agents who learn you know and actually adapt right and I'm trying to demonstrate that whenever we include these agents is active inference agents who can learn uh actually like the impact of engaging in a project where you're able to just steal your neighbor's answer without doing much of the work yourself like if that's kind of what you learn or adapt to then uh then over time like that's kind of where you'll start off your next group project potentially like your beliefs about what the optimal solution is Will point you towards doing the easier thing so so it's just kind of trying to add a lot of more Nuance to those that traditional simulation it recreates the previous simulations Dynamics it recreates the Dynamics found in empirical literature of of group uh Dynamics and performance and yet this by creating agents that have these kind of internal cognitive active inference parameters you can you you know the idea is to try and have proxies for like okay what how does this impact back on the agents themselves and the longevity of doing practices uh practices like these so so those like those are just some animation plots that show like the distribution of beliefs of uh if it's basically mapping the likelihood of if I see myself like exploring coming up with my own answer you know what how does that map to observations that are oh I'm getting a better answer so it's kind of like a personal efficacy um belief it's like oh how much do I associate exploring with a better result a better solution in the end which then would condition your decisions uh over your actions like your posteriors over policies to continue exploring right so over time they all start off you know kind of low that's how I I set them up as priors but many of them just get lower and lower like they you know you just you have so many neighbors that you can kind of take the answer from so I I could go on about this all day but it's just you know the the the slides get into some of the more kind of textbook formulas equations Etc but the the the script here was really to try and demonstrate like what happens at a broader scale and how could you actually use this um you know to approach problems that we're already trying to get at like not throw a bunch of new stuff at people all at once um about here's a whole new set of problems you can now try and approach thanks to these methods instead it's like here's the value added of using these methods even whenever you try to approach um you know existing paradigms or problems so that's my I ask you a question um I haven't had a chance obviously to look at the data but um you had mentioned you know like uh a group of like 30 people for example in a node if you consider that you know one company right let's say it's a department a company you're still connected to another node of say another if your n value remains 30 per Department um if you had you know one individual in each of those nodes that wasn't conforming or wasn't you know kind of going with the same flow was there any correlation did you see it anywhere else in the topology that might have affected chains that aren't directly connected but would be through the network itself that's interesting um so I didn't get quite that far right because this was basically just kind of put together as like a toy situ situation right just to demonstrate but that that's an interesting question I think you could attempt to get it something like that like so this is basically just creating a single Network like a a single um you have two options like the way I set up the function you can either make a like a random graph with like P connectivity that you can Define yourself or you can set it up as like subn networks um where where the the separate subet it's like five groups of four agents or however you you know want to Define that but they're completely separate from one another but what you could do is you could adjust that to where you know you do have connections between the sub networks um and then I wrote everything you know just in a very programmatic like make all the agents have the same priors but you could set up an agent who has you know very different priors from the rest see how that plays out so I guess the the simple answer is like I'm not sure but the the the the tools are kind of there if one wanted to maybe approach and answer to that question great thanks sure cool maybe a model stream maybe with somebody else who's um done it but you should post it in Discord and let's see if anyone plays with it and then let's do it because I think that's a great framework for playing around and linking it to the sections of the book sounds good yeah I'm I'm I'm someone who comes from a social science background so it's kind of like for me it was just kind of this plunge into talking about like U statistical physics and so on that it's like it's super interesting once it it starts to catch on but until that point it's I'm just like thinking like how do I use this right so that's that's exactly what I'm trying to get at but yeah no stream sounds really awesome so I'd be happy to do that cool okay thank you Andrew and cool to hear the update thank you all for joining see you next time take care