hello and welcome it's November 11th 2024 we're in active inference guest stream number 92.1 with Max eer we're going to be discussing a variety of thermodynamic and basian topics it should be very exciting if you're watching live feel free to write any questions in the live chat Max will go through some sections of several papers and I will read questions and ask questions so thank you Max for joining looking forward to hearing about this take it away great um yeah thank you uh for the introduction and thanks for having me on uh really excited to talk about this stuff um so there are a few papers I want to talk about um one called thermodynamic linear algebra about kind of a novel Hardware approach to solving linear algebra problems and another one called thermodynamic based inference which is similar similarly about using these these new thermodynamic Hardware devices for beas and inference problems um and but before I get into that I just wanted to make a note on kind of like the story of this work and how it evolved because I think it's pretty interesting um so I'm working at a company a startup called um normal Computing and where we started off was just thinking about what's kind of the best hardware Paradigm for for AI and especially probalistic machine learning uh because these these are some of the most challenging tasks computationally and seen as some of the most necessary to be able to do kind of robust um AI without you know hallucinations and a big approach to that is is probalistic machine learning um and a lot of our approach was was inspired by this report that came out of of um a workshop in 2019 called thermodynamic Computing um and I'm sharing it uh can you see my my screen here what I'm sharing okay yeah so there there's this one quote here in the introduction that I think really summarized the point it says somewhat paradoxically while avoiding stochasticity in Hardware we are generating it in software for various machine learning techniques at substantial computational and energetic cost uh so one of the big kind of takeaways from the work they did in this um this Workshop was there was kind of a consensus that emerged that we're working so hard to suppress the randomness that comes up naturally in our hardware and then we need Randomness actually to run you know various randomized algorithms especially in prob wisom machine learning and so if there were some way to just use the randomness that's naturally there that we know about due to thermodynamics to achieve those algorithmic goals maybe we would save a lot of energy basically so that was kind of one of the the Inspire one of the ideas we were inspired by um but the first you know step along this journey was uh so there was an earlier paper um where we basically proposed circuit that are capable of sampling from a normal distribution um and I'll get more into the math of why that happens you know why do circuits that look like this allow you to sample from a multivariate gaussian um but so this was kind of the first work that was published at normal actually before I started working there called thermodynamic AI in the fluctuation Frontier but how you can think of this is this is the electronic analog of a system of coupled harmonic oscillators so if you can just think about a bunch of masses that are coupled together by Springs and um that are also damped so they they have friction um acting on them and there's also noise acting on them so kind of damped damped system of harmonic oscillators uh driven by noise that's the kind of system that we're talking about in in these works and we're just kind of looking at this electronic analog which is completely uh analogous completely isomorphic to that that picture in terms of masses on Springs um so one of the first problems we interested in solving was solving a linear system of equations so you can think of this as if I have a few planes in N dimensional space here I have three planes in a three-dimensional space um and in general I I have n planes in an N dimensional space and I want to find the one point where they all intersect assuming that there there is such a point um and you can think of that mathematically as I'm giving a matrix a and a vector B um and I want to find the point x that satisfies this equation um ax equals B uh so solving this kind of problem has has tons of applications in economics you know engineering but also in in AI for for you know training um neural networks more efficiently um you know if you can solve linear systems quickly then there's benefits to training Etc um so that's one of the first problems that we decide to to look at and well so I think that it's interesting to compare our approach with earlier approaches to um analog Computing basically because this is something that people have actually tried to do for for quite a while is build analog computers in other words where this the signals are not stored as binary numbers ones and zeros but can take values in between and so you're kind of using the capacity of the hardware to represent more precise numbers um than just a one and a zero and in theory that seems to make sense uh but the big problem that analog Computing ran into is is basically that there's a lot of noise that's present and noise and imprecision kind of prevents you from answering from solving these problems like like linear systems of equations uh with the accuracy that you that is needed uh by the application um so I guess the the big Insight of of this work in this thermodynamic linear algebra paper is that if you model the noise if you understand the noise in your system well enough and you model that noise then you can actually predict the behavior of the system on the distribution level level even if the system is UN unpredictable on the TR trajectory level um and the way we describe that modeling the noise is using what's called a stochastic differential equation so here uh equation two here I've written is a stochastic differential equation where I'm saying that DX the change in the state of the system which is really a collection of voltages on capacitors in the circuit uh the way it changes in time has two components the first is this term which you can think which is called the drift term and you can think of that as kind of the predictable part of the change in the state and it's the gradient of this quadratic function um and then the second term is the noise term so that's the result of kind of the random forces from the environment um and what this actual potential energy function here corresponds to is exactly that system of coupled masses on Springs or harmonic oscillators um which we've kind of drawn uh here Illustrated in a way that like you can basically think of the system as being a bunch of little little balls coupled together by Springs that are all being jostled around um by noise um and so the problem we wanted to solve right is that we had this Matrix a and a vector B and we wanted to find the point x such that ax equals B right and the way we're going to do that using this this physical system is by allowing it to come to equilibrium meaning that after it's kind of run for enough time under under these Dynamics eventually the state will be uncertain but the state will be described by a probability distribution that is the you know the boltman distribution the exponential of the negative potential energy uh and so because the potential energy here is a is a quadratic function the um the distribution of this form where you have e to the minus V ofx where V ofx is this quadratic is just a gaussian and it turns out that the mean of that Gan is a a inverse B which is exactly the solution to that system of linear equations um and the co variance Matrix is actually a inverse so there's there's I guess two things to notice here the first is that if we want the mean of the linear system of if we want the answer to the linear system of equations we can just allow this system of coupled harmonic oscillators to come to equilibrium and then estimate the mean of its state and if we actually if we wanted something else if we wanted the um inverse of the Matrix a then what we could do is we could allow the system to come to equilibrium and then estimate all of the second moments of its state or in other words estimate its covariance Matrix which turns out to be this a inverse here um so I also I want to expand a little bit on this idea of like what do I mean when I say that we can model the system and we can predict Its Behavior at the distribution level even though it's unpredictable at the trajectory level right so when I wrote that when I showed that equation this equation two on on the earlier slide what I mean by when when I say it's unpredictable at the the trajectory level is that if I know X of T I can't predict like X of t+ one with certainty right because there's this noise that acts as a force on on the state and so you would need to you know the what those the values of those random numbers are going to determine what the state is at time t plus one um but if I know like initially if I have some probability distribution for the state at time T1 and I want to know what's the probability distribution of the state of time T2 that is a question I can answer using this equation um and just for an illustration of this on the left hand side here this kind of blue um twisting path is a trajectory of the system where I've initialized it at at this point over here and then I've run it for a long amount of time and the state of the system here there's only two variables X1 and X2 kind of orbits around in this in this ellipse um but if I instead of just running one of these simulations running this one uh trajectory if I ran many of these simulations and sampled the initial state from kind of a from a normal distribution centered on this point and then I look at the distribution over time for that collection of you know many thousands of trajectories I would get this plot here on the right and so what you see that the big there's a big difference between these two pictures in that the left one we have this trajectory which is behaving in kind of an unpredictable and random way but the distribution itself is behaving in a in a very predictable and in nice kind of smooth way um and and one another way to think about this is that the equation I showed earlier is a stochastic differential equation called a lement equation and it describes the Dynamics in terms of the left picture in terms of the trajectory or at the trajectory level but if I want an equation that describes what is happening in the right picture um that would be the fuer plon equation which describes the Dynamics at the distribution level and so it's it's basically it's nice to be able to have these two pictures in mind at the same time on the one hand we're thinking about the trajectory level and on the other hand we're thinking about the the distribution level picture of the Dynamics um and so when we go up to to higher Dimensions it's not as easy to make you know to make this plot I can't make uh I have no way to easily draw you know a 10-dimensional hyper ellipsoid the way I can do it in two Dimensions but there is still a way we can visualize it and the way we can visualize it is by looking at the covariance matrices um so I guess just to go back here like what really are these ellipses well these ellipses really each of these ellipses really represents a whole distribution a normal distribution um and this ellipse is kind of the typical place where you would expect to find points that are drawn from that distribution um but another way of describing the the properties of that distribution is by its covariance Matrix which describes all of the kind of paraly par wise correlations between all the different variables for here we only have two variables so it would be 2 by two but if if we had 10 variables it would be 10 by1 here we we have it for you know eight eight variables so it's 8 by8 um and what we're looking at here is really um over time as we go from kind of this black circle on the left side to this red ellipse on the right side you can think of that process in higher dimensional in higher dimensions in this eight dimensional case as how this Matrix here is changing over time so it's kind of the same the same thing but now we're just watching a video of how the coari Matrix changes over time instead of plotting many ellipses uh at different moments in time uh now another interesting thing about this video here is that this isn't a simulation um this is actually experimental uh demonstration that we we did on the hardware that we we created at normal Computing um this on circuits that look essentially like this uh so these are just electron as I mentioned earlier these are just electronic implementations or realizations of kind of coupled harmonic oscillator that happen to come to this equilibrium state which is a multivariate normal distribution and which has these properties that you can use it to solve linear systems of equations and and get the inverse of Matrix um I guess yeah just one more word of detail here so so this input Matrix here is the Matrix a and then Target inverse this is the actual inverse of a that you can do just you know numerically you can compute the inverse um and then what these hopefully and in fact do kind of arrive to are are the are estimates close estimates of the inverse of the Matrix a um because that's the covariance Matrix is supposed to be proportional to the inverse um so you may be wondering at this point uh you know this this seems interesting but but why is it that we would go to all this effort to actually try to solve linear systems and or invert matrices in a completely new way right um what about this approach is promising so um one thing that's promising about it is that we have kind of theoretical results that show that we get better ASM totic scaling um as the problem size increases with this um thermodynamic architecture than the state-of-the-art digital algorithms do to solve the same problem um so without uh yeah I can talk more about like the difference between the overdamped and the underdamped at some point but just the the headline here if we look at this one row linear system what this is saying is that basically on the digital state-of-the-art methods take like order of D Squared you know the the the amount of time scales with a square of Dimension to solve a linear system using something like the conjugate gradient method for example um whereas with our kind of thermodynamic approach you get an amount of time um scaling with with d so like order order of n instead of order of N squared so you have some kind of like polinomial speed up there um and we proposed a number of like other algorithms in that paper too so the one for inverting a matrix um I I basically explained how that one works it's just you you end up estimating like the second moments instead of estimating the mean of the state um and there you also get like a polinomial Advantage because instead of taking like order of n cubed you get order of N squared um and we also have algorithms for getting the determinant of a matrix or solving something uh called the yov equation which is a matrix you know Matrix equation that kind of generalizes the idea of the inverse um so one other thing I wanted to show actually is just kind of an animation or like maybe a more Vivid illustration of what's going on here so if we this this uh what you're seeing here is just like a simulation of a two-dimensional coupled harmonic oscillator system um where right now the Matrix a is just the identity Matrix and uh so in other words there's no coupling between the two harmonic oscillators we have two separate harmonic oscillators that aren't coupled together and the coordinate of one is plotted as the x axis and the coordinate of the other is plotted as the y- axis um so because they're not coupled we wouldn't expect see any correlation between them and and we don't in fact um and there's also noise being added um so I can kind of change the amount of noise here by increasing the temperature um and I can change you know the resistance to change the amount of damping um and and change the inductance which is essentially like changing the mass of of the the Mass on a spring and by kind of tuning these parameters I can get something that looks more or less like I'm getting a bunch of samples from this multivariate normal distribution um and in fact I am and I can look here at the marginals and see these are samples from these you know these are the histogram basically looks like a normal distribution um although just because all the samples seem to be to have the right distribution that doesn't mean that the samples are independent from each other they could all be you know highly correlated and so we can also look at kind of autocorrelation function here where basically the you know the more you crank up the noise the faster the correlation decays in other words it's if you want to predict where will the next sample be based on the current sample if there's very little noise that's kind of easy to do but if if there's a lot of noise that's really hard to do um and I can also just take samples less frequently if I don't want as much correlation so that's what I'm doing here is I'm kind of cranking up the amount of the interval between samples and now that will you know suppress correlation between samples uh a bit um but at this point this is there's something a little bit trivial about this example because they're just two harmonic oscillators that aren't coupled to each other at all so really what we're interested in is is when we couple them together um so I think yeah we would change this kind of term and so what this ellipse now is the ellipse has changed and it's predicting you know where we expect to see the samples now that there's a coupling between these these two masses on Springs um and I think it's nice just to think intuitively about why does it happen why do we expect to see the distribution look like this when we turn on a coupling between the Springs well it's basically just that like we instead of having two separate masses on Springs that are oscillating by themselves now there's another spring that's pulling them together and so they want to be close together right and so that means that we're we're likely to see points where the position of X1 is similar to the position of X2 whether they're both positive or both negative and that's kind of exactly what we're seeing um as as we see samples is kind of filling in this this ellipse um so yeah I just wanted to show that kind of Animation that's a this is just a kind of uh some JavaScript code I wrote a while ago as kind of a visualization tool for that um and I also yeah I have the paper pulled up here and I can talk more about like how how do we um there are a few things I could talk more about so for example like how do we derive these complexity results of the ASM totic scaling or how do these other algorithms work like um the determine estimation um but yeah I want to maybe at this point pause and see if if there were any questions either from the audience or Daniel or anything yeah awesome okay anyone can write questions in the uh chat yeah hearing more though about how do you pull out different analytically useful values [Music] from heat and what does that mean I it taking a stab at it now but revisiting it I mean how is it that there are these tractable useful quantities arising out of physical objects like this right yeah I think that's a good question um I mean to to go back to kind of yeah the history of like so first of off like the first thing people tried to do was just pure analog Computing where they didn't really consider you know the noise or assumed you could suppress the noise enough and that analog Computing approach is based on a system that physically solves a differential equation uh so whereas our approach is a system that physically solves a stochastic differential equation but you can still it's still useful to think about the analog case where there's no noise and where you're just trying to solve a differential equation um because uh you know one thing you might think to do is if you want to solve a differential equation instead of just solving it numerically on a computer you could actually just try to build a system that actually evolves according to the differential equation you want right so that's like one perspective on why do these physical objects do useful computations because it's kind of like saying we're going to build the physical system that behaves in that way instead of trying to simulate it um and I guess yeah another perspective is that well so with the with the linear systems right like you can in theory you can solve linear systems on an analog Computing device as well that doesn't have any noise and what's kind of going on there is that the um you're basically doing very uh efficient multiply and accumulate operations in a sense in that if you want to add together like N Things um digitally that's going to basically take order of end steps um but if if you want to add together end things kind of using some analog device there are ways to do it that are more more like constant time so for example if I have n wires that all converge at one point and send a current into each one of those n wires then the current that comes out is the sum of those currents so it's kind of a way of doing of like adding together all of those nend things in constant time so I think those two perspectives are kind of useful that one we get very efficient analog multiply and accumulate operations and the other is that um we're kind of building the system instead of simulating it in some sense what is the transferability of these shapes like do you have it work really well on this 5x5 Matrix but then you need to go back to square zero for 6x6 or how do you deal with making on the Fly changes or adapting to specific problems right yeah so that's a very good question right like how you know how does it how do these things work in particular when we go up to like the limit of like much larger matrices which is relevant for you know the big kind of AI and Industrial applications what what we what we found is is that generally these algorithms behave um pretty well as we increase Dimension over a large range of different dimensions we can go up to thousands of dimensions and still get the answer very accurately um but there are other properties of the Matrix that are relevant too that can make it hard to solve the problem uh one that's very important for example is the condition number of the Matrix um so if you think about those ellipses uh well I guess I can just go yeah scroll down here if for a matrix well the condition number is the ratio of like the largest singular value to the smallest singular value of a matrix and what the singular values are is they're the length of like this kind of this long axis here and this short axis here uh and so an ellipse that's very long and skinny has a very large condition number basically the condition number basically describes how long and skinny the the ellipse is or if it's in high Dimensions it's like some kind of n dimensional pancake if it has an N if it has a large condition number and basically yeah um matrices with harder with larger condition numbers end up being harder to invert or to solve a linear system for if the Matrix a has a large condition number um but you know there's still uh there's still ways to do it but it's that's I would say one of the bigger challenges to generalization is that like as you go up to higher Dimensions it's kind of easier to get matrices that end up having very large condition numbers so more can go wrong I guess and you you to what extent rely on repeated um decorrelated long-term sampling of single objects versus parallelized or replicated sampling across objects and then what is that have to do with ergodicity yeah so um I think I'll first answer the question about ergodicity actually because um yeah I think that that's a that's a very good question that's that's a very good way to phrase the question actually um because if I look at this plot on the left I this is just a single trajectory right that I've run for a very long amount of time and it turns out that if I just take enough samples of this single trajectory um that even if even if those samples are kind of correlated with each other um it still you know will work but if if if I have n samples it's better to have n uncorrelated samples and end correlated samples but I don't need to actually run many trajectories in parallel I can just run one and it turns out that that one trajectory has the same statistics the same mean and covariance as if I had run a th you know or a thousand or a million separate trajectories and that doesn't happen for every you know for every stochastic differential equation but it does happen for this one and that property is called ergodicity right the property of ergodicity is that the Ensemble averages and the time averages you know are the same they have the same statistics um so on the right hand side here this is kind of looking at The Ensemble picture which would be more like if I had used parallelization and and built many of the devices and kind of random in parallel um so I guess the answer the question of like which one do we do or which one you know in practice is more useful you can do either one um I think that it's it's a it's kind of a knob or a lever you have to turn if you if you have more if you can pay more for more Hardware uh and you can pay more energy then you can solve the problem Faster by running many trajectories in parallel whereas if you only want you know one device that that only runs one of these trajectories you can just take samples at different points in time and because of ergodicity it's the same as The Ensemble statistics basically cool carry on cool okay yeah I thought those were all all great questions so thanks um yeah I guess there was one other thing I wanted to say just at a kind of a high level about like how do we go about getting these complexity results um because you can imagine there might be something subtle about it just because this algorithm for example is never actually guaranteed to give you the right answer because it's based on Randomness uh you know the state is not gu the mean is not guaranteed to converge to the you know to the solution to the linear system it's just very likely to do that um and so you need basically I think of it as it's um yeah it's was this term that was coined by uh I forget his name a computer scientist um Leslie I think or what was his name yeah I forget his name but um it's it's called probably approximately correct um is the idea that you have a computation that with a high probability will be within a certain radius you know a within a certain error tolerance of the correct solution and so that's kind of the approach we take to quantifying like the runtime and analysis for these algorithms um and I guess an example of that is down here in the appendix um where you can kind of find we have bounds on um let's see where is this yeah it will be down here right um yeah so we basically have a bound on how long do you need the time to be in order to have the state close small closer than Epsilon to the solution with probably with probability at least P basically and so all of our results are formulated in that framework of you choose the success probability you choose the relative error tolerance and then you get out a time basically that you need to run your system for you need to average for um and those kind of results are quoted up here in these uh these tables basically um but yeah so I think that's really what I had to say on the on the thermol linear asra paper unless there are any other questions about that and I think otherwise I'll move on to talking about this um thermodynamic Asian inference paper I guess let let me ask one question about that last bound uhhuh um how do you get there did you build different objects and then back cast the formal relationships or do you play around with the formalisms and then ask if or how a physical object could realize it right so yeah so all these mathematical results are derived within a pretty abstract framework um which is the abstract framework is just the stochastic differential equation so in other words in order to derive these complexity results we just start by assuming that the the system evolves according to the stochastic differential equation and once we've made that assumption we can completely forget about the physical implementation whether it's actual masses on Springs or capacitors and inductors or whatever those details become irrelevant and so we're just talking about the kind of mathematical properties of how quickly the distribution converges under these Dynamics to the stationary distribution of this equation basically okay cool um so yeah so one thing that we noticed basically when we were doing that that when we were writing that thermol linear paper is that we noticed that while we'd gotten these very nice and satisfying um polinomial speedups that we predicted it seemed like we could some we somehow should be able to get even better speedups and the reason for that was that much of the runtime of running those Thermo and your algebra algorithms was actually dominated by just taking averages of the state of the system um in other words if we go back to this picture um here it turned out that we start we initialize the system out of equilibrium it it very rapidly comes to its equilibrium distribution and then we have to take a long time we have to spend a long time drawing samples from this equilibrium distribution and averaging those samples in order to get the estimate of the mean and so we started to think about well what if there are applications where we don't need to take averages where we just want to draw samples from the equilibrium distribution because if that were the case then we would probably we might be able to get a much better speed up because we wouldn't even have to do this this long you know the longest or the hardest part of our algorithm which is moment estimation and so that I was basically the Genesis of this um therm oasian inference paper because we started thinking like what kind of problems is the output a sample from a distribution what kind of problem you're you don't want something that's a deterministic function of the input but you want a sample and one thing that came uh that came up is sampling from the basian posterior of some model so uh so that's kind of a pretty common task that that you know people want to do is they have some parameter Theta say and then some data observed data um y like different samples y1 Y2 so on um and you want to condition your you have some prior distribution for your un your hidden VAR or yeah you have some prior distribution for your parameter Theta and then you have a likelihood which is like a theory of how the parameter Theta determines the observed data Y and given those two things you given your data and your prior and your likelihood you want to condition the the parameter Theta on the data right um and then often you want to sample from that um posterior distribution the distribution that's kind of been revised by the presence of your data um and so we basically started thinking about whether there's a way we could use a similar approach based on a physical realization of like noisy uh lement Dynamics in order to do beian inference and and then wouldn't have to do moment estimation or averaging and so we might get much better speedups um and so that's basically what we did in this paper and I guess at a higher level there's kind of a nice formalism for how you can think about yeah just what what is going on at a higher level and how we're doing beian inference using a physical system here um and so what it is it's it's B it's related to the idea of an energy-based model that one way of parameterizing a probability distribution p is to write that probability distribution p is the exponential of some energy function uh so s or e to the minus E to the minus V right so this just a way of of writing so any distribution you can you can write in this form but also importantly this is the form a distribution will take in statistical mechanics um when you allow a system to come to equilibrium and it has some energy V this is the form of its kind of equilibrium distribution um and so this when you talk about probility distributions in those terms it's often called like an energy based model approach um and there's something convenient about using energy based models for basian inference basically uh which is that when you take the log of your probability density function instead of like multiplying together probability density functions you end up adding together energy functions because we're now talking about the logs of the probabilities instead of the probabilities uh and so that's what's going on with this equation here it says you want to thet equal minus Ln of P Theta minus Ln of py given Theta so here um l p Theta is the prior that's our Assumption of you know the distribution for the parameters Theta before we've gotten any measurements P of p y given Theta is our Theory or model of how um how y depends on Theta in other words how does the data that we can observe depend on the parameter that we that we can't observe um and so what you would do in in basis theorem is you know you multiply together or you or not even basis theorem just the the definition of the joint distribution is p of theta and Y is p of theta time P of Y given Theta but now instead of multiplying these things together we're going to be adding them together because we're talking about the energy um right so this energy kind of represents the The Joint distribution somehow because because it includes the contributions from the prior and the likelihood um and what so what you do in these Thermo basan inference problems is you start out with one energy fun one potential energy uh which can be thought of as like kind of a a box that you know you could think of the system as a as some well like in thermodynamics we might think of it as like a gas inside of a box and then you can change the potential energy by moving a piston in or out or something like that or sometimes we think of it as like a marble in a bowl and then you can reshape the bowl um changing the potential energy which is maybe closer to like this picture here where when we CH the potential energy we're like changing the shape of this bowl basically um so go back here what's plotted in this uh panel a is what happens when we vary when we change the potential energy function over time so between time zero and time one we're going to change the potential energy from a potential energy that's associated with the prior uh to a which is U so u0 equals minus log of P Theta and and that's like this this blue curve is the probability density when we're in that prior distribution and then we slowly change the potential or slowly or quickly we change the potential energy to U1 which is the distribution that corresponds to the posterior basically uh for for Theta um in other words it's the distribution where you've conditioned Theta on all of your all your observed data basically uh and so what we're seeing in this plot is that as we as we change the poti over time the distribution of the system changes and it goes from this gaussian distribution to this kind of asymmetric distribution which in this case is the posterior for like basian logistic regression um and another view of that is in panel B where we're looking at how the thermodynamic quantities change over time so whenever you're changing the potential energy of a system the potential energy function of a system you can be doing work on the system uh and so this orange curve here is beta times work it's uh beta is one over KT and we see that the potential energy changes between time zero and time one and during that window of time we're doing work but then at time one the potential energy stops changing and so no no work is being done there um and so we can see you know how how the you know how much work is being done on the system and then there's also heat um which is the change in energy uh that's not associated with the work being done which you can compute just kind of using the the first law that de equals DW minus DQ um so we have work and heat which are kind of the two most fundamental thermodynamic quantities I guess um and then we also have the free energy also you know a quantity of great importance and there's there's kind of two different versions of free energy that are that are plotted here so one is this dashed line which is the equilibrium free energy um and what that means is that at each instant in time uh the potential en is changing but we could imagine a system that was in equilibrium at that instant in time um and if we did have a system that was in equilibrium at that instant in time its free energy would be the the the the equilibrium free energy so that's kind of the definition of equilibrium free energy is the free energy of a system at equilibrium with the instantaneous potential um and then there's kind of the non-equilibrium free energy uh which can be which can basically be larger than that um and the reason it can be larger than that is that the system is not in equilibrium at all times that if you're quickly changing the potential energy the system is driven out of equilibrium and so you can kind of look at the gap between these like the gap between the dotted black line and the solid black line as the extent to which the system is out of equilibrium at each moment in time and what happens is when when we quickly change the potential from Time Zero to time one the system is coming out of equilibrium these these two lines are getting farther apart and then at time one we stop changing the potential and the system starts to come back into equilibrium basically um and just another note on this is a nice interpretation of the difference between these um f minus F equilibrium is that it's actually the KL Divergence or the the call callback lior Divergence of between the distribution of the system at any time and the equilibrium distribution uh so that's just another way of saying that it characterizes how to what extent the system is out of equilibrium because this KL Divergence is is basically a way of of quantifying the distance it's not technically a a distance measure but a kind of distance between probability distributions and so it turns out that this like f minus F equilibrium is equal to the K Divergence between the distribution and the equilibrium distribution um so that's kind of the general framework of like what we're doing in thermo asan inference is that we're we're setting up a system so that we can change its potential energy and we turn on we we have a potential energy term that represents the prior and we have another kind of coupling term that represents the likelihood and then we have like physical degrees of freedom that represent the observed data that we have and when we turn on this interaction between Theta and all these um observational degrees of freedom then you then the equilibrium distribution Bec becomes the beian posterior and if we wait for a long enough time then we can measure the state data um and get samples from the basian posterior uh so let's see I I say a little bit more about that um just in theory and how that plays out but you might notice here that this kind of is is the key to the algorithm is this stochastic differential equation here which is you know similar to the form of the stochastic differential equation I showed on this slide equation two um and in that it has kind of this drift term which is like the predictable change in the state of the system and then this um this noise term which is like the unpredictable change in the state um and so let's see yeah I think that oh yeah okay so I guess what I'll yeah I'll talk a little bit about the examples we did in this paper so we we we what we did was we tried this out for two kinds of beian inference like two examples a beijan inference one of which is a gaussian gussian model um so where you have a gussian prior and a gaussian posterior and the other is um basian logistic regression so where you have like a gussian prior and a logistic likelihood um so so this plot here is for the gaussian gaussian model um and we see the um basically the prior is is one of these you know Green ellipses and then um the likelihood is you know the red ellips or might be the other way around but then you get the posterior which is kind of in the middle somehow um and it turns out that you can use this circuit over here in order to sample from that that blue ellipse uh that blue distribution uh which we've actually simulated this circuit in spice uh which is you know popular Library popular software package for simulating circuits and so what you do is you you use one um kind of you have one set of resistors that's used to input the prior covariance Matrix and another set of resistors that's used to put in kind of the likelihood uh Co covariance Matrix and then once you do that you can measure the currents like through these inductors and measuring those currents gives you a sample from the desired posterior distribution um okay so yeah I guess that's at a high level what I wanted to say about this Gan gussian model case were there any questions about either the overview like the general picture of therm Asian inference or about like this gaussian gussian model yeah a few questions how do you know that you aren't too confident or not confident enough with respect to the posterior like your Precision or your attention what makes you not just H how do you get confidence in your confidence level MH such that you can draw a a useful basy incredible interval rather than for example making it much wider or much tighter I see right like how in other words like how do we test that we're actually drawing from the right posterior kind of yeah if you can can compare it with the exact compute then you've already done that computation so then when do you feel like it's okay to get out without the guide rails and take the thermodynamic estimate as it is without doing secondary calibrations yeah so that's a good question right so one of the nice things about the gaussian gaussian model is it is one of these very few cases where there is an analytical solution so you can compute exactly what the posterior like the posterior is a gaussian again and you can compute exactly what the mean and covariance Matrix of that Gan are and so we can compare them um but I think you're also alluding to the fact that you know eventually we we aren't going to have that guard rail and we're just going to say we're now confident enough that this system can example from the true posterior and we're kind of done with with testing it and yeah I think the question of like when exactly do we become confident enough that it it gets the right posterior is maybe not completely solved yet um but I would say that because in the gaussian gussian case there's an analytical solution I feel pretty confident that like we can do enough testing even at pretty high Dimensions that we'll be able to you know assure ourselves basically that it works but where that becomes more difficult is for cases where there is no analytical solution to compare to um like uh in the case of the basan logistic regression which we also do here and in that case the best thing you can do is just kind of run a Monte Carlo simulation digitally and compare that to the results that we would predict with spice or compared to experimental results um which also works is just much much more expensive computationally um but on the other hand the fact that it's much more expensive computationally means that there's that we're solving a really hard problem uh which is good but yeah I guess yeah the to to make a long story short um that's still kind of something we're g to have to figure out you know in in complete detail is like how do we do enough tests and what tests we have to do to assure ourselves that that it gets to the right posterior yeah another interesting piece was that changing differential between the equilibrium free energy and the the non-equilibrium so do you experiment with like different speeds and find a tradeoff between moving it too fast but taking you too far out of equilibrium but then is there any downside to just moving it super fast or do you uh get better accuracy your performance in the kind of infant asmal movement case keeping it close to equilibrium all along the way way right so that's a that's a really good question and actually something that we're probably that that's a focus like a current kind of research focus is like what is the like given that we have this freedom of like how quickly we want to turn on the potential how quickly we want to turn on the interactions um what should we do with that freedom basically uh and there's like this really interesting literature on like energy time tradeoffs in stochastic Thermo so let me see if real quick I can pull up this paper um werstein uh um well just while you're looking for it you mentioned probably approximately correct that's Lesly Valiant that's right Lesly Valiant that's right exactly yeah um thanks um yeah so okay so I can't find exactly the reference I'm looking for but basically what it says is that one so I talked about the KL Divergence which is one way of quantifying the difference between two probability distributions another way of quantifying the difference between two distributions is the the werstein distance which um is kind of has this very deep and elegant theory in in kind of optimal transport uh Theory and where was sign distance came from originally was was optimal transport problems and in particular how do I transform one configuration of some material say into another configuration or if I have like a mound of dirt and I want to move the mound of dirt and also reshape it uh how how many shovels full of dirt am I going to have to take basically and that's kind of the classical um canich problem uh or there's there's another guy who well I think it's it's the other guy the problem I'm thinking of but they're they're these two dual optimal transport problems that are basically the same thing that are that problem of transforming one mound of dirt into another and the washer sign distance is the amount of shovels of dirt you need basically to carry to transform one distribution into another um so you can think of it as like accounting for it accounts for like not just um assigning low probability to high probability events with one distribution versus the other but also like if the mean of one distribution is very different than the other then you can think of it as like having to move a lot of Mass from one place to another and the kind of cool result that there is in in statistical mechanics and in particular like stochastic ther around this waserstein distance is that if you want to change a system State um over time then there's like this tradeoff you need to pay between the amount of work that you dissipate and the amount of time that you take and it ends up the form of that trade-off is that the product of the dissipated work and the time duration of your protocol is lower bounded by uh something times the waserstein distance um so I guess you can think of that as like given that I have two distributions that are a certain distance away from each other I can either transform from one to the other really quickly but dissipating a lot of work in other words paying a lot of energy or I can do it really slowly without paying really any work at all or I can take some trade-off do something in between where I kind of slowly CH change from one to the other and spend a medium amount of work and what we're interested in doing is applying these you know this formulation this theory of waserstein distance and trade-off between energy and time to solving problems like this one like doing basian inference and kind of saying there's like this optimal Frontier of there's not just one optimal solution uh because you might be in a situation where you care more about speed than you care about energy or you might be in a situation where you care more about energy than about speed but there is a set of solutions that are optimal with respect to kind of your disposition towards and how you value energy and time and I think it's basically related to these like energy time trade-offs that's kind of a classic pure SL metab basing approach anytime you have a free parameter treat that as another kind of variable to do inference on um what is the work Reservoir as we're not exactly picking up weights and lifting them to a higher elevation or anything so the heat Reservoir makes sense in terms of standard thermodynamics heat bath and all that but what's happening with the work Reservoir and what is it touching or doing with the device yeah yeah that's a great great question too so if I go back to um to this picture for a second here you can you can visualize these systems again it's like a collection of masses coupled together on Springs and then what we're doing when we're changing the potential energy is we're like changing the spring constants of some of these Springs so like maybe each of these Springs has like a little screw on it that you can turn with a screw driver to make it like more or less stretchy basically um but you need to like draw a boundary between the system and what's outside the system somewhere and where we draw that boundary is that what whatever is turning that screw that's tightening you know that that's changing the spring constant is not part of our system and so that if if you need to do work if it costs energy in in order to turn the screw then that needs to come from somewhere and we're calling that a work Reservoir and so we might actually be like lifting weights up and down if those if that's where the energy comes from in order to change the parameters of the potential energy function we're just kind of saying that wherever that energy comes from if we have some battery or some you know flywheel or whatever that's kind of outside of our system and we're not really going to not really going to worry about it Beyond just quantifying how much energy it uh it uh interchanges with the system basically yeah yeah it's it's interesting that the device almost has these dual reservoirs it's it's like one of those toothpastes with a dividing line in the middle and squirting out both kinds because on one hand it's interfacing with heat defined as that which does not do work just the thermal dissipative and then on the other hand it's connected into the work Reservoir which is sort of the complement of heat M and then the device is is interfacing with both of them and as you described seeking to find a path or a trajectory for itself that isn't leave that's not either dissipating extra heat unnecessarily or leaving work convertible work on the table either because it's sort of able to interface or or mediate between the work and the heat here right yeah yeah and there's a really a nice interpretation of that too I think um I I the the way you put it as like a a toothpaste tube where it can come in one in and out the other or something like that um and it is it's it's well you see a lot of diagrams like this where you have a heat you know you have you're interchanging both heat and work with an environment in the context of like heat engines right because you have a heat engine that well often there will be three W reservoirs in that case like you'll take in heat from a hot Reservoir dump out heat to a cold Reservoir and then do work or something but here we have two things we have just have a heat Reservoir and a work Reservoir but there is a way of thinking about this as a kind of heat engine like thing um but it's it's more of a refrigerator than a heat engine I guess because the the goal of a heat engine is to take heat and then output work of course you also have to Output heat somewhere but that's that's the goal is to use heat as a resource in order to Output work but what we want to do here is we're actually going to input work and then we're going to Output heat and as a result the entropy of our system decreases uh and this is just kind of a general thing that happens when you condition one random variable on another the entropy on average uh of the variable you conditioned decreases because the mutual information has to be positive so this is just one of these fundamental like information Theory things because of the positivity of the mutual information conditioning on a random variable decrease the entropy and you can think of in in some sense like decreasing the entropy of your system as as the operation of a refrigerator um even though it's not necessarily decreasing the temperature per se but it is decreasing the entropy um and so there's kind of yeah this nice way of looking at this as like a heat engine but really a refrigerator where you have this flow of work in and heat out and and decrease in the entropy basically but but just one quick not on that of course you can't decrease the entropy of the whole universe so the entropy has to be increased somewhere to compensate for that and that's what's happening where we have heat flowing out into the heat Reservoir so the entropy of the heat Reservoir is increasing to compensate could you maybe give a little detail how do real empirical measures y1 Y2 Etc come in like in active inference we're often thinking about perception as inference or action selection as inference but just on on the perception side so some perceptual prior new observation comes in new Photon hits the retina or whatever it may be new new thermometer reading comes in for the iot and H how does that feed into this and and how do you how do you schedule or bring that empirical measurement in right yeah so we think of the the measured data these observations y1 Y2 YN as representing constraints on the system somehow and so when you when you get new data you introduce kind of another one of these constraints by writing down your observation and then coupling that those phys and then those physical degrees of freedom that store the observation then get coupled to your system uh subsystem Theta but like just to make it kind of concrete of like yeah how does that actually happen so in this circuit here the the degrees of freedom that represent Theta are the currents going through these inductors L1 and L2 and the um degrees of freedom that represent an observe data point why are the currents that are provided by these current sources um i1 Prime and I2 Prime and so what you do when you get data is you turn on these current sources and set their current the current that they're programmed output as equal to the um the components of the data that you got um but you could also maybe something you said actually I thought was really interesting which was in terms of like thinking about observation as like perception or learning from perception um and you maybe could even think of these maybe if we got rid of these current sources and just had the environment kind of coupled these wires and somehow it's like taking a measurement of the environment directly more or less and then conditioning on those I think that that's also like kind of a valid interpretation which hadn't really I hadn't really thought of before but I think that's an interesting way to think about this as being kind of having these perception inputs here that are coupled to the environment and then conditioning its internal state based on those somehow cool yeah I mean a neurological analogy to these circuits are like there's some neural manifold and spiking patterns or neural electrical fields are traversing and they they're they're itinerating around this manifold describing the pre-observation state then a new observation comes in if it's not attended to it's like an uncoupled aesome later like the observation that isn't attended to it's as if it didn't happen tree falling in the forest and all that whereas if it the observation is strongly attended to and there's a strong coupling between the observation and the resonating state of the the prior then it moves more to be influenced by that observation more strongly and then hierarchical systems just have series of layers with possibly different attentions to layers with with resonating uh information coming from the environment in towards the deeper priors like of the organism and then and then more on the outbound action selection is when it opens up to well maybe the uh prior from the higher levels Cascades out and gets reflected as action modifying the environment to be more like the priors of the organism that's the change the world direction of active inference ongoing with the change your mind Direction updating the priors to be more aligned with what the environment is giving I see yeah I think that's a really cool way of of looking at of looking at this um in in that like yeah exactly as you said that like if you're not uh if there's no coupling between the degrees of freedom representing the parameters you're estimating if if if those are coupled to some source of information in the environment then yeah it's like you're paying attention to it in some way whereas if there's no coupling it's yeah it's it's for the purpose of your of your beian inference it didn't happen or or the information just isn't there and so somehow like the con conditioning on a piece of information is represented is like embodied physically as a physical coupling between kind of your we your description of the the ween variable and the actual physical encoding of of The observed data I think um and and then the other thing yeah the other piece you mentioned about like what about kind of some feedback effect where like you as as a result of your knowledge of this variable you come up with some policy for like how to behave or something like that and then that will actually change maybe that will have an influence on the next observations you get and that's a really interesting direction as well I think like for the purpose of this paper we've just assumed like all the observations are independent of each other uh and and that would kind of break down if you assume that like if you were using um some kind of uh decision you know decision strategy or policy to make decisions based on the data you get and your estimate of the state your estimate of the parameters data to inform your your future decisions in like maybe like a reinforcement learning setup um but definitely like figuring out how to use this Hardware in that context is something of of interest you know of current interest for us now so I I'll definitely you know keep keep people posted as as that progresses for sure yeah cool feel free to keep going if there's any other pieces you want to explore and then people watching live can write any questions in the chat uhuh cool okay um so I think that yeah so one thing I haven't talked about yet with this paper is our results on complexity uh which is of course is a really important part of it because that's what motivates Us in the end is like why we go to this effort of build this totally new kind of device in order to solve problems we already have a way to solve them um but it's just really hard it's you know intractable a lot of the time the sample from basian posteriors if you have to run some very long uh you know Markov processor or you know some Monte Carlo simulation uh so we have some results um oh yeah and I also kind of hinted at this earlier that we expected that we might get better speedups in this case than in the case of the TLA the thermo and your algebra algorithms because in this case we don't have to do moment estimation just want to Output samples um and so that did kind of turn out to be true that we got pretty significant like predicted speed UPS so just for this case of the gaussian gaussian model where we're given like a gaussian prior and a gaussian likelihood and some data and then we want a sample from the gaussian posterior we found that the amount of time that it takes that the amount of time you have to wait between when you in when you input your uh when you input the problem and when you output the samples scales logarithmically with the size of the matrices involved basically um which is pretty good time scaling because if you think about like what you would have to do digitally to accomplish this You' have to like get the inverse of a matrix you have to get the inverses of two matrices and like add those together and take an inverse again that's essentially the process you need to do when you want to do conditioning for gaussians um and so that's something that would basically be n cubed time maybe you know somewhere between n s and n cubed uh using state-of-the-art algorithms and so if we can do that in the amount of time that scales with log n that sounds really good um it almost sounds too good to be true in a way because you know how is it that we went from polinomial to logarithmic it almost sounds like an exponential speed up and it's I think like I while I think that these this result is really cool I don't it's not quite that cool in that it's it's not like fundamentally changing a polinomial operation to a a logarithmic and the reason is because we also have to look at the energy cost um and when you look at the amount of energy that go the the energy consumed by the algorithm basically scales linearly with the size of the problem so we get this scaling where we have um logarithmic time in dimension and linear energy in dimension which is still like a pretty significant uh Improvement um and then we also did some analysis of the like time complexity for the um basian uh logistic regression uh scenario and we found there we were able to show that you also get like um logarithmic uh scaling with Dimension but we weren't we haven't yet figured out the like energy scaling analysis for the logistic progression because that circuit ended up being a bit more complicated and it uses these like differential pairs of transistors to get kind of logistic functions um and it's a little bit uh involved to like try to estimate all the energy um but those were the the two kind of circuits we we gave in the paper was this one for doing the gaussian gaussian model and this one for doing the um basian logistic progression and we have some promising results on like the time and energy complexity of those operations um so oh I guess and one other just kind of interesting note about the interpretation and that also informs like how we derive these scaling results is that there's kind of this interesting literature on like waserstein gradient flows um which is uh basically you can think of like when when the probability distribution is changing over time here you can think of that probability distribution as a vector in like a very high dimensional space or really an infinite dimensional space and the Dynamics of that Vector can be thought of as actually a gradient descent on some objective function uh and it turns out that what that objective function is is actually that callback lior Divergence or the difference in free energy between you know F and feq and then it's and then the distance that um kind of the step size of that gradient descent is measured in terms of the washer Stein distance which is that distance between distributions I talked about earlier so you can think of this is um like the Dynamics of the probability distribution as like an ordinary differential equation in an infinite dimensional space where it's like going in the line of gradient of steepest Ascent in K Divergence with respect to changes in was time distance um but yeah those were the main things I wanted to talk about in this paper I guess and maybe yeah at this point we can see if there's any uh questions from the audience or something cool yeah I think people will definitely be interested in that connection with free energy where the kale Divergence comes up in both the variational free energy bounding the basy and surprise and expected free energy which is when considering policy inference as computation as a cognitive process and looking over expected observations asking what SE what policy dependent sequence of expected observations would have what epistemic and pragmatic value so these circuits aren't planning they're in the variational free energy kind of mode but it's interesting that again we see K Divergence popping up in both and and different divergences and distances between distributions being basically the Crux of the question and which measurements about which distributional distances and which properties of distributional distances and divergences can be enacted or how costly is it to emulate them when those are the calculations that it's important to know and the most classic of all being basically prior going to posterior how much should update right yeah yeah I really like yeah what you were just saying because I I think yeah I'm kind of aware of of these I've read I heard a little bit about um like kind of these interpretations of K Divergence as like in terms of games and like how how much do you expect to kind of lose or win if you have some assumption about the distribution of a parameter that if if kind of your distribution for a parameter isn't the actual distribution or something like that and how how well or badly do you do this game based on your kind of estimate of a distribution um and I think that I really like that that characterization of it because it gets it kind of a more like endtoend measure of quality uh because if you yeah if you if you use some system to accelerate the computations you need to power an agent and then you want to estimate like quantify how good is your system really doing then what people will care more about at the end of the day isn't necessarily like what's the uh like you know what's the relative error between these two matrices or vectors but more like what how much uh you know how how um how often will I make the right decision or something like that basically or what's my expected reward based on decisions I make and so I think that yeah if we can if we can somehow introduce the kale Divergence in in on that end as well that'll be a really nice way to kind of formulate things how do you see these elements playing a role in systems engineering and design like is it something that gets brought in like another kind of GPU or CPU we've talked about processing but not really about memory or storage so how do you see this playing a role in whether specialized inference pipelines or consumer Hardware or what right yeah that's a that's a great question I think there's really two ways to look at it one is like what what how do the theoretical results matter in terms of the future of computing Hardware um and I think that like these theoretical results can be pretty influential like thing like scaling laws like you know like like um Moors law and stuff like that or like how Land hours principle informs how people think about what's the minimum amount of energy that you can achieve with a computation and I think that there's one like impact of you know these theoretical results is that it kind of gives you a a bar to aim for and that if we can say like this is the energy time tradeoff for be and inference you can you can do it this fast if you pay this much energy but if you go a little bit slower then you can save some energy then that kind of sets The Benchmark for like what people should hope to achieve with new hardware whether or not they're using our uh Paradigm but and then there's the other kind of way of looking at it which is just a more kind of literal level is like what's the path from these designs we've presented in this paper to actually building hardware and where will that Hardware go and what will it do so I guess the exciting news kind of on that front is that yeah we talked a little bit about on on Twitter recently how we got funding from an an agency in the UK called Arya that's like their new more or less their version of DARPA kind of that they recently created um and is is really interested in bringing down the costs of AI like in terms of the hardware production cost and also like the energy and time cost of training um and even and inference as well um and so they've kind of funded our our project on a timeline of you know let's say like we're we're aiming to have Hardware in the next you know three four five years basically uh at kind of varying level of of um kind of increasing the dimension that it'll increasing the size of the problems it'll be able to solve um but in terms of yeah like where exactly that Hardware will go or who will Who will end up using it I think that there's still like there's still some open questions around that um and and more like I'm more working on yeah the side of like designing the algorithms and trying to figure out what you know what error mitigation or erir correction techniques we can come up with to make it work better and make it more robust but yeah I hopefully you know yeah maybe next time you know I I'll have more a more detailed answer on that but I think yeah at the moment there's it's not totally set in stone yeah what else do you think is out there in terms of land hour you know what what bounds are you scraping up against or what big powder s of information and work and heat do you think might be out there and and touched upon by this line of inquiry right so I guess like one kind of historical note is that like for a long time people have focused a lot on on just kind of land hour's Principle as like the fundamental Bound for computing um and and just for you know the audience and people who aren't necessarily familiar what land hour principle says is that to erase a bit of information you need to dissipate an amount of heat uh which is log 2times um KT so in other words if you can run your computer at a very low temperature then you don't have to dissipate as much information but there's still you know amount of of work that sorry did dis paay heat there's still amount of um energy that you have to pay that's proportional to the amount of Aer that you have to do now the issue with Land hours principle one issue is that it's something that we haven't really been able to achieve um there's nice kind of plot on one of these slides about it like showing how well we are still getting you know more and more efficiency that we're still well Above This thermodynamic Li limit which is Land hours Bound in terms of how much energy we we pay um and so I think the trend more recently is to say well we need to also account for time because land hour principle doesn't really account for time it you know assumes you can do what you're doing like infinitely slow and in reality you know we don't want to do computations infinitely slowly and so that's kind of yeah the angle I'm thinking about when I'm I'm saying like let's try using these um kind of uh these results from stochastic Thermo that bound like energy the product of energy in time using the washer sign distance but I think that like I've just kind of dipped you know a finger into that literature and there's a lot of work on on that stuff in ter in like speed limits uh especially in like Quantum systems Quantum speed limits and and classical speed limits and so yeah that that's like I guess the line the pattern I'm I'm most excited about is using these bound on like the product of energy and time in terms of you know distance measures between distributions but there may be you know may be other patterns as well so definitely curious to hear yeah if any other ideas I think come to mind but yeah yeah that's exciting to bring time into the equation literally and and for for real embodied systems that have existence in space and time that their material properties and the propagation maybe even coming down to um speed of sound speed of light deoration velocities and and these sorts of things could become dominant in terms of whether um the bulldozzer moves a few large amounts of Earth with great cost or whether it's very fine grains of sand MH which might be very efficient but then it might take so long that for for a practical situation it doesn't really have utility yeah yeah absolutely and and I think like one the one reason I'm I'm really excited about yeah as you put it like bring time into the equation is kind of at a higher level like big picture I think that where things are going in terms of the theory is like some kind of unification between like computational complexity Theory and stochastic Thermo because like we've we've been approaching some of the same problems with of of like yeah how fundamentally does your resource costs of like energy and time scale with the size of a system uh kind of as it scales um but so far like we we haven't like I think fully broken through to see the shape that connection takes and and yeah the approach that I'm that I kind of take to that is like first go for the low hanging fruit like not you know we're not necessarily going to see it all at once like what is this relationship between stochastic Thermo and complexity Theory but the more we can like build up these little results of like well you can um by looking by building constructing kind of a thermodynamic system that you're going to change the parameters do work on and see it as this kind of heat engine or refrigerator you can achieve a certain computational complexity of this operation I think these like smaller results are are helping to you know bring bring the those two Fields a little closer together maybe yeah interesting also with time it's almost like it's like with a body there's a baseline a basil metabolic rate and then exercise is doing extra activity on top of that so it's like if you have to pay the upkeep on the energy of the circuit even if it only is using a little bit of extra activity to do the target computation you're still paying for a large block of time the Baseline level and so when we get to the thermal limit then the Baseline is free because it's happening at a temperature that's it's it's happening at an ambient temperature so it's not needing to be powered to give some of the sampling Dynamics in the same way the the the informative sampling and that's the part that that I think there's still so much learning and and interest in how how do these higher moments arise with with no extra work that seems like good information and yet it's falling out of what seems to be powered just from thermal vibration yeah know I I definitely like think about it in those terms as in like what are the sources like fundamentally the sources of energy we have energy takes the form of work or heat and and heat is like cheap and work is expensive right because heat just kind of comes from a reservoir can come from anywhere and it's not organized and yeah in work you have to you have to go to some trouble to actually get a a source of work so yeah I definitely think about like that like how can we optimize a computation so that more of the energy comes from heat as opposed to work basically but yeah yes I think that's that's exactly it having having something rather than needing to add energy from the wall so that the energy gets pushed through a system does some computation and dissipates the extras heat it's almost like there's another Avenue where the heat in the room vibrates the system to functionally implement that computation or cognitive process it's it's all about arbitraging heat and work in new ways and seeing basian updating and equilibrium and far from equilibrium processes as happening as sort of a first principle of intelligent matter yeah yeah yeah I think that's really cool really cool way to see it actually yeah absolutely um yeah and and I guess yeah one one other thing I'll say I guess that I was thinking is um in terms of yeah like like how where where do we look for kind of fundamental constraints on computation in terms of the resource costs I think that a lot of people some some people have taken the view that like really land the land hours principle is kind of what what's the most is the most fundamental thing and then the reason we aren't achieving it is just kind of practical considerations on some level is just that it's hard to engineer but yeah my Outlook is is more that like well maybe there's a fundamental reason that it is hard to engineer something you know maybe there's a fundamental tradeoff that we just haven't discovered yet that if we knew about would actually very well explain why we're still a thousand or three or four orders of magnitude above Land hours principle so yeah I'm hoping that it's that maybe just considering time will get us there if not then yeah there's there's more to think about but yeah who who knows I guess at this point but yeah cool do you have any final riddles or thoughts or comments um yeah I can't think of anything else yeah I think this is I think I really covered everything that yeah I was hoping to get across I I think so far it's been really good it's been really great um but uh yeah if there was any any questions from the audience we of course be happy to take those yeah okay no specific questions this was very informative Max I think it's it's uh been a topic coming up again and again with these not just similarities and differences and analogies but implementations of information geometries and information processes on embodiment on physical embodiment biological designed and and all of this and so it certainly feels like there's a lot of threads swimming around and and exciting opportunities for synthesis so thank you for this exciting research and and the empirical connections and everything absolutely thanks for having me um and yeah as I as I mentioned earlier like when we first started out on This research we definitely had no idea or or didn't anticipate at all that it would lead us to kind of these these things that can be interpreted in terms of like active inference and connections to that um and and like free energy but uh yeah it's just been really exciting for me that to yeah be working on something I think is is both a practical approach to improving our landscape of hardware for AI but also has these interesting deep you know thermodynamic interpretations so yeah definitely I'm I'm happy to come back anytime and chat more I thought this was really really fun cool let's check back in a couple months in a couple in a couple trillion oscillations of the cesium as they say all right thank you Max fawell yeah you bye have a good one e