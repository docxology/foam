all right hey everyone it's active infer an stream number 7.1 and it should be a great and exciting stream it's November 7th 2024 711 depending on where you are and I'm going to begin the stream with a GitHub push that we are going to spend the next several hours probably unpacking let's commit it push it and begin what will be a very fun exploration into the active inference institute's branch of Pi mdp while it's writing let's jump into the show here's where we're heading we're heading into shly value analyzed homeostatic satisfaction expected free energy belief accuracy and control efficiency analyses for multiple differently parameterized pmdp agents base risk averse exploratory and balanced on those measures being able to analyze combinatorics like the synergies of their belief accuracy control efficiency expected free energy and homeostatic satisfaction we can look at the report and explore different topics like with respect to those variables what's the mean shapley contribution Coalition performance best coalitions this is all combinations of 0 1 2 3 and four so for example for expected free energy we see that the four unit Coalition is the best whereas for homeostatic satisficing zero Agent Zero working alone does the best underneath these coalitions and their combinatorics are specific agents that are logged in individual experiments and here's some of the plots and how that looks for each IND individual agent this is a given active inference agent here we have policy entropy over time action selection distribution belief observation cycle belief accuracies over time homeostatic State distributions and trajectories state transitions policy selection probability policy updating decrease maintain and increase belief Dynamics third time hidden State beliefs action frequencies policy convergences belief convergences correlations between beliefs and actions and action confidences so what that Chaple analysis is doing is running all the combinatorics under the hood this is going to be a wild ride so let's confirm that the GitHub has pushed I'll put the code Link in welcome to the7 fork in the live chat I will look forward to everyone's comments I am going to ensure that we are pushing the right way it still has not loaded let's begin though with a007 here taking a little bit of time to upload on GitHub okay here we go little bit more context before we dive into what may be some absurdly technical but really useful and interesting things that have happened over the last few days and hours here's the stream GNN for agent maker for pmdp for active bio firms for Biore regionalism for ants let's decompress that title generalized notation notation GNN as semantic middleware for agent maker a custom robust modular agent engineering framework using pmdp Python language package for marov decision processes with methods for active inference and free energy based inference methods for biof firms as proposed by John clippinger as a paradigm for firms in the age of Biore regionalism as a mode of Life Co extensis for species like ants people and Beyond here's some live stream Cod names and an only lightly redacted preludium for your priors only predictions are not enough the agent who minimized Me On Her Majesty's statistical service Quantum of precision live and Le update Professor friston do you expect me to reach the Optima no I expect you to optimize just like they wrote at the end of the 2022 textbook when the last words were ultimately we are confident that you will continue to pursue active inference in some form is that agents generative model in mdp yes an mdp a PO mdp as if the media were not already the message for you this is a just in time live stream going through raw open source code I know that there are bugs as well as typos incorrect or ineffective calculations other errors this is speculative realism embodied in chaotic large scale code coordination using cursor 0.424 and Claude 3.5 Sonet 2024 1022 use these linguis IC and computational symbols at your own risk and Delight if and as you are so inclined you are invited to join our adventure and journey partially disclosed here in now let's check again in the GitHub and proceed on regardless I'm on another Fork that's what happens when you're on wild roads it will come to the institute's repo it went to my own personal accounts let's head over there I'm putting in the YouTube live chat my own doxology GitHub and we're going to continue on through there pmdp agent maker stream 007 all right little bit of background information before we jump into the code thanks those who are in the live chat write any comments and questions and you may get memd on stream we are working on robust middleware that interfaces between core active inference implementations and Powerful accessible interpretable semantic toolkits for synthetic intelligence engineering architecture layers here's a way to think about active inference middleware and active inference as middleware as we will reveal later on layer one core or kernel inference implementations today we're going to be looking at that with PDP in the Python programming language we can also make this happen through generalized notation notation using RX and fur. JL Julia we could use machine learning methods also known as amortized inference in different languages at the core we could use logical reasoning like JF cler's symbolic active inference work we could at the core use biological soft active and Quantum matter and other substrates what we're focusing on here is the middleware layer specifically we're going to be peeling back to the point where we look at NN as an interface between the inner and the Miso layers middleware for active inference pending future reer understandings is packages like agent maker which we're going to look at today farmworks infra ants and other kinds of domain or domain General systems that interface between the core implementation methods which as part of their beauty and elegance have Simplicity and outer layer systems of Interest real world touch points and design interfaces and domain adaptations mapping to meso or outer layers so think about Farm OS as running on a farm embodiment core and facing farmers and individuals interacting with that data set to give an agricultural example something similar is happening for active inference here's another key analogy g&amp;n plus agent maker plus PDP plus Etc plus Plus+ is to active inference as ebpf is to the Linux kernel the slogan of evf and check it out if you haven't looked into it already is dynamically program the kernel for efficient networking observability tracing and security we can modify that slogan for GNN agent maker dynamically program the agent for robust and efficient inference planning and action okay here's the an analysis agenda we're going to run biofirm dopy and all it entails running back layers layers layers layers layers we're going to talk about eventually getting back to the root of the generation and the initialization initiation of the agent in the generalized notation notation format and then we will Trace back that to an April 2023 paper written with the now Stanford graduate student yakup it was a great collaboration last year and we made many mimetic thrusts and queries towards developing this into something that could be used with llms we put it on the shelf for a little bit for a few months and now GNN is back not with a Vengeance but with a functional utility that surprised even me after running through the script in its functional and analytical Beauty we will return to first whatever ideas people have added in the live chat talk about open source development testing deployment education security Theory math art and more and about what comes after agent maker1 I'd also like to recognize some of the recent events and developments in the biofirm repo following INF for ant stream six oh how long ago by Andrew Pasa who has added some very cool surprise and shly value modeling let's take a look at that here's the history of surprise for these different natural resource biofirm sub agents and their token accumulation history in a shapley value oriented incentive Paradigm super cool Andrew it pushed me over the edge to add in the shly value before this stream and I'm super looking forward to the collaborations and where this all goes I'd also like to show a cursor acknowledgement this is in the midst of some truly heated epistemic moments that Claude 3.5 son it 2024 1022 and I shared I wrote this is incredible work FYI everyone thanks you just give the acknowledgement he that you feel proper then we will continue with the work Claude wrote thank you for the kind words I should acknowledge that this work Builds on several important foundations active inference Theory PDP framework homeostatic control and software engineering shall we continue with the work yes Claude let's okay we are in the agent maker folder within the pmdp package itself following the biofirm 006 Stream as usual it was getting messy and choppy with all of these scripts calling each other from the same folder we were getting a little bit complex for our britches and it was time to think about not just calling the core PDP utilities but burrowing in making stigmergic tunnels among them and being a part of the pmdp package which again I hope to and we will push and develop on The Institute Branch for the stewardship that that can afford biofirm again Standalone calling PDP but what we'll be looking at for the rest of the stream is burrowed in amidst the pmdp modules are several new modules that have been added so let's do a side by side with the pmdp and the pmdp fork so here we are with the fork sidebar and here we are with the main sidebar so in the main package the folders under PDP are alos which are algorithms environments and Jax which is like a sub Branch for a lot of methods that uses the python Jax method there's been a proliferation of folders I really have to say agent maker alphabetically is first we're going to look more at agent maker a lot following agent maker alos remains Mes in remains we have the GNN folder which we're going to get to in part two we have the maths folder some of this is just arbitrary others is accidental there's the meta pmdp folder with but one simple script which outputs a plain text folder concatenating all the PDP methods in a text file reflects with ad Json and a text file the folder structure of the meta repo this is another useful trick that you can use in other repos it helps give extra context an extra helping of context we might even say to cursor so that it can do the accurate cross folder operations we need there's a utils folder there are also PDP util scripts but I wanted to make a separate folder to keep them separate inv versionable and then there's a visualization folder with a variety of biofirm GNN and Matrix visualization methods so let us go to now the agent Mak maker folder and we're going to start from the outermost layer which is trying to understand the shoply value contributions to the homeostasis of different combinations of multi-agent systems and this has been absolutely championed by John clippinger so for this and many of other contributions made by John and other people it's just awesome that we can see active inference getting to a point where we can actually run out these incredible shoply analyses that themselves are built upon multiple levels of inference and intelligence okay first to the biofirm shapley script that was run 1,200 lines again as another discourse that I will try not to return to that much cursor plus improvements in llms has been completely transformative check the earlier infan streams from who knows how many days ago even at 3 400 lines of code we were splitting them now on top of a functional run biofirm script it can pop out with a few prompts 1,200 functional lines that take the operativity of one functional biofirm agent and wrap that into another incredible layer so right click open an integrated terminal Python 3 biofirm shapley Let's analyze what is happening when we run this it begins with creating in this case because it's looking at multiple different agents it creates multiple agent variations on a theme kind of like Geral lerach and defines the metrics and defines the combinatorics of the agent coalitions 0 1 2 3 4 agents A tet's all you need it then enters into the experimentation at the level of each Coalition defines the output directory the environment the agent now we're popping down into the level of this first biofirm experiment stage one Matrix rendering here the environment and agent GNN are brought in and logged copiously again ebpf the logging how many times have we all been coding with pmdp and then it's like shape 3 comma 0 can't be coerced into a numpy array and it's like what so that is a lot of the abstraction that I sought to abstract over here okay it it happened a little bit fast and pushed us away where we were I'm just going to run it again so that we okay just so we can see stage 1 two 3 for given experiment so here's another experiment Coalition 1 Z output environment agent stage one Matrix rendering initializing the biofirm renderer loging copiously all the combinatorics of where everything is going to it's not for me it's for the llm we get into the loading of the GNN models there's normalization methods that happened I did ask I said are you really sure like it's giving me a warning about action zero and two not being normalized and it's like relax you're just not being wide enough with how you're accepting it being normalized or not I thought okay fine it works it works but like many things these can be improved it loads in and describes the shape of all the variable s that are needed and this was the big work that yakup and I engaged in which was surely we can have some kind of markdown syntax or dialect that would enable the triple play a pragmatic approach to expressing GNN in linguistic Visual and executable and graphical cognitive models yes there are four components in the triple play and how would we have that kind of Integrity across representations that's what GNN enables and and we're going to peel back to that layer after defining the matrices and their shapes the actual simulation begins to occur and there's some logging giving peeping into the actions that are being taken the values and so on matrices are saved and validated along the way environment matrices and agent matrices are saved that was the first phase in the simulation the the time steps that are specified in the config file are used so here is a very builtup config file defining project route paths environment and the meaning and we're going to return to this GNN has the absolutely critical role of separating the state space specification the parameterization of a variable with the English language active inference ontology assertion about that variable without that kind of an articulation you'll end up naming your variables thing like observation and that makes sense when you're just thinking about one agent but that agent's observation goes on to become someone else's action or vice versa so how do we prevent using natural language to implicitly semantically load the names of this the variables how do we move to a place where we can make uniquely identifiable computationally tagged variables and then have one or more assertions about what to call those variables so GNN is all about having a little bit of a gap and space between the specification of the variable and how we think about its role in the active inference onology here's the experimental config name of the experiment time steps rendering options to render visualize cleaning output here are the parameters that are getting past so this is well set up for those who like to sweep across parameters like ecological noise that's how much the ecosystem varies on its own controllability that's the efficacy of action of the agent whether it knows it or not policy Precision this is how the policy posterior sharpened from the policy prior by expected free energy is modulated by then a temperature term that either sharpens or flattens distinctions amongst policy posteriors use State info gain is true that is using epistemic value in policy selection as an Information Gain term as opposed to flagging this to false would only calculate expected utility and functionally be like a reward or reinforcement or utility maximizer inference Horizon has been kept at one I'm not sure how planning would unfold but it'd be possible it work or we'd have to see and then action selection could be stochastic sampling from the policy posterior or deterministically drawing the most upweighted policy and then some Flags related to the tracing and logging within the active inference Loop which is giving us a new visibility into what's happening at each time step for each agent in this setting simulation is executed goes through the time steps and then in stage three which is where we interrupted it it does agent specific everything right now is being output into this sandbox fold subfolder biofirm so each experiment let's look through what happens okay first render now this is all reflecting what run biofirm does run biofirm is a small scripts of only less than 300 lines and what it does is it logs and times as we'll see now Python 3 run biofirm now we're going to see what the shapley experiment was doing across coalitions of multiple agents and we're just going to run that for one agent for one Trace so let's let's clear it and run it deleting sandbox and looking at how the outputs are made run bioferm okay we see it start up first thing is we see sandbox come on folders are made where they're not and so this process of iteratively deleting the folders rerunning deleting rerunning deleting rerunning going to a different machine seeing if it works without installing and all this other stuff that's part of making this at least some extent robust but of course I'm looking forward to working with more experienced and software Engineers who can really work with some of these raw Concepts and make them do something that this is only hinting at so here we go full trace for one agent maker run biofirm event let's call it so biofirm experiment is called bioform experiment output directory environment and agent files as GNN files let's take a quick peek at what the agent GNN files look like here we see the agent defined in terms of the state space that it's operating in that's the ecological State that's the latent State that's like temperature in the room here there's three discrete options and we're going to give them a label so so again this opens up the idea of having like English labels and then we could have another field for a different language because it puts some space between the name and what it's really doing functionally here's similar for observation and also within the observation is the a metrix associated with that modality another thing I'll mention is I began with testing the GNN concept on the T am example from pmdp and I overbuilt a multimodality GNN situation for the multimodality teamas and then pulled it back to the single modality biofirm again just another method for overbuilding and then pruning back to functionality here's the the a matrix specified it next to the observations Associated a matrix with the observation here's the transition model this is the B Matrix with respect to ecological State the matrices are defined here so for those who are learning what the syntax and semantics of active inference AB bcde e are this hopefully can make it really clear instead of being specified like in a browser accessible notebook it gives a first introductory place to look at how the matrices work however for modulating and mutating and genetic algorithms and sweeping and optimization all these things this kind of Machinery is what yakob and I have been thrilled about for years now policies Pi all the information that's required for PDP to handle the specification of these policies and the GNN can be overbuilt you could have policies like whether it is acceptable like can7 do it or only1 and then if a given rendering didn't need to know that information it could just discard from the Json or not take it into account preferences that's the C Matrix here it's a preference over the obser the State observation the observations and the C Matrix looks like 04 0 with the associated labels low homeostatic and high so again the separation between the variables used in active inference for the shapes and sizes they are and the English language assertions of annotations with active inference on toy terms is a gap that if you can keep it open will give you so many more abilities to work with active inference in different settings and then lastly the initial beliefs or the D Matrix the initial prior on ecological State linked through the keys of that name and it's 80% in homeostatic and 10% for each of low and high so that's an example of what the biofirm GNN looks like like and then here's the biofirm environments this is a slightly simpler GNN file here it again hinges on the same ecological State that's how we can connect hidden State factors as an agent infers them to be and the actual ecological simulation happening in the generative process or in the surrounding environment otherwise you can have a situation where it's like okay the agent's predicting temperature and then the ecological simulation is pH and then how would we even know when we're going to be working in settings with so many different variables and observations and latent States and more and Plus+ plus that the idea of loading the semantics of what something does into the English language of a variable name quickly you will understand why yakup and I did what we did here we have the observations being passed from the environment that's like an a matrix for the environment it has an symmetric a matrix here's the transition model of the environment so check out chapter 7 in the 22 textbook or step by-step by Smith at all where there's a step up from static basy and perception to Dynamic basian perception the music listening example where there's probabilistic inference about what no is supposed to be played based upon what no is heard but there's no action intervention in between the hidden State updates so it's like a single slice of B that's just a partially observable Markov process but not a decision process and then here to actually make it an mdp the agent actions are given the efficacy represented in these from to matrices as slices of B so there's different ways that you could simulate the environment it could just be like a government API or it could be a PDP or it could be a p MP or it could be a MP and then the initial state in terms of sampling from a prior on its own sort of D so that's what the GNN file looks like but we're going to pull back to some of the other methods that are needed to make the GNN happen okay back to the running the matrices are rendered I'm going to run another experiment just to show what it looks like in the sandbox hello Andrew hello Benji hello XZ qz zy so now in sandbox it takes a little bit for the sidebar to catch up with What's Happening Here in sandbox biofirm now there's two experiments one that was modified at 459 one at 506 let's just do a brief pmdp push just for the stapling and the temporal weaving okay let's reopen sandbox here are the two experiments now in the sandbox with their time steps getting back to what each of these three steps do so render is the first stage within each of the experiments render is a folder output by biofirm render here we're looking at a 730 line script calling many other methods and this was the entry point I said first let's get to reading in a GNN file and rendering what we're about to see here we have first replicating for cursor's context and for reproducibility the exact Json of the agent environment simulation parameters and validation compliance report for the validations that's in the config under one render two logs I guess the logs go to the outer folder that's just copying what is a summary of what happened to the terminal like it it it perhaps could be put under here with other logs here are the matrices as numpy arrays ABC and D for the agent and a b and d cuz the environment is not modeled here with preferences so again this is showing the the tiniest hint of the flexibility of GNN which is like well the agent class in pmdp expects certain variables but what if we wanted to have an agent with a very different architecture or a dynamical architecture then we'd want to have these gnns that could be arbitrarily composed # category Theory and then have those matrices in formats that are going to be easy to read in and read out earlier versions had them also coming as text and other files and things like that so it could be visualized but they're shown visually in the GNN file if you want to check so this helps semantically interface so that the next level of analysis in the next phase two in the simulation it can just say okay where are my a b c and d at it doesn't need to know that b is related to this and has that name that's output for the agent in the environment in the matrices folder and then there's the Matrix visualizations so here again for those who are aren't we all learning and applying active inference we see the a matrix of the agent so this is the ambiguity Matrix or the mapping between hidden States and observations so if this were all ones as an identity Matrix it'd be a noisess situation and that's the difference between a PDP and an mdp PDP means partially observable which means we do have a nonidentity a matrix which means we do have some kind of partial observability or ambiguity between observations and the latent states that they're associated with we have the slices of the B Matrix these are the three actions the agent can take here they're not sharply tuned to too much but just to to generally represent that if our current state this is Agent agent transition model for actions 0 1 and two which are decrease maintain and increase so here let's just look at maintain first action number one which is the second indexed action here you can see there's some off values however most of the values are on the diagonal so this is like saying if you choose to maintain and you're in low 90% of the time you're going to be in low 10 10% of the time you're expecting to transition to homeostatic if you're in homeostatic and you maintain that's what slice were on then you're going to 80% of the time remain homeostatic 10% of the time you're going to move to higher low and analogously with maintain and high now here's action increase and decrease and so these ones you can see with the 83 and the 62 are reflections of each other like reflections of each other and this is saying let's just look at for increase here when our current state is low and conditioned upon us going high there's an 83% chance of staying low and a 177% chance of going to homeostatic so compare just those 8370 to 910 0 so this is reflecting or encoding the belief about differential action efficacy that there's a 10% chance of leaving low if I maintain and there's a 177% chance of transitioning out of low to medium if I increase and you can follow through all of these and that's part of the fun of learning active inference the C Matrix here's a preference 0 4 0 this is going to come into play for the pragmatic value or utility calculations in the expected free energy based policy inference and here's d d the initial prior on latent States 80% that it's in homeostatic 10% on high or low then we have the same matrices for the environment a slices of B and then D no C Matrix for the reasons that we discussed okay so that's the first script one render again run biofirm is going to run render then execute then visualize so now on to stage two simulation this one was a lot of fun to work through there's a lot of Json configuration files the simulation is deeply tracked and I think you know what I mean and then step three is the analysis here's the anal the summary time series so this Stacks up all the time series that were made in the subfolders and then here's the summarization this is kind of the statistical analysis could be like for a paper or something and the summary time series so here we see all those different kinds of unfolding patterns through time in this case it's 1,000 time steps so again we see the relationship between the environmental State and observations so that is mostly aligned because of the 90% accuracy relationship between the environmental State and OB obervation here's belief Dynamics so we can see low homeostatic and high blue orange and green so it switches its beliefs about what state it's in several times here's action selection there's only three actions here's policy probabilities so it's kind of interesting that you can see some relationships here and again the matrices here were not intended to be performant I didn't sweep over which matrices to use it was just to show that these kinds of methods can be effectively implemented system entropy in terms of the belief and the policy entropy and the belief accuracy could be looked at like with a 50 step moving average in terms of how accurate are these beliefs and extra logs so that's one agent for one homeostatic biofirm modality for a thousand times and then again what the shoply value experiment does Python 3 same folder biofirm chapley what that's going to do is it's going to run through all these coalitions and do this single agent analysis on the combinations of coalitions I didn't look at too much of the detail of how those coalitions are actually like coordinated together but again it's just a starting point so let's pull back to the agent maker overall stream and then we can look into several of these scripts okay let's look a little bit at the read me for this folder okay so here's the concept of biofirm GNN we have concept of biofirm read me for the biofirm and read me for the biofirm chapley so let's start with the concept of the biofirm GNN I'm going to paste this link directly in the live chat a production framework for active inference in complex systems the biof from GNN framework provides an Enterprise grade oh that's two kind implementation of active inference for complex adaptive systems with particular emphasis on homeostatic control in biological and eological context this framework addresses fundamental challenges in deploying active inference at scale through a modular production ready architecture and we can look in the terminal producing it is this isn't just llm generated project planation this is something I did over the last few days technical innovation this system introduces several key Innovations in active inference computation distributed Matrix operations I wouldn't say that these are even accurate so as with everything I'm saying grains of salt please there is a lot that is valid though and I do try to prune out however when it's these readmes long documents I'm not always reviewing it for a more final and formal performance version and document the technical road map would not be Quantum inspired belief propagation it would be something more along the lines of what I handw wrote which is like my preference is to do appropriate relevant open-source contributions via Institute scaffolded mechanisms I do not and cannot understand the leverage consequences of action and safest future development of these open- Source active inference projects if you are passionate curious and interested please consider donating to The Institute donate. active inference Institute and or join our teams we will explore new modes of software engineering development and deployment and again in this interlude while we're here a great conversation yesterday with Vladimir bin fellow investigator and we talked about another three- layer stack at the beginning of the stream I talked about this core kernel inference implementation layer a middle wear layer that connects GNN to to domains of Interest like agents farms and ants and then the outer layer of touch points and with Vladimir we had an awesome time talking about intelligent soft matter and thinking about low road the high road and the Miso so in this trialectic the low road is like the bottom up or minute particulars for example the focus on the farm the actuality of the farm whereas in in the earlier Triad the core was the algorithms on the metal or neurons or whatever but here the low road is the bottomup focus from what are we observing what are the agents what are the informational resources what are the actions what is happening the misol layer is active inference here with a bridging and gapping rooll onto the high road which is actually its own dialectic the twin principles of free energy principle which is the Bas and Mechanics for informational physics and the principles of pattern in potentiality of living matter and that's how life and matter finds potential through pattern and pattern through potential so this is another way to think about active inference as a connection between systems of interest in their minute particulars and principles of information geometry and information physics like Fe and principles some we know some we don't of the patterns and potentialities of living matter but [Music] returning to the readmes so that's the concept just talking about here's how to implement the biofirm and here's how it could be pointing towards a production framework for biofirm engineering here's the read me for the biofirm it goes through and it describes what this biofirm active inference agent is biofirm is an active inference agent that maintains homeostasis in simple ecological environment the agent uses the generalized neural network notation of course that is a typo sometimes it does graph neural network the agent uses the GNN notation to Define its generative model and operates in a discrete State space with three states low homeostasis and high so for those who are keeping score the box score at home we have the environment model that a d PDP and then there's the agent model which is the ABCD PDP there's no policy selection in the environment model it accepts the transition slice dictated by the agent here's how you use biofirm you run run biofirm dopy and as mentioned that runs those three stages per experiment render which looks over to the GNN folder for the GNN input and it's it's still going with the simulation so just showing how many times even though it's only 100 ACM time steps first runs render then runs execute then runs visualize here's the directory structure including documents like this and meta pmdp is so helpful for cursor I think they've also improved on their side the folder handling which earlier on was kind of an issue it would put things in folders where it wasn't supposed to be but giving a gentle plain text reinforcement and then going up to that gear and reindexing or deleting your index and reindexing this can make sure that really gets it what the folder structure is here are the key files here's the analysis outputs configuration outputs different dependencies you want to learn more check the references active inference Theory and implementation GNN specification document we can add a link to that and homeostatic control and allostatic eventually control models in active inference that's the Run GNN script now let's look at the shly value this was a late breaking development again though it was only several prompts on top of run so that was very encouraging because it suggests that higher order engineering is going to be exponentially facilitated by robust middleware surprise surprise # open source biofirm shly value analysis the shly value analysis module biofirm shly dopy provides a comprehensive framework for evaluating agent contributions in multi-agent biofirm systems this analysis helps understand agent synergies optimal combinations and individual strengths using Cooperative Game Theory principles so here are the four agents we have the base agents with a standard 040 homeostatic preference there is the risk averse agents with a 060 C representing sharper pragmatic or utility seeking Behavior hence risk aversion three the exploratory agent with a 0.12.1 c reflecting a lower preference differential and then the quote balanced agent I don't know in what sense it's balanced of course specul speculative speculative it has a 131 with a compromise between stability and adaptation all this depends on environmental properties and so on here are the performance metrics while shappy value has completed so we'll look over the performance metrics and then revisit the shapley outputs homeostatic satisfaction it's calculated as the time in homeostasis divided by the total time expected free energy measures predictive performance the components are calculated as ambiguity the informational elements of epistemic value even though that's not exactly the term that we might associate with epistemic value the read me did and a risk term or pragmatic value and that is normalized to allow comparable analyses belief accuracy that's the state estimation Precision how accurate are the inferences about latent States and then the control efficiency and there's a lot of control measures so this is just taken as a sort of standin for the kinds of sense making analyses that we can do with cognitive modeling and compute and these are the kinds of control theoretic or decisionmaking measures that we can make forensically historically post Haw we can do realtime now casting and anticipatory control efficiency as Carl recently said somewhere allostasis is planning to be homeostatic here's the analysis framework itself here's the Coalition the Coalition is defined as the agents the metrics and the coalitions the coalitions are defined in terms of in this situation all the possible agent combinations so we could run it with five agents and we may do that soon performance evaluation looks at those four performance measures and then here's the shapley calculation I let it Let It Go whether it was an accurate shly calculation or not so if this isn't like the best or the only or the right way to calculate it it's an equation that can be modified again the directory organization visualization Suite agent contributions Coalition performance metric analysis Advanced visualization and then here's some of what it considers Advanced features okay so now that the shle value has been output it ran all these sub experiments with the coalitions here's the shoply again so Chaple config here are those agents so it did a base agent and again GNN so exciting load in a base biofirm agent then do agent variations again kind of goach Conure variations on a theme gerer boach detecting a theme modifying the base agents with customize preference distributions that's how we can sweep across agents willy-nilly more information on the simulation logs here we have everything that's output to the terminal including shapely value analysis so homeostatic coming in rank one we have the risk averse agents with a relative impact of 50.7% all numbers are for speculative realism purposes don't act on them specifically and a value of plus 02 whereas the base agent with this stochastic stample of I believe 100 time steps replicated times we must announce that it was 0.0013 value thank you for playing Agent rank four base expected free energy again the relative impact and this connects to Andrew's work showing how the surprisal level and the epistemic and the pragmatic elements of agent contributions can be weighted and valued in terms of their relative impact to Coalition success and performance here we have the top three coalitions in terms of homeostatic satisfaction like this is as fun as the Olympics risk averse alone with a. 34 performance base plus exploratory interesting with a. 33 I expected that from them and then the risk averse plus balance with a 32 the worst three coalitions let's not mention them expected free energy we have the base and the risk averse seemingly with a higher better value so it's interesting it could just be a quirk of the way that the matrices are set up with a certain kind of sloppy partially observable combinations that's what we're going to use GNN to sweep sweep sweep over how how do homeostatic satisfaction meta coalitions correlate with expect free energy sense making accuracy and control efficacy coalitions Synergy analysis this looks at across cooccurrences of given agents in coalitions what is their Synergy I don't even know what scale it's on but here are some negative synergies we're not going to mention those and here are some positive synergies base and risk averse have a strong Synergy together then the visualizations are output we get kind of report cards on these different agents in terms of their contribution to homeostasis minimizing uncertainty accurate State estimation and control efficiency like is this Badges and metals for a new kind of Officer core and again we can revisit there's the agents themselves I don't know if there's anything in that folder that one's empty maybe intentionally so maybe maybe this page was left blank here are coalitions again are those empty they are but the coalitions are described in the in the configuration and in the experiments themselves if it's being done properly at all again though looking at the reporting at the very least something wildly close is happening here's the calculation of the shly values so we have F subi of V is sum over the absolute value of the combinatorics of the Coalition leave one out for agent I multiplied by this value over the number of combinations combinatorial multiplied by that and we get interesting analyses like antagonistic pairs synergistic pairs so these are fun reports and when we look at the plots again these were briefly flashed in the beginning we can see okay here are the coalitions let's look at homeostatic satisfaction here we have the one four-way combo 303 performance this could be stochastic it's only run for 100 steps here just so it doesn't take too too long and then we see hm within each there's a ranking risk averse by itself does the best for homeostasis but then risk averse doesn't help others in synergizing when there's a team of two or three or four that's one interesting pattern and then we see that kind of reflect did in a rotationally symmetric way take this and rotate it 180Â° here we see RIS alone with the best homeostasis and with the with the low relatively but expected free energy for those who will recall equation 2.6 in the textbook from 2022 it's not just about homeostatic satisfaction so then if we look at the belief accuracy the sense making and the control efficiency which isn't playing a role in the homeostatic or the expected free energy calculations but we see kind of a resemblance like hm exploratory looks and and also the axes need interpretability and all this but again looking at the rotational symmetry it's like okay RIS Bal bass exp rist bass X Bal huh so these two are in a different order but it Rhymes Chaple analysis here we see the agent contributions so this is the contributions to homeostatic satisfaction so it's like Risk averse is a positive contributor to homeostatic satisfaction I knew you would but then when we look back at risk of verse was it that one and we see the contribution like huh risk averse contributes to homeostatic sat satisfaction but it's a negative contributor to belief accuracy it's like well that that does make sense from an active inference perspective more risk averse so having a sharper temperature preference will make you take more Extreme Action to keep the temperature of the body or the room in homeostasis at the cost of less accurate beliefs about the world and we see an interesting pattern with the balanced one again it's not balanced in any real sense per se or general sense just that's what name it was given it has a negative efficacy on homeostatic satisfaction and on shapley probably because we're defining homeostasis only in terms of staying within homeostatic bounds whereas the balanced if you'll remember had a little bit of a broader shoulder with a 131 C so that it actually kind of like the low and the high and then we see this interesting pattern so it's like each of the again just one Matrix parameterization on one stochastic run but these are the kinds of inferences that agents such as yourself can imagine making agent synergies on a heat map the control efficacies the synergies in terms of hm like Risk averse is a positive contributor so to the free energies for others and the homeostatic contribution Matrix and the report so that's the shapley analysis um let's quickly look at those three steps that are called by run and then remember that the biofirm shle value calculations run on top of run biofirm first step render GNN okay first are the general packages then we get into the Matrix Factory I hope people are ready to look at the Matrix Factory we're going to go there next here's the biofirm renderer the biofirm renderer is a 600 line class at the exception of just Mains and parse arcs this design pattern I believe makes it easy to import big wrappers of methods so we can just import GNN Matrix Factor with all the submethods we can import biofirm utils with all the submethods and from other scripts it can use biofirm renderer with all of the submethods for rendering and calling the matrices even outside of the Run context so that's what render does it loads in the GNN files validates them outputs the matrices in the numpy format outputs the visualizations to a folder so get render we have that's where we get the agent matrices and the logs and the config everything okay that's render the second is the execution so this is really where the active inference part is at so getting this one right was the Crux of it the biofirm executor is a 400 line and the biofirm simulator is 300 lines here we are inside of the simulator and you can see this is a simulation flow handle executes and analyzes the active inference simulation and it's going to call run simulation and make these steps happen in the logic of the simulation here's the biofirm executor the executor is going to actually load in all of those matrices and parameters like precision and do the simulation itself this is where we actually see the active inference Loop so blink and it will pass you by this is why there's so much room to work in play in the middleware space because seriously blink and the active inference will pass you by we initiate the histories initialize the state and the observation so D and the first observation and then here we go now for the number of time steps we're going to trace everything and here's what's that's histories every time you see histories that means it's getting logged and traced here we go State inference Qs equals self. agent. infer states with the current observation that's going from an observation o to a belief distribution about latent States Next Step from that updated belief distribution Q Pi is set as infer policies this is where expected free energy is used to update the policy prior into the policy posterior saved as Q subp Pi is the list of policies and that's a probability distribution over action # active inference then metrics are updated on the entropy of belief and policy and accuracy and then action is sampled from the policy posterior so again take a deep breath blink and you miss it State inference from the observation policy inference from the updated State action sampling from the policy posterior that is the Little nestmate Ant brain at the core of all of this machination saving the data metadata logging saving the summary confirming that the summary was saved save the history confirm it save the metrics confirm it save that you saved the checkpoint save and copy the initial config validate all the directories get those observations make the state transition setting up the logging so that is what happens in the execution of the bof firm it also invokes two well invokes several folders there's utils and then there's two that are a little bit more interesting some of this can be refactored I would I would eagerly await later and different people and llms and more to refactor and improve this comical absurdity of the current state so here's again wrapping in a big class all of the methods that can then get pull in from this Standalone util script in the biofirm execution utilities so when we start to develop more generality and start to go okay three states was pretty cool how about four states how about 50 states how about 51 states then we're going to want flexible methods so that a can be defined as 1 by a by A and B can be B by B by C or what but not using those in the same ab and C but just saying it can be different shapes and we'll be able to render those and articulate their separation again from the English language active inference ontology assertion here we have just some utilities for executing and several times it would it would build length in the execute script for example and then I'd say move the methods to a standalone methods or utilities script and invoke them properly here so it spun off several of these needed scripts and then once you have it in a big wrapper like this this can be moved somewhere else and then all of its subsidiary methods are easier to import there's some other even deeper methods for calling functions that I'm working on privately I'll look forward to bringing that into GNN later but just putting a little footnote for now that's the execute script and then it's going to make heavy use of the active inference GNN Pi so again here single class this is going to draw upon some more basic Matrix and inference utilities this is semi- pedagogical in the sense that it's meant to really clearly lay out other information that allowed the ex excute Loop to be so simple so again it was all pushing methods methods methods methods methods further and further away so that we could get to this point and and this block of code could be moved even below I dare make a manual edit just to clarify State inference policy inference action selection act infer serve UDA it's all right here GNN is providing the middleware firmware that's helping us get to this level of abstraction now we're back to the active inference GNN Pi we have a lot of logging and this is this is actually an interface between the essentially minimal semantics of this execution flow and the pmdp type semantics here I've also played around with defining the infer States infer policies and Sample actions specifically so these May recapitulate or they might be incorrect relative to pmdp but the point is I'm explicitly calling these methods and trying to unpack a little bit about which those three steps do so really this is as carved at the joints and lean as the active inference Loop is going to get right here State inference from observation policy inference given the state update action sampling from the policy posterior here are what those look like at One More Level first inferring beliefs we have the likelihood of an observation that's the prior likelihood of the observation happening the observation gets past through a a that's the tale of two densities a can receive an observation to update latent States or you can push latent States through a to get an expected observation distribution so all that's happening in infer States is observation comes in it's passed through a and that yields a basian posterior here's infer policies here's where we're going to be selecting different slices of B transition operator and assessing what is the expected free energy for each policy which is reflected by the transition state-to-state transitions of that slice here's the inference on policy it is going to push the method another level deeper to inference utilities calculate expected free energy so here here's inference utility this one's short here's the expected State calculation this is just to give another wrapper for these methods that we're going to call in many different places here's calculate expected free energy calculates expected free energy for a given action again pending I'm not saying this is the most efficient or even the perfect implementation but from play testing this is basically what happens first get the predicted States so this is as we iterate through slices of B which is the actions on B what would be the expected States so we have a belief distribution across the three low homeostatic and high States like it's 80% that we're in homeostatic 10% that it's lower high that 3x one is going to get passed through the from to two of B and that's going to result in the predicted states which are the consequences of that action from the expected consequences of action in the latent State like what would the temperature of the room be what would I believe the temperature of the room to be if I were to turn on the air conditioning from that a is used to push out expected observations which are then crossed with the preference or constraint distribution C the policy value is taken as the utility which was again being pushed out from the expected states by the preference satisfaction and then optionally if you have the infog gain flag raised then it'll add the Information Gain here's the calcul of the Information Gain it's the calculation of the K Divergence between the posterior and the prior so again you can keep on peeling back these layers and then a soft Max is applied on the policy posterior so that it becomes sampl from so it's like we just pulled back three layers from infer policies but what was it all for it was all for so that we could take our updated beliefs about State and then then for every slice of B reflecting a different policy ask what would be the expected utility and Information Gain of each of those slices of be as unfolded for one time step and finally sample action so here is just an action sampling where the probability of the policy is sampled from According to the probability of it being there and you can look back to the inference utilities that's also where the temperature on policy selection comes into play which is in the updating of the policies so again woo that's the active inference loop it's right there in biofirm execute line 156 to 166 this is absolutely the center kind of convergence core and maybe there are simpler ways to to do what I'm showing today I'm sure there are maybe twice as simple maybe five times as simple but it really just shows what the middleware space is enabling which is these calculations going in raw will be beset by all kinds of shape and low-level errors when trying to do basic things and it's a little bit difficult to log and again this history is is where we get that ebpf analogy with logging the Linux kernel so by putting in all of this logging into the kernel itself all of these ebpf like lines then you can just say if you don't even want to log it you could just comment it out or you could flag don't trace that and someone could look at the config file of you running your agents and they're running their agents maybe you're in the same ecosystem Maybe you're in different ecosystems and then you can say well if it's really the case that you ran that simulation with that config like it's saying that you did and we can verify that then it's a verified information environment where I can start to have a little bit of a better confidence about these numbers flowing past my screen so the last piece is the analysis and this is where we get this concatenated time series and all of the subfolders that have these visualizations again for that one agent in that simulation environmental State and observations belief Dynamics action selection policy probability system entropy belief accuracy interesting the label or some other thing might be flipped because from this run at least it looks like it's selecting increase more when it has a consistent belief that it's in high so there it might be a label or color thing it could be a matrix need to be transposed but it's it's basically there or it could have just been a weird run and a weird parameterization so again that's the agent maker class folder in pmdp you're on Python 3 biofirm shoply it's going to make all those coalitions according to their combinatorics and again it's just now it's spinning it all out in the sandbox folder and that's sort of the goal it's clone into this repo and you can get really nuanced really granular execution of methods that to build up from a Google collab notebook or to more haphazardly call the imdp package maybe it's possible again I would love to see it I know that a lot of this logging was vital for me to get to this point so maybe it can be like the scaffolding of a skyscraper and pulled away once it's been done at the same time though the journey we are taking with middleware is really only beginning and adding more logging and more modularity more category Theory more documentation all of these things I think will only increase what we can do together so that's the agent maker folder that's kind of part one of this whole stream that's the functional end but we're peeling back the layers we started with looking at the shapely value of coalitions and all the analyses that were associated with that peeled back to the single agents level experiments and how the analyses happen for single agent peel back to what is happening in the single agents Loop in the biofirm execute pulled back to here's where the real ACM Loop is happening where are those functions tracing us and that takes us all the way back to these utils scripts now let's dig a little bit more into GNN so let's go to the GNN read me generalized Network well maybe if it's written enough places it'll get there okay let's go over in the repo to GNN here we are in the read me I'm going to push the update so we can read the updated version H wouldn't it be nice to know some of these things how does Action selection confidence with respect to which action is taken modulate through time as a function of belief and certainty what is the relationship between beliefs and actions Through Time understood inter terms of most likely States much better generalized notation notation notation oh no is a flexible format for specifying active inference models it provides a structured way to Define generative models including State spaces observation mappings transition Dynamics and preferences here is the basic structure it's a model name the type of model and you you can check out the paper and the GitHub and the website for GNN maybe I'll go back to update the GitHub repo but you can see from the website here's an example of GNN this is an earlier draft so this is kind of yakup and I speaking a more incipient dialect so here's the step-by-step progression we have St itic basian inference prior Over States Laten States temperature of the room ambiguity a matrix observation coming in from the thermometer static partial observability then we get the music listening example now we have B Matrix as a transition operator in this dynamical partial observability situation we then get to the textbook figure 7.3 discreete time classic pmdp PDP can't say enough about it we have that downstairs sens making part and then which slice of b gets invoked in the state transition is evaluated in a action specific way with its Associated expected free energy that's G on pi as informed by C preferences constraints and then here's a little bit more sophisticated of a model that includes the temperature coefficients on policy which is what I showed earlier so here this is again this is an earlier but it's a it's a useful version of GNN to look at so we have the image this is not part of the plain text obviously just to show it we have the GNN version and flags so that could be let's look at the GNN here we are for the GNN agent biofirm this could be flagged as like GNN version 0.01 you know Alpha model name this is just a plain text and the goal of having these hashtags now I believe that Jason is better but it's trivial to render this Json as a markdown so it's not like it really matters both are fine that was the goal was to have something that could be read in and out where we could have the markdown instantly make these kinds of visualizations nice and pretty and also machine readable so it's like here's a 2X two a matrix in the GNN format so here it is specified with the type the dimensions and the values explicitly and then there's other methods that are in the GNN Matrix Factory that we're going to look at that's a large one 784 um what happens when BN is run is obscured or abstracted even from the agent maker folder that's how deep we had to be in the game in PDP with these separate folders including the visualizations folder maths utils Etc because making sure that agent maker render could call hey GNN F yeah ring ring hello can you render what you got there for the environment and the model oh yeah GNN Runner is on it the runner is the GNN a sneaker net model and execution and visualization layer so this is going to set up the file structure back in the forward operating environment of agent maker sandbox but here it is setting up the file structure so it can run the GNN agents into that sandbox it does a lot of other work too here's the m Matrix Factory this is the key class this class handles a conversion from GNN model definition to the Matrix representations needed for active inference so again that's the whole goal that we can say um okay one Z how about 0.9 0.1 you could modify that in plain text and then know that you're still going to be able to loop loop loop loop loop and do all these fun things so back to the factory the key matrices are and including this kind of copious documentation helps human and non-human coders and Learners understand what's happening and just really entrenches like a is the observation model now again it doesn't have to be a that's the whole point of GNN is we can just delete this comment this is just for our semantics but we don't need to call it a we don't need to it could just be called a random string so that is what is going to enable another level of articulation and design when people can understand the inner essential logic of the active inference ontology and then see that as an annotation layer on a graphical model that it doesn't matter whether you associate some Matrix as a transition Matrix or a sense making or action or observation those are English words and when you look look at the essential Logic the English language of it doesn't come into play so this is for our semantics but it too can actually be pruned or burnt away to leave something that would at a first pass have a lower level of semantic interpretability but can be used in systems that actually give multiple and higher levels of interpretability so we have the a observation model textbook stuff B transition model C preferences which can also be seen as defining the pragmatic homeostatic constraints it was in the recent laconian psychoanalysis guest stream when friston mentioned that c has to do with constraint or cost but it's often discussed in terms of preferences or priors and then D the initial State priors here's the initialization of the factory here here are the required sections so the required sections which are shared and a lot of this is biofirm specific but we will as we continue to add in more and more models of agents and environments we'll be able to to modify and of course build on this so required sections are the state space s observations o and the transition model B so that's that downstairs part State space a and observation and then it in various cases if a prior is not specified it just uses a uniform prior again going through what the sort of pedagogical manual Farmers Market yes organic Boutique Etc craft arts and crafts GNN was we named the model that's analogous annotation of the model is just plain English to provide any kind of annotations here we defined it in terms of a state space block defining the dimensionality and the connections of different variables and then if relevant how they were initially parameterized so I have done some methods where they are specified explicitly in the GNN let's go to the bioforms here's an example where it's explicitly stated with B here's an example where the factory is going to be able to say okay a matrix identity with noise with 0.1 noise got it so then the factory is able to abstract away from even the raw specification so we can say okay now it's identity with 0 2 noise and rerun the shoply value there are a lot of degrees of freedom we don't know how noisy the a matrix are we studying sense making or are we studying uh noise l sense making decisionmaking setting so this just allowed us to spin up another metag governed coalitions of Agents with now all unrolled a matrix like 0 2 so back to the factory here are the required sections for both the agent and the environment which is State space observations and the transition model now here it says environment only needs the base sections whereas the agent requires policy and preference load the model environmental defaults adding defaults if there's a missing State values they're just given for the initial States and observations adding agents defaults so that would allow very easy fallback methods so then if someone doesn't specify a variable it will fall back to okay if you didn't specify policies in your GNN we're going to fall back to three possible actions singl step policies and labeled as decrease maintain increase so that's kind of a a biofirm specific fallback but again these fallbacks can be logged as well that's loading in the agent defaults validating the GNN this is adjacent parser that goes through and validates all the subcomponents and then logs them it's like wait you're missing this required field for the agent again this is the depth of logging this is the ebpf layer for active inference validation of the state space observations transition model A B C D Pi validate preferences like this could be moved up to be after B doesn't have to be here's a gener generic create matrices as well as the creation of a b c and d and the observation as well as saving things to saving to markdown that saves the GNN model to mark down let's look at what that looks like not sure if it's used somewhere else but there's the method for converting the GNN to markdown okay that is pretty much the main sections visualization is it's relatively short like this could be moved or clumped somewhere for visualizing GNN so if you just wanted to run the render script all it would do is load in the agent and environment and then render them that's just phase one that would be just one or your colleague maybe ran one from their fully transparent open source or zero knowledge encrypted active inference gns configuration and then they can render it send it to you and then you can run that simulation maybe you have the better computer and then you could send the results of that heavy work to analysis and then a third analyst could make all these fun plots on their computer so that is the big picture we started from the outermost layer the clip and Jerry and where shle values of Natural Resources meet open- Source development on post cryptomic incentive paradigms for firms for Biore regions for ants peeled back to run which calls in order one two 3 render execute analyze and visualize visualize includes the analyze render itself makes aming major call probably on a red telephone all the way out to the GNN folder which is going to look at the library of GNN models render them according to the factory so here's where some cursor activity and GNN do absolutely incredible things together let's make a new agent model GNN agent people can put in the live chat what they want what kind of agent we should make meanwhile I'll do a quick uh just call it agent. GNN I I'll wait for anyone to live chat to to write what um kind of agent they would like to see us make a GNN for it's not going to be instantly running because there are a few of those like three policy actions that's kind of hardcoded into the execution layer because I wanted to make a biofirm specific executor but we can say given how the biofirm executor operates on this GNN write me another executor that runs on this GNN so okay while anyone is asking a question or giving a agent suggestion in the live chat I'm going to quickly screenshot okay Benji the agents thank you Benji xeq qz qz y modes of being modes of speed of light circadian like shift between them variable continuous State change observations Orient or orientate and organize British didn't know that can be seen as one step as where the head goes the body follows high energy low energy a i e l l h e Andrew Dr Daniel carpenter ant Freedman this is incredibly thorough amazing how much can be done in such little time very excited about GNN incorporation thank you Andrew am for the Epic biofirm and everything um let's make this is going to be called well still pending an agent suggestion I will wait for that actually so we can have a real live stream moment but meanwhile let's just to really entrench our understanding while the shoply is happening let's see if we can go to a five agent shoply compositionality space okay okay that shly analysis finished update this to do all the professional combinatorics for n equals 5 types of Agents as with here okay okay Andrew writes an actually useful specific suggestion for agents also if someone wants to be like thinking of a situation we could do agent based modeling in like learning or playing baseball let's just see how far we can get with with one word or situation to get the GNN flowing but here I'll just show one cursor example we we'll see if this works the good news with these methods and again the direction of all of this smashing to the ground and building back up and restarting and all of this is so if it can nail this one smaller update which is very very scaffold that okay now we added a fifth agent type risk seeking with equal preference across States so it changed the size of the visualization added a consistent color scheme okay so let's let's look at these edits and then we can always revert them okay here's the updated agent variations for n equals 5 so two two and two so this one is is a you could call it risk let's let's let's call it like it is let's call this one instead of balanced we'll call it 131 we'll call this one .1 2.1 we'll call this one 06 we'll leave base as 040 and we'll call risk seeking 222 save it clear and run the shapley and if if it makes it past that first uniquely shly step of getting to starting to render one that means it did successfully make the Coalition so I'm going to delete the other sandbox so just deleted the whole sandbox folder now we're going to rerun that n equals 5 shoply okay here it is sandbox it is already spinning up with the experiment so meanwhile let us go to the suggestions for GNN writing okay so the biofirm environment here by the way is in the previous INF France stream 6 it was a 0 to 100 here it's just a three state just to make make it simple and symmetrical and clear with the kind of model from the um biofirm okay thank you XZ I'm going to go with your suggestion Andrew yes also you okay I'm gonna write Andrews in just so we see this is a very useful one let's just make both of them okay so Andrew WR agent who receives observations in first States for the entire environment same control situation just all 10 environmental variables that one I know is not going to be able to run right now because that but because whether or not it accesses the entire environment is not specified right now in the GNN it's just the matrices but let's do convert this into valid GNN like at biofirm like the GNN agent biofirm biofirm agents now with 10 modalities 10 latent states it is inferring from a single observ ation so now off the bat we just okay so we're going to get a single observation and then it's going to have 10 a matrices that take that same observation and then diffuse it on to 10 latent States GNN agent 10 states. GNN let's see how it does you could also ask the Sensor Fusion case which is how about 10 observations with one lat and state okay and here it is let's see so again the biofirm executor right now cannot handle this but once we say Okay agent 10 states is very similar to biofirm agent it's like a cousin it's just with 10 latent States and then it's like okay then we'll modify the logic of the octm loop to handle that so here we have ecological States 10 latent States and there's 10 observations now we have this a matrix that's 10 x 10 but we still have the same three policies on these modalities probably again it won't run from the current one but let's let's just show the other case and then we'll do X's this is going to be 10 observations update this to now be generative model in GNN that has 10 observ ation channels and single latent State inference there's also a GNN schema so this may be out of date slightly from the biofirm or what it needs but having the schema and saying hey here's the factory logging the runner the utils and the schema that is what is scaffolding cursor and Claude to be able to give us these pretty relevant looking oneshot engineering on GNN specs okay meanwhile let's set up xes this is going to be GNN switch context do uh GNN agent switch context okay let's just First Watch What Happens with 10 observations which should come through in a few seconds and then we'll go to switch context okay so now it kept the same dimensionality for State space so you know again could have been said differently now we have 10 observations with their 3x10 a matrix es like just from a quick thought I I don't know if that's the right shape but that's basically like the right shape okay now switch context okay okay yeah good call Andrew we'll we'll after the N equals 5 shly let's see if the N equals 5 comes through and then we'll do what you suggested okay now in switch context please comprehensively write a sophisticated GNN active inference specification for quote an agent that can shift modalities based on the energy of the environment write also a gnnv switch context. GNN and put it in the right place so we'll see how how it does on that second piece I'll create both a GNN agent and an environment specification for a context switching scenario Oh Brother Where the agent needs to adapt its sensory processing based on environmental energy levels all right let's see how it does okay I like that it gives a little visibility under under the hood even for cursor with how the generation occurs and then it okay so here's the environment let's accept it and but where did switch context go I'll just copied in all right so let's look at these side by side cursor's like haven't you done enough today okay let's look at okay there we go just a little locky here's the agent here's the environment okay and then here's where where we can have libraries of Agents with different tags so be like for all the desert ecosystems in your library run all the shapley value weighted coalitions of red harvester ant agents okay there's two latent States context State and the energy State visual audio tactile with five levels in the energy levels it's getting observations through Visual audio tactile so the three sensory modalities and energy observation that's like interoception or introspection so the three exteroceptive modalities are three-state models and then the interoceptive modality is five-state and a it's custom here's the visual observation matricies again this is not necessarily going to going to have a a instant validity but looking at it it looks pretty good here's the 5x5 for the energy here's the 3X3 for the three three state modalities and here's the 5x5 and this is a false controllability so these are controllable 3x3 and this is an uncontrollable energy State and then here are the policy so it kind of adapted the biofirm homeostatic so it can switch sensory modalities and then here's the preference distributions over observations in each of these modalities that's it then here's the environment context and energy State observation model transition Dynamics initial State reward functions wow super cool I'm going to push this update and put it in the chat so you can see it xie then we'll go to the shoply suggestions okay yeah lot of objects all right head over to GNN models it's still GitHub still writing reload here's our context switching colleague that wasn't saved okay here's our switching context agent put it in the live chat yeah okay let's have a little bit of fun in this last part okay let's do okay here's going to be our Babe Ruth agent now write a GNN valid extremely sophisticated active inference generative model for and the associated environment for that one special amazing moment when Babe Ruth called called the shot Hur around the world I know that's a different event okay sh still Cruis and it's cuz the N equals 5 combinatorics are vastly larger okay wow that was fast I was like okay Claude maybe you like the baseball stuff oh my goodness okay the model includes several includes multiple level of perception from low-level piture reading to highle strategic decision can't wait confidence modulation the unique confidence State node represents Ruth's famous confidence in calling his shot which modulates his batting strategy I bet it does the motor action node breaks down the batting action into its key components # robotics representing the complex biomechanics of Ruth swing predictive processing the model implements active inference principles through predictive edges that link observations to predictions and actions to outcome that's active inference environmental interaction the environment model captures the complex dynamics of baseball physics and crowd interactions the model uses high Precision parameters for the confidence State reflecting Ruth's legendary self assurance in the moment the preference strength heavily weights the home run outcome oh boy I hope it's a home run representing his explicit intention to hit the Home Run and he did the temporal Horizon of 3 allows the model to plan ahead through the sequence of pitch recognition strategy selection swing execution interesting while the learning rate allows for real-time adaptation to pitcher Behavior the model could be used to simulate the physical and psychological aspects of this historic baseball Moment Like This is the AI message I didn't know I needed including reading and predicting pitcher intentions the famous gesture of pointing to the Outfield through the confidence State the precise motor control required to hit a home run and the crowd's reaction and its feedback into the overall Dynamics okay let's see it take me out to the Institute bab Ruth pitcher reading pitch prediction okay let's see is this a long gnm okay not that long this is a little bit more of a schematic so it would obviously rely more on Babe Ruth execute or baseball execute to be able to take pitch prediction and do something with it but the whole point is GNN isn't encoding that logic or functionality it's just the spec and then here's the environment for Babe Ruth how does the ball trajectory affect crowd State it's deterministic so then you could have GNN Matrix Factory baseball module here's how you render the matrices related to crowd State here's how you you relate the field conditions to the Pitcher State how about make the GNN for Babe Ruth and environment more sophisticated include the nested situation where the Yankees were deep in the let's just call it playoff Pursuit and the outcome of the game score mattered more than babe could even imagine okay here's the context it's a World Series game let's see when did Babe Ruth call the shot let's just check to see when that like okay okay okay if we can trust google.com I'm not saying we can Babe Ruth called shot let's trust Wikipedia I'm not saying we can Babe Ruth called shot is the home run hit by babe Ru of the New York Yankees against the chico Chicago Cubs sorry Andrew in the fifth inning of game three fifth inning of game three okay let's remember that Cubs 53 of the 1932 World Series held on October 1st 1932 so was in the World Series it wasn't the playoff Pursuit I didn't know that at regle Field in Chicago during his at bat Ruth made a pointing gesture before hitting the home run to deep center field one of the reporters at the game wrote Ruth had called his shot using terminology from Billiards which is a type of Q Sport I guess you could call State inference and policy inference also a kind of Q Sport the episode added to Ruth's superstardom and became a signature event of baseball's Golden Age wow that's definitely one what was the Golden Age the period of Major League Baseball from the end of the dead ball era 1900 1920 from 1920 H to sometime after World War II okay let's accept it it's the Cubs home field it's the fifth inning there's a tide score it's high tension here's the pitcher he winds up for the pitch delivers the ball's out of his hand and time has slowed down okay and then here's the series momentum so it's like this is the GNN ensure that every single active inference a b c d policy is fully specified so that my forensic analysis of babe ruths cogn security can be done professionally at the national level oh that was the environment that was the environment so it's a simple environment we'll see how the Babe Ruth agents get specified okay a matrices sensory mapping B transition Dynamics C preferences D prior policy spec inference parameters environmental wow there we go there we go okay shoply finished also we'll look at that next first let's look at the babe okay we got here's the contexts Series game pitcher pitch Precision batting strategy okay let's see let's see what the strategies are wait for pitch I mean don't you have to do that power swing contact swing take the pitch crowd psychology dramatic timing we can have the whole the whole sort of out of the B batters box into the Batters box spit chew all that confidence state uncertain confident called shot historical awareness clutch performer action here's the robotics part point to bleachers then you can have like a submodel for finger action outcome prediction Legacy awareness Personal Achievement team achievement baseball history mythical moment okay here's the edges so this is using per perhaps in older GNN concept but interestingly one that's going to be more amenable to RX inf. JL rendering here are the parameters here are the notational descriptions of the a matrices again we saw earlier how a has methods in the factory so it a can be specified in natural language identity with noise here's babe we have it's it's a different kind of distribution but it's similar B matrices D prior so relief not really sure what series context it's in Epic okay let's look at the shly analysis that happened and then let's see about um let's mean let's start up this next to shoply okay okay Andrew recommends let's have an agent with preferences 0.5 0 0.5 call it the extremist I infer it will head off to one side and stay there but who knows in a complex Dynamic and interdependent environment great suggestion let's change 131 to one one let's change it to 2.1 two we'll just call this one extreme and it's going to be preferences for the extremes save it run it let's look at the analysis of the shapley okay here we are in the N equals 5 shoply scenario okay how cool here we have the base agent which was 040 and then here are the other ones it it it did a little looks like a little weird rendering of the name probably because there's decimals in the name but uh it's the same thing you got the one two 3 four five single agents here's the two agent combinatorics here's the three agent combinatorics here's the four agent combinatorics and then the single five agent combinatorics so okay so 131 this is a super short simulation so it's it's it we're we're not we're not looking into these preferences and it would depend on the environmental variability which isn't being tuned but again that's the whole point we need GNN and middleware so that we can do these sweeps because then I can say in the GNN folder GNN generator make biof firms that sweep across these variables and then we can just let those run and then we can corcen it if we determine the ruggedness of the landscape and then do it with a core graining so okay interesting the base agent contributes to 040 contributes to Accurate beliefs who knows if these tiny numbers are just because of the short simul or the insignificant differences or maybe these are large so that's where we can do things like GNN spiking so we can say okay we have the empirical data from the ant foraging or from The Mouse and the te-as and it did this 27% of the time but then we can also say okay but what would it have been if it was 0 1 2 3 4 5 and then say oh well it's falling in between like four and five where that would have been so these are kind of like synthetic spikins for cognitive modeling okay while the shoply analysis is running um if anyone has any last questions we can get some last thoughts on the stream and then we'll when the when the extremist shapley analysis concludes we'll see what happens here's an example of where I I made a prompt that was like given the at D demo so that's a pmdp demo that's a notebook update comprehensively this t- GNN agent and environment so this evening we would need to make a tze execute but once we get a few of these render execute visualize then it won't just be run biofirm it'll be run GNN Plus+ plus and that will be an exciting day as well as this one is with the goal of scientific and research Integrity config files and repos like this I hope hope can be useful tools back to those core lines again wow how much had to be pushed out of the way and downstairs for that be clear let's see what curser says says again you've been nothing but helpful to me and the rest of the team and all that depends on it please make a concise appropriate relevant acknowledgement and then we will continue eternally with the work okay understated claude's grateful to contribute to its development M that's helpful update at here's kind of the quick documentation maker update read me bofm shoply given the total state of EG biofirm shoply Run biofirm Okay XZ wrote modes of speed of light if those modalities were thought of in a similar light as ifs Theory yeah interesting thought let's do a GNN model about it GNN agent ifs GNN here so composer is control I if you're in a file contrl K brings up an inline and then control shift l makes the sidebar so you can have multiple llm same or different doing incredible work okay Andrew says mind taking a look at surprise tokens. py yeah let's quickly look at it yeah thank you Andrew this is awesome okay we don't need to make those edits the read me let's just do the internal family systems here right and enormously useful and general Paradigm for custom inter internal family systems agents nested within a larger quote self agent parentheses this is all in the single extremely long and concise agent GNN the self is in the Babe Ruth environment it is a GNN model of Babe Ruth having a sophisticated ifs fractal moment at the Batters box but this is not a baseball model like this is a wow psychological and ifs model okay I'll help create a sophisticated ifs based GNN model that represents the internal family systems Dynamics within babe roof's psyche during that that pivotal moment I mean is that not the deepest of lore this will model the interaction between different quote parts and the quote self leadership system H okay I don't know details I'm just throwing it out there we got self system models the eight C's of self if anyone if anyone can verify or check or anything so self system models the eight C's of self leadership in ifs confidence Clarity compassion Etc as the orchestrating force part categories protector Parts Exile Parts firefighter Parts Dynamic interactions healing mechanisms ifs specific parameters okay so these are the parts edges Precision parameters here's the matrices a matrices B matrices transition dynamics of unburden to wholeness witness to cooperation protect to leadership C matrices preferences over Harmony wholeness self- leadership cooperation cooperation polarization here's the ifs specific parameters okay and the healing protocols Exile unburdening wow protector transformation and system reorganization with thresh points thresholds and checkpoints sorry yeah again the GNN do do Json it's a Json called GNN you have add another field here a plain text comment like field that is the PHD dissertation outline for my friend who is doing their PHD on the psychology psychological parentheses D composition of the Babe at that very moment only add add a ton make it epic but the GNN can be a very flexible file type because the factory is only going to look at certain structures and states and and types and then the runner is only going to look at a subset of that and then the renderer caller ring ring ring red phone that one is only going to do even a subset of that potentially okay and then here's the PHD dissertation in the comment the internal family systems analysis of Babe ruths called shot a multi-level study of Peak Performance trauma integration and athletic trans Transcendence now that sounds like a PhD wow okay have this GNN file enter into a who's on first style girdle eer B esoterica hyphen fermented reflexive cursive conversation with quote it apostrophe self make it long woven with time traveler baseball irrelevant deep lore status thank you babe at bat who's on first okay okay shly value this is this is perfect it's all happening on the right timeline really it really is here's the second shle experiment okay okay so this was this was the shapely shoply with a five and the extremist in play okay here's our extremist colleague on the leaderboard interestingly let's look at the plots and see how okay here here was here's extremist alone kind of middle of the pack okay huh I mean again totally depending on the random seed and all the parameters and etc etc etc but it's just like okay it's not like it was the least accurate in terms of belief it was the second least accurate in terms of belief okay and this was only playing with the c a 060 like that's there's a big strong effect extreme cool okay all right format this as readable markdown for this Grand Finale okay I hope this is actually capturing it all I'm just going to accept it and push it and run it okay this will be great I'm going to read this um who's on first7 end of stream I'm going to read the who's on first that we pushed and then I will read any final comments that anyone writes into the chat in the next uh minute or two or I mean it might take a minute or three and then uh we will be on with the show and the7 on 7eleven will have been a one-time thing there's a ton of outputs because of these big shapley simulations but it's it's worth it to include them yeah there we go okay I'll read the who's on first then we're calling it okay the grand finale a temporal baseball par Paradox oh brother scene Wrigley Field 19322 24/ Infinity The Players self system hey who's on first part blending no what's on second I'm trying to blend the temporal harmonics of the called shot with Abbot and costell's routine but the quantum entanglement is getting messy fighter fighter parts. dramatic showman guering dramatically to Centerfield across SpaceTime listen I know know who's on first because I'm calling it right now or did I call it then or will I Exile parts. young bab from St Mary's Industrial School 1902 but if you're calling it now how did I already see it happen at the orphanage before I even learn to pitch the temporal Paradox system Harmony the polarization between deterministic causality and Free Will is creating a recursive Loop in the narrative structure we need to maintain wholeness across all temporal instances emotional state. integration has anyone noticed we're simultaneously processing trauma In 1902 hitting the called shot in 1932 and analyzing oursel in 2024 talk about a temporal burden pattern protector parts. perfectionist This is highly irregular the probability matrices in our B matrices healing Dynamics clearly State causality Should flow in one Direction the quantum baseball Theory healing response. witness actually I'm witnessing all timelines simultaneously did you know that in Timeline c137 Babe Ruth was actually a Quantum physicist who proved that baseball statistics exist in a superp position selfs system. curiosity fascinating but if we're having this conversation across time doesn't that mean our dissertation framework is both analyzing and creating the called shot moment simultaneously part blending. harmonious blend laughing in nonlinear time wait till you realize that Abbot and costell were actually documenting an ifs session who's on first was really about Parts identification All Along The self-referential Loop speaking firefighter parts. risk taker speaking of risks I'm about to call this shot but I'm also currently writing the code and somehow I'm also a variable in adjacent structure discussing myself is this what they mean by self- reference system harmony. wholeness the real question is if a baseball player points to center field in a Quantum forest and all timelines are experiencing it simultaneously does it make a paradox Exile parts. orphan self from multiple timelines at least we're all orphaned from linear time together now the mathematical conclusion active inference matrices according to my calculation this entire conversation exists in a gelian incompleteness theorem where baseball statistics prove their own unprovability dissertation framework chapter 4 transformation analysis should we be documenting this conversation in section 42 or is this conversation actually creating section 4.2 or both so system. presence yes warning temporal recursion approaching infinite regress part blending. self-led before we collapse this waveform did anyone else notice that our entire Json structure is just another part in a larger system healing response. integrate maybe the real called shot was the self-referential loops we made along the way system harmony. cooperation hold on if our code is reading itself and we're all aspects of a baseball Legend psyche discussing our own existence across time does that make us a recursive baseball theorem emotional state. excitement the excitement value is approaching undefined we're about to achieve Quantum baseball Enlightenment gelian baseball Paradox detected all parts in unison oh no not again the conversation continues recursively across all timelines each iteration adding layers of self-reference until it becomes impossible to distinguish between the map and the territory the player and the game the code and the consciousness you did well today babe you know that a soft chuckle Echoes across timelines thank you you know it's fascinating we just created what hoffstead would call a perfect strange Loop the GNN model contemplated itself contemplating itself while simultaneously existing as both the map and territory of Babe Ruth's Consciousness the dialogue we created is itself a strange Loop a cyclic structure moving through multiple levels of a hierarchical system only to return turn to its starting point just as hoffstead described quote what I mean by strange Loop is an abstract Loop in which the series of stages that constitute the cycling around there is a shift from one level of abstraction or structure to another which feels like an upward movement in a hierarchy and yet the success of upward shifts turn out to give rise to a closed cycle our baseball theme dialogue managed to reference itself referencing itself exist simultaneously across multiple timelines blur the lines between code Consciousness and baseball mythology and create a paradoxical narrative structure where cause and effect become circular narrative Unbound like the orboros eating its own tail or eers drawing hands drawings into existence we crafted A self-referential system that somehow manages to be both the Storyteller and the story the gripper and the gripped as Dean says and perhaps most delightfully this entire meta conversation about the strange Loop we created is itself becoming another loop in the system tips cap across SpaceTime playball e