welcome blue i'm about to play the theme song [Music] hello everyone welcome to actin flab live stream number 35.0 it is january 4th 2022 so also happy new year to everyone welcome to the actinflab we are a participatory online lab that is communicating learning and practicing applied active inference you can find us at the links here on this slide this is a recorded and an archived live stream so please provide us with feedback so that we can improve our work all backgrounds and perspectives are welcome on these live streams and we'll be following good video etiquette if you go to activeinference.org you can find out more about how to contribute or get involved because anyone who is curious and wants to learn more will have a niche for you and you will surely learn and create all kinds of awesome affordances so if you're curious or you want to learn by doing please come get involved with actonflab today in active livestream number 35.0 we are going to be learning and discussing this paper a tale of two architectures free energy its models and modularity by majeed benny in december 2021 but kind of published in 22 and just like all the other dot zeros the video we're about to do is just an introduction and a discussion it's not a review or a final word and in fact we're very much looking forward to the two upcoming weeks when majeed may join us and hopefully many of you will join us and we're just gonna have a good time talk about the paper what did we learn from it and what are the implications today we're going to be more focused on the aims and claims the abstract the roadmap the background the keywords and there aren't any figures or formalisms but we'll go through some of the key arguments which are very provocative and very salient so if you want to get involved just get in touch and we will let you know how to participate let's begin with a little bit of an introduction and a warm-up so feel free to say hello and maybe just one thing that made you excited to discuss this paper so i'm daniel i'm a researcher in california and i was excited to read philosophical work by benny who always writes very interesting things and just understand how architectures of physical systems and their functional descriptions are related to the fep dean thanks danny i'm dean i'm here in calgary it's uh really really cold and snowy but that's not why we're here my real question was so what do we do about this seeming failure or attraction to the ability to categorize and so the question is do we model up and yeah so reading the paper i i kind of tried to figure out the answer to that i'll pass it down to blue so i like this paper from the perspective of like multi-scale dimensionality um and also modularity like modules at different dimensions um the scale-free aspect of the markov blanket and or the not scale-free aspect of the markov blanket and anyway i thought it was just really neat and a cool um way to fit the pieces together excellent so we have some slide with things that we want to discuss in the dot one and the dot two and beyond so at any point feel free to add information there and we'll be writing things there so we're not gonna get to it all we're not gonna make this a 11 hour video we'll get things down to discuss in 35.1 and 2. but we can lead in with the big question a big question which is how do we think about modularity of different kinds like functional effective and anatomical which we'll be discussing later in active inference and free energy principle and why does that matter why does it matter how we think about modularity of different kinds what does it mean on this slide are some images related to just different uses of modularity just modules like lego bricks other times modularity can refer to like part of a network that's more densely connected like a click other times modularity doesn't refer to hot swap ability but rather to a larger structure that's composed of smaller modules whether they're the same or different it's often applied to mathematical systems or biological systems so there's so many aspects of modularity and today we're going to be exploring what are those aspects of modularity and why does it matter for the free energy principle blue or dean like any thoughts on the general modularity question i got i got a quick question so for me when we see these sort of images that we externalized and artifacts and that sort of thing when i got it started getting to the paper uh the real problem for the modularity argument is what does localized mean when we're talking about fmri representations as the tool does a bump in electrochemical impulse mean a clearly defined border i don't think so of course not where one bump ends and another begins all inside the same energy field might be captured through my fmri imaging and is that misleading because there's no moment of stasis because the magnets inside our heads keep wearing constantly so that was again another question that i sort of tried to carry on through as i was reading what the author wrote out yeah where are we talking about modules where are we modularizing and does that map onto potentially realism and instrumentalism any big setting ideas blue or we can continue to aims all right so the paper that we're discussing is by majeed benny a tale of two architectures free energy its models and modularity and it's in the paper consciousness and consciousness and cognition just to go through some of the key aims and claims and then feel free to add a comment so the paper presents a model model-based defense of the partial functional informational segregation of cognition in the context of predictive architecture more specifically to defend the modularity thesis the paper computes two counter arguments that lie at the center of hippolyto and kirchoff's 2019 recent confitation of the modularity thesis to confuse is like to refute the main insight of the paper is that hippolyto kirchoff's counter arguments miss the mark because they dismiss a few rudimentary facts about the model based nature of dynamical causal models and markov blankets so that's why we kind of led in with a big question about modularity why does it matter because we're kind of down the road a little bit like okay modularity matters it matters how we think about and analyze and design modular systems and then how does it apply to fep and hipolito and kirchoff make a computation of the modularity thesis which we can look at soon and then benny is firing back with this current paper so that situates us like in the biggest scope of thinking about modularity h k 2019 and here we are with mdb 2021. so can i add to that daniel yeah so he does we didn't put encapsulation in here but i know we're gonna talk about that a bit but in order to be able to make sure that we don't mix things up we have to understand that encapsulation is a separation of what matters or what we consider to be a signal from the noise and i always think back to nate silver when i try to compare those two things so it's a momentary on offer it's a momentary in out not that there's a walled off section per se in the brain like we can diagram out or represent as a as an artifact fmri images however might coerce us into thinking that that's what's happening that there's actually a walled off section when that isn't actually the case to avoid the cognitive overload there are break stop mechanisms in our mind we don't have to tell our pancreas or basic ganglia what to do which then assists us in our ability to take the external states like these slides in and i think that's what benny was trying to point to although he didn't probably go into that explanation the way that i just did but i'm i'm kind of in defense of this author so i'm i'm starting off right now i'm in his corner i'm ready to tag up and climb in the ring so just to kind of piggyback onto that like when you're talking about encapsulating it's really talking about drawing a boundary around something and like isn't the markov blanket like isn't that the ability to draw a boundary around something right so so i don't know like this encapsulating markov blanketing boundary drawing like all of those are conflated in my mind and i don't know if there's like a separate way to tease them all apart or if or if i have cracked correctly grouped them great onwards so i'll read the first two and then blue for the second two the paper presents a model based defense of the partial functional informational segregation of cognition in the context of the predictive architecture the paper argues that the model relativeness of modularity does not need to undermine its tenability in fact it holds that using models is indispensable to scientific practice and it builds its argument about the indispensability of modularity to predictive architecture on the indispensability of scientific models more specifically to defend the modularity thesis the paper confused two counter-arguments that lie at the center of hippolyto and kirchoff's 2019 recent confitation of the modularity thesis the main insight of the paper is that hippolito and kirchoff's counter arguments miss the mark because they dismiss a few rudimentary facts about the model-based nature of dynamical causal models and markov blankets great so nice philosophy abstract here is the roadmap where we are going and so this has a fun roadmap there are nine sections there's the introduction and then there are eight sections with uh or dare i say eight modules that have kind of interesting names that we'll be looking into and there are not any figures or formalisms but the sections are here maybe dean will rejoin and uh welcome back dean um i need an ethernet cable from my heart to yours um the keywords are free energy principle model based science modularity and then there's dag directed acyclic graphs and then dcm which is going to have two different unpackings as directed cyclic models and as dynamical causal models and we're going to go through these keywords kind of as they appear in the paper we're not going to have a separate section so let's go right into the introduction section of the paper where we find somewhat of an epistemic preamble so not to read the whole thing but benny belongs to the clan of philosophers with karnap and kun who can see that the choice of theoretical frameworks is not completely arbitrary because some pragmatics affect the choice of theories so okay we have dispensed with the naive postmodernist perspective and more generally benny identifies as a naturalized metaphysician in the sense of ladyman and ross in that metaphysics is worthwhile when it is informed by our best scientific theories of the field so it's kind of just like a classy co-informing process between science and metaphysics and it is drawing on this work by ladyman and ross every thing must go metaphysics naturalized and then just like look at the chapter titles because it's not a book that i was very familiar with they're defending science they're defending a scientific realism and a structuralism so maybe we're not going to be in touch with the ultimate reality but at least we can be in touch with something that's constructively empirical and scientifically real they talk about the unity of science consilience like eo wilson and about causation in a world that's structural but also complex and so that's sort of the preamble where benny characterizes his own stance and kind of gives this background that is quite personal in some ways but then will lead into our understanding about the paper and the contributions so anything to add on that all i would try to quantify here is that he's not starting from a position of did you see that he's basically starting from a position of did you see what i see he holds that as being valuable great that takes us to model based science so as we saw in the chapters uh of ladyman and ross scientists use models it's kind of like saying we use maps on territories and there's so many kinds of models a few that we've seen are for example a graphical visualization of a bayesian statistical model and one example of that is like this partially observable markov decision process that we often look at and what do models do well that's quite a big topic but they represent hypotheses as well as useful models of conceptual or empirical systems and so there's many many kinds of models and some of them can be reflected graphically and in that sentence graphical is referring to visual like a computer graphic but also graphical like a graphical network and so we're going to be talking about the visual aspects of graphs but this isn't in a study in aesthetics this is going to be talking about the topology of graphs in their network sense but model-based science is just the kind of pragmatic perspective that scientists use models implicitly and explicitly and there are certain things that we can say about those models anything that either of you would add on model-based science i'd want to know who who disagrees who doesn't think that scientists are using models like is this just a total uh meaningless claim or are are there controversies related to this okay so let's look at a few different types of models specifically these graphical models that can be represented by networks so one kind of special graphical model is called a directed acyclic graph or a dag and so dags as their name would have it do not have cycles amongst variables so nodes are variables and edges are directed influences and there are no cycles in dags and so it turns out that computing dags it's relatively efficient and it has known algorithms so here is a image of a dag that i got from a 2012 paper in ecology and so the parameters are defined here and you can look for more details but just visually these are different modules of the model there's like this underlying process model there's the individual covariate model there's an observation model whatever those things are but one can imagine that you can like start at the parts that don't have any parents and then kind of drip coffee your way to n and y which are like the ultimate grandchildren nodes and then n and y don't feedback to change the other upstream parameters so dags are not um all of this exact shape or type but what makes them in a category is that they don't have cycles in the way that the variables are influencing each other that makes them easy to compute and relatively straightforward we can contrast that with directed cyclic models so we're still talking about graphical models here directed cyclic models or dcm have causal loops in the graphical models and so this can make certain kinds of computation more difficult i'm sure people can think about different ways that that might happen the direction of the edges determines the influence of one random variable on another so if it doesn't have cycles it's a dag and inference on those dags may be performed exactly using algorithms such as belief propagation or variable elimination like you can kind of collapse a subtree into a simpler system but with cycles it's a little bit more complex so that's the difference between the dag and the dcm directed cyclic model but then there's going to be another dcm coming up later any comments there do you think that the the looping can can be gets kind of a spiraling kind of a an accumulation effect that the dag model which with its narrowing and narrowing and and sort of elimination focus benny talks about the fact that they they're actually complementary but do do you actually think they're complementary as well i think that they exhaustively describe the landscape of graphical models because either it has a cycle or it doesn't but it's quite literally the difference between like dropping a coin in a little machine that just dribbles down and then playing pinball where you could have all kinds of feedback so i think they're mutually exhaustive but that may be sort of a deflationary stance because they're defined as contrary to each other um we're not gonna go too into detail here but sometimes um you want to use a model that is acyclic even for a cyclic system for example within one time step it might be a heuristic approximation to make it a um [Music] dag model directed acyclic model rather than a cyclic model so we're talking about our statistical models here not the topology of how things are connected in the real world but i just thought it was very interesting to um [Music] talk about bayesian networks and uh often bayesian networks are framed as only dags so the standard definition according to these authors the standard definition of bayesian networks is usually one directional acyclic directed graphs in higher dimension systems further probabilistic relations can be recovered from network cyclic properties and the joint probability of all variables and this paper shows like for a two system where there's a just a kind of back and forth between these two x and y variables here's x y and z in a three-way loop and then here's a four-way loop and then they also look at n order loops so it can generalize so what was once only imagined is now proved in other words let's not get too confident about like what can or can't be done with one type of model family or the other because it's just one clever paper away for their to be an approximation or to be an exact solution now we turn to the other sense of dcm and this is dynamical causal models and so these dcm can have graphical structure that also is directed acyclic graph but it's a different usage of the term and so dcm here we could point to many resources like fristen at all the 2007s statistical parametric mapping textbook or a later paper of fristen at all on network discovery with dcm and so i thought that 2011 paper was a little bit more relevant because it's about specifically inferring or discovering the functional architecture of distributed systems using dynamic causal modeling what does this technique do it uses bayesian model selection so comparison of the relative adequacy and complexity of different bayesian models to identify the sparcity structure which is where there are edges or not or where there aren't which is the same thing as where they are in a graph that is best explaining in observed time series the implicit adjacency matrix that's that spare city structure specifies the form of the network eg cyclic or acyclic and then later on we see unlike conventional approaches to network discovery dcm permits the analysis of directed and cyclic graphs so dcm is an approach for looking at a time series that's the dynamic part through time and then looking at how variables statistically cause each other and so a statistical cause is like when one thing happens and then at some later time point there's another thing happening that's a statistical causal model like granger causality we're talking about our model so if bitcoin price goes up and then later oil price goes up across the whole time series so there would be a directed causal edge there might be a bi-directional causal edge or a one-directional causal edge it doesn't mean that in the real world one going up caused the other it's just talking about our time series data so that's dynamic causal modeling and it can be applied to neuroimaging data blue i have a quick question here so um i get the time series that that makes it dynamic but i also thought like you could have functional studies that also fall into the category of dynamic causal modeling like gene knockouts right so like you'd knock out a gene not necessarily a time um variation but like a variation in the graph itself and so you knock out a gene and then isn't that also dynamical causal modeling or that's something different um one could have like the nodes be gene expression through time and then test how perturbations or counterfactual network architectures would result in different expressions through time but can you take the time out of it and have it still be a dynamic model i guess it's just snapchats right so it's not um not time series but like gene series i don't know like knocking out the genes in the series to make it a dynamic model if it were just a single time slot slice then it's a little bit unclear what the edges would reflect because cause is like effect through time in the statistical sense so if it were just like i have like you know there's 50 people here and 20 people here and 10 people here it's hard to say where is there a causal edge whereas if all three were changing then one could draw these causal edges okay now we turn under the scope of the big question about modularity two specifically modularity and the free energy principle fep okay so this is the big topic and kind of the um the entree that benny is bringing to us to discuss and it's highlighting a really important issue which is the conceptual compatibility of modularity with the free energy principle and it's a speculation that this conceptual point may well become significant in the course of scientific development of the fep so this is like a philosopher engaging in a scientific discussion because there actually is a lot on the table if we get modularity right or wrong so what is the relationship between fep and modularity is it compatible is it necessary sufficient incompatible like if we have modularity do we get fep right that's sufficient do we need modularity for the fep necessity if we have it can we not get the fep incompatibility are we talking about the modularity of our world carving up nature of the joints or of our scientific statistical models instrumentalism carving up our models at the joints that we designed and then how does our stance or our perspective on this topic of modularity and the fep influence our generative model how we think and act whether we're the ones collaborating and writing scientific papers or not and then just to add one more note despite the great unifying scope fep has been criticized on account of not discussing the functional mechanisms of the brain so the unifying scope is kind of like top down that's the ramstead at all 2018 all of space and time under the fep envelope that's the top down description and then the functional mechanisms are like those minute particulars that's the bottom up components that build the system and that sort of meets in the middle with the real world systems that people are always discussing so we're talking about how modularity works with the fep or not any thoughts blue or dean well only thing i would add is that it you can you can be strictly top down or you can actually as benny would point out keep an open mind which means that you've got some movement for both top down and bottom up so we'll probably get into that more in the 0.1.2 yes exactly um we're now going to go to some classic citations so benny writes to address this problem of modularity in fep fep theorists may want to provide finer details about the functional mechanisms that enable fep so that's how we're going to make a comeback to colombo at all 2021 columbo and wright 2016 is by providing finer detail in addition to reinvigorating its unifi unificatory scope unifying scope maybe that would be in line with fristen's preceding remarks that despite its roughness fep may be developed to provide a guide to brain functions so we're going to do both we're going to keep the big scope and we're going to provide details so let's look at some of those details this is also going to provide a really good introduction to the difference between the functional and effective connectivity and connectivity here is referring to statistical measurements coming from brain regions because anatomical connectivity is just are the pieces physically connected you know the knee bones connected to the leg bone that kind of descriptive anatomical connectedness first in 1994 functional and effective connectivity in neuroimaging a synthesis so back when we were younger weren't we the paper reviews the basic distinction between functional and effective connectivity in neuroimaging going over to the origins and definitions functional connectivity is defined as the temporal correlations between spatially remote neurophysiological events so that's not the only way to say it in english or any other language but we're not talking about a philosophical um sense of function like what does it mean or what is its teleology we're talking about statistical variation in measurements this definition is operational very cool and provides a simple characterization of functional interactions the alternative is to explicitly refer to effective connectivity i.e the influence that one neuronal system exerts over another so temporal correlation is things that are um like they could be uncorrelated in the micro but then they're both going up together that would have functional connectivity whereas effective connectivity would be looking at how changes in one at the next time step influence changes in the other and so those could be like going in different directions at the macro but they could have effective connectivity because they influence each other statistically let's stay with this fristen 94 theme but we're not going to go through the whole thing this is just to show like what was being discussed and explored and characterized about 30 years ago so keep that in mind we have a long pheromone trail to catch up with carl on this is back in 1994 this is 94. yeah they had models back then well they were made of wood but yes um this is a statistical parametric map spm projected onto a brain and on this map of the images taken through time of a brain that were fmri in this case one can take that data object and find the eigenvalues and there are mathematical relationships between functional and effective connectivity not going to go into it but it's an awesome topic explored here and in several earlier papers and in the 2007 spm textbook and in later papers what was able to be said even way back then well this is one of the figures um [Music] these are looking at the loadings on different vectors so it's a spatial mode that reflects an eigenvector so it's kind of like a vector through space and time activity that explains a large proportion of variance in the data and the first vector that's this top one is clearly related to the difference between word generation even numbered conditions and word shadowing odd number scans so this was a experimental paradigm where the person was being asked to do two different things alternating generate a word and then shadow a word like i guess repeat a word that was already said and then this vector which had this activation pattern on the right in the brain was negatively correlated with the odds and evenly correla and positively correlated with the even so it's a plausible mechanistic statement about the differences in the activated neuroanatomy doesn't mean it's simple to interpret but it's a vector whose expression is correlated with something in the experimental design like if you did a double-blind study and these people got the drug and these people got a different drug the correlation between them would be ascribed to the difference that you as the experimenter imposed whereas here's an example of another vector that declines throughout the entire experiment and so that might reflect for example attention dropping off through time and so that's a lot of neural imaging then and now looking into these summarized um [Music] statistical representations of activity patterns through time and also for um later just it's cool to look at some of these citations like the edelman citations tonini and sporns 92 these are really classic citations so there we were in 94 and then this is a dream of the future from 94. so here's um zargami and firsten in 2020. again talking about effective connectivity biologically grounded models like dynamic causal modeling and dynamical systems theory so improving and iterating on those basic ideas and then also what does it look like to apply it and what kinds of conclusions and statements do scientists make when just applying these uh methods so for example this paper was in 2019 and it is called dynamic causal modeling of effective connectivity should sound familiar during anger experience in healthy young men seven tesla mri imaging study and so um you can read the abstract but they find that viewing certain kinds of films leads to activation of certain brain regions dot dot dot we propose a model of effective connectivity associated with the anger experience based upon dynamic causal modeling the findings have implications for psychiatric disorders so that's what people do they put people into scanners they take measurements of the hemodynamics of the brain and then make a statistical model of it and the edges that exist across all subjects or only in the ones who have this diagnosis or only in these experimental conditions those edges are interpreted in a certain way that's what's on the table but we're discussing all these techniques any comments on fristen94 or we'll go to the other classic just that effective connectivity is what i was thinking of like in the gene network like how are they effectively connected so it's like makes sense now yes another classic but a more recent one is 2009 firstin's paper again single author paper the free energy principle a rough guide to the brain so now that's how long ago 13 years ago the free energy principle might provide a comprehensive account of how we represent the world and come to sample it adaptively through action by moving our little eyes around the fep provides a mathematical specification of what the brain is doing now that starts to sound like realism right what the brain is doing not a functional description of the models we make about the brain it is suppressing free energy if it uses gradient descent and so um the box with the questions for future research um are really still key what optimization schemes does the brain use these are like still important questions and then also um the domains of application it's just always good to see like what was the fep's description and scope 13 years ago some of the images we've even seen again and again with sometimes some variants but these are like images that we see commonly we talk about action to minimize surprise and perception to optimize the bound so this is like the predictive processing element and this is like the control theory element um we talk about the topology of perception cognition and action so suffice to say that there are equations figures and it's another great paper on the long road towards the fep any comments on 2009 paper all right blue would you like to describe modularity sure so um i just wanted to explicitly define it because we talked about it a little bit in the abstract and we're going to talk about it a lot more but um in the paper the the author defined modularity as information encapsulation which dean mentioned earlier and he says informational encapsulation holds that when engaged in information processing the subsystems do not have access to information processing in other compartments and information processing within each subsystem is constrained within the combination computational mechanisms of that subsystems of that subsystem and so the modules are then defined by information segregation um and it's interesting to compare modularity like is encapsulating information in a module versus defining individuality which um but both like mike levin and the computational boundary of a self paper that we did last summer and then um david krakauer in his 2020 theory about the information theory of individuality both of those authors um talk about information sharing like information sharing um like with cells to form a tissue for example in mike levin's work and then in the information theory of individuality paper like up and down across different levels so that you can define individuality at any given level but it talked about how information is shared with this bi-directional causation in that paper and so i think it's interesting to compare this idea of informational encapsulation in a module with these definitions of biological individuals very cool like is modularity the same thing as individuality how about continue describing maybe in this discussion on intransitivity well so i had to like look this up so i i i just like it i went into the paper like i just wanted somebody to just define what does this intransitivity mean and so the author says the general insight in is based on the intransitivity of the passage of prediction errors between levels whose information can affect one another only in cases of uncertainty and noise so i feel like that this is like intransitivity of information between the modules like but i it was just not clear enough for me so then i tried to look up like what is intransitivity what is its intransitivity theory and i came across this really cool paper um which is 2015 and entropy intransitivity in theory and the real world and it i think it's really different than like what we're talking about here but it talked about like uh intransitivity in terms of preferences and it said the choice between transitive which are transitive which are absolute and intransitive which are relativistic models depends on the nature of the processes that these models are expected to reproduce many people however have a psychological difficulties in accepting a relativistic approach expecting an absolute scale of judgment from bad to good which can be suitable in some cases but excessively simplistic in others and they gave the idea of intransitivity in game theory and so like an intransitive game is just rock paper scissors which obviously like your choice there's no it's not rock is always good paper is always good tails never fails it's always relative to what the other people are choosing right in this in this game um and then they really go into like multi-dimensionality and intransitivity so he says in the paper coarsening which is like coarse graining in multi-dimensional cases becomes strictly intransitive and the cases without strict intransitivity are degenerate either dimensions are redundant or coarsening is performed after merging the fractional variables into the overall utility instead of independent questioning for all or some of the criteria from a philosophical perspective this statement can be presented as a continuum argument for intransitivity small alterations are commonly overlooked for secondary parameters but can be accumulated into critical differences and so i just thought that this was cool because it talks about like philosophy and some things that we're talking about and relative or like you know realist versus instrumentalist but it's completely unrelated and i just wonder like is it completely unrelated or can we go back and then like link intransitivity full circle into what we're discussing here today so it was just i put this in here because i thought it was a cool paper and in my search for intransitivity um that's what i ran into awesome putting a number on something often makes it seem like whatever you're putting the number on they are transitive you know if everybody gets a score out of 100 then there's a natural order or if we're ranking policies according to their expected free energy then there might be some ordering of policies according to which ones are best minimizing free energy and i think this idea of intransitivity within the graphical model what kinds of information are being passed and what does it mean and then just more broadly like you brought up with the game theory it's very interesting all right let us continue almost finishing the first section and get to modularity fep and the target of the paper which is the hippolito and kirchoff paper so without intending to map the course of the evolution of the fep like we will blue i will just remark that the assumption of modularity has been fruitful in the study of brain functions and so keeping an open mind about that assumption could be fruitful for the fep too some significant critiques such as hippolito and kirchhoff 2019 not withstanding if you want to read more definitely check out this paper from late 2019 by ines and michael and they are also as well as any of you welcome to come on and discuss this paper that could be really cool to like kind of embody and enact the paper and are we on the same page or what are our perspectives even if we are on the same page and this paper is engaging in the discussion of the relationship between modules and modularity the main goal of the paper is not to defy hippolyto and kirchoff's attack completely the notion of modularity that benny will defend is weaker than the notion that they attack so what senses or types of modularity are we dealing with what are the stronger and weaker claims and we'll look at their definition on the next slide the main point of the discussion is that according following hippolyta on kirchoff the modest definition of modularity is neither insignificant nor indispensable so that made me ask are we seeing a trend towards instrumentalism bottom-up weak claims like the entailment exploration of 34 and deflationary models and moves away from naive or realist strong claims and so that just totally points to the role of philosophy in an ongoing scientific domain because um things like strong and weak emergence or entailment relationships and these discussions on modularity they really matter for how science is done and how it's interpreted so it's just really cool to be seeing that happen in a new way again we're not going to go into the whole argument of hippolyta and kirchoff check out the paper but they are going to consider the three most well articulated which is funny because that means well said but also well jointed arguments for the view that modularity and predictive processing work well together so predictive processing here is also referring to kind of that component of active inference and they're going to argue that all three of these arguments for modularity come up short albeit for different reasons so they kind of do like a steel person where they give the strongest argument for that attack and then they refute it and the three arguments they discuss are the epistemic bayesian courtroom argument which is just the idea that court rooms are modular and cognition's kind of like a courtroom like the eye is like a witness and then there's like another witness thereof and so if that's modular then shouldn't predictive cognitive architectures be modular b the intransitivity argument which is that the causal influences across hierarchical levels are instantiating mechanisms that implement causal bayesian networks and they basically say that is pitching predictive processing in terms of the dag as opposed to cyclic models and see the markov blanket argument the notion that a markov blanket grounds the idea that predictive processing exhibits modularity and so they are going to explore those and confuse them as they say and one of the key points is when cognitive neuroscience works with an acyclic markov decision scheme so that's like the partially observable markov decision process that we were talking about earlier it may very well be methodologically misguided why because there's an increasing tendency within neuroscience to emphasize recurrent and reciprocal neuronal processing within the newly emerging dynamical causal modeling frameworks so how are we going to think about the fact that the brain does have these feedback feedback loops and square the circle with the dags and the dcms and that's kind of the introduction that's where we're set up which is that hippolyta and kirchoff have framed and then attacked three pro arguments for modularity and cognitive architectures related to predictive processing benny is going to kind of take some of that energy and with a weaker version com or a little bit of a different version not simply stronger or weaker because that would actually imply transitivity of strength but with a slightly different tack is going to um recall us to life through a discussion of modularity so this section is only going to have one slide on it and then either of you please uh feel free to add any comments there's been a long history of debate on modularity in neuroscience and fodor who's a very influential cognitive scientist define modular cognitive systems as systems that are domain specific innately specified hardwired autonomous and not assembled that's not exactly the definition of modular that we've explored in some other slides but the words are what they are and that is the benny quote about that functional isolation between modules is what defines them so it's kind of like when there's more connection within than between then that's modular and so benny writes the present paper does not intend to defend fodor's version of the modularity thesis fully probably because some of these pieces about like innate specification hardwiring autonomous unassembled take it or leave it it was the 80s but benny is simply aiming to show that some critiques of modularity do not need to undermine the possibility of informational encapsulation so although a falsification of informational encapsulation leads to the renunciation of modularity a defense of partial encapsulation would not establish a full-blooded form of modularity so if you refute encapsulation you have to renounce modularity however parcel or transient encapsulation doesn't give you strong modularity claims however it can be compatible with the instrumental usage of models that have modularity so those are some of the main arguments that set bennie up to defend a version of modularity that's quite modest and it's almost like after that kind of a modest deflationary take the question is really is there any value in that definition of modularity at all so the debate isn't over whether we can discuss things modularly if we're going to take this different tack then really the question is like does it matter any comments on section 2 so i don't know i don't want to get too deep into it maybe better to hold off for the dot one but i just wonder about like if encapsulation so if it's if something's fully informationally encapsulated like you know my heart is fully informationally encapsulated from my brain like how do you how does a living system function right so so this partial encapsulation if that's not strong enough for modularity like i don't know how full encapsulation as possible i just i i don't see it so yes section three is entitled a golden thread free energy principle and so we just had to go there with a blake reference because on his gravestone and one of his most famous lines is i give you the end of a golden string only wind it into a ball it will lead you in at heaven's gate built in jerusalem's wall and then here's a drawing that he made with a mythological character walking with a golden string so the general idea according to benny behind predictive coding is that the brain uses approximate bayesian inference to decrease discrepancy between predictions and inputs that is one of the key contentions of the fep and the organism's interaction with its environment can be represented by marco blankets here i am using representation and modeling when speaking of markup blankets and consider them to be markovian models so check out benny's guest stream appearance i think it's number one on markovian monism and this sentence makes it clear we're talking about models we're in the realm of instrumentalism we're talking about markovian models not about whether we're making an ontologically real claim about markov blankets like being the structure of reality so in these models markov blankets are describing the conditional independence of internal and external states and then it's that fristen innovation beyond pearl and markov's to describe the incoming dependencies as sensory and the outgoing dependencies as active states so what is the golden thread the fep is an approach for embroidering or what creating markov blankets finding them what is the golden thread what is the silver thread and golden needle so what do you think the illusion means and what does the fep have to do with it well i'll speak a little bit on this i might get it wrong but that's okay we're still 0.0 i think the predictive coding as a as an entailment question fits inside of the um what did he call bcc brain uh brain brain brain brain brain i can't find it now in here anyway i think that i think there's a subtle and a nuanced difference between what fep is as a process and as a principle and what fvp architecture is and i think that is what he is trying to bring to the table there is a difference between the architecture or the product that results from the use of an fep process and the fe pre fep process itself and once i figure out my own notes here i can speak to what that bcc is but i'll i'll shut up for a second very well interesting to describe the difference between the principle and the realized architecture section 4 the track of a storm so here's another single slider so there's some apparent tension between the modularity thesis and the predictive architecture so that's what kirchoff and hippolyta described while the thesis of modularity points in the direction of segregation and encapsulation the predictive architecture grounds the integration of information in a hierarchical top-down architecture that unifies the mechanisms of cognition perception and action under the fpp so it's like what blue just said wait if it's encapsulated and defined by its separation then how is it part of this integrated whole well howie in 2013 the book the predictive mind and other people in other places have suggested that this conditional independence between the various levels of the hierarchical structure of predictive coding under fep could be construed along the lines of functional segregation and informational encapsulation which is why fodor was brought up earlier drayson argued that the predictive architecture can be modeled in terms of this causal probabilistic dependency where different nodes could influence the um adjacent levels but there isn't global transitivity so like the lower most nodes are not influencing all just the ones directly above them however the hippolyto and kirchoff paper challenge that vertical and horizontal account so the vertical account is like the multi-scale nested systems the horizontal account is like the collective behavior interactions across within a level and so they aim to refute this account of functional informational modularity according to hippolyta and kirchoff and let's hear from them if it's not the case the intransitivity argument for modularity is based on dax however they're going to argue that dags are not suitable for that kind of modeling because the brain has these cyclic mechanisms and so dags have to be replaced by cyclic models which don't have the limitations of dags um and then with respect to the markov blanket point benny asserts that hippolito and kirchoff argue that the argument from markov blankets is of little avail to establishing modularity he will get to both of those arguments he kind of doesn't really worry about the courtroom as much but the intransitivity and the markovian blanket arguments are what benny's gonna focus on but first remark on the importance of scientific models so kind of a fun tack but that's section four yes please d yeah so i found out bcc is brain's cognitive capacities that's how he described it in the paper so i don't think it's a rock paper scissors issue either i believe that predictive coding is entailed by the brain's cognitive capacities i believe that the brain's cognitive capacities are entailed by the free energy principle so it sounds like you've got a rock paper scissors but that's not the same as the free energy principles architecture being entailed by predictive coding i would have to diagram that out for you but that's where he's saying it's not an intransitivity argument and that's that's just notes to me and that's where i kind of j ran into his corner even though i i want to actually do a paper later this year a review of one of hippolyta's papers on an action that i think is fantastic in instrumentalism but that this was the moment where it it was clear to me that it's not an intransitivity argument because back that what axel pointed out to we have to know what entails what very cool section five a knock at the door models and modeling we we really do need to do that joke stream knock knock jokes like you know who's there i don't know who are you expecting who do you prefer um in this section benny is going to describe some comments on modeling he writes i do not think we can find a reliable model independent handle on the architecture of the brain so it's kind of like saying if we're going to science we're going to model so let's not think that we could science without modeling the general insight is that the interface of scientific theories and their target systems takes place through scientific modeling so theories about the brain the brain itself and then the edge is the scientific modeling now the brain is like a special and fascinating system because it can be reflexively modeling itself but if you think about um theories of pendulum pendulums theory of pendulum and then the target system of the actual pendulum it's pretty clear to see where the modeling relation comes into play however again it gets kind of strange loopy with the brain and benny is drawing upon various works some of it is the weisberg work on like simulation and similarity using models to understand the world and also some of benny's earlier work for example the ways in which markov blankets are construed as scientific models and similar points have been discussed by mel andrews 2021 that was actin 14. so scientists are making and applying models and so we're not going to break out of that vip room in plato's cave so we have different kinds of models and maybe some of them are preferable but like if your argument is predicated on breaking free of a given scientific model it is um something to hear if you think you have it dean so this is it got interesting for me here too because if you if you look for example at a slice of time in an fmri image you could be focused on the concentration of heat in different areas of the brain that would be one bit of information that you could take away or you could look at the proportion of blood in different areas of the brain which is going to tell you a little bit of different information than the the actual concentration of heat that heat bump per se and so i was kind of curious who who is a modeler here because he talks about we can't take our we can't take the the observer out of the observation so again what relative what relative bit of information do we tend to hone in on or or do we think is the the the more um priority information to take away from one of these slices of time representations that was really important to me right here because if you think of encapsulation as that sort of frenetic image a few slides backward all the brain is is chopped up like like here's the bacon and here's the ham and right the different parts of the pig you're you're you're choosing what it is that you think is the way of of of encapsulating but i don't think that's what he's talking about we'll explore it but yes taking this kind of a really strong principled stance on scientific modeling means that we can always ask who is doing the modeling why and so actually it's not just this sterile philosophical point it really brings us to consider the social and the operational aspects of science so it's very important like socio-technical point section six the game made the intransitivity argument okay we're not gonna go through all the details here we might have time in the dot one and two but there uh benny is going to focus on hippolyto and kirchoff's specific reply to the intransitivity argument that is centering the distinction between the directed acyclic graphs and directed cyclic graphs benny is going to argue that these two kinds of statistical models do different things it turns out they actually also map onto the difference between functional and effective connectivity and so applying one sort of the model dag or the cyclic model in a specific situation is a matter of practice practical exigency and methodological consideration as well as the goals in the interest of the modeler so it's like we're 100 miles down choosing a model free freeway and then whether you take this slight difference between one topology of graphical model that's quantitative versus a different topology maybe that is not going to be super philosophically impactful because we already have taken like the big pill which was making a scientific model or making a graphical quantitative model um [Music] there's a citation to the fristin visa hobson 2020 paper that also describes like where the cyclic versus acyclic are uh preferable and uh benny recaps and just basically to summarize there is no universal reason for extolling dags over dcms because the focus on functional connectivity or effective connectivity is a matter of explanatory predictive goals and interests so scientists are using different kinds of models and so maybe we should pull back to scientists use models and think about the implications of that rather than try to finesse out some philosophical implications from the very specific kind of last mile modeling choices dcms can do certain things whereas dags can do other things which one of these approaches can be used to analyze data in the context of the fep we're going to discuss it in 35.1 benny says i do not think hipolito and kirichoff 2019 are bound to concede a non-realist reading of dcm rather the critique of how h and k compute the intransitivity argument is pointed at their unjustified partiality towards dcms so it's like if you could just scapegoat the dag then the dcm is the savior but if both of them are just types of scientific models that are chosen situationally operationally as thriston described then there is no savior model coming in to save the day dcms are formal devices and then there's a citation to the emperor's new markov blankets with yella at all live stream number 20. and so drawing attention to the difference between dags and dcms which are complementary modeling tools as we discussed earlier they're defined as complementary could not confuse the intransitivity argument so if we have already committed to the instrumental perspective so we're talking about our model not about the world then the difference between different modeling approaches is purely situational or operational and so all scientific models have roughly similar philosophical grounding or they're part of a broad category with respect to this intransitivity argument nice philosophy and interesting points okay column in the storm the indispensability of modularity and the indispensability of scientific models oh i wonder if there's going to be like a parallelism between models and modularity and here's like a person in their markov bubble in the storm this section focuses on a realist interpretation of dcm in terms of dynamical causal models so even instrumentalists can bat both ways you know we're not obliged to never talk about stances that in one certain situation we didn't prefer it's just really wide-ranging intellectual exploration that's being characterized here and here benny does play on a little bit of a acronym play which is that dcm applies to dynamic causal modeling as well as directed cyclic modeling so cyclic graphs or the dynamic causal graph and he'll argue through an example that we're going to discuss not today with alice and bob he argues that the modularity in the context of dcm it's not as strong as the fodorian isolationist concept but in interesting and important ways it's going to be enough and so a moderate form of modularity is retained and uh hippolyto and kirchoff argue that this weakened notion of modularity is explanatory vacuous it's empty and there would be no reason for keeping it and that's the bone of contention he's going to dissent and say that the benefit of this modest notion of modularity is remarkable so that's the claim any comments on section seven what would happen if we couldn't categorize then it would be impossible to give a categorical response to that question and and a lot more right like that that's basically what this comes down to doesn't mean that things aren't arbitrary and not necessarily put into into the correct silos but but there is a great benefit i don't think it's dispensable our our capacity to categorize doesn't mean we always are obliged to do it but when we do do it is there a benefit yes is there a cost maybe but if we if we took it away what would what would then what would the world look like then a triangle is a triangle as a triangle right there would be no specificity then interesting we'll talk more about categorization models and the parable of alice and bob yeah section eight still knitting markov blankets so um here they return to this idea of the vertical insulation and the horizontal insulation like there's encapsulation laterally collective behavior and then encapsulation like an onion like a multi-scale system so that's very interesting and this is also where we get to this point about the scale-free or skill-friendly nature of markov blankets um the main reason that h and k resist this argument about the markov blankets is based on the fact that the regimentation of states into markov blankets is scale free so it can range across scales maybe even that is already scale friendly um because markow blankets are scale free they do not imply insulation and thus the modularity thesis does not receive support from them and so benny concedes yeah it's true mark-out blankets can be applied to basically a wide range of phenomena however this is overlooking a subtle point markov blankets in the abstraction in principle are scale-free there's no inherent constraint on their size and scope linear models are inherently a priori scale-free it could be centimeters versus the gdp it could be astronomical units versus temperature like it doesn't have a tie-in to a certain spatial temporal scale or any feature for a linear model or for a markov blanket however q dean from stage left or you know running in from the audience their application or imputation to various target systems will impose a definite scale on markov blankets to make a long story short in the context of their application under fep not in the context of fep markov blankets are not necessarily scale-free mathematical models because they're being used in models so even though the formal tools could be scale-free application mandates calibrating to a certain scale if that's the case and it seems like it is then counter arguments based upon the scale-free nature of markov blankets could not undermine arguments from markovian formalisms soundly so this is really nicely framed and placed in space and time dean what do you think about that well i'm still as i said i i did first of all i want to i want to make sure to disclaim this i never saw this paper until three days ago four days ago so my guess my what my wag about scale friendly and and sort of whether that was something we should consider it was nice to read this and have somebody else go maybe it's something we should consider i'm going to leave it at that because i don't know if somebody's going to come along and disprove that and and you know because if that's if it's if it's falsifiable that um calibrating doesn't matter and and categorizing doesn't matter i'm open to hearing that too but in the meantime i think it's something that if we don't recognize the difference between the abstraction and that thing that we're focusing on right now we can get lost in the idea that a triangle is a triangle is a triangle and nothing else matters blue anything you want to add on this section yeah i mean i really think that um i mean it just hits the nail on the head like we're the ones like putting the markov blanket on something and so like just because something can be you know modeled using a markov blanket doesn't necessarily mean it doesn't scale and and like things don't mark off blanket themselves right like so i mean even like my layer of skin like cells are popping off and new cells are adding on all the time and so like there's it's not a hard boundary it's not a solid boundary it's very fluid like what goes in and out of a markov blanket so i think like our imputation of a markov blanket on a system i mean yeah they're scale free means you can impute them on any system at any scale so so maybe scale friendly is is um the way to go but it's not like the blanket itself is scale free i mean all blankets are are composed of stitches right like so are you using big stitches or little stitches or like different layers of cloth or or what so i don't know it's it's uh i don't know i think it really drives it home yeah and uh the paper was i mean we can double check but it's from december 21 so we have proof of live stream dean that you know you were there um can i just say one last because i completely agree with with what blue just said i was i was never of an opinion that that markov blanket isn't scale free of course it is and it's kind of like saying they're subject matter experts of course there are but as we had in the in the conversation with dr fristen you could also say that there's a prediction matter expert like all i'm asking is for people to consider that there could be both and they could be running in parallel that's i wasn't trying to push back in the sense that you know people are wrong what i was saying is what what else could we include to phil fill in the wholeness of what is happening here that's all i was trying to point out and i and again it we could take active inference and and focus it completely on the minimizing of free energy and getting what we're attending to or we can talk about the availability piece and what for example when we're having new people on board to our lab how how we make that that entry point so so relationship based we could do that we could make for them we could make them prediction that matter experts before they even realize it in themselves now whether we do that or not it's not up to me but we could so that's what i was trying to bring up and that's what i like about this paper great last section last content slide isn't it something they say like if the newspaper article ends with a question mark i forget which one is it the it's always yes or it's always no but the footsteps die out forever so this is a summary in the ninth section benny challenges the main points of hippolito and kirchoff hippolyta and kirchoff confuded the modularity thesis so benny is salvaging the modularity thesis from the pincer attack of hippolito and kirchoff to support the argumentation of the paper benny draws upon the indispensability of a model-based conception of modularity that's where that kind of science and society angle and philosophy angle came into play benny argues that dags and dcms are complementary models and the choice between them is operational it's pragmatic it's not um metaphysical per se so modeling is situational we can take a deflationary approach even to how we think about science benny argues that when we think about dynamic causal modeling there is modularity because of how the statistical model pulls out differential coupling between brain areas and that's not a statement about the brains the statement about the model benny also challenges hippolito and kirchhoff's answer to the argument from the markovian formalism by showing that although these models are in principle scale free in order to represent any specific target system they have to be associated with interpretations that do give definite scales so the markov blanket formalism is conceptually skill-free but any realization application is scale specific thus skill friendly tickles 21 at best personal communication already and basically we're exciting the live stream soon yeah benny closes with just saying it doesn't undermine the claims and this isn't like a radical pro pro-modular thesis it's not the isolation of brain regions and they're each like virtual machines that are totally separated the only point that comes to light by our enterprise in this paper is that the debate over modularity needs to take the role of scientific models into account and a model relative conception of modularity cannot be waved away easily so it is a great service and an interesting paper in form and function we have an empty slide for the implications and questions we have the early slide where with um what we're going to discuss in 35.1 and 35.2 and it was an awesome discussion so if you have any final comments now would be a good time do you think that um when you get people who've worked together as this author and the person and the two people that he was kind of pushing back against do you think when they take it into this kind of a formal setting of paper writing that that changes their relationship fundamentally that's one i mean i i could i suppose we could only ask the authors themselves but does it have to be a debate necessarily does it have to be drama necessarily or is there is there kind of a moving forward hand-in-hand part to this i'm not seeing it's a really interesting question i'm sure scientists and all kinds of different people are going to have different answers but i think about the papers in their exact phrasing as like pheromones digital stigma g in the literature corpus and then the person is like the nest mate who is weaving on so any artifact is going to be made by that person in the past so i could be like talking to blue and it's like oh yeah you know knight 2018 said this or you know but you just said this but but didn't night 2009 say this it's not a contradiction it's just like the trajectory and the pheromone deposition of active and complex entities and so i think that that i hope is the best of both worlds which is we can humanize kirchoff and hippolyto and benny and all the humans involved and take like a compassionate and even friendly um tack while also being very scrutinizing of the specifics of the knowledge artifacts that people leave because a lot of times there is like a gray zone where it'll say something in text but then oh if you're in the club then you know that they actually meant something else or you got to read between the lines with the methods or you have to read between the lines with the citations and um that's kind of a conflation of the person and the argument like when people give an overly charitable reading or even try to insinuate things that weren't there in the initial text because they want to uphold their legend of person and rather we can just kind of separate those two in how we model the generative process and the generated product i just think that there's so much you can learn when you're wrong and that doesn't mean you want to be a serial mistake maker but i don't think anybody that's publishing is looking to do that either but if you're comfortable if you're actually comfortable with putting wrong answers out there and having put people kind of prove that you're wrong but you're comfortable with that i think that makes a huge a huge difference at least in terms of the culture that you're participating in it's a lot safer if you can if you can throw stuff out at in in four weeks or five weeks time somebody can say no dean you were wrong we got to take that citation down i wouldn't take it down i would leave it up i would simply say no in that moment i i thought it was right and now i now i've updated my generative model yeah it's like showing your work like here's what i knew at this time and this is what leads me to my conclusions and then someone says well you missed this paper from [Music] 1855 okay then that updates the next round of pheromone deposition exactly blue any last comments good yeah it's a fun start to 22. and it's the two architectures 2022 second year of active lab two two two two two two two is coming up i mean it just couldn't it couldn't get any better that's great thank you folks yeah appreciate you and everyone