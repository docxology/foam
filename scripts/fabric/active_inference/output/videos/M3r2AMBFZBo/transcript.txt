okay welcome back Arts of cohort 7 um we're in Three so beginning in three is there anything that anybody wants to begin with like any overall thought on three or any any place to start I guess I was a bit a bit slow with the uh with the recap of the the chapter here but one one thing at least that I uh thought a bit about while reading it was and I guess uh not unique to this chapter but the proceeding ones as well is the interesting connection to other domains and mention like the the physics and activism and cybernetics and all of these different ideas and also like how it seems as if active inference has evolved over time and emerged from all of these ideas and like the connection between it which I U I I think seems very I think it's very interesting and um I was just wondering if there are any Resources with with someone that has like uh mapped up the connections and perhaps like Evolution over of of the ideas over over in history uh so that you can get like a good overview of of of how how this has evolved and it's connected to other areas and perhaps like even what different assumptions and applications go into it yeah that's a great suggestion I mean the you mentioned kind of like a um historiography like bibliography tracing but then also like the claims and the rhetorical assertions and understanding what which claims um transferred it also kind of reminded me of this um I I'll I'll put it here but this in the complexity Sciences this one graph I mean even even though it's just one partial representation becomes quite popular even though it's just a subsample of the tip of the iceberg of one person's representation of one way to view it but but then it does give some coherence um even just from chapters 1 and 10 of the textbook it could be possible to um pull out some of these kinds of threads and then yeah that Beal and it's like how different would it really be from active inference mathematics of complexity systems and complex systems Network science cybernetics maybe there's information Theory here somewhere artificial intelligence so agent based modeling so I think it would it would it would have a lot of similarities to this but but I I agree yeah yeah super cool I'll check that link out um I guess it has some some resources resources in the in the book like the table 3.1 for instance but also from like chapter 2 the figure um which one is it 2.6 as well which I think have like quite nice connections to one um kind of uh history crossover moment from uh from the last Friday this uh model stream 13 synthesizing the born rule with reinforcement learning so they're coming from a um Quantum measurement empiric IAL setting and then as they started to relax certain assumptions and try to generalize the born rule they got into the generalized sensory motor interface and the sort of generalized cognitive setting so that's like a low road generalization and so we had some interesting um crossover moments were like they were they're in the labor measuring these Quantum collapses and then they've converged upon where from active inference it it generalized into the quantum over the last several years but then so there could be cool ways to go [Music] um any other random thoughts on three or or the high road I mean that's kind of what three is about one just opens the book just like 10 closes the book two took us on the low road now three is going to start from up here and come back down to active inference so that we're we we get off the slide of chapter three and we end up right a chapter four where we finally see the active inference generative model but yeah any thoughts on high road three like just to kind of illustrate that um yeah yeah good good the um to me I mean it's almost like we're just creating a more granular structure around the Socratic method how so uh we've got you know agents in an environment and they're um asking questions about the environment and receiving a response from their environment and then um integrating that response into their internal model of the world and rinse and repeat yes interesting there's the there's the socratic element on that there's the hegelian element on that and like all of these more like composite Frameworks where like it doesn't seek to reduce situation down to just like a a a monad Unity but to a DI dialectical Unity are there other aspects to the Socratic method Wonder reflect refine and cross-examine restate repeat this this connects I mean to the active inference ontology what is surprise or you know these are these are the kinds of questions and these are like a Playbook what does the book mean by novelty what why would they think that the K Divergence is the way to do this is the K Divergence the only way to do this there's a nice buildup towards three in chapter one this is kind of the minimal agents Niche figure ground like two-part um partition that gets nuanced into kind of like a four state partition we have a a true internal and external and then there's two aspects to the blanket or you can kind of collapse those two into to one blanket and that's where the the Markov blanket concept initially was was just like it was one blanketed node and then one of friston's Novelties to to adapt the Markov blanket concept into the cybernetic setting was to kind of split that blanket or interface into an inbound and an outbound so that's where we get the four but here it's still framed as like they're just four variables like in a program in chapter 3 it picks up with those four and now they're defined in terms of flows like the dot being a derivative so now there's like four simultaneous flows on this fourfold partition so that that is coming more from the basian mechanics but that just shows like it's like chapter one is the is the parent of both two and three and then chapter two goes more of like an engineering program way of doing this like well what are the variables like what are like um what's the local computer State the remote computer State and then the the the sending to and from State here's more of that physics um way to see it we we can look at this figure in context but this is kind of like showing uh B is the blanket X is for external mu is for internal kind of like I maybe mu for mind for M or something but it's like saying if you have like a um just just to make a b numbers if you have a 0 five correlation between um internal and blanket and a 05 correlation between blanket and external then you're going to end up with a 0.25 correlation between internal and external just because it's kind of like it's two hops and each one has a 0 five correlation so that's kind of how you end up with correlations across blanket because of kind of like the chain rule of partial correlations any other random thoughts on three or we can look at the accident questions or we can look at the text this is one of oh yeah go ahead Jeff um the one thing that I think and again you know we being stuck here in the in the forward era of time um Melvin vosen um has developed the theory of info Dynamics which is a a corollary to thermodynamics and I feel that there's overlap here and uh I can't I can't be more specific than that but I can link the the the article um and I don't know maybe somebody wants to take this and run with it or maybe I will at some point okay I remember Alli in a um characteristically um oi styled Terrence Deacon has also has touched upon the info Dynamics it's kind of like the the data information knowledge wisdom like kind of but but it's it's a little bit different than that but it's like what are sort of the um syntactic dynamic of of information like at the sensor processing level then as you move into more semantic levels of informations um how does and then and then Deacon highlights that um those higher levels they they are dealing more and more explicitly with like adjacent posses rather than processing what is like immediately there like you can't understand the higher levels without also considering like this kind of like as yet unmanifest shell of which is kind of like when we get into action planning That's a classic example like most plans will not happen yet the expected free energy still kind of considers them but in so in this question we'll see if the qu if if the actual maybe the real questions will be address but this image this is from one of the earliest like pre-2010 winged snowflake so here temperature increasing is going down so it's colder higher up in this image and this is like the actual sky so it's like it's colder higher up and then like closer to the ground it's cooler so there's some critical temperature under which from an elevation perspective like the snowflake is going to melt Above This level it will persist as a snowflake so if it was a inactive Snowflake and um then let's say you started with a cloud of like a bunch of snowflakes that was that were high up um then you just have would have diffusion so you wouldn't need to propose any kind of action selection it would just be like um if there was lamin or flow all the snowflakes would stay up here if it was going straight down all of them would fall down like that you wouldn't falsify the hypothesis that it was just like a particle but then what you see with like um life is you see action that that acts as if I mean if you came back millions of years later then you you'd be seeing snowflakes that would be acting as if they were staying above that temperature threshold because the ones that didn't have kind of crashed out so this is like showing up in a population of actual neant Tropic organisms and they've been fighting um death you know even without gting reproduction stuff like that but but that that was an early physics inspired way to think about survival but this this could be a blood sugar critical threshold temperature critical threshold okay quick yeah that's that's a fun one of the early fun representations um where was that from um you know let's just look up what it's like it maybe 2006 first in paper okay okay cool not that kind of [Laughter] snowflake 2000 I can look look it up yeah yeah yeah yeah this this 2006 paper with Kilner and Harrison yeah here's the here's with a different notation but but we see a lot of the same input and output and then here's like three levels like this is kind of the fast inference layer then there's the slower attentional neurom modulation layer and then there's an even slower topological change neuronal connections so it's like already there's kind of nested time scales of inference um because those were already being considered in the fmri SPM setting let's see what else is in this paper this kind of looks like a heat engine kind of like a a duty cycle on an engine cortical columns comes back in the book generative and recognition directions from pixels to planning that's like the most recent um paper but I mean here we have pixels and still that same kind of um minimal case already kind of highlighting uh FM and repetition suppression and those are some of the robust EEG and the fmri type findings like in different populations of people and then like when the mismatch negativity and the 200 millisecond tone and all those kinds of things yeah pretty interesting almost 20 years okay F first question is about a Markoff blanket in time okay a as usual attaching a last name to something does not always add information because it doesn't do anything other than just make sort of a historical illusion but this is the marvian property in time which is basically that the past only influences the future through the present so it's like the current state of the program influences the next state and anything prior to that gets distilled or like projected onto the present State um that's the that's a marov chain and then if there are like two time states of time dependency then it could be like a one marov chain with two time steps like if your last two moves were up up then here's where that transitions to so even if it is like multiple time steps in the simulation you can still kind of model that as a one Markov chain or you can you can model it with with multiple time steps but then people also have have broader questions like you know without knowledge of the present what what can you do say two what is a statistical rather than a non-statistical interaction um we're talking about a statistical model so all the interactions which look like edges on a base graph are statistical interactions um then it's an interesting question what what would make a non-statist maybe that's the real quote real interaction itself and then third [Music] question why does Independence between the flows on the two side of the blanket matters so much it's a complex question like matters so much relative to what internal and external States they can influ you can set it up so that they have total influence on each other so it isn't that it's that the blanket isolates it it defines how they articulate and then it could depend a lot or not but I think a key piece is that their random fluctuations are kind of buffered from each other like they're getting the noise is getting um at least the noise or orthagonal they're being like randomly sampled from noise but that may or may not matter in a certain situation these are great um questions there's kind of this these cousins of of closely related terms like of course we have active inference but then we also hear about Basi and brain hypothesis that's in figure 1.2 and then there's predictive processing predictive coding um this was a question that we asked of friston in 2008 and I think the answer has also kind of sharpened since then um you could have a situation where all of these were in play you could have an active inference system that was brain likee being described by basian brain hypothesis where the processing that it was doing was based in terms of prediction and anticipation and and all of that and the messages being passed between layers reflected predictions and their discrepancies so all four of these could be in play or you could have situations that kind of nuanced that um but they're more similar than not predictive processing highlights making predictions which is is almost without a space between with the basian brain hypothesis because that's kind of what a prior observation R predictive coding sometimes is used just equivalently to predictive processing other times and this is explored a little bit with Maria in um the live stream 43.0 and she studied some of the philosophy of the predictive processing predictive processing can refer to like the fact that the whole cognitive stack does this predictive process whereas predictive coding is more of a subhypothesis that the messages being that are transpiring between layers are encoded in terms of the predictions but some other type of message format could be passed active inference amongst all of these highlights like the role of action whereas basian brain hypothesis it could be a passive basian brain but again it could be an active one and predictive processing predictive coding a lot of those models were sensemaking only but you could consider making predictions to be like a kind of internal action but then those types of models generally earlier were not considering like I movements but once you get into the sense making for what the retina sees in a moment and the choice of not just what to predict at the next time step but where to move your eyes and what to predict when you move your eyes there then that gets more into the full active and front setting so yeah that that's a question I thought about many times so it's great to get some more meat on that but I specifically wondered about the uh like overview picture or over overview figure of the low road on the high road where predictive coding is specifically on the the low road and predicted processing on the the high road if I didn't mix them up now um could you perhaps explain why yeah why they're separated like that uh let to put some more meat on it sure no I mean it's it's a it's a great observation predictive coding down here yeah first off um unlike a subway map it's it's not that these are like strictly prerequisite in a certain order yeah so but so it's kind of interesting but you know it's so it's not that this is like the only final representation but um predictive coding it could be argued it's an information optimal way to send messages about predictions within a system so when doing this kind of perceptual inference it's like let's just say that we were we were um we we were um doing a measurement scale and and uh we're measuring cars they're 1,000 lb we expect them to be 1,000 lb we could um perhaps most parsimoniously report like minus three if it was three below or plus seven so it's like that's smaller than saying 997 17 so th this could be as argued as kind of just like a model as a sort of like an intra model strategy for information theoretic optimal transmission of information about predictions whereas predictive processing one which it's I don't think it'd be um illit on the low road because we're talking about basing brain and stuff but one reason why it could be put on the high road High Road aims to start with minimal assumptions other than a persistence either a self-observed persistence like survival or a sort of measurement type persistence like a experiment or observing something repeatedly so in that situation you don't know what is happening necessarily amongst the elements of what you're observing but you could say there it it evinces behavior that it is doing something like um you know when when the nest mates come to the surface of the ground at in the morning just as the sun is Dawning we don't know how they're sending El you know information within the colony but it's like they're predicting that it's about to be the right time to forage so it's or or whatever this thing is we don't know what it is but it's acting like it's predicting what's happening great thanks the ordering is it's it there's a lot of it's like the the um slide slide some game I forget what it's called but it's like where somebody else makes the slides for you and then you have to do like a lightning talk slides in a random order yeah yeah because I I definitely when I looked at it the first time I definitely read it as a subway map but yeah I when I looked at it the more I was like a bit confused about the motivation between putting it like that here were some of the awesome slides from Maria with the history of the perception and about how how it's it's an ancient from from Antiquity to to the the uh the idea that pre-existing information structures sensory data then where the book kind of picks up is with helmholtz and said and that's sort of this like hypothesis testing then that sort of like hypothesis testing idea finds a more natural fit with basian epistemology rather than for example example scientific positivism or scientific falsification approach so it's not that we're just like seeking to lock in a fact about observation or seek to lock in the rejection of a hypothesis it's more that there's just this like envelope or portfolio or distribution that's getting updated and so that aligns more closely with the basian methods than with um kind of rule it in in positivism or rule it out falsificationism okay 3.2 I think it'd be a cool thing if we uh maybe now it'd be easier we could paste it into an llm and just say generate the code for this but it's just showing that you can have um chains of partial correlations like of everybody where a happens 50% B happens of everybody where B happens 50% C happens what percentage of a had C happen and then you can just multiply the probabilities like a chain if one defines preferred States as expected States this the book then one can say living organisms must minimize the surprise of their sensory observations I'm not clear on the ontology here is it that preferen is the same as expectation or formally we can use them in the same equation or something else does active inference make ontological claims EG preference is actually expectation just as heat is actually exitation of molecules more generally is free energy in physics just analogy or an ontological assertion this was brought really nicely together in in [Music] um I'm forgetting the first um author but Stephen Francis man p as a measure of both probabilities and preferences that's where we get pragmatic value that's the clearest difference from reinforcement learning rather than the proposal of a totally ancillary secondary reward distribution that's like observations or observations plus actions like Q learning rather than projecting those onto a reward ranking and then using that reward ranking in this actionable way the observations directly are going to be compared with a preference distribution which is a prior over sensory observations and that does the pragmatic value work but some and then they they kind of even talk about how like people will lean on one of those interpretations or another but they're they're both equally viable is there a minimal example of a thing defined by marov blanket such as a cell or or some subcellular elements is a thing Persistence of marov blanket are all things non- equilibrium steady state processes do we need to be more strict in saying these things are only self- evidencing things rather than things in the colloquial sense some work towards that is is from this um particular kinds path integrals particular kind strange things paper just showing that um ranging from inert things to classical simple things to strange and self-reflective things they all fit within this interface concept it's really just what is the modeler system of interest and that's also the first step of the chapter 6 recipe for modeling and it's non-trivial to identify the system of Interest I mean if you're studying the heat transfer from the engine that you could make an argument that the system of inter should be like the solar system or you could say okay but I'm only interested in the 99% heat um transfer threshold and then at that point you might even exclude some of the plastic on the engine so it's not that there's like one um kind of thing or or maybe you're interested in a specific thingness I'm reminded of um fields's course as well Chris fields's course like in in how uh the physics of of information processing right and how you have to define a thing and and really going down to um bits being the fundamental construct of the Universe um you know in um um shoot I've got I've got the I've got the article on my bookshelf behind me but um art wheeler you know John Wheeler John archal Wheeler it from bit right so you know ultimately things are constructed from um plank units right so yeah and the bit is like a collapse onto a yes or no question that's like the simplest question okay I'm even going to look at what these are hylomorphism every physical object is a compound of matter and form hylozoism Doctrine all matter has life okay what is the analogy to friction in a cognitive system how strong is the analogy okay nothing here what would anyone say like if we're thinking okay the baseball is going to go in the parabola path of least action baseball's quite massive compared to the air molecules still though there is friction with the air some of that energy is going to be lost to heat and then if it were in a vacuum you would lose less energy to heat if it were in a very thick liquid you would lose more energy to heat so this person is asking about how these these equations might work well for like the frictionless Assumption like um you know it's a collision on the frictionless billiard table and no energy is lost from hitting the sidewalls and then you get a certain play out but then if you do have friction on the table it's like everything is getting slowed down because it's getting dissipated what do you think Jeff I think the distribution curve is going to be wider right I mean if if an agent is hungry or um dehydrated or any other type of um state that impairs um a optimal band of processing capacity then you're going to have a broader yeah you're going to have a broader distribution curve like if I'm under the influence of drugs you know um that you know make me hallucinate my ability to interact with my environment is going to be diminished right but but isn't isn't friction just included in the oil garage questions like isn't that just shaping the the landscape of which you find the the path of leas resistance like it's about finding the equations of motions right and if friction is part of your system that is going to be part of of finding finding the PA maybe with very high friction does it break down also friction is so close to friston it's a classic typo it's so it's so funny also just reading these like okay then there's the helm holes but we just saw Helm Holts from the perception as unconscious inference side but then here's Helm holtz's work from the um Flow dynamical side so it's like it was already right there you can modify the oiler lrange equation by adding nonzero right hand side to incorporate friction that's dissipation function okay let's let's keep it in mind one one thought about the under the influence are there any treatments or or or substances that reduce the variance on performance or are is is or do do interventions always are usually increase variance like if you you did something just quote normally a 100 times and then okay now do it with one eye closed or do it like you know standing on one leg or do it when you're really tired W maybe some of those or or do it on caffeine but it's like it might be you might be better you might be worse on average but then would any of those have a tighter distribution or when we change something do we always make it more variable too seems like it will be very oh sorry go ahead Jeff no go ahead go ahead seems like it will be very like dependent on the on the task um as well but I'm sure that certain interventions would lead to both higher and and and lower variance like I don't know if you would take a sleeping pill that would like reduce the the bar of what you'll be doing the the next the next few hours but uh we probably increase the variance in your performance on on certain tasks like I don't know reading a book or doing something that requires you to be awake I'm coming down to instrumentation and augmentation um if I'm you know in my natural state in my body I'm not going to be able to stay underwater and explore for a very long time but if I have a a mask and a snorkel then I'm going to be more adapted to the environment but it is a technological adaptation not a biological ad adaptation and if I have a SCUBA tank even more right so that is tightening up the curve in terms of my performance in that environment yeah that's a great Point too is the the off Source I mean if you go on a ventilat or a pacemaker you could have lower variability in your heart rate or breathing or if you had an exoskeleton that was like drawing for you you you would have lower variability but with kind of cascading externality and this comes back to me again to the to the fields course where you know we've got this mesoscale where we're naturally inclined to be able to understand and comprehend but when you look at you know things at the you know below the the classical Newtonian scale if you look at astrophysics or quantum physics um there is no conjoining or comprehension without instrumentation so so we literally can't even Explore those environments without augmentation yeah well it's like you you all like uh let's just say the base balls are flying around in the dark room we can just put on a strobe light take a picture we can say well the photons of our strobe light probably didn't influence the baseball that much that's why it's classical but then yes when you get into things that are on that scale all of the sudden it's like it goes from not mattering not mattering barely barely barely barely barely and then all of a sudden it's like it overwhelms when you're studying things are at that exact scale then your instrument becomes as big it's like your thermometer has a certain heat capacity if you dip it into a little to one molecule of water you'd have in order to not in order to get an accurate read on that temperature you would have had to already know the actual temperature otherwise you would be getting a compromise between the temperature that it really was and what you thought it was but you would yeah it it's funny because I was just reading about from economics I was reading about jeevan's paradox which is that the more efficient a system becomes the more or the more the more efficient um you become in resource extraction from an environment the more you're going to use that resarch that that that resource and then it could cause it to collapse so like if I'm you know I'm I think an example is um you know the EPA requires higher fuel efficiency on cars so because of the higher fuel effic efficiency um you uh people wind up driving more because it's cheaper to drive and you're actually putting out more pollutants into the environment than you would have otherwise and then another car related one would be like adding a lane to the freeway and then people think oh great now there's more lanes and then oh yeah capacity planning for Highway it's huge right like like you look at Houston or or anywhere where they do widening and it just stays it just stays it's actually that they're incentivizing people to get in cars more um and and not realizing that it's going to cause you know friction or eventually collapse right you know in the end it you know it's it's it's collapse Building Systems that have uh like like if you look at how the the the camir civilization fell it was because they created all this wonderful um um water um Management systems and and it was very very brittle and as soon as they had a drought or a flood then it like it they didn't have water you know and then people literally just died from dehydration so and the other thing from a car perspective right we can look at it at many scales me driving my car independently doesn't do much in terms of pollution right it's not really measurable in terms of the scale of of of the earth B biosphere but everybody driving their cars has absolutely a measurable impact thank you all so much see you next time I've got another Peace Jeff Frank you wna bring up anything H last point on kind of the friction I mean considering friction as energy that is used that that becomes converted to entropy and not like to work if we consider statistical work to be Improvement in accuracy and then the entropy is just the variance estimator which could be overfit or it could be inflated so then it's like if a new observation comes in the sort of um 100% efficiency motor it would take in one calorie of energy and it would translate it to one calorie of moving the car forward so that' be 100% efficiency it wouldn't change the temperature of the environment at all whereas if you just burnt the calorie the car would go nowhere and you would have released one calorie perfectly as heat so there's probably some connections there with with the information content of of what the model is ingesting and then it's like is that information getting like cleanly burnt into the best possible ACC accuracy Improvement or is it just being like thrown away but then it's like what would it mean to throw it away like if it just what didn't pay attention to the new data point and it just deleted the file in the real world that would change the heat balance in the real world because of like the energy and and um information equivalences but I don't know if that's exactly the right angle there okay well August is gone almost if you return at this time next week it'll be chapter eight uh oh let's see this time next week yeah chapter 8 part two which um everyone's welcome to join otherwise wise there'll be another three and then we uh are on with it but any last comments or questions oh just say yeah just thank you and see you next time cool thank you Frankie yeah thank you yeah thanks a lot Daniel bye talk to