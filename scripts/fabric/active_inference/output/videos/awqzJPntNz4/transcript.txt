hello it's February 8th 2023 we're in cohort three and we're having our second discussion on chapter one so just a few side notes before we jump to the questions uh first I'll place this in the chat but we can um hey Maria are you recording the the meeting yes I'm recording it with OBS like on my local computer okay I'm sorry oh no thank you for checking the icon okay thanks for checking yes it doesn't mention it it's like a yes so last week we talked about neats and scruffies and those terms are due to Raj or shank and it was actually last week that Roger shank had passed away which I have just placed in the chat so auspicious though tragic and people may find a lot of in this article by Harold jarch a lot of interesting um thoughts on learning by doing teaching others to do this is the next step in the education Revolution and also there's a student's Bill of Rights that I had never seen from shank before so there's a lot of interesting um pieces here so for those who are interested take a look and maybe see how we can bring some of that back to the textbook group and then also awesome thanks yeah and then um I don't see Yana Here but yesterday Jana and I went to the step-by-step active inference paper which I'll also put in the chat is one that we reference all the time because it has a step-by-step building of like static perception Dynamic perception these are passive interference and then action comes into play and we use the ontology to describe what was happening and use latex in coda to write the equation and then uh made some tables that allowed us to flip between different ways of talking about what was given and what we're calculating wrote the pseudo code made tables for every variable and interpreted every column so this was just for the static example but it was a lot of fun and I'll also put that thanks Jonathan that's that sounds cool too yeah so this was a lot of fun that we had and just uh there's definitely some walls that we run up against like doing vector and matrix multiplication in Coda but it's a fun direction for making really interactive and multimedia um systems all right so let's go to chapter one does anyone want to give any thought or comment at all on chapter one any thought or or question at all and then we'll jump into the questions that the cohort has had on chapter one it feels like a long while now since reading it could have been last week could have been last year yeah feel free to raise your hand or write in the chat any comment or question that's presenting itself to you today or we will look into the questions that the cohort wrote okay it looks like we may have done this last time what is the relationship between policy and environment maybe anyone can just give a summary or thought on that and then we'll move it up okay yeah very informative comment thread Brock go for it and then anyone else um policies are um selections on affordances in uh like late in the foreign environment speak thanks yeah and then let's look at the comment thread generative process stomach is empty stomach emits a rumble that's a great example because the generative process helps frame it in terms of what it is which is the process that passes observations to the blanket this doesn't have to be outside quote of the organism so the true status of the stomach is an external state with respect to the blanket States being interception and the internal States being cognitive modeling of interception generative process is just whatever passes observations so it doesn't have to be the niche but in the case of exteroception Vision hearing Etc pockets coming into a server then it is outside of the agents but it doesn't have to be spatially outside of the agents Jonathan yeah we said that the generative process is the thing that passes observations um presumably it doesn't have to pass an observation there can be things happening in the outside world that we don't have access to but may still be part of our generative that what yeah what is actually the generative process of the real world great point the generative process does pass observations to the blanket but that is not all it has to do so it could have um the extra the generative process could have 10 variables like the thunderstorm could have temperature light sounds but then we only have a microphone so we're only perceiving sound so the generative process is passing us sounds and then that is being used by the agents but that's not to say that the generative process is only sound and that comes back to to a um slightly more General point which is that the state space of the generative process doesn't have to be the same as the state space of the cognitive model foreign foreign processes can be other generative models in the social setting as Jonathan is pointing to that's sometimes called thinking through other Minds and let's look at this it's cool when we can see a previous question on the notion of surprise is the agent's perception not only affected by the influence of its environments but also an agent's peers so the agent's peers are updating their beliefs in a collaborative fashion what would be the extent of the update to an agent's GM of perceptions if an agent Witnesses the annihilation of one of its peers for example something like this okay it's a wildebeest people can check out the video okay Michael please I I just have a question with respect previously you wrote down that policy a policy is a sequence of affordances and I was wondering is it a sequence or is it the one affordance is it is a policy one affordance or is a policy a sequence so is it can it be more than one influence I was of the understanding that the policy is one affordance but maybe I'm confused yeah good good question and policy and affordance are used slightly differently for example in the reinforcement learning setting but we won't necessarily go there so if wardens are the actions that can be taken in a single moment alternative actions that can be taken so this could be movement up down left right this could be an eye cicade up down left right policy is going to be a sequence of those for a given time Horizon so if the time Horizon is one or the temporal depth of the model is one this is the same as affordances but if the the temporal depth were two then it would be all combinations of two affordances so up up up down down left right right left how does it then work with epistemic and pragmatic affordances at some points in the book it says that these are two aspects of one affordance mm-hmm yes great we we are going to get there and here's what it's going to look like and just to peek forward in chapter two so um Pi our policy Pi for policy G is expected free energy expected free energy is going to be calculated for every single policy so again if that is temporal depth of one it's just equivalent to the options that can be taken in that moment if this is a temporal depth of five then it's the free energy expected free energy of up up up up up up up up up up up up down now those different policies are going to be evaluated according to this single imperative expected free energy that's going to rank different policies based upon their posterior likelihood in reward slash reinforcement learning you would rank policies by their expected reward in fep we're going to rank policies by their expected free energy which is going to describe their posterior likelihood different policies might be seen as likely for different reasons and this equation can be partitioned in different ways to understand that so a policy might be seen as really good let's just say it's good but that means the same thing as saying it's a likely policy if it secures a lot of Information Gain on the other hand a policy could be seen as good or likely if it secures a lot of pragmatic value those both get projected down into the expected free energy now conversationally people will say something like oh well opening the book that's like an epistemic affordance that's compatible with what we're talking about here but the partition here would be like the affordance is to open the book or not open the book and then the action selection to open the book is selected because it has a high Information Gain so the idea and one that we'll continue to revisit is that you can get Behavior that's able to exhibit pragmatic values seeking components and when those are unclear on how to pursue come into an information seeking mode through a unified imperative G so we still do have epistemic epistemic affordances in the conversational sense but to be strict about it there are just affordances which are the capacities for action and then different policies are selected or not and we can partition that differently and that partitioning May reveal that a policy was selected because it reduced information had high epistemic value reduced informational uncertainty should I say um or it was aligning observations with preferences which is pragmatic value foreign can we relate policy with Goal I'm going to just copy in these answers page 101 chapter five well we'll come there okay any other comments or questions on this topic okay Ali uh actually about about Maria's question uh that if we can relate policy uh with goals um well maybe I don't know I if I can reiterate that example I pointed out in the last session about picking up uh a couple a cop so yeah actually uh the the goal is somehow inherently Consolidated into our actions and our policies uh or at least at our goal directive actions uh so I pointed out to an example um from ritzalatian senegalia's book mirrors in the brain which says that picking up a cup of coffee can be done in various ways depending on whether we are drinking from it uh in which in that case we would grasp it by the handle or if we're washing it in that case we'll grasp it by the rim or moving it out of the way uh in that case we would grasp it by the body so yeah actually in this scenario selecting the appropriate policy would necessarily require considering the goal of that policy or action yes thank you and we can talk about goals but the way that it plays out in the generative model there isn't a variable that's called the goal so here um Jonathan wrote the goal is really about minimizing expected free energy so yes some kind of meta imperative is to fulfill the minimization of free energy but let's think about like the goal is to move uh the goal is to move the coffee cup to the drying rack that is actually going to be embedded in the preference we expect and prefer to see the cup on the drying rack oh I observed it in the sink I'm surprised maybe even anxious what are the affordances well without going too deep into a motor model we could like grab or not grab move arm left move arm right and then some policy like move arm left grab move arm right release the grab that's a four-step policy that has pragmatic value again looking forward but we're going to come to this in the coming weeks that policy has value and it's like a goal-oriented policy because we reduce the Divergence between our preferences and observations so goal oriented or pragmatic Behavior is loaded heavily in this pragmatic value section which at its heart has to do with the um relationship between preferences and observations that's why we talk about like expect slash prefer like we talk about it as a preference but the way that it plays out is again not by preferred states are the most rewarding but preferred states are the most expected you'll be least surprised when your body temperature is in its preferred value when your body temperature is out of your preferences you'll be surprised how are we going to bound that surprise free energy just as it's done in Bayesian statistics how are you going to bound surprise there's two ways you could change the world or you could change your mind changing your mind depending on the time scale is like perception or learning changing the world happens through action so let's just say we're again surprised at seeing the coffee cup in the sink changing our mind might look like updating our model of where we expect to see coffee cups so that we're not surprised oh it's normal that it's in the sink so now I'm not surprised anymore so we effectively reduce Surprise by learning or you could reduce your expected free energy by taking sequences of action and whether a generative model learns or how it learns or or whether it acts and how it acts that has to do with the details of how the model are set up why exploration and exploitation are automatically balanced through policy selection and active inference what does it mean to say both are balanced any thought or related idea here Jonathan and anyone else yeah I mean I think it's to to really understand it you have to understand the equation that you were just showing us um where the information game is about exploration we can think about about exploration and the pragmatic is about exploitation um and so to really understand how that's automatically balanced you have to understand exactly where that equation comes from I think awesome totally agree yes it's captured in expected free energy calculation so this equation is not necessarily the solution it's not a strategy to balancing explore exploit like depending on what variables are set you could result in a agent that always goes for the right slot machine or always takes the hint so it's not that just by Framing it this way the problem has been solved but this as it turns out creates an incredible flexible framework for fitting parameters and testing different models that include the wide diversity of cognitive phenomena like attention and all of these other complex phenomena so it's like linear regression y equals MX plus b that's not a solution to the regression it's the space in which lines are going to be compared to each other so expected free energy isn't the solution to Adaptive policy but it's a space in which policies can be compared with each other how are they going to be compared with each other with expected free energy what are some decompositions of expected free energy it turns out to have some very useful decompositions that connect us with on one hand in the top line the semantics of value broadly in terms of informational or epistemic value and pragmatic or utility value so that's one huge connection because we can think about special cases like if there's no information to be gained expected free energy is going to get only pragmatic value if there's no pragmatic value then it is equivalent to a pure information novelty approach and it can do mixes but there's other decompositions that connect to the middle lines here have to do with um decision and control theory and then this bottom line points the way towards connections with physics where we see energy and entropy for example in the Gibbs free energy so that's kind of a doorway into physics and thermodynamics and it's this these are all just different decompositions of the same functional foreign it's a an advocate's claim that active inference simply balances explore exploit but a slightly more measured angle would be it frames the problem so that generative models can be constructed and parameterized that are able to adaptively navigate explore and exploit any preference for a question to go to next or anyone please feel free to just raise any questions coming to mind Michael and then anyone else yeah I was wondering this distinction between exploration exploitation does it only apply to the expected values or also to the variational free energy good question um we will come to explore the similarities and differences between variational free energy figure 2.5 F and expected free energy G equation 2.6 in short variational free energy f is taking in as arguments Q are beliefs the variational distributions that represent our beliefs and data so in variational free energy we're actually not engaged in policy selection in expected free energy we are engaged in policy selection so variational free energy is a common measure used in machine learning and statistics because of its ability to effectively fit models Based on data and then to really take the full octave turn and talk about not just optimal fitting of data but not overfitting which is like what variational free energy does in the expected free energy case is when we actually get into the consideration of alternate affordances yeah Michael then anyone else yeah yeah so so you're you're saying that exploration exploitation relates to the policy so to the somehow to the Future right but I can also engage right now uh right now into an exploration or an exploitation isn't that the case um so it I mean it does not only relate to the future I guess does it or or what I'm I'm misunderstanding there so I can explore right now not only in in a plan for the future okay Jonathan yeah I'd say that by some exploration and exploitation are sort of active things you know even if it's in the moment now um it's still uh you know it may be some sequence it may be relatively short but it's still something about what's happening now and where I want to be um so I I think that you know even if you're thinking about your exploration in this moment it is really about what's happening in some some future time that you're attempting to do nice thank you and thanks great thank you yeah and and also like exploration exploitation are kind of informal terms to describe different behavioral outcomes they're not necessarily like formal um and then also uh a great comment there in the chat um I'll just put it in here this is a good reminder that like affordances and policies it's like always come back to map and territory there's the affordances that the person can engage in and that's like the territory if you really want to think about it and wonder about it like what can a body do but as modeled there are modeler degrees of freedom in which affordances are going to be considered for the agent to do so go to the vending machine like that could be you could have the affordance go to the vending machine or go or not go it's just binary or you could have raise your quadricep muscle and flex your calf muscle so that's going to be a model that can do a lot of other things but then you're going to have to have all of this parameterization just to be able to get out of the chair so how you coarse grain action is one of the major modeler degrees of freedom and challenges in action modeling we'll come back to this more times any just offhand comment or question that someone has foreign following the question mark is just a tracking device okay it's a Twitter thread we're reading books why you want to go with a computational approach why not just go full on Gibson plus dynamical systems well this should be very um relevant I'll just bring in update here actually Maxwell also had a response on that tweet okay let's let's start what what do you remember or what was the response oh here responds to this oh yeah and there's active inference wow look at that foundational Atlas Atlas Shrugged do you remember what his response was Ollie uh yeah he somehow um well there's just the word uh was that those two are not necessarily exclusively mutual and I mean I mean uh mutually exclusive sorry but uh actually he's writing a paper to show the relevance between the two uh and uh yeah they're more compatible than uh some people might think so uh let me find the exact tweet thank you yeah like if it comes to conceptual understanding almost everything is compatible it's like just how flexible are you willing to be but there are things that are incompatible and then the question is like kind of so what or what is the bigger framework that those are or the context in which those are aren't compatible um excitingly though this will be tomorrow um I'll put the paper in the chat this is uh so Jay Benjamin Fallen days will join for a guest stream a potential mechanism for gibsonian resonance behavioral entrainment emerges from local homeostasis in an unsupervised Reservoir Network so I hope to um see A Accessible presentation on modern gibsonian modeling and drawing out some similarities and differences that are real or perceived with active inference ever and then anyone else this gibsonian or computational approach there's also links to um to the question is uh perception inferential or is it is it more direct perception and I don't really find a good argument that discusses the evidence for for inferential approach to perception or ecological direct perception so I was wondering which way to go yes there's so many um angles on this one of them is maps not territories so whatever it is that perception really is for ants or humans or computers we're going to model it with Bayesian inference so that's a very strong position because then it leaves the other person debating about how Maps really are while we're over here using modern computational tools to do statistical modeling and inference so that kind of sidesteps the discussion about the ontology of what is actual perception and puts it into the instrumentalist camp and then in terms of evidence the first thing that comes to mind is we're perceiving colors and shapes in our blind spot so no of course it's not direct perception you don't have photoreceptors there is that conclusive so okay this is this is mainly if it's fission visual perception is mainly uh used as a as a way to discuss perception but it gets more difficult if you talk about about for example pay or olfactory perception and then and then the question is is all perception inferential or are there is does it depend on the kind of perception you're talking about is it visual or auditory um and I'm wondering yeah it's it's um there's definitely a lot of nuance once we step outside of the clear invisible visual setting or the tangible and comprehensible tactile setting those are very immediate but analogy is certainly apply to other sensory modalities and again whatever the modality is one can say we're using Bayesian inference so let's just say whatever direct perception means how is it being statistically modeled is this yeah so the direct perception the way I understand the difference is that uh our priors are determine uh uh have a big influence and what we have uh as a perception and in the direct perception our priors don't influence what we perceive uh but maybe I need to black and white here lay it out and see if it's been argued that way elsewhere or what exactly would reduce your uncertainty about that question and if no one has laid it out so simply then it will be making a contribution Jonathan yeah I I didn't have this this answers the question at all but I think your question there about the prize um we it may be that we have um very accurate incoming information and therefore independent of what our priority you open the door and you don't know what's behind the door um the the prize will still have some effects but they may have much less effect than in than the incoming information um so I I don't think it's a matter of one uh sort of one form of perception using priors and others not I think it's just a balance between how strong those priors are that's my my take on it awesome yeah exactly um in the Bayesian inference modeling setting we could model a case where accurate information is coming in which is to say that the generative model has high precision on the information coming in it's updating priors a lot it has high attention or salience so it's like whatever the new information is it just updates it's prior to that so to the posterior becomes the incoming observation that's the special case of like a Time series filter with a depth of one it's like whatever the last data point is just go to that so that is functionally direct perception whereas if we have ambiguous information coming in there's low Precision on sensory data priors are not updating a lot in low salience it's low attention then the belief moving forward is reflecting the a pre the a priori stance the prior stance so Bayesian inference is just giving us computational tools and formal methods to describe that possibility so we can go from something that's being updated time Point by time point or not but I've never seen any kind of useful model presented other than just the appeal to direct perception not saying it's not there Brock and then anyone else um I just wanted to bring um of something that ali um continues to remind people because I think it's hard it's easy to forget or not or look over here is that uh we're using all this language about uh you know vision and um in the context of it like us a human and the brain and all of this and um actually it's not uh that that sort of entails a belief about the about active inference being um physical like that the blanket is physical that the senses and the observations all these you know actions are always kind of purely physical um or that the epistemic value the pragmatic value well that's epistemic that's information that's you know pragmatic that's always action it's not um so cleanly that is actually an informational State space that we're talking about that the blankets in right so it doesn't um if you remember that I guess is what I'm saying um and that it is constrained in a physical substrate like you are in a space you are in a Time um there are you know additional there is a generative process outside of you that is constraining your generative model like there is a constraint of affordances like you can't have um you you can't be a thing with an attracting characteristics like State space um and like ignore that completely sort of um you will always have priors so to ask like yeah what what how is it that we have like direct perception or when are when are we ignoring our priors that's back to this anthropomorphic like purely physical thing it's like when do the you know beliefs that statistical beliefs kind of um cancel out or something right with the when when are they purely reflective of the sense you know of the blank um that doesn't mean that you're ignoring your priors it just means that like like Daniel was saying is just a you know a well-fit you know high resolution High um the expectation and the the blanket state does the evolver are uh you know low surprise so thanks thanks again just physically constraint that's that's the important part is you can't you have to have beliefs you have to have prayers and so thank you yes it is a double-edged sword with the appeals to physical organisms because on one hand it kind of anchors how we think about these informational spaces and relationships on the other hand it naturally leads to a lot of important and interesting questions that very often it's mapped not territory but if one doesn't know the territory and is just learning the map then it's it's no bad thing to ask questions that bump up against map territory but to be aware that there is a map territory relationship that becomes clearer and clearer as people learn about cartography how the maps are built and why and as people explore territory and then um yes some of the key uh citations in this area one of them would be the emperor's new Markov blankets which was from we we had some live streams with yellow in 2021 and then most recently the blanket trick which is a whole other story we're not going to go into it again but I'll put the link there and um it captured a lot of this discourse on the blankets okay in our last um other than just the last thing um so Jonathan I think wrote imagine seeing something in low light or bright light there's a Continuum of how strong the priors will will um influence I believe the inference and that has been captured like in psychophysics which is from a long time ago small changes in brightness are more detectable in a dim room so the question is how to bring these kinds of empirical cognitive phenomena into our statistics and inference modeling methods and in the eyes of some it's it's a done deal so here Maxwell is saying like this was never an issue you get information theory in dynamical systems theory naturally so it was never an issue that doesn't mean every single researcher was aware of it but it wasn't an issue and then um the map territory fallacy fallacy which I'll also put in the chat where they I we I think we've even brought this up previously but they argue that fep is the ideal model of these kinds of map territory situations but a lot of the frustrations are related to different understandings and framings of map territory so anyone please feel free to raise your hand just bring up any comments or daughter question otherwise we'll take a look at one or two more of the chapter one questions that people had ever yes yeah so so as you probably remember I I work as a physical therapist and I treat people with mainly chronic pain and I it is quite uh essential to make a stand as to uh uh perception being inferential or direct because if uh pain is the experience that comes about uh by integrating priors and likelihoods and you could make a case that the priors are let's say male adaptive and are determining the the ongoing pain experience and instead of the likelihood uh in this in this example but um yeah if that's not the case then that has quite some implications for the way I treat people so that's why it's also very clinically relevant to uh yeah to have a good good uh reason to say okay I'm going for this inferential computational explanation of uh perception so just to to highlight where this uh question is coming from thank you yeah that's a great point and So like um we're going to come to this later but with cognitive modeling so let's just say again whether or not it's really direct or inferential in the world we're going to be using Bayesian inference as a tool and we find that somebody is engaging in some behavior that we don't prefer it's like a child doing something that we don't prefer or the person has expressed that they don't prefer it or however it is with cognitive models it's possible to ask or differentiate kind of like a differential diagnosis and Ryan Smith and others have done a lot of work in this area like is the person repeatedly taking this action because they think that it leads to positive outcomes so that it's a learning failure to understand the consequences of action or do they have a preference for that outcome those are two different clinical situations does this person prefer X outcome and they are taking the approach that makes sense at which point you'd want to be like hey it's really cool to be X and then figured that they'll take the right path or do they know that they want to be somewhere but they are not clicking on the consequences of their action in taking them to that goal so that kind of differential diagnosis and like you said is it like that the person has um a high prior likelihood on well people like me have this kind of pain at which point maybe any stimuli might interpret it as as that type of pain because it's likely right why not or is it a sensory attenuation is it a sensitivity to something it it could be any number of things so we can still use this differential diagnosis paradigm a little bit one step closer to being operationalized it doesn't need to pull back to like direct or inference philosophy within the maps that we can make you can still ask about the relative contribution of prior's likelihood sensory observations and so on but I think that's these are the exact kinds of application Avenues where hearing people's like insights and questions on which parts of this framework are relevant for them as they continue to go deeper into it it's like that's what is great to see okay well let's look at where we're going to be going in the coming weeks and chapters so we're having our second discussion on chapter one chapter one there was no equations it was giving some big overviews and laying out a lot of the big picture for active inference as the authors see it then we're gonna have two weeks as we go into a lot of the substance of the book chapter two three four and five okay what are those chapters gonna be about well chapter two and three are going to describe the low road and the high road to active inference and we're going to talk probably a ton about low road and high road um the low road and and we can come up with just tables and tables of concordances it'll be really fun the low road is in a way asking how how with Bayesian statistics this is how we're going to do it this is how these Maps work this is how these models work active inference is about cognitive modeling how are those models being implemented Bayes theorem not every Bayesian statistics equation has to do with cognition and action and perception you could have a Bayesian statistics model of something that wasn't an active agent but we're interested in the generative models that do perception and action and planning as an inference challenge and then in the case of brains that has been called the Bayesian brain approach so how Bayes theorem chapter 2 low road foreign is coming from the imperative for persistence or for survival or for repeated measurement so treat it lightly when we talk about the imperative for persistence and I know we've had some discussions even last week on what about these kinds of um seemingly self-inflicted injuries and all of this but just from a statistical perspective something has to persist long enough to be measured as being that thing otherwise you won't measure it at that thing like if you're taking measurements every hour and the cloud is dissipating every five seconds you're not going to see that cloud if the cloud is dissipating on the hourly time scale and you're measuring it every five seconds there's going to be some equations that you can use to model the cloud moving or growing and changing so that's coming from The High Road this imperative for persistence which becomes operationalized in a way that's compatible with Bayesian statistics through this concept of self-evidencing and the reduction of surprise about one's own perceptions like if you're unsurprised that you're in homeostasis you're going to be persisting as that kind of thing if you find yourself surprised at your homeostatic parameters it won't be long until you are not that kind of thing chapters two and three low road how High Road why those are importantly the low road to active inference High Road two active inference that's going to bring us to chapter four generative models of active inference that's where we're going to see the kernel that is situated on one hand using Bayes theorem as a how and explaining self-organization and persistence in terms of why chapter 5 is then going to talk about the setting where octave inference generative models have been studied most extensively to this point which is the mammalian nervous system so that is going to bring up a lot of examples from the Central and the peripheral nervous system of mammals and talk about how generative models have been used to study those kinds of phenomena that people are interested in from motor Behavior to decision making that's the first half of the book so we've kind of like gone in the skateboarding ramp or like the ski jump or whatever it is that is like chapter one it's kind of like going over the edge and now we're going to have more equations and some technical pieces are going to be introduced along these two roads and just like with everything it's many coats of paint so read through it and and ask questions every question is important so even if it's a very big what does this letter mean why is this here what would this mean if it doesn't didn't have to be this way how does this apply to this setting how does this help us do this or that like any structure of question if each of us can come up with a few we'll have many and um yeah specifically let's just look at what will come to in chapter two and then we'll close William James my thinking first and last and always for the sake of my doing this kind of speaks to this essential embedding of action in inference in active inference we start with perception as inference so that's going to cover some of the topics that we talked about today Box 2 1 is going to introduce Bayes theorem and probabilistic reasoning there's going to be an example that comes back a few times with a person holding something in their hand it could be a frog or an apple and then it's going to jump or not and we're going to model our uncertainty about what that object is based upon what we observe it to do there's going to be some discussion of basic statistical Concepts like support and expectation that is going to be applied in the setting of The generative process and the generative model process like the niche model like the cognitive agents action as inference previously we were talking about perception as inference now action is going to be treated as a variable that you can do inference on both perception and action can be used to reduce discrepancies which will also have a technical definition variational free energy is going to be introduced as a statistical measure that helps us bounce surprise and it will be shown what that means and then expected free energy is going to be introduced as a way that is as a way that different policies about the future different sequences of actions can be compared with each other special cases of expected free energy collapse to various other important settings like if there's no information to glean you can pursue pragmatic value if there's no pragmatic value to pursue you can purely pursue informational ends and that's the end of the low road thank you everybody farewell