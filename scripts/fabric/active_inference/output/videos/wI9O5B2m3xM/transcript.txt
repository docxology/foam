hello everyone it's June 13th 23 and we're in cohort three discussing chapter six so we'll head over to the chapter six page and uh before we look at some of the specific questions and like pick ones that are interesting and so on does anyone just want to give any overall thoughts or questions okay well of course just write in the chatter raise your hand if you want um we can look to some of the previously addressed uh or at least asked questions and get some more perspectives and improve some of the discourse does anybody have a alternative preference all right so also definitely please vote with a interesting button because once we get above like 10 or or some number of uh votes then we'll make a short video so we'll kind of be upvoting and then seeking to improve those sections most all right why is modeling of the generative process a necessary step for building an active inference model who wants to give a first thought on this that we can review but first just yet Ali and then anyone else just why why are we talking about modeling the generative process uh yeah I think as we talked about uh the the distinction between General to model and generative process before uh well at least uh according to the previous active inference framework generative process is uh basically what um I mean it refers to the latent state of uh the observery data we get from the environment uh in other words uh what causes those uh data uh in this case uh is put into a kind of probabilistic model so on the other hand generative model I mean the aim of generative model is to provide a kind of mechanism to track those uh generative process as close as it can or at least based on the situation of Interest so that's one distinction between General to model and generative process but on the other hand um well recently I um got to the understanding that it's not so straightforward to separate generative model from General to process as because in some situations we might never know what generative process uh is I mean what it actually constitutes generates a process and the only thing we can concentrate or we can at least uh confidently focus on is to model the generative uh model based on uh some of the assumptions about how the environment will behave in the future or at least based on some of our knowledge about the overall mechanism of the environment so but in some simple situations it might be possible to differentiate between the two awesome thank you anyone else have like any related thought or question about the role of building a generative process in a generative model and then we'll look at some of the previous responses and then we'll move on to another question okay I'll bring in one um paper path integrals particular kinds and of course remember that you can always just click on the on the the icon of the institute on the right and you'll jump to where we are um so in this paper which we often look back towards we see this taxonomy of different kinds of things ranging from the simplest inert systems through active systems but perhaps simple active systems like a metronome on through sophisticated or strange systems which have hidden internal states that are doing like counterfactual kind of world modeling self in World modeling so in chapter six we're talking about whether you're trying to set up a simple inert system or a simple octave system or you're on the path towards making more complex cognitive models there's going to be certain steps that are outlined in the recipe so that is like the continuity of active inference type modeling of the particular partition splitting things into internal external and blanket States and then further differentiating the blanket into the incoming sensory States and the outgoing action States we're calling them sense and action is of course conditioned upon choosing one side of that blanket to be internal and that's kind of like the cognitive system of interest and so we call the cognitive system of interest in terms of its particular States the internal and the blanket States that is like the thing and that is the generative model Ali I get and one other related thing is I mean this typology is actually based on a three-level classification uh namely at one hand we have the distinction between active and inert particles which do and do not have active States and then on the other level we have distinction with between dissipative and conservative particles which are and are not subject to random fluctuations and finally the ordinary and strange particles um which have active states which do you have and do not have active States and one other point is it's interesting that in some recent literature especially uh the one the white paper published um about four months ago ecosystems designing ecosystems of intelligence from first principles and this recent paper the inner screen model of Consciousness the term generative process never appear even once in the entire paper so basically uh they they've began begun to use a generative model interchangeably with generative process in some sense yes um this is this is something that we're gonna be asking about in guest stream 45 in six days because we noticed that in this presentation that Maxwell had generative model covering the entire particular partition rather than the way that it was shown in um the figures of the textbook where we had the generative model with internal and blanket States essentially being partitioned from the generative process which is the process which actually gives rise to the observations so we can think of it as kind of like some uh dialectical usage in the dialect sense of the active ontology so Evolution and and use of what people are referring to um that's how it goes when things are changing fast but we'll find out in a few days some more takes on this um active inference agent employs a generative model as its model the external world and uses the generative model to perform inferences about perceptual input to make decisions about actions the external world or the generative process is complex and unknowable generative models may or may not be able to learn but learning and also action selection puts the generative model in better alignment with the world's generative process whatever it might be two ways to minimize free energy change your mind through perception and learning change the world through action and there's some more discussion any other for anyone a comment or a question about the generative process and the generative model and kind of where we're at in chapter six or we'll move on to the next question all right awesome and also please use the upvote so that we can just figure out which questions we want to make improvements and um short videos around okay next question again please just raise your hand if you have if you have a different question or put it in the chat so this is kind of a core question about chapter six what are the four steps in the recipe to construct an active inference model so from the very first sentence of chapter six what the chapter is aiming to provide is this four-step recipe to construct an active inference model now it doesn't have to be strictly linearly followed they're more like four considerations or four areas of questioning more so than like you must take on one two three four in this order um but um let's look at the Active inference model recipe we made just a sub page because this is such a central topic I mean all of our expectations and preferences slash hopes and dreams about applying active inference using active inference modeling for some system or phenomena of Interest this is kind of what it comes down to again this isn't the only or the total protocol for modeling but chapter six is the transition point in the book where the first five chapters set us up to understand epistemically what active inference models were about the low road and the high road in chapters two and three how we approach active inference chapter 4 the generative model itself and some of the mathematics and the formalisms of it and then chapter five exploring some applications in mammalian neurophysiology and now chapter six is like our system of Interest whether it's another aspect of mammalian neurophysiology or whether it's any other of the many many situations that we're interested in modeling this is the model recipe as laid out by the authors here so does anyone want to give a thought or a question or just overview on the four considerations that that are in chapter six for the model recipe yeah Ali and then anyone else yeah just one thing uh that I think uh We've also talked about before is to keep in mind that it's not absolutely necessary uh to follow those steps uh strictly in a sequential order so it would be possible to uh to address them in at least uh in uh an asynchronous way or even uh in some cases even change the order of the steps so it's just a general framework to follow the recipe it's not I think needs to be strictly observed yeah maybe it's more like making four dishes but let's look at what they are so first question which system are we modeling and this is analogous to the identification of the system of interest in systems engineering and there are situations where this is trivial or where the teacher tells you which system is being modeled but there's also situations where it's non-trivial because of course everything is attached to everything in the world and so making these distinctions about the spatial and the temporal and the causal boundaries of the system that we're actually going to choose to model such that it's at some base optimal trade-off point between being tractable and understandable implementable all of these different features that's kind of iterated process and that's not one that's just simply written on the world as it is so we just get to show up and find out like this is where we have to take an active approach to modeling to even determine some of these processes through inquiry but what which system are we modeling the um second question is what is the most appropriate form for the generative model so let's look at where they describe this in a bit more detail foreign this is the decision whether it is appropriate to think of a process in terms of categorical or discrete inferences or continuous inferences motivating the choice between discrete or continuous time implementations or hybrid of active inference so just to recall figure 4.3 is where we see a juxtaposition of the discrete time active inference generative model on the top and the continuous time active inference generative model on the bottom they're being laid out this way to highlight their structural similarities like they have this kind of downward facing e and then the upstairs with action in both cases but there are some differences between the discrete time and the continuous time formulation we're not going to go into too much more detail on their differences right now but we can discuss if people want and this is going to get explored in a lot more detail in chapters 7 and 8 the coming two chapters which are explicitly about discrete and continuous time generated models and you can also make hybrid implementations so the most common hybrid implementation is um in the folk psychological setting where decision making is discrete at a higher level like should I um reach for the the orange or the Apple and then at the sensory motor or lower smaller or faster level you have a continuous time model like a motor reflex model and then the motor reflex model the attractor of where it's going to be expecting to find itself which is where it reaches towards is being imposed from the top down by that categorical decision-making model so Hybrid models are absolutely possible and one setting that they're used in is systems that have discrete decision making processes that interface with continuous sensory motor activities then we need to select the most appropriate hierarchical depth motivating the choice between shallow versus deep models so how much spatial temporal or causal depth is the model biting off are you trying to model leather for one season or for one year or for 20 years or for a million years and then how is that scope going to be compartmentalized into the model so let's just say we wanted to do an 100 Year predictive model one approach would be um one tick of the model one time step in the discrete time model is a hundred years and we fit all the parameters so that they are like what's accurate after 100 years go by but then we wouldn't be able to necessarily make a prediction at 50 years so okay what else can we do we could have the tick be one year and have this model go 100 into the future or we could have a nested model where we have decades where the tick goes by one year at a time and then 10 decades and so at the higher nested level it's like the transition between decades and so these are all structural variants of a model that can do prediction of 100 years or maybe you want every single day maybe you want a transition Matrix amongst seconds but each of these are going to have trade-offs in terms of the computational requirements of the model whether you're going to be able to calibrate it with data the amount of parameters that you're going to be creating and so this is the modeler's quest and Art and Science to find the right models for a given situation because you know all models are wrong some are useful and finally we need to consider whether it's necessary to endow the generative model with temporal depth kind of previously mentioned and the ability to predict action contingent observations to support planning that's called planning as inference and it is using the expected free energy or if you have different actions that can be taken different policies which is kind of like an action over the given time Horizon then planning as inference means predicting the consequences of those actions and then doing a type of inference to determine which path of action to be taken after determining the form for the generative model there are the questions of setting up the generative model and setting up the generative process so the kernel of active inference if we see it in figure 4.3 again the discrete time or the continuous time this doesn't have attention metacognition um learning of preferences counterfactual World modeling what would happen if they did that there's a lot of sophisticated cognitive phenomena that are not found in the base model in fact the base model doesn't even have learning at all we're going to see in the coming chapters how this can be straightforwardly elaborated to include learning on any parameter shown here but this by itself does not include learning and so they're they're highlighting that there's a lot of decisions to be made in terms of setting the priors and which aspects are going to be fixed and what aspects are going to be learnable and remember that the models are maps not territories so just because something is learnable in principle or in practice in the real world doesn't necessarily mean that the model is going to be simply mimicking that and vice versa so again these are just some steps to consider essentially setting up the generative model and the generative process the the type of thing that we're modeling the cognitive entity and their environment and they say that these four steps in most cases suffice to design active inference model once completed the behavior of the system is determined by the standard schemes of active inference this is a huge advantage of working with active inference cognitive modeling is once you get the model set up and entered into whatever implementation approach you're using SPM or Pi mdp or RX infer Etc then the methods of parameterizing it fine-tuning it fitting that model are very generic and straightforward so it's not like you kind of slap together how you're thinking about the system and then you're going to spend all of this engineering work on making the optimization tractable it's the opposite a lot of the work goes into a structural understanding of the system because once you have your model entered in to Pi mdp for example then standard routines are used to fit the model Ali than anyone else uh yeah I'm wondering uh how I mean to what extent uh this recipe is applicable when it comes to modeling the collective intelligence which is uh I mean the current interests of active inference research largely uh and in particular I believe based on the stages of development proactive inference outlined in designing ecosystems white paper currently we're under systemic intelligence level of modeling and we're aiming toward modeling or toward developing an efficient way to model a sentient intelligence but we're not there yet on the uh problem of modeling sophisticated intelligence and sympathetic and ultimately shared intelligence so it's interesting to see how those four steps can be applied when when we finally get into those stages of development of active impress agents yes this is from the paper from 2022. Olivia yeah oh so I suppose that you know the best way to understand these four different points is to uh look at how you know uh current examples or papers uh have done them uh so take you know already implemented models uh and identify you know uh step one two three and four um and you know do we have in uh in the active Enterprise textbook groups uh some kind of uh you know list of um example models to do that yes yes absolutely so it's a it's a great suggestion though I agree that um showing these stages being carried out we can hope becomes a practice in the active inference ecosystem because it would connect a lot of the dots for people replicating the analyzes and for learners but here's what we can look at now in the code page we have several dozen different languages different implementations of active inference drawn from a variety of uh papers pretty much the GitHub pulled out where we can now not all these are heavily documented or pedagogically oriented so sometimes there's some forensic work to be done with like understanding um because and also a lot of this happens outside of the context of shared epistemic niches and shared education so the variables are going to have different names and the implementations are going to be quite different these are not necessarily created um after reading chapter six especially if they yeah but but it certainly is a a retroactive approach that can describe um and then I think one of the most clearly unpacked and didactic examples that we can look at is uh model stream 7.2 and in model stream 7.2 in the video description is The Notebook of this presentation and so it does in a much more pedagogical way and in an executable way it runs perfectly as is you can see how is B getting set up so again this isn't exactly aligned with the four stages of the recipe but but like we said those don't have to have in that order but this is like these are the variables that you need to set up a b c d e yeah and then at the bottom you see the routines the Run active inference Loop so if seeing it in a pseudo code way helps you understand the perceptual nature of the active inference Loop better than the analytical equations that's definitely a good way to learn and study this okay yeah great any more that we can say on this one other resource I'll link in there this is to the octave block friends um Coda this is another project at The Institute so here we we've kind of expanded on the recipe to include more up front and along the way so more of like the structural understanding of the system and why the model is being made then we kind of include the steps of chapter six but also take more of a life cycle perspective on the operations of these models and then we have all these different settings where people have started to explore those kinds of modeling approaches so I'll just link to this page also um in in the recipe okay let's go back to the questions so what are the four steps we just looked through them essentially they're a set of considerations that build the generative model the generative process so the cognitive thing and the environment the niche that's giving observations for considerations that help us develop that from its kind of sketchiest outlines on through the determination of which variables are going to be like learnable or not which ones are discrete State space which one's our continuous State space Etc and then once we have that set up and entered into our implementation approach then all the routines are standard and there's always exciting developments with making those routines better at dealing with sophisticated um planning and so on so again this is a big strength and a growing one for active inference that the work in understanding the system gets us to the point where it can be run generically as opposed to just taking an ad hoc understanding of a system which is like kind of a mistake but one that flies by in many situations and then confusing the engineering work with improving the computational aspects of the model with an understanding of the system okay so that was this question again upvote the question so they rank higher but I'm just going to continue down from the top um in figure 6.1 what do the unidirectional and bi-directional arrows mean so we see there are some connections between nodes nodes are random variables and edges represent causal influences possible causal influences just because they're here doesn't mean that they're relevant in a given situation but this is kind of like the set of the possible connectivities of the action perception Loop so the blanket states are connected to each other possibly because they form that insulating set around the internal States so again you can design a system where the API call comes in and then a second computer computes it and then a third computer emits it so there doesn't have to be an edge between these two but in principle it's allowable um we see this symmetry where again an internal and external that just depends which system we're focusing on but there's a symmetry across here so you can kind of see it's like a rotated 180 degree symmetry where sensory states don't have a backwards Arrow from internal States and external states don't have a backwards Arrow to active States however external and sensory have bi-directionality and internal action have bi-directionality so um the particle that which is being partitioned off from the world can have different sensory and active blanket States blanket being the joint set of U and Y and internal States and these arrows are just shaping out the space of the possible interactions amongst those variables and um in let's see guest stream number seven how particular is the physics of the free energy principle if people want to go into more detail on this question uh Miguel Aguilera and colleagues provided some technical analyzes and basically asked under what topologies of the action perception Loop does the free energy principle apply for example if we have like a simple around-the-clock model none of these backwards arrows do things still apply or if we have more or less connectivity in in principle what applies and um the short answer to this is basically it's always going to hold in some fashion but it may or may not be interesting and the important constraints that we're really adhering to the most important constraint is across the interface there's no telepathy and there's no telekinesis that doesn't mean internal States can't track or phase lock onto external states with very sparse sensory input the point is they do so only through the blanket so you can't get information about hidden States except by sensory States that's no telepathy clause in the no telekinesis Clause is you can only influence external States through the octave States the blanket so the fact that there's no connection between internal and external States is really the most important constraints on the topology of perception and action and active inference and other than that there's some technical discussions to be had about exactly um which situations have bi-directional arrows and so on and some of it is explored in 7.1 Ali and then anyone else I just want I wanted to mention a couple of technical terms um that being used in the literature repeatedly one is the autonomous states which refers to um The Joint set of internal States and the activist States instead of the whole blanket state so particle is the joint set of internal States and the whole blanket States but if we consider only the active States among the blanket States then that's been referred to autonomous States and the other term is a sparse coupling which exactly refers to that unidirectional Arrow in this figure so very briefly sparse coupling refers to the fact that things are defined by what they are not connected to so if the whole diagram here would be connected the whole states here would be connected through bi-directional errors then that would just that wouldn't be a sparse coupling so the reason this term is used is because of that unidirectionality in the speaker awesome and one important piece on the autonomous States and this is kind of like a cool way to think about active formally but also informally autonomous States again are just the internal and active States so these are the two ways that you can reduce your free energy change your mind change the world through action learning a perception update internal States action updating active States our preferences the C Vector are over sensory States so we say I prefer to find myself at 37c homeostatic body temperature and so because I prefer that I'm going to seek policies that Meander my way even if it's one step backwards Two Step forwards to reduce my surprise bound my surprise reduce my expected free energy about finding myself at homeostatic body temperature so our preferences are over sensory States but the two things that we can control the autonomous States like all knowing and all-powerful are the internal and active States and another way of saying that is you don't directly have your thumb on the scale we want to see a certain number on the scale but all we want to be able to do even in our maximal empowerment would be perfect updating of learning and perception and perfect selection of action if you enable the model to also take control over its sensory incoming data not the not the downstream processing of it but the primary sensory data then the model May ins in pursuit of seeking its preferences just simply modify the sensory data so if we'd like to see a sunset you know we want to either learn but we're not seeing one we want to either learn that we actually don't prefer that then all is good with the world or make a plan to see it but if you can just turn on the VR in your mind and see it right there you've kind of um made a hollow satisficing of your preferences and in the ecological evolutionary context you're going to get swept off the table so the autonomous states are like what we would want to control under maximal empowerment and they're the two Avenues of reducing free energy changing mind and changing the world Olivier yeah I mean uh I'm not sure I got it uh but you you said the preference is put on the sensory uh state correct yeah uh so if that um reflected in the mathematical uh expression of free energy oh absolutely it is not shown here this on a particular partition we don't see the C vector or preferences but um let's look at it in the equations so here equation 2.6 on expected free energy and so in the top decomposition expected free energy G is a function that's evaluating policies so it's loading in our policy prior that's like our habits and then it's sharpening those policy priors into a policy posterior that then you can sample from or just select the best option from so let's just say that um two-thirds of the time I turn left that's my habit and then if we just passed the prior on policy through then action would be selected according to that ratio two-thirds the time going to the left however what expected free energy does is it sharpens the policy prior habit into policy posterior in the top decomposition we see one way of thinking about what contributes to the expected free energy for a given policy concern or option and that's thinking about it in terms of the information gain and the pragmatic value so first The Information Gain here we see that there's a KL Divergence between hidden States Through Time X tilde Pi is on both sides and here there's a y so if the Y the expected sensory information under that policy if it didn't give us any information it's not expected to give us information then the KL Divergence is zero no information is expected to be gained from that course of action however if the policy does have a sensory observations that would lead us to learn then epistemic gain is non-zero here we have pragmatic value and this is basically how surprised are you about the sensory data given your preference and so if your preference is 37 and it's like a bowl around 37 then the highest pragmatic value policy would be the least surprising meaning that the ball would be right at the bottom of the bowl at 37. so just to contrast with reward learning reinforcement learning in reward and reinforcement learning you have this reward function that's like 37 is the most rewarding body temperature so I'm going to try to find my way up to the most rewarding point we take an opposite approach we say I expect and prefer to be at 37c that's what I'd be least surprised by if my thermoreceptors were at 37. that's why expectations and preferences are kind of used together in that way and then policies are selected that are able to um contribute to pragmatic value and Information Gain and during the modeling process you see that there are some fine tuning needed to balance these two drives and that's actually explored in this notebook like if you set the preference for getting sugar to 1 million to one then it'll never seek information it's ready to risk it for the chance of winning a million but if the pragmatic value is um very small then the Information Gain term dominates and another way that that is shown in a figure is in figure 2.6 where we have expected free energy just as shown now here the pragmatic value term is on the left but it's the same equation yeah and so if only pragmatic value matters so it's a fully observable there's nothing epistemic to gains like a chessboard then you get expected utility Theory in contrast when there's no pragmatic value on the table so all outcomes are equally pragmatically valuable then you only have two three four five in which case you're having information driving decision making yeah but both can be on the table and that is how octave inference in a first principles way is negotiating the explore exploit dilemma yeah thank you Ali thanks and also this kind of information seeking or a preference seeking is what referred to as curiosity or rather artificial curiosity in the literature but it's probably worth mentioning another recent Trend in active inference literature which is the development of sophisticated active inference which I don't think is explicitly stated in the textbook but basically sophisticated inter inference um deals with the situations in which rather than trying to answer what will happen if I do this they try to address what will I believe if I do this so basically it's it's based on the consequences of actions for beliefs rather than just the states of the world thank you yeah especially with all of the developments and elaborations happening like around the time of the writing of this textbook and since then um it's kind of It kind of contextualizes the bigger picture but like figure 4.3 is like the Lego block this is like the the neutral minimal cognitive kernel shown in its discrete time and continuous time setting and a lot of the work right now on the analytical and on the formal side for example with category Theory is to understand the compositionality of these models like can we really attach this to that in principle and then a lot of the computational work which you'll see um in the code section are using techniques from computer science broadly like search on large trees and branching and pruning on trees using these computer science and engineering approaches to make running large active inference models more tractable so the textbook helps us um parachute in and get a first overview but for those who want to see more there's certainly more on the computer science implementation side and on the analytical on the formal side but all things considered the textbook s the line between that and again chapter six is like the moment in the book where it transitions from the first five chapters which are like a background and statistics class on through chapter six and Beyond which through our work we can even develop into something like a A playbook or a set of code and and in cohort three which we're in right now with chapter six one of our goals for this activity interval is to leave an executable Trail so we want to develop the answers to questions but also especially where we can to um leave a code or executable or just pseudo code way to approach this and that's something that can be collaboratively worked on inversion through the cohorts okay a few more questions all right how does the particular partition so figure 6.1 particular partition the particle blanket and internal States autonomous States just internal and active but the particle imagine if you're looking at a dust particle under the microscope that would be an inert particle but a cognitive particle is like the agent in the agent-based modeling so we see sometimes a simple action perception Loop and other times we see the the more um expanded particular physics but then this question asks how does the particular partition relate to the partially observable Markov decision process in figure 4.3 so where did the Markov blanket go in figure 4.3 okay one simple thought that anyone can add more the observations here oh are the sensory States and so in the continuous time they're even shown with Y so that's actually the same variable as used for sensory States and the particular partition but the O are the observables across the markup blanket and then here Pi's policy selection policy inference which is influencing the B Matrix which is how the agent thinks things change Through Time but we could also Imagine That Pi also reaches out to influence the generative process which just isn't shown here here just the agent's generative model is shown there's no generative process but if there were a generative process it would be receiving an input from PI and sending an output to observations so the pomdp can be seen as like a way of unrolling the particular partition because this gives a um sequential linear executable format to modeling the particular partition any other thoughts on this Ali uh yeah one other way to like look at it is to interpret the uh I mean because in sorry in pomdp uh the a the agents preferred observations um somehow strives toward keeping it within the high probability States uh which would be consistent uh with its continued existence in other words uh this uh striving toward uh keeping these hyper probability States can be interpreted as keeping uh its markup blankets marker blanket intact so in other words markup blanket is kind of implicitly um implied in Palm pmdp but not uh obviously explicitly stated but it can be interpreted from various perspectives yes thank you okay gibsonian affordance concept does anyone want to give a little information on this question and then I think we'll have a response well it's a controversial issue indeed yeah if you can just briefly uh yeah remind uh Gibson's affordance concept yes okay yes let me get the right page here okay here I'm going to um share some work by Paulo an intern and he's analyzing the affordance concept and the representation Concept in the English and in the Portuguese literature using the active inference ontology to to connect between the two of them um and there's a table so recently there was a um paper written by ramstead about the affordance 3.0 concept and basically says the way that we talk about affordance is an active that is pretty much the gibsonian affordance concept so as of the um tactfully noted this is like an area of discussion slash controversy so I look forward to Apollo developing the work more and and bringing this out however affordance 1.0 concept by Gibson was that the affordance was about the perception of a capacity for action in the environment like a handle is perceived as for grasping and people focus a lot on this direct perception and there's the whole Markov blanket trick which we've talked about elsewhere and people focus on like whether the Marco blanket is direct or indirect perception but that is actually a little bit of a red herring the key piece of the gibsonian affordance concept is that the affordance is doing something explanatory about perception it's explaining a perception of a certain type which is the perception for action in the niche however inactive inference as it's been used affordance is used to describe action capacities that are not necessarily perceived more like something that the system can do and so when we look at the pi variable from like figure 4.3 then like we call those a for what we call E affordances and then Pi is the policies of affordances so if it's just one time step then Pi is the same as e but if it's uh 12 time steps then it's all the 12-step combinations of the affordances e what can be done however active inference does not highlight the perceptual aspects of the affordance because it's kind of a view from the inside view from the outside which we're going to come back to in chapter nine but just to show what this looks like the experimenter might say well that Mouse can go up down left right so that's how the active inference affordance concept is used up down left right are the four capacities for action however the traditional ecological psychological gibsonian affordance concept highlighted the view from the inside which is the perception of an action capacity now that's not a perfect Concept in and of itself because it just begets the next question well what raises Salient affordances to awareness so it's not like one is better than the other and surely they can be understood of as compatible however there is some significant work needed to understand the continuity of these Concepts and whether or not it's valid to say that the affordance 3.0 concept is actually in the direct lineage of the affordance 1.0 and 2.0 concept and Paulo s is the best intern to speak to about this topic cool well that brings us to the um end here I'll unlike these ones for uh next week will be at the other time and um yeah everyone's welcome to add or upvote questions or anything else any anyone else want to add anything before we close awesome thank you yes chapter six is when it really starts getting into the the modeling and the doing so also next week I'll I'll hope that we can um develop out some of the code maybe even annotate some of the um the pi MTP examples or some of the other examples in terms of the recipe okay thank you all farewell thank you thanks bye