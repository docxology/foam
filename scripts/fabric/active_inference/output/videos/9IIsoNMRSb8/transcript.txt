hello everyone welcome to active inference live stream number 6.1 it is October 13th 2020 whether you're a firsttime listener or not welcome to tecom tecom is an experiment in online team communication and learning related to active inference you can find us on Twitter at inference active at our Gmail address our keyb team that's public or our YouTube channel this is a recorded and an archived live stream so please provide us feedback so that we can improve our work also all backgrounds and perspectives are welcome here and in service of that remember your video etiquette M mute if there's sound in the background and raise your hand so that we'll be able to hear from everyone here we are in actim stream 6.1 and today's stream is going to go like this we're going to start out with a warm-up section where we introduce some of ourselves especially our newer participants and just have a quick check-in then we'll turn to the discussion of the paper today we'll try to cover the goal of the paper the road map how they get from A to Z go through the abstract which is how the authors represent their work in the most distilled form and then look at some of the figures see where they're going to be going with the figures what they're going to be showing and then next week in 6.2 we're going to have a lot more time for further discussion on this paper and also to dive into some of the technical details of the figures so please save and submit your questions all right here we are in the intros and check-ins for the introduction section please introduce yourself and your location just say a quick hello anything else you'd like to add and then feel free to pass it to someone else so I'm Daniel I'm in Davis California and I'll pass it to one of our firsttime participants Maas it's actually matthys Matthis pink um I'm a master student in Germany in um at the University of osnar Brook which is in lower Saxony so it's uh afternoon where I am I guess it's in the morning where you are um yeah I'm excited about participating thanks for having me great let's I will I don't know is there another person who's new here uh lee Alex maybe let's go to Lee our other new participant yeah hi um yeah I'm Lee uh I'm based in London but I'm actually studying at the uh University of York uh studying embod cognition and um yeah look really looking forward to this um I will pass on to Alejandra hello everyone um I'm again at Mexico kind of tired um last week was uh very hard but um yeah nice to be here again with you all and um pass it to um Alex uh hello everybody I'm Alex I'm an engineer basically and now also a researcher and I am situated in Moscow Russia and affiliated with uh system management school so I'm pass it to clip hi I'm John clip I'm in the Cambridge Mass with the MIT media lab I'm actually doing this at in Northern New Hampshire at my farm um and I'm very pleased to be a part of this and here to [Music] learn let's go to Alex kefir I'll pass it off to Maxwell okay hi everyone uh so I was here a couple weeks ago um I'm a philosopher I guess and sometime computational modeler at manash University and right now I'm in New York City um and I've been involved in this debate uh that's that's explored in this paper for a while so thought I would join in and I will pass it to who's left um Shannon hi I'm Shannon Crooks um I'm part of the sensory motor Neuroscience Lab at the University of California in mered but currently I'm in South Dakota um so I'll pass it to Sasha hi everybody I'm Sasha I'm based out of Davis California and I'm affiliated with University of California Davis and also um just very excited to learn and unpack some of these topics um it's been a really great uh past six or so streams so I will pass it on to Stephen [Music] uh hello yeah I've been involved in this for the last few sessions as well find it very very helpful and very interesting I'm um doing a practice-based PhD into some um processes to explore social topographies um and uh at cry Christ Church University at the Solomon School of Applied psychology um with the help of the professional development Institute um and I'll pass that to Maxwell I suppose is it I believe I'm the last one um yeah so uh I'm Maxwell ramstead uh I'm based in Montreal where I'm talking to you from uh at Mill University and I'm also the first author on the paper that we'll be discussing today so I'm quite excited to discuss it with you uh thanks Alex kefir by the way for showing up Alex and I have had a sustained series of discussions around these papers that have led to followup papers and I think to a really robust and fun friendship uh through these discussions so I'm looking forward to discussing all these issues with you uh thanks uh thanks for the uh continued following of our work awesome you know we bring the ideas together sometimes through the people and the friendships so and I guess I'm not going to pass it to anyone since since everyone else has uh spoken right yep I think that is everyone so cool let's go to our warm-up questions and anyone who likes to speak can uh feel free to raise their hand or jump in if there's no one Speaking yet so the first question is what Drew you to this paper or topic and while people are raising their hand I'll start I think what was exciting about this paper was about just combining two different schools of thought and bringing them together in a constructive way that was really super additive rather than just choosing sides what about you Maxwell um well so the motivation for writing the paper in part um was that I don't think that at least at the time I didn't think that what the generative model business uh you know under the free energy principle is all about really I don't think that was well understood um at the time um that we wrote this so I I I allude to this I think a few weeks ago uh this paper uh the answering Schrodinger's question paper in physics of Life reviews and the paper that we discussed the last few weeks multiscale integration were all originally the same paper it was all one big thing and we ended up splitting it into uh different papers to address different things uh so you know the multiscale stuff that we'd been uh discussing to address like the the the scale-free and multi-level formulation of the Fe and the the aim here was really to connect uh the Fe to other pragmatist approaches uh the center act the center on action um and also to clarify uh the nature of the generative models that are at play here uh which aren't just kind of brain bound statistical models but turn out to be something like the phenotype of the organism cool anyone else have thoughts on that uh Alex kefir yeah thanks um so I guess well I was drawn into the debate because um um some of my work with yakob hovi was among the uh the sort of Target um the critical Target of the article although Maxwell and Company were very nice to us and they didn't say we were wrong they just said this doesn't exactly generalize to the free energy principle um so that's how I got drawn into this and I continue to be interested in it because I think it I mean I think we've we've converged on more of an agreement than maybe existed at this time this paper came out but oh yeah 100% I think I think we we've basically converged to one coherent story at this point but this is two years in the making so yeah but but I mean the issues raised here are still interesting to think about you know and I continue to learn more by thinking about them so awesome all right the second warm-up question is going to be what would be something that you'd like to have resolved by the end of today's discussion so that could be a specific question about how to apply something to a system or Le would like to speak yeah Lee go ahead go ahead Lee H sorry I was just turning my sound up um so so yeah essentially um I I guess I I was drawn to this topic because um uh my journey to towards active inference has been via cognitive Linguistics so I started off looking into relationships between language and perception and particularly metaphor so I think I've got quite a different understanding of um what's meant by model uh probably something more kind of phenomenological and uh maybe epistemic um and and I really starting to understand that that's not what really what is meant by active inference so I've taken a good look through this paper and I'm hoping to build some kind of bridge from uh where I'm at to more of an understanding of what's implied by generative model in active influence cool well great because that's one of the main topics of the paper and Stephen actually just so just bouncing off what was just said there in some ways when you take metaphors if you bring metaphors into embodiment and as being embodied in space and around us actually then suddenly that whole metaphor work becomes actually almost very close to what might be a generative model in a funny way even though it's different so there might be some way I'm actually so in some ways I'm kind of interested how this sort of becomes full circle and can come back to these kind of um uh kind of human ways of knowing even though we've accessing it through um maybe kind of of abstracted models interesting and I think we'll return to some of these ideas if anyone else wants to chime in on what they'd like to have resolved but very interesting to hear about metaphor as cognition and how we can humanize our understanding of some of these technical or conceptual issues all right well if there are no hands remaining I'll move on to the next slide So today we're going to going to be talking about A Tale of Two densities active inference is anactive inference which is a article in adaptive behavior in 2020 by Maxwell ramstead kiroff and friston and in this paper they lay out their goal really clearly which I always love to see in a paper they write at the very beginning the aim of this article is to clarify how best to interpret some of the central constructs that underwrite the free energy principle or FP and its Cory active inference in theoretical neuroscience and biology namely the role that generative models and recognition densities play in this Theory aiming to unify life and mind so what are the two densities they're going to be the generative models and the recognition densities and we're going to learn more about them and hear about how they're related and discuss different perspectives on how the densities are linked and specifically the question is what is the tale of these two densities it's alluded to in in the title and it's awesome that we have Maxwell and Alex and so many other voices here to to make that synthesis and that tale that we're all telling together realized so um in the ACT imp stream 6.0 I provided a little bit of context just from my perspective on some of these issues if people want to learn more about uh some of the background ideas but for now we're going to just jump into the abstract and at any point people can just raise their hand and I'll just pause right there and we'll take a comment or a thought in the abstract they begin by rehearsing what I had just read that they're looking to clarify how to best interpret some of the constructs underwriting the free energy principle and those two constructs are the generative models and the variational densities so those are the two densities and the tail is going to link them we argue that these constructs generative models and variational densities have been systematically misrepresented in the literature because of the conflation between the Fe and active inference on one hand and distinct albeit closely related basian formulations centered on the brain variously known as predictive processing predictive coding or the prediction error minimization framework more specifically we examine two contrasting interpretations of these active inference type models a structural representationalist interpretation and an inactive interpretation so so we're setting up the two sort of sub stories these are the the tension between these two perspectives that we're going to be looking to resolve under the F through active inference we argue that the structural representationalist interpretation of generative and recognition models does not do justice to the role that these constructs play in active inference under the FP we propose an inactive interpretation of active inference what might be called an active inference in active inference under the FP the generative and recognition models are best cast as realizing inference and control the self-organizing belief guided selection of action policies and do not have the properties ascribed by structural representationalists so for this next slide I'll really appreciate anyone's um perspective or linking it back to things they've seen before because I just put it up there as a visual and uh just a starting place on the left side here we have the Bas structural representationalist perspective that we're just trying to highlight the features that are going to be most simple to carry forward and the basian structural representationalist story is about how data and another type of data which are often called hyperparameters are linked through a recognition model that takes data like sensory data and recognizes it and then um going the other direction you have the hyperparameters that are generating sensory data and we can also to talk about why it's important to have this generative step and the outcome of this um basian computationalist scheme is that there's a statistical conversion of a multi-level model that represents structures of the world through something like expectation maximization or em models and we can contrast that with the inactive Paradigm and the inactive Paradigm is about how agents and the world are related through perception and action and the outcome of the inactivist perspective is in embodied ecological action sequence really from an embedded agent who is enacting behavior and so this is always the school of thought where we see all the ease encultured and embedded and all these things and they um seemingly at least at the first pass up to two quite different explanatory uh outcomes they seem to be talking about somewhat different aspects about the world and they definitely link them through different ways so I'm just curious um Maxwell or anyone else like what led to these two models being the two cities the two densities that were chosen how does one come down to just two why is there not one or three cities and then how did the basian structural representationalist and the inactive Viewpoint rise up as like the two kind of uh tier one theories that we wanted to find a synthesis between well so when I got into this literature um especially from the the vantage point of philosophy what I noticed was that very very little of it was technically rigorous in the sense that you know a lot of it was telling uh like a story about how you know the brain roughly performs basy and inference and then uh you know kind of saying well there's like a family of different theories that do this in various ways and grouping the free energy principle under that I say A you know uh there was like a a lack of technical rigor uh I I want to emphasize that Alex's papers uh with yakob are probably the exception to that uh when I uh consulted Alex's papers in 2018 I thought well here's you know some wonderful work that is really taking the time to drill down on um the formalisms as they're used to study the brain I thought that was great uh but i' I spent a lot of time really drilling into the formalism of the free energy principle per se and one of the things that I was sort of surprised to find out as I was learning the formalism was that although everyone is talking about the generative model uh there are really two models at play um so those are the generative and the recognition models or densities equivalently um I mean so first of all we say model by model we just mean a probability density right so uh a probability distribution over a bunch of variables uh that are of interest to us um and so yeah the the two models in question uh under the free energy principle function slightly differently than they do in more um traditional brain-based uh so to step back a bit in in um in machine learning and in statistics a recognition model basically tells you the probability of some State given a bunch of other things it's a it's not a joint probability distribution um it it and it's it's used essentially to recognize what's causing your data so you're using it basically to invert uh your mapping I mean Alex also if I'm saying anything uh inaccurate here just uh please uh jump in and let me know uh but yeah so there's basically in traditional uh kind of you know basy and brain machine learning architectures the generative and the recognition models are basically just the inverse of one another so uh the kind of top uh the kind of bottom up pass uh is a recognition uh pass it's a recognition model in the sense that it's starting from the data and then kind of passing through uh the network you're able to infer what must have caused your data and uh the generative model is the inverse path where you're starting from your beliefs about States and you can generate fictive data you know based on uh on this model and at least in Al papers the way that this uh well the this is how it was described as applying to uh the free energy formulation as well and my point in this paper was that well this is a a very technically rigorous and accurate description of what's going on in the basian brain but these constructs have a slightly different meaning under active inference uh and to to bring it back to I'm almost done uh just give me one one more minute uh to bring it back to uh these schemas basically the so the recognition density is sort of like your best guess right now you can think about it sort of like as your posterior and your prior so your recognition density is a density defined over all of your States and your parameters and it basically tells you what do I believe is the most probable value of these states and parameters now you know given uh my prior beliefs in my evidence your generative model uh to the contrary is the point of reference uh you know for the generation of free energy gradients so it's not your posterior it's your prior it's sort of like it harnesses all of the priors um especially the priors about your preferred data distributions relative to which the free energy and therefore the Dynamics are defined so you know you write uh inference and control I think you discussed uh in 6.0 Dan yeah the so the recognition model is responsible for inference and the generative model is responsible for control you might say so I'll stop there cool Alex keeper and then we'll go to anyone else with a raised hand yes thanks so I I stopped myself from jumping in I mean that was that was a good summary um the only thing the point at which I wanted to jump in was to say well so the recognition model isn't uh as Con constru in these Basi and brain theories is is an approximate inversion of the generative model so my my um if I have any complaint about this paper it's that I think that there's a a closer sort of conceptual connection between the generative and recognition densities than than maybe the paper suggests um and that I don't think you can cleanly separate these things so uh well anyway I don't want to launch into this yet what I wanted to do first was just address the the question was sort of how did these two visions sort of arise and my sense is that what Carl friston did he did a lot of great stuff but the main thing he did that distinguish his approach from the existing stuff in machine learning a lot of which was based on free energy minimization uh which I think he came to around the same time as people like Jeff Hinton but anyway he you know he added action into the picture and he pointed out that you can act so as to reduce the surprisal or the free energy caused by your sensory States uh instead of just revising your generative generative distribution um anyway so I think I'll hold off on on arguing for the moment awesome just want to say I agree with you now uh I the these two things do do not really come together uh come apart sorry um I mean it's it's really just an implementation of variational inference from that point of view and variational inference and this is why it's a tale of two densities is that to do this variational inference thing you need both you need a kind of point of reference that's going to give you the free energy gradients and then you need a sort of what is my best guess as I am performing gradient descent on my free energy and yeah like I I I don't want I don't want to say that the two come apart and indeed I mean I think you know in in a newer paper that I've written on this uh I basically just straight up say that you were correct initially uh in with respect to the recognition density so the recognition density it's fair to say that it's a representation in the structural representationalist sense that uh you've been uh articulating in in in the series of really awesome papers which you should all read by the way I think uh yeah whereas the the the one point of disagreement that I think we've clarified now is the status of these generative models and uh yeah yeah I'll I'll stop there too nice we'll go to Stephen and then anyone else with a raised hand before the road map yeah one question I've got is in terms of if if these um kind of um hyper parameters that they use in machine learning are are using a free energy is it that they're they're just minimizing the kind of energy expenditure and the entropy internally and and they're not using Shannon entropy I they're not looking at how entropy is inferred or transmitted sort of in a second order process from interacting in the world they're just minimizing it within the kind of data that's being kind of ACR which kind of in some ways seems to happen easily when you look at like Vision data but may not be so easy to pass when you sort of look at the whole body but that that question of entropy is it that they use entropy in a different way and they're not really using entropy in the kind of um external entropy of interaction but kind of just the entropy within the um calculations in terms of there are two kinds of entropy at play in general right uh so entropy in the thermodynamic sense is a measure of how many macro states are com uh compatible with a given uh value of a macro state right so I don't know your temperature is 36 degrees Celsius how many different macro State configurations are compatible with that um so that form of entropy is one special case of the broader kind of entropy which is more or less a measure of how flat your probability distribution is uh over your States so if you have a perfectly flat distribution your entropy is optimal and um so the the entropy that we're concerned with is really the second type it's the information theoretic entropy it but uh it's it's transpired over the last few years that uh variational free energy is also a thermodynamic free energy you just have to mult mly by boltzman's constant so essentially yeah it's always information theoretic measures but when this is realized in actual physical systems it is also a thermodynamic uh free energy but you know the the variational free energy it sounds kind of spooky and esoteric but it's really simple really is that you have a preferred data distribution and you have an actual data distribution and the free energy is just a way to quantify the difference between the two um yeah awesome we'll go to to Alex and then back to Stephen yeah I was just going to briefly say in the you know the earlier machine learning literature the free energy definitely wasn't supposed to be anything thermodynamic or I mean maybe that was it maybe that was an open possibility but it was just a it was just a measure of as you were saying I think Stephen between two internal internally determined distributions it was the the top- down generative posterior versus the approximate posterior and um any connections to thermodynamics are really cool but I think that's a additional like very substantive um question slth thesis Stephen and then anyone else who raised their hand yeah I think this is this is quite a useful distinction because I think that's where a lot of the mixing gets sort of caught up at the moment because a lot of stuff has been referred to in like the last 15 years around basian optimization and basan stuff and then where it's all pretty much as if it's in contained in the data in the brain and then now it's like try it's like a reconceptualizing of that so I think it is a big big challenge for people to like forget about what they've learned before really agreed with that Stephen and um that's really what this conversation and synthesis is about is about bringing those qualitative off insights from an activism and saying well wait a minute perception isn't simply the reverse of action you know there's not photons coming out of your eye so what is different between perception and action but also recognizing that the world and the agent have this sort of symmetry and that they are linked so again anyone can raise their hand but we're going to turn to the road map and ask how the authors said up the discussion between the basian and the inactivist approached and then ultimately converged towards some of a synthesis and on the right side is just the title page of the Dickens work Tale of Two Cities so first there's an introduction sequence and then they talk about statistical models as representations and specifically they talk about generative models and recognition models in basian cognitive science as well as generative models as structural representations so that's the basian structural and the representational components then they talk about generative models and action policies which is sort of opening the door to this potential inadequacy of the purely basan approach which is that it's not action oriented in the third section they discuss the active inference framework first they start by talking about how phenotypes are conceptualized under active inference and about marov blankets and there's a figure one which we've seen before and we will see again about how marov blankets and active inference are linked they then discuss surprise entropy and variational free energy which are all terms uh perhaps not surprise but the other two that we've brought up in this discussion and in the paper they really go into detail a bit more about how these topics are linked there's then a discussion about how active inference specifically links the variational free energy with the inferential models in section four A Tale of Two densities they talk about how the generative model and the recognition density are to be conceptualized under the Fe and specifically they talk about the generative model and the generative process in active inference in figure two they depict a generative model and represent it as a basian network in figure three they talk about the same generative model in active inference represented as a forny factor graph and the similarities and differences between figure two and three we probably going to go into next week in 6.2 there's then a section on variational inference and recognition Dynamics under the F in the fifth section they turn to purely inactive inference and they say first the claim that the generative models are control systems and so this sort of borrows on and builds on the generative model idea which is a bit of a computationalist perspective as well as this control systems perspective which implicitly means action orientation because control of action not just control of theoretical parameters they then take the fighting words section generative models are not structural representations I always like it when we can get down to specific claims and negatable state statements and uh just really being specific because sometimes these abstractions get pretty far out there's then the final figure four which depicts the action perception cycle in active inference as a generative modal and a process and last they conclude with some remarks and the remarks also conclude with towards multi-disciplinary research characteristics for cognitive science and I know we have a lot of awesome cognitive scientists and other perspectives in this room and so this is sort of our springboard where we can take the ideas that we're talking about here and ask well how does this impact how we're going to do the cognitive science research what kind of explanations what kind of predictions what kind of um experiments are we going to do differently how will our research Paradigm be different if we take this approach that is synthesizing the inactive and the basian approach so especially cognitive scientists um would be awesome to hear any thoughts and while people are sort of collecting their thoughts about anything on the road map or prior in the uh last 20 minutes here we'll have good time to go through the figures and ask about how they relate to this big topic how are the two cities linked what is the highway that connects the two cities or what is the broader collaborative Network that links these two any thoughts here on the road map you you definitely laid out the reasoning in the paper very well so thank you good and uh these papers are uh straightforward to lay out because they really have almost a uh additive way of laying out the topics first you lay out the strongest version of the other approach and actually it's the um professionality and the clarity and not misrepresenting another Viewpoint just to throw it under the bus or to make a straw man argument it's it's laying out the strongest form of the um prior literature is what allows us to build another level of strength on top of the literature rather than just cutting out the pillars from underneath us so I always well and I have to say you know we started off with this a much stronger position uh than we ended up with and it's it's by engaging seriously with the arguments that Alex and yakob had prepared uh you know with a few other people pow glazi and so on had been uh arguing for this kind of stuff but I mean thank you for for saying that about the professionalism I I really think that there there is something to that argument and the whole point is to keep the baby you know uh with while getting rid of the bath water uh and you know the the baby is this sort of idea that there is something like a a rep representations of the external world that you know carry semantic content and so on like uh it's just that it's not the generative models uh it's it's the recognition densities that's that that was sort of The Tweak that we wanted to bring to the table but cool Alex and then anyone else who raises their hand yeah so um yeah like like Maxwell says we've had a lot of interesting discs about this um I guess the point the point on which I remain not convinced yet is that I think I still think of the generative model even in the FP as a representation so we can we can maybe talk about that um the I think to me what this brings to the table and this is like transformed how I see this stuff is the importance of understanding the generative model as a control system um I just think you can do that in a way that also grants that it's a structural representation and that's but I've been that's still the framework in which I work um so I think there's another question raised here about whether the generative model is sort of encoded and um I do understand where where the authors are coming from um on that question and I think it's not so straightforward at in the FP as it would be in some earlier models like the H holds machine um so I don't know I'm curious to see if Maxwell and I still disagree I have the sense that I maybe still want to call the generative model a representation um more than Maxell does but we can get to that can I ask um Alex and again anyone can raise their hand and have a here too is what is the advantage of wanting something to be a representation or what is the alternative to something being structural right so I mean so I don't think in those terms in terms of the advantage of it I just think is it a representation or not I think it is based on what I what representation is and how this thing functions in this model so I know often times people talk about like what's the explanatory value of talking in terms of representations um but I mean to answer more directly um what's so what's the alternative to it being structural that's another good question um in my view this structural representationalist Paradigm really isn't anything new it's kind of just like the core notion of representation that's been at work in serious cognitive science since like Turing so like if you go back to um you know papers uh like um there's a paper from 1980 by uh Alan new on um sort of uh foundations of cognitive science and and he he described how um what makes a particular symbolic um physical symbol system um able to uh what gives it its Universal Universal computational capacity is its capacity to simulate other systems so I really think this notion of simulation is at the heart of of um what representation is supposed to be in cognitive science and that that really just is structural representation and if you go back last I won't go on forever if you go to um cummins's early work on on structural representationalism um the S representation can also be read as simulation um so it's not that I think that you need to call it a gen the generative model a structural representation I just think once you understand how it functions um I would say even under the FP that's like what it is but there's still a question about how it's encoded or whether it's encoded I think that's a separate question a awesome thanks for that response we'll go to Lee and then anyone else that can raise their hand okay so um sorry excuse me I I was just trying to make sure that um I I was understanding terms in the same way that they were being used but Alex you you just talked about the uh the notion of representation simulation and um I you know one of the ways I've kind of arrived at active inference is is via the work of of barel and perceptual symbol Theory and simulation does that is is that overlapping with what you're meaning by simulation or does it have a different um meaning if you're familiar with his work to probably I'm not I'm not as familiar with that work um as with um the the newal paper that I just that I mentioned I am and it is just a yeah great no just kidding I want to read it um okay I'll accept that I'll I'll take next word for it yeah I mean essentially uh especially these deep generative models are they allow you to entertain uh well I mean the there's a sense in which the like the baralo you know idea of metaphor is just what the generative models do uh you know if we're talking about a kind of loose associative structure that redeploys inferences about one domain in another I mean uh this is the kind of thing that you would expect a generative model would be able to do uh so these things are definitely I think strongly aligned uh in effect uh I mean didn't step suggests something similar I think uh like the yeah metaphors are generative models in a strong sense cool notion will go to Alex kefir and then anyone else yeah so um that's interesting I don't know what to say about metaphors but um I think the way I see the way I've this now is that um I don't think what Maxville at all are saying is is at all of course um maybe not of course I don't think it's at all wrong but I just think that our uh the sort of the structural representationalist reading my view is that it doesn't quite say enough but not that not that it's wrong in any particular respect as applied to the FP like so so after further conversations with Maxwell and also with um with Michael and the other authors on this um it seems to me that you still there's still a need for a sort of of neuronally realized generative model uh in addition to considering the entire phenotype to be a generative model so if you have a fancy organism that can do you know deep temporal kind of modeling and plan for the future and things like that um I think there's still a need for something that looks like a structural representation um in the brain that that is the generative model can be construed that way as well as there's this sort of larger more encompassing system and maybe this could be some somewhat hashed out by appealing to the multi-level active infant stuff um but last piece of this um in discussions with with um Michael kirov I hope I'm saying his name correctly we've never said it out loud to each other um it it seems as though he at least he is thinking of top- down sort of propagation of signals as a form of action so the stuff that we were saying about um top down generative models might just be sort of a special case of the sort of action that um this paper is talking about cool before we go to Stephen and then Lee it really reminds me about Alejandra's point one or two weeks ago about what are the similarities and the differences between the systems that can at least appear to do these deep simulations counterfactuals like the brain versus a embodied phenotype the cell perimeter is not simulating other cell perimeters um that's a little bit different than the way that the brain might be able to do something strategic so um we'll go to Stephen and then anyone else can raise their hand yeah one one thing I always look at when you think of rep we talk about representation also in performance um is to think of like representation like is there another presentation in the brain which often people start thinking of as a projection and then you start getting into into this very visually dominated view of what our knowing is you know so whereas it's a bit different to reenacting or reimagining so like if I was to reimagine as an engineer um a a model and then I manipulate it in my brain well am I manipulating in my brain or have I reimagined it in my peripersonal space and am I now manipulating it at actively in my peripersonal space and that is what I'm actually thinking of as a representation but it's not actually my brain at all it's just a reenactment in space for me to then start to work with or if I do it on paper I think the mechanism for that is this is not quite clear but this sort of opens up that question Cool Lee uh Stephen I think I understand what you're talking about but I are you just kind of um mixing up the phenomenological with the with the the underlying ontological level so if you have a representation in the brain and you simulate it that it that it manifest in experiential space or perceptual space is that what you mean well to to manifest it in the phenomenological space is to enact is what I'm saying so it's not like it's in the brain then I project it into space it's like it's not in the brain it might be encoded like Place cells grid cells all of that stuff with all the other stuff going but it might be encoded in a way that can reenact it but once it's reenacted so with the work with clean language and microf phenomenology looks at like re embodying Concepts in space around us so my kind of feeling is that a metaphor is kind of like our reading on our kind of affect and our kind of thinking our beliefs recreated in a kind of a physicalized way you know so we actually do like we I feel like I'm stuck behind a wall like I st you can actually ask people well where's the wall and they they'll know where the wall is and what's it like to be stuck and where so suddenly actually find that they've actually got like a model but they never had that model before they kind of created it so the question becomes is it a reenactment a reimagination and how much of that was already I suppose this is a question was that already sitting in the brain ready to go or did it only come about through the act of reimagining cool um in our last 10 minutes it would be awesome to hear from anyone who hasn't spoken as well as just to flip through the figures so that we can see where we're going to be headed to do some technical unpacking especially next week so anyone can feel free to raise their hand if they have a related or unrelated point but in these last few minutes let's just try to look at the figures and hear some closing thoughts so in figure one we have the marov blanket and active inference and we've returned to this figure many times it's used across papers and it's really nice to see it again and again because the context is always different and the part that I underlined in red was um in graph theoretic terms the marov blanket per se is defined as the set of nodes that isolates internal nodes from the influence of external ones and in in this capacity it's really good that we had the discussion about integrating internalism and externalism because those are also sort of like two ideas that have this tension between them and the Beyond internalism and externalism paper was about building on top of those about taking the strengths of those two ideas and then asking how they're integrated under actm and today what we're doing and in this paper is about taking interpretations of internalism and externalism specifically this basian more computational perspective and this inactive embodied perspective and building on those strengths so it almost reads like a recipe for how active inference can be used for synthesis which is by identifying uh areas of tension in in the literature or previously unrecognized harmonies between different ideas and then just asking how we can build strength on strength rather than attack strength to weakness or just um you know contrast weaknesses and I'm just going to continue just to show the other figures but I'll pause anytime someone raises their hand on figure two oh Alejandra go ahead uh actually yeah in that figure um I can take again uh the question you mentioned um I'm still confused in terms of um this generative models and their recognition density um in which temporal and um spal scale um OCC course in each individual cell of the brain this this process is occurring and then in I don't know in a layer of the cortex and then in the the hierarchy um of of the cortical layers and then in the whole brain and then blah blah blah but um so um belief updating is happening in each cell um I don't know if if um if if I'm um I'm I'm getting to to to to the to the point but um the cells have to maintain actually this blanket contains also some beliefs that never can change right um those so in to to continue being the the cell it it is um um so um I don't know uh this this this process of of the densities is is occurring in I don't know how many scales and that's all of that I mean uh we'll we'll end up uh hopefully discussing this next week if it's if it's unclear I mean I have to say I don't think the figures are super useful in this paper uh they're mostly there to illustrate a few things what's really important is the equations um so I mean for next week Dan I'll show you which ones in particular so that we can put them up uh yeah so uh Alejandra what you were saying is exactly right all of these things are performing a belief updating and when we talk about Behavior or Dynamics or whatever it it is all belief updating and belief updating just means changing the physical value of the recognition density at a moment so basically um in this paper like the big kind of conceptual contribution that I tried to make to this literature is to say well uh with active inference we can rethink what we mean by embodiment and enactment so embodiment means encoding a recognition density uh so your physical body is a guess about the it's a posterior probability uh that you're you're constantly updating through this process of belief updating AKA Dynamics AKA adaptive Behavior like you've got this we live literally embody this this density uh the physical states of our body encode the parameters of probability densities this is like the this is the idea um and then basically the the generative model is just the point of reference for the Dynamics that exists in the Dynamics the way I like to think about it is sort of like dominoes falling over where the recognition density is The Dominoes right each of these dominoes is like a posterior it you know and they kind of accumulate but the wave is the generative model you see like the Domino wave itself that that the generative model exists in the same sense as uh the wave kind of you know making all the The Dominoes fall and the recognition model exists in the sense of the the physical dominoes that are kind of encoding the the process as it kind of flows over uh but this will be I think hopefully clearer next week mathematically it's it's it's actually pretty simple it's that the generative model is the joint probability density over all of your variables and this this density doesn't exist in the brain it's not anywhere uh what exists is the the factorization of this density so you know the you always see this in all these active inference papers it's like P of all of your variables so Ada mu and all the parameters Etc equals and then this long factorized which is basically a it's it's a product of uh likelihoods and priors so this product of likelihood and priors is the recognition density that's constantly updated right and that's what exists in the brain uh but this joint density only exists as a function of the Dynamics it's like all of these part partial uh like carving UPS of this density right this factorization they all move together and in their Dynamics together they realize this joint density sorry I just I I do have to end it at the 59 as we discuss but this is the perfect excitement to build for our follow-up discussion next week we're definitely going to go into this question we'll just pick up right here we'll literally just hit play on the video and uh go into detail on the technicality and let's even have some dominoes on the screen so again just thanks everybody for understanding about the timing I've provided a follow-up form to the live participants in the chat and we welcome any other feedback suggestions or questions and please just uh stay in touch stay engaged if this was interesting or exciting we welcome all participants and it would be awesome to have you on this stream asking the questions and also learning by doing with us so thanks everyone for the awesome and energizing discussion and I'm really looking forward to next week when we can go another level detail into all of this so thanks so much