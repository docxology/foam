all right hello and welcome it's June 4th 2024 6424 and we are in active inference live stream 57.2 welcome to the active inference Institute we're a participatory online Institute that is communicating learning and practicing applied active inference you can find us at the link on this page this is recorded and archived live stream so please provide feedback so we can improve our work all backgrounds and perspectives are welcome and we'll follow video etiquette for live streams head over to active inference dorg to learn more about projects and today in 57.2 we'll jump right into it with a new guest Frasier and picking up on some topics that we left from the do one plus any other things that come up so by way of getting started Frasier you want to say hello and then any recap slash anything that you're thinking about would be exciting to discuss today hello yes so my name is Fraser I hope everyone can hear me okay uh so I'm I'm a recent computer science uh honest graduate from the University of Western Australia my interest is very much ly in in applying active inference in sort of Inu real world you know real time processing and so forth so I'm I'm very much interested by the the way in which organisms can well artificial or otherwise can use active inference to sort of build an an Eco Niche that affords their their adaptivity over time of course that's quite a general statement but doing this in real time is is quite difficult and if we can get a way to optimize on how we're soliciting data you know soliciting data intelligently and so forth where going to be able to do that much more effectively than we have in the past so that's a little bit about where my interests lie uh and I'm particularly interested in the consan is between this paper and this Suite of ideas uh with another emerging framework in in cognitive science called relevance realization I think there's there's quite a bit to be had there so that's a little bit about me and my interests so thank you cool Thomas what would you say just right off the bat in terms of relevance realization and active data s or or what else would you want to sample to know how you could answer I'd want to know more about um about relevance realization and and what that involves it's not something I have any expertise in well excellent I think we'll be able to um to have a bit of a back and forth then so sounds great yeah go for it fer how would you bring it in and then we'll see where it goes well it is I must stress it is a a an emerging framework there are several papers on precisely named as such you know relevance realization an emerging framework in in uh cognitive science but the general idea and this is very much spearheaded by I would say John V of the University of Toronto and a few other people Mark Miller in in um the University of monach here in Australia the the idea the central idea is that the ability to zero in on relevant information is is the Criterion of the cognitive so you know there are cognitive agents we are all cognitive agents um trying to make cognitive agents in active inference what exactly does that entail the the hypothesis is that to the extent that you are a cognitive agent you're able to to zero in on the relevant information that is uh necessary for maintaining your survival across time and your your ability to to achieve certain goals certain goals that one would expect are constitutive of your autop poesis as as an organism um and so the question then becomes okay well what what what precisely does this mean how can we cash out what it means to to look for relevance in an environment you know classically this is going to involve avoiding things that deleterious to our our markof blanket and and seeking out things that are conducive to it um the only other thing I would say so that that's that's a bit of a broad discussion the only other thing I would say is that it's it's very much stressed in I would say the work of AI and and colleagues that we actually cannot end up with a theory of relevance per se nothing is canonically relevant so things things might be relevant in so far as they are large or in so far as they are small or in so far as they live for a short amount of time or they have you know they R selected or k selected there is nothing that is uh you know relevant in in any absolute sense but what we might be able to do is have a theory of relevance realization that is to say the processes and mechanisms and trade-off relationships that allow and afford for the realization of relevance uh well one more thing the the the emphasis is on that that web realization is quite important uh the the framework does not presuppose that relevance is sort of out there in the world and we merely detect relevance neither is it assumed that we simply uh Express uh something from within our own schema in a sort of you know romantic idea where just sort of Express relevance relevance is co-created in the you know sense of motor Loop the econ between the agent internet's environment so so I mean all of these ideas are very very broadly consilient with uh the active inference you know framework more generally uh so I thought this would be a Kind of Perfect Place to um to bring this this other framework in I know I'm sorry Thomas that I'm sort of blindsiding you here with respect to this this Theory but um I think the general discussion that we will have even if we don't focus on you know the particular theory of say relevance realization per se will very much swim in the same sort of waters that I'm interested in in in navigating so I hope that makes some sort of sense absolutely and thank you for explaining it um the thought that came to my mind is if you sort of go back a little bit in and psychology what what's the relationship between the idea of relevance there and the idea of savs would you say the two are in some way analogous or is one subser of the other well one so the the framework in so far as I'm familiar with with it the idea is that relevance is in relevance really Iz ation is perhaps isomorphic or at least deeply uh very much deeply you know bed fellows with predictive processing so the idea would be that the the mechanism of say Precision waiting is is very very uh very much shared by by all of the processes that underwrite relevance realization so to the extent that predictive processing and precision waiting uh have things to say about salience as opposed to relevance more generally construed I suppose uh there would not be much of a distinction to be to be made but so to try and answer your question the the the uh you know consilience are very much between the idea about self dynamical self-organization over sets of trade-off relationships that's essentially what relevance realization uh you know the ontology of relevance realization the the isomorphism is between that and precision waiting in predictive processing that's the very specific mechanism that is that is identified okay so that that's an interesting point to sort of consider and one of the reasons I think that's quite interesting is is to think is there anything intrinsic about relevance that requires action um do are my actions in a in a clear way determined by it because one one could imagine having an attentional system that just Precision weights based upon some passive data to work out which stream is going to be most informative in updating beliefs without actually acting in any way to change it whereas the concept of sence I think goes a little bit beyond that and says actually it's not just a matter that I'm I'm estimating how precise the data streams that I'm getting are I'm actually choosing those data streams right where approximately do you think it would sit uh okay in that in that sort of schema I would I would very much say it's within the salience kind of landscape uh the the emphasis is very much on the the the means by which we can adaptively interact with our environment to solicit the right observations that are you know condusive to our agency per do you mind then just I suppose ripping on the the exact kind of definition of of salience as you've already done it I suppose but that that might be helpful discussion as well I I think it's an interesting one and and probably if you asked five or six different people you get five or six different definitions would um and I think you know I don't want to put my definition as being in any way Superior to to anybody else's but the the way I tend to think about it is that attention as you say is effectively a process of game control it's working out how precise of the different modalities that are available to me and that can be various different levels it can be a sort of spatial channels that I want to emphasize in spatial attention it might be attending to particular features um and there are various different versions of it um the distinction I'd make with salience is that I think salience is something that will actually drive action it's the amount normally I think of it in terms of the amount of Information Gain I would associate with several different actions and so the the degree to which I'm drawn towards doing that also raises the question then of what do I mean by doing something um because I could be doing something by overtly moving my eyes towards it but we may be able to loop back around and say well actually there's also the possibility to do something without making any explicit action but by choosing to allocate more of my or choosing a model in which I allocate more Precision to a particular Channel compared to another um but I think it it relies Upon A weighing up of Alternatives that there are several different things I could do here uh and a selection between those of course how I select between different actions will also depend upon the Precision that I ascribed different or the modalities that I might be able to observe following those actions because if something is more precise then that also implies less ambiguous and has the potential to to allow me to gain more information so you you see immediately why all these Concepts end up quite conflated because they do you know quite sensibly some ways um they do all feed into one another in quite a profound way um but I think it's sometimes useful just to be able to separate out the process of describing Precision to something from the process of choosing between several Alternatives in order that I can gain the most information right yes because specifically with that information gain there is of course the perhaps equivocation between say which model are we going to deploy to to you know make sense of the the sensory erors and so forth and then so exactly what observations are we going to pay attention to so that that issue is perhaps you know one that needs to be finessed um and I would say more more particularly relevance realization is is uh at least historically uh comes from the issue of model selection so the the the emphasis was very much on how the framework might be able to address the frame problem in Psychology so which you have a particular schema that you're bringing to bear on the way in which you're dynamically self organizing around your sensory prediction errors that's within a particular model um the yeah so historically that's been the focus I would say which would fit more precisely with with model selection as opposed to just uh the the key sort of you know base raw salience of of any particular observation so there almost a form of covert sence attribution isn't it not necessarily acting in the sense of moving but acting in a a covert mental action to select between some Alternatives have that yes yes there is a there was an action in terms of which model is deployed and in that respect it is very much you know action of the praic kind of the deflationary kind as KL might say of you you know moving your your finger or carding your ey and so forth that is that is definitely part of very much included in the relevance realization framework but um yeah that it does go all the way up to and is largely concerned with the question of model selection as we might pose in a machine learning context this I think that's incred sorry D do you want to go ahead go go I I was just going to say I think that that's a really nice perspective really important perspective to bring in in this particular discussion sort of around themes that we've been discussing over the last couple of live streams as well um about um the importance of selecting your data and that only comes about when you're capable of a particular kind of action and it's worth thinking about why particular kinds of action like this are so important and one of the reasons may just be a matter of efficiency that if you can select relatively small portions of the data that are going to be relevant then you don't have to process everything at once um arguably that's the reason we don't have you know many many eyes pointing in all different directions because we don't need to we just need something with a very high focus at a FAL level uh that we can use to specifically select the information we want to at any one point in time on this salience question it reminds me of the classic two two options to dissipate the free energy with change the mind to change the world so in terms of changing the world or at least what it hands to you there's the over choice of which stream of data to sample from that's like moving the eyes and then on the change the mind there's the inner salience landscape inner relevance realization that given a fixed stream of observations still enables a degree of freedom in selecting models that provide epistemic value what what is the pragmatic counterpart to salience expected utility associated with an action yeah I think that's probably again it comes down to lots of different words possibly with different meanings but also lots of different meanings that sorry lots of the same meanings that have lots of different words and so you're probably right to say pragmatic value expected utility um expected reward in some communities um the negative cost um there are all sorts of words you could use that more or less mean the same thing and what that means is is um just a description of something being attractive or aversive and even that is itself a little bit torical because it's just saying um my description for why a particular Behavior has occurred is that there is something that this particular Behavior or or or that will will bias behavior towards or away from it so it's almost quite a simple idea which is that that the behavior depends upon attractive or aversive things but in a sense the reason they're defined as attractive or aversive is entirely in relation to the behaviors they elicit yes I I think this also relates to the first principles partitioning of pragmatic and epistemic value in active inference so if we were dealing with a CO with a purely cost based data sampling method so something different than the approach taken this paper then we might find a way to add in different epistemic features or her istics and make a cost objective that could Encompass uh various elements of like novelty and so on however we would still only end up with one monolithic cost-based still pragmatic objective whereas the approach taken in this paper was to actually start with the costree p epistemic elements of Information Gain and then from there cost can be brought in but then it is clearer how the costs associated with sampling are not of the kind that the epistemic gain is whereas if you start with a cost reward pragmatic utility Etc based model then the only real method is to bring in the costs or values of information but then that ends up all kind of dumping into the same Silo and it can't be brought out back later yes and it's interesting thinking about those two different strands um partly just historically thinking you could regard active inference and the the the approach that we sort of outlin in this in this paper as being a point of convergence between several different strands of what you've been going on for many many years before this so there's a lots of people would think of it in terms of how things like expected utility Theory or reinforcement learning or those approaches that are based upon the idea of a cost might have now have uh Incorporated Information Gain like terms into those cost functions um but the other way of thinking about it is that there's a long tradition in things like Basin experimental design and optimal experimental design so much more from the the the question of how do we best design experiments um or even feature selection um from particular data sets to try and work out how best to draw inferences from it um and you could argue that that those sorts of entirely reward cost-free approaches that have then been u based upon how do I get the most information out of these things are now being equipped with a cost function so you could see it from either perspective and really this is this is one way you could go from either way you could either say am I trying to equip my cost with Information Gain or am I trying to equip my information gain with the cost of something yes meeting in the middle but it really does depend where it starts from um Chris want to add anything or or we can continue I think um I don't know can you guys hear me okay um what I really appreciate about kind of the cost in this uh on that topic uh in this aspect is that it is very useful sense of when do we not care about what we're gaining um at what point do we say hey we've made enough it's good enough and I think it's it's paralleled to a lot of the costs that we have in other models but it's also own unique thing where you're just saying hey you know we don't need to sample more we don't need to go with the full factoral like sort of like sampling design we've gotten to the point that we are satisfied with the information that we have gained here and we can move on with kind of the next steps of actually using that data in some way um what's really nice about it is that it know if you equip the cost to your situation appropriately you can really reduce sort of the time it takes to sift through large amounts of data or kind of through the monetary cost of actually collecting that data um because that's we're in a big data world but still a lot of areas that just don't have a lot of big data that you can actually utilize you have to collect it yourself and so you're actually doing the concept of cost dat sense to a literal monetary value I think that makes it infinitely usable uh in Industry spaces so pretty sure Thomas want to add anything or we or we can move on to some of the pieces that we didn't get to in the dot one I have I have a few questions of my own but I would very much like to get on to some of the things we didn't do in the the dot one just initially okay I think the main area that we held off for so maybe we can cover it and then and then sort of just in the in the openness see where it goes was section six um so for review in the one other than Carl's amazing Exposition in defense of epistemic value we walk through a few the fundamental formalisms and got essentially on up through figure five with a dynamically changing setting and spoke a little bit about the uh the similarities and differences with the maximum entropy based sampling then several pieces come into play in section six um they close section five saying we address next we address active sampling in a situation where analytical Solutions are no longer possible so there's a few things happening first is that the the loss of the analytic character where the generative process and the generative function have the same form that's what is going to motivate this kind of variational proximation and then also there's the sheer fact of bringing in the cost and the relevance of the clinical trial setting so maybe to kind of set up this example Thomas you're a clinician what did you bring in or how did you bring together this research section and ground it in what you felt was going to be helpful and meaningful for clinical settings well I think you've you've highlighted of the key sentences already and that's the idea that when we're you know as as a theoretician often the sorts of simulations that I'll end up building are those that work relatively well in an analytic setting or or where a lot of the problems are relatively easy to solve uh and and that's certainly the case for some of the earlier simulations in April um however there anything to be practically useful you often need to go far beyond those those domains and you need to work with problems that are sometimes not linear uh don't have clear analytic ways of of solving um but it was also trying to think so so it was trying to think what's a good example of something that's a bit more realistic a bit more like what people might do in practice um the other part of it is is trying to think what's a really good example of something where there's a really obvious cost but also it's really important to gain information about it um and clinical trials are quite an obvious example when you start thinking about it in those terms where there is some uncertainty about the benefit of a particular therapeutic intervention whether that be a new drug or surgical procedure or whatever else um and if you knew the answer to this if you knew whether it was effective or not or or or even harmful that could um make a big difference in terms of your cost function because you can benefit some people relative um to to if you hadn't offered them that intervention um so here here there's this sort of interesting um combination of those two things uh and and you think about how how a lot of these trials work in practice and in some cases they end up stopping early either because they've just become so convinced of the benefit of the effect that it seems unethical now to have a control on where you don't give people the treatment or if they started to become convinced that it the intervention is harmful and therefore the trial should be stopped so as Not to cause any more harm um so there's already implicitly a lot of these evaluations and these tradeoffs going into this domain um and so I thought it would be really interesting to try and unpack that um explicitly and formally to see how we might might start to to deal with this in a simulated context but in one that could be applied um in in in quite an important real world question okay so here in 14 we have delightfully stated the whole joint distribution so maybe could you summarize equation 14 here yes so um equation 14 was a way of writing down something very much like um Klan Meer uh type survival analysis um function but in in WR WR written down in terms of a basian generative model and something that could actually generate some data um so these sorts of survival analyses essentially look at the time or or or look at the probability over time that someone has experienced an event and what survival would come if that event is death that we're looking effectively how many people have survived over time and the shape of that function then you can compare that with different um different function shapes uh to see the the ratios between them which intervention led to Greater survival essentially uh it doesn't necessarily have to be um death it could be um it could be acquisition of a particular symptom it might be a positive thing so you might actually want to to um to flip it the other way around you know the time until sudden recovery threshold has been um but essentially you've got people moving from one category into another um and tradition in a survival analysis that would be from alive to dead and you're trying to then M that out but but again it doesn't necessarily have to be so mid and can even be a positive category move um so the way this is constructed here um I think our y variable is uh the the let me try to remind myself as a while since I've looked at this uh so the Y variable will be whether or not or or depending on how many people you're looking at the proportion of people who survived to a particular time Point um the the high tow variable that's underlined in blue is going to be the time we've chosen to sample to check how many people have survived in this analysis uh and then we have another number of other parameters that are going to be potenti entially relevant in um in explaining that um the Theta variable here uh which is underlined in purple is going to be the effect of our intervention or anything else that that might be relevant and you can see that's making use of a design Matrix which is this X on the the lowest Row The Columns of which are each going to represent different sorts of potential explanatory variables stop me if I'm jumping around too much as I as I do this um but you can imagine this X or the multiplication between X and Theta being very much like a standard General linear equation of exactly the kind that you might use in a regression analysis um the F variable uh is a set of temporal basis functions so the point of this is that we can now start to estimate a time varying survival function so something that that is bit more uh interesting than than just a simple sort of exponential decay and the relevance that might be a time since a particular intervention might there might actually be variations in terms of survive or experience particular outcome as a consequence of uh the time since an intervention was put in place it might might work for a short period of time and then stop working for instance um then I think the D andv here are um additional explanatory variables okay so V is the randomization ratio we choose or or sorry which group someone was randomized to it's a categorical variable uh and that's chosen by our variable pi r so pi r is going to be the um whether we've chosen to randomize uh in various different proportions so I think here the options were to randomize in know a one to two a 1: one or a 2:1 ratio between placebo group and Interventional group um so depending upon those will sample a value for V and that will tell us which group somebody has ended up in um and the row variable here is just giving the um survival function so this is effectively just a sigmoidal function at each point in time saying whether somebody has survived up until that time point and you can see that that's the product of that over a series of discrete time points um uh and the reason for that is that we're effectively saying if I have survived one time point then I'm in F to may or may not survive to the next time point and then I'm in the cohort of people who may to the next time point which is why it's that product over time so cumulatively the number of people who have not experienced the outcome should drop at each point in time uh and again the sigmoidal function at each time point is just to make sure that that's in between zero and one so that one would be everybody avoids the outcome and zero would be everybody experiences the outcome from one category to the next the key thing to bring out of this is that the two choices I can make represented by pi as to how I sample my data are um are when I choose to follow someone up um and what randomization ratio I choose and each of these are going to be the things that are subject to our constraints based upon our our pragmatic value cost which here is going to be the want for people to survive or to avoid the the negative outcome and the randomization ratio will also affect that same and and and the um sorry and the Information Gain that I'm going to achieve by doing this and so the idea here was that we will carry on gaining information about the shape of these survival functions until the cost of gaining more information or the benefit of gaining more information is less than the cost of randomizing to the R Group awesome thank you so we see it in its joint distributions specification form in equation 14 and then figure 9 the top with the graphical form okay so then let's briefly Walk On Through To The figure we then have equation 15 16 17 giving details about how the variational lause is being applied to the Joint distribution before anything to add on this I don't know how How Deeply you want to go into it but essentially the importance of these things is is just that we're now to deal with approximations and because the form of the generative model on the previous slide was quite nonlinear uh it becomes much more difficult to solve in an analytic way uh so what we can do is make use of various components of a um of an expansion um around different gradients and HS so this is looking up to up to second order um and that's quite useful in that those same quantities are the onsters that come up in um I think the lowest row here is effectively the penultimate row is a mutant scheme to optimize variational for energy uh and a variational for energy under plus approximation requires exactly these gradients and heskin so first and second derivatives in order to be able to to this sort of problem cool yeah there's probably a lot to say on the math but one part that I always find fascinating is however these distributions are shaped whether they're with a central tendency like a gaussian or whether they have some other kind of structure the variational lause is going to fit a parabola basically facing down over the central tendency and so there's places where that's misleading or not but it's just so interesting to see here how you stepped through and we can still Trace out what those variables mean and then by looking at the the properties of the distributions as specified it's like there's this incremental optimization scheme that will put a central tendency on the distribution so it's a it's it's really getting at what the variational approximation is which is there's some family of function that maybe is completely intractable but then we can choose to treat the distributions in a way where it is possible for us to shift and scale and tune an upside down Parabola and then that has a well- behaved property so it's cool um okay and then we get can I yeah go ahead can I just ask sorry on that on those approximations there um is it the case that with respect to this approximation that we assume the distribution is quite tightly peaked about the mean so we have quite a precise approximate posterior is that is that the case no you don't need to assume that it's tightly um you just have to assume that there's a reasonable approximation around that in fact I'm trying to see whether it's obvious from these equations um slightly different form to to what I'm used to but I just wondered if that that was the case the answer is no then so no so the the reason that that sometimes comes up is that if you are trying to derive a variation of a plus procedure often part of that procedure is is said saying that at some point you effectively say that all I need to do is work directly with the mode rather than working with both the mode and the variance and the reason for that is that the the variance or covariance and the posterior should just be in an well not necessar antic but a function of the mode in relation to the probability density you have and that's that that's evident in the in the lower part of um final equation here so Precision here uh is dependent directly on the Hessian evaluated at the mode and that's why why we're looking the maximum iteration where we've reached hopefully the mode of that distribution um now it it sometimes seems that to go from a free energy functional where we're taking an expectation under the posterior to one where we can effectively neglect the um the the variance to um to just deal with the mode one way you can think about that is if I were to assume that the mode is so sharply peaked that there is no variance to deal with and then the expectation just becomes a Delta function you can just evaluate directly at mode uh and and that certainly will get used in very similar equations and you'll end up sort of arriving at a m esate the other approach to this is to say that if I'm assuming that the um posterior is approximately gausian in other words that the the log probability of my data and explan variables are approximately quadratic um then it means that expanding up to a second order term so making a tailor series approximation up to the the quadratic element I can assume that that quadratic element is effectively constant in the region I'm I'm dealing with it um that means that when and that that quadratic bit is effectively our our posterior Precision or our negative exterior precision as you can see in the sort of final plot here um so the point I'm trying to make here is that that um although it one intuitive way of of deriving some of these same quantities is to say well let's throw away the variance and imagine we're just doing a map estimate a maximum apost estimate um then you'll arrive at very similar modes however the variance and the posterior Co variance can actually be recovered under this assumption that that you're treating it as being approximately alian at least close to the mode around which you're estim yeah yeah it's explored in SPM I see the variational Applause as mode seeking and then secondarily estimating how spread a parabola should be which isn't a normal distribution CU a parabola drops off whereas if you do the variational gaussian then you actually are jointly tuning the mean SL mode and the variance parameter and then you do have the Tails going off into the probability distribution well what what what you should remember there though and so you're exactly right to talk about the mode seeking behavior and and fitting a parabola um but remember that the parabola we're talking about so this quadratic function is actually being used to fit the log probability not the probability itself and if your log probability is of a quadratic form then you are dealing with a ging distribution and in fact it is the coefficient of the quadratic term that is then your Precision where you're inverse covariance thank you great addition okay we get to figure nine so it's in it's in the medical journal what does it mean what is it saying um so when when you're looking at probably the easiest thing to look at here um would be sorry I'm just minimizing video so I can see it clearly uh yeah so the sort of thing you might see in a medical journal would often be a survival curve that looks a bit like the prediction curve that you see here often it's more stepwise in terms of how how it's expressed and that's to do with form of of KL Meer estimators um and the the way in which you'd read that is that the Y AIS is showing the number of people the proportion of people who have yet to experience an event and often that event is is either a particular kind of clinical outcome or sometimes lost to followup which is another thing that always needs to be incorporated in then you end up in questions about sort of censorship of data which essentially means how do I deal with data I no longer have access to um and and the xaxis here is is time so at each point along the x- axis I'm asking between these two curves each of whom represent a population of people who have or have not been exposed to an intervention um uh what's the difference in terms of the proportion of people who have not yet experienc an event so that event might be a heart attack or a stroke or and you know various other things that you might pick out as being clinically relevant and the key thing really is trying to understand how do these how how does either different interventions or even the absence of an intervention or more commonly a placebo intervention uh differ and that allows you to estimate the effect of a particular um therapy that you might want to choose awesome so here we have the random sampling in figure 9 for the randomized control trial so in this situation there was randomization of 50/50 and then the choices as shown here are are uniformly scattered throughout the the duration of the study then yeah you build in the [Music] um deliberate choice of follow-up time and random ization by combining the general message passing with the information uh gain imperative here and we get to figure 10 so what is different in figure 10 well I mean the other thing I'll just point out is um so the choices here are both the choices about follow-up time and also the choices about randomization so the size of the dots uh representing each choice uh represents and I'm afraid I can't remember which way around this is but the number of people who are randomized for each group so three different size dots one of which represents uh one3 in the placebo group one of which represents half in the placeo group and one of which represents two3 in the placeo group so it is actually and you're right to say it's it's deciding a completely uniform way in the um first figure just to illustrate what would happen if we if we just decided these things at random say nobody ever decides these things just at random it's a bit more rational there often pre-specified followup time or even in Bas adaptive type clinical trials there'll be criteria that been m in terms of when people have followed up and how the randomization works but we're comparing to a slightly um straw man example of if we were to completely randomize and just pick things entirely at random um so the difference between figures is it figure nine and 10 is that in figure 10 we've now um now now put the information gain as one of the key things we need to make use of and so here it's going to adjust the randomization as it goes to try and and make sure it learns uh most about what happens in each of these different conditions so it's more uncertain about the trajectory in one condition um it will it will assign more people to that condition and vice Versa until it's got more precise estimates hopefully of each of these lines um it's also going to change where it solves and you can see that there's a slight um a slight shift I think towards later in the trial one of the reasons for that is that the later the follow-up time the more informative that is about all the previous follow-up times if I observe someone early on and see that they've survived that doesn't necessarily tell me how much longer after that they've survived whereas if I observe someone at the end and and know that they've survived that tells me they probably well that tells me they've definitely survived throughout all of the preceding D points as well um so there's a little bit more information to be gathered towards the end compared to at the beginning so there's a little bit of a shift in that direction what's not done in this particular uh simulation is uh any cost or any preference for people surviving which obviously is a very important thing to include in any realistic decision making I think that's going to be the Fig we look so then you layer in the cast in 11 so explain this one yeah uh so F first thing I tried doing with this one actually was was just putting a general preference for observing someone surviving the issue was it then just selected all of the the points at the very beginning of the trial um because everybody survives at the beginning nobody had time to experience the AL um which if you prefer seeing people survive is is actually a completely reasonable thing to do um but what we really want is for people to survive for the duration of the trial so here here there's a um a sort of increasing function of prence that says I I prefer to see people having survived at the very end which is of course also weighted with this potential information gained to and one of the things you'll see here is that it relatively rapidly switches it Behavior to randomize more people to uh the placebo group which is the group in in pink and that seems like a very reasonable thing to do because a as things progress you can see that the placebo group even though it's less confident than on the previous slide it learns that the placebo group um actually survive better than the treatment group so in this particular case the treatment would not be a good treatment it's actually harmful um and this is analogous to the idea of stopping early in a clinical trial because you're you're concerned about the effect that your intervention is having um and so I think this is this is sort of encouraging to see that it's um it's behaving in the right way it's um it's saying actually more people survive and don't experience this delerious outcome if they have the placeo so as I become more and more confident of that I'll randomize more people for Placebo arm uh and the end conclusion of this is that everybody would be randomized that are and in a sense this is this almost blurs the boundaries between between the information seeking which is the primary IM of a clinical trial and the public health imperative to try and um make available the the best treatments that that are going to be most effective and to not give people treatments that are going to cause them harm but by trading off exploration and exploitation sort of traditional um sense we can actually blur the boundaries between those two things and gather information until we've reached the point where actually the amount we could potentially gain from that information is less than the cost that that's having on people who are randomized to the wrong group thank you it's very interesting in light of our earlier discussion on the sort of reward first or epistemic first when we think about the hypocritic oath like Do no harm do no evil and then it immediately comes in well what about a blood draw and this is going to cause harm oh well there's a a better benefit but then that is still all cast and reduced down to the expected benefits and utilities which leaves Information Gain kind of out in the cold as something that can't really be compared or brought in whereas this is in in certain C ways blurring a line that gives that there's a lot of structures around that line between what is health research and what is public health and so helping paint that it is blurred in practice and that the formalism brings Clarity to that Fusion imperative rather than blurring what was clear is a it's a very I mean it's a society shifting concept that would change how studies and day-to-day Health could be done and I I think in many ways it is done already at an implicit level I mean I think a large a large part a large number of the decisions that um is any any doctor is making on a day-to-day basis um revolves around do I have more to gain by getting this new piece of information versus the potential cost of doing this to the patient the Health Service to society in general um and um you know do you do you treat somebody early before you're completely sure about what condition they might have or do you wait until you gather more information but potentially risk them deteriorating in that time um so there's there's always a lot of these trade-offs happening in clinical practice I think implicit they are already happening in at the level of these sorts of trial dists as well that people do stop trials early um or or or do use adaptive trial designs where they can change the parameters based on what's happened probably means they AR implicitly using these same um uh ideas without necessarily formalizing this way so in a sense I in a sense I think it you know is maybe an endorsement of that approach rather than necessarily saying people should do differ I think in many ways people are already doing yeah um from the help oh yeah Chris Chris go ahead I was just wondering because you you what's I like about this figure that and you much said it outright is that it it shows kind of a stopping early sort of uh modality in the study where you know you're shifting more people towards the placebo group you're effectively more less just saying you know it's not worth it anymore um what was interesting to me or I guess what I'm wondering is there's also the C the counter to that that you could you know in a different scenario say hey this is working really well um we're going to put more people into the treatment group absolutely fine but is there a way that you can embed kind of extending the time into some of these models or decreasing the time they're just saying at some point hey it's no longer worthy of me continuing to randomize people here it's just let's stop here this is kind of that cost function can you optimize the cost function to um either decrease or increase the time so that you can get the most benefit from The Trial that's kind of my what I was wondering yeah um no absolutely and I think um I think sort of changing the the time parameter is another one of the key things that that you I mean in a sense you could argue that that that this um choice of when to follow up is precisely that um that that that actually it's already to some extent doing that um and it would be interesting to trade off the costs uh in terms of the information lost when people are lost to followup and those sorts of things as well in an more realistic model relative still relatively simplistic one we forward here um but I I think it's to take your point more generally as well it's it's really interesting to think about what are the parameters not just in a clinical trial but in any any um any sort of experimental design or policy decision what are the key parameters that you have control over and what are the effects of those parameters on the information you might gain and on the preference you might have the different kinds of outcome and in principle any of these that you can form at in in a clear way uh you you can use these sorts of approaches to start to try and optimize and choose in a principled way and I think that's fantastic I'm kind of thinking through now um you know survival is a pretty binary like outcome you know it's you're you're dead or you're alive um it's a very clean system to try this out in when do you start getting into more Nuance health benefits so if you're looking for possibility of um you're if you're tweeting somebody with a myocardial infraction or faction however you want to say that um and you're trying to treat them with a drug that is supposed to change an arisia in their heart or something of that nature um you'll see smaller Gaines instead of just like alive or dead you hoping the patient lives regardless in both cases but you're not really measuring death you know how does this sort of model change when you start to look at more distributed data I think I of that sorry that the sound is still a little bit quiet but I I if I could summarize I think the question is it effect ly one of yes is obvious that that if if your outcomes are life or death that there there's a clear distinction in terms of preferences I might want to have for those things um but there are a number of things that are much more nuanced and may have trade-offs in themselves um that that um it becomes a little bit harder and less obvious as to how to assign preferences degrees of preference um and so you always get back to the what is often quite a generic issue as to how do I choose my priors how do I choose my degree and in this case it's the prior preference that I'm choosing how how do I select that um and there are a couple of a couple of interesting approaches that people take so one would be to say well let's actually look at what people already do settings when do people set these criteria early stopping the trial or or whatever else um can you then invert that process and then infer what the implicit cost function they were using was or what the implicit prior preferences were uh and then that might be a way of of then just formalizing that and saying Okay so this clearly is the the relative preference I have for these different outcomes relative to The Information Gain that might be one way of approaching it um the other the other approach I mentioned at the beginning of of the session last week that a lot of this had sort of come out of um initially attending a a workshop in Australia um in Sydney where a lot of the discussion was around basing networks and how you select PRI and a lot of people there um work on work on the problem of um elicitation and how you how you take uh focus groups or samples of the population or key uh key groups who are invested in a particular problem stakeholders uh and how you extract from their views and how you how you ask questions in the right way to be able to get out prior that matter to them or that that they see they take to be relevant and that's obviously particularly used in contexts where the PRI are uncertain and you want some expert views or there's limited information you want some way of constraining um uh a particular prior for a particular setting but I think it's also potentially very useful in terms of writing down the right kind of preferences here so you could imagine if you asked enough people who might be relevant stakeholders in in a particular outcome how much do you value this over that and and and do a number of comparisons there you could con start you could start to construct the relevant cost function because the relevant cost function here is often going to be for the people who For Whom the intervention is offered and so um those of us who are not necessarily the beneficiaries of it or or people who might be harmed by it are probably not the right people be setting preferences finding out a way of engaging the relevant people and taking account of their views on it and how those might be incorporated into private preferences I think is a a really interesting and not entirely solved question could I could I jump in with a quick question as well please so if I may be so bold uh the sh shall we say The Guiding normativity of the let's you know the various uh simulations that were offered in the p was something like at least initially uh the degree of expected Information Gain that one is is able to Asain at a certain point in time as a consequence of a certain intervention or not and now we're running into the issue of uh this let's call that the cost function perhaps this is this is what we're going to perhaps use as our proxy for the relevant thing to do at the relevant time for the relevant population and so on but we're coming up against issues now of uh yes but there are the question as to the relevant uh you know action is not merely reducible to expected Information Gain at you know as a consequence of a certain action there are meta considerations like ah we would like to observe people living throughout the trial basically so we don't want to just have you know people be observed to be living at the beginning of the trial uh you can do expected information G perfectly fine with all of that but there is this matter consideration um of the way in which we're going to you know solicit uh preferred observations that doesn't seem to be just reducible to expected Information Gain so a lot of my particular you know interest are in well how do we how do we map out that sort of space it perhaps expected information game could could be you know exacted into this larger space of considerations um one might think but but that's that's a very interesting problem that I think you said as well was it's an incredibly difficult problem um and it wasn't it certainly wasn't the focus of this paper um so it's a bit unfair to to to lay upon you um you know questions as to okay well what what might guide those those higher order considerations but that that is something that I thought was would be very interesting to discuss maybe later or or now as you as you've raised it now should we discuss it now yeah unless it was I mean I think you're exactly right that expected Information Gain on itself is not enough um in in at least in some settings I think in some settings it probably is an ins um and and that almost begs the question in how do you know whether to put more emphasis on expected Information Gain on other forms of cost and I should say that the the sort of addition of cost into this is partly relevant in the sense that as in relevant to the expected Information Gain in that it's only when you have a good quantification of the cost of or or or the benefit of of gaining information cost of not gaining that information that you can actually start to do that tradeoff um so although it it can sometimes feel a little bit arbitrary that you're just sort of adding another term to the the objective function but actually the only reason you could do that is because by expressing them in exactly the same units and the same Notions different kinds of probability distribution uh or or log probabilities or potentials it's only by by being able to put them in that same space you can even start to do this tradeoff um which is the reason it was relevant to ruce the cost function in addition to that in this setting obviously the other approach that we might take in active inference is actually to go from first principles try and derive something that looks like um expected free energy that is already a combination of these things and then can be pulled apart to see how it contributes to both these sorts of costs and Information Gain um and I think clearly putting the right sort of costs so that you will only seek out information if it doesn't lead to something that is very very aversive and um and vice versa you'll only seek out things you prefer if there's also some scope to gain information at least relative to other actions you might take I think is useful in allowing these things to contextualize one and that's something call but very well last session we did what what were your thoughts about it how would you approach that question I mean I I can't think of any other way than to sit you've kind of already said it then to situate the whole task where uh considering you know in this case it's it's maybe clinical design trial design and so on for for survivability the only way I can really see to do it is to relate it to the kind of autopoetic goals of the agents involved so we maybe we have a met assumption that all of these agents wish to continue across time or a certain subset of them we wish a certain subset of them to continue across time given certain considerations um that I'm I'm just spitballing here but I don't really see how to situate The Guiding normativity in anything other than the continuation of of the the the you know sensor motor Loop of a particular subset of the the the uh you know agents under consideration of course then that raises the question well which subset do we want so we sort of have a recapitulation of the same issue so to sum up I have no idea but um that's that's the only really thing that comes to mind if we can somehow tie this to the the you know the ways in which autopoetic beings are able to maintain their AIS across time um if anyone else has a better of suggestion um that's that's as far as I've been able to get so far okay what what that makes me think about is something like a um semantic supply chain for this for the clinical study so it's like we didn't assess in this paper should we do a clinical study but there's another room where that's a question it's like well what could we stand to learn what would the cost be and then some and then someone so somebody says should we do this clinical study and then someone's like should you have taken the policy to ask if we should have done the clinical study and someone's like yeah I didn't know so I asked to find out and then that's where the buck stops because right there you can say here's where there was a definable uncertainty that was actionably addressed and that's how it propagated on through to the clinical study and then and then um all along the way counterfactuals could be analyzed like if it were 10 times more costly to sequence The genome then we would have had done this study but then that also opens the door to when the cost of something is lower that another study could be done um there's this element of the participatory stakeholder involvement and asking people questions that that keeps it grounded but uh and it's it's obviously such a generic situation that there aren't strong answers but just the idea of Tracing Our un uncertainties and preferences and Norms back on through to the cognition of the study design seems to take it into a place that's going far beyond just trying to sample optimally from a population because it calls into question like what does optimal sampling if the people so strongly don't want to be sampled then what is this kind of optimal sampling protocol actually sampling it's all it's all maybe somewhat moot obviously because in this example we are doing you know beijan optimal trial design a lot of those questions are going to be you know sort of posed and answered for us so trying to trying to make it more General is is maybe maybe just a false errand maybe there isn't uh a way to generalize that other than to swim in the waters of the particular situation we're considering and of course it's a very Noble and worthwhile thing to consider Vision optimal tra trial design so perhaps not much of a problem well I mean I think you're right to think about how to try and generalize the problem and arguably the the answer is exactly the same way exactly as Daniels described you could could say the question of actually designing this child that's Bas thinking of doing it is itself something that comes with potential Information Gain potential cost benefits um and that actually a lot of behavior is based well almost all Behavior where I select between alternative things I could do is going to be based upon similar desires to both explore to find out and uh to explore which once I know that I can satisfy certain preferences um arguably it's only by doing those things that that you can maintain your persistence over time in exactly the way you describing that possibly is one of the key imperatives for any sort of creature that can um envisage alternative paths forwards and select between to the public playing the game oh go fure sorry go oh sorry I was just gonna say to to keep playing the game basically is is the uh yeah the answer I think there's another uh way that this comes into play with the health study versus is just Public Health in a health study often times just like laboratory studies in general there is you want to make a a control group that's actually like a valid comparison like if you're studying the effect of food X versus not you really want to make sure that people who ate it ate it and who didn't eat it didn't eat it because you're trying to to make maximally separable whereas if a given Health intervention or or program were driven to to a large extent by pragmatic consideration like we want to reduce the prevalence of this in this population then that would plug into many other policies that could come into play so instead of like we're going to study whether a daily email can help with this health condition and then you want to then the whole imperative of the researcher okay we want to make sure those emails were delivered or not versus if we pull back and say okay they want these people to have less of this disease and here's how that is being balanced with reducing uncertainty about the effects of email then somebody else maybe that group or another group could pick up on the pragmatic consideration and then plug in with a different policy so from that pure epistemic standpoint it's like oh but now this is like less of a controlled experiment and it's like well yes that is the tradeoff that is being finessed is the frontier with who does what when there are both things that are uncertain but there are things that we could be uncertain and simply be unsent to us and then we don't need to take the policies to reduce uncertainty because the Information Gain even if it was a lot could be just like well you could look at a a block of random text and you could reduce your uncertainty a lot but then that is not usually selected because it's not aligned with other preferences and that but that also I think the example of looking at a block of text is an interesting one as to why why you might not do that even though it might resolve your uncertainties to what's on the page because you also need to think about what else it might resolve your uncertainty about um so if you are curious about something or do not know something and that block text will tell you it then it may be quite a useful thing to read that block of text whereas looking just to see the particular wording about something you already know about about some sorry terrible English isn't it the the the wording of something about which you you already know then there's not much um there's not much Point looking at it is though it's sort of a waste of of time and energy because it's already um some some uncertainty that you you don't even have to resolve you don't have that uncertainty in the first place uh similarly you might not know something and the text may still not arguing about it in other words it's quite ambiguous text because it doesn't help resolve between the alternative hypotheses um and I guess this comes down to an interpretation of expected Information Gain or the mutual information between your hypotheses and the data that you could measure um and a mutual information can always be separated into two entropies so one of them is an entropy that is um how uncertain am I about what these data would look like under this under this plan and the other one the other entropy is which is subtracted from that is the conditional entropy so how ambiguous is this measurement and the way I would often like to think about that is there's no point doing an experiment we already know what the data would look like um if if I could picture exactly what I would measure before I even did the experiment there'd be no point doing that experiment um because what am I going to look for and that's our our predictive entropy that's the first one which is how uncertain am I about what I see um but then you have to account for the amount of information that you're actually going to be able to resolve and so subtracting this ambiguity making sure that that actually this experiment is going to resolve that uncertainty it's not just going to be uncertain noisy data that yes I can't predict but that's just because I've used an extremely noisy measuring instrument that would also be a pointless experiment to do the right experiments to do are the ones where I couldn't predict the data uh based upon what I know already but that the conditioned upon a particular hypothesis the data would actually be very predictable and so by seeing those data I can start to really disambiguate between things that I didn't already okay in this kind of spirit of the the block of text there's a lens or or a frame in which it's just uniform but then there's another way in which it might resolve or not okay so there's no point to do the experiment if you already know what the outcome would be but then maybe in that case it would be something more like a habit or ritual or even if you have an experiment that you don't know what the outcome is going to be there's still procedural elements of the experiment that you do want to know the outcome on like the Intermediate calibrations or assays so I think this kind of points to the very rich and and woven nature of epistemic and pragmatic value and why it's so important to have an accounting system that can hold them up side by side because even on one action there might be many ways or different scales of a nested model which that action or the consequences are are being chosen for a variety of of competing factors and then sample probabilistically and then the then the impact on a hierarchy arcal predictive processing system Also may not simply fall into an epistemic or a pragmatic bucket because it could be epistemically novel at this layer but then that was exactly what was expected at another layer but then the fact that it was expected at that layer was learning at another layer um so it's very interesting yes we spoke last week about the idea that you can actually use a form of message passing in spas generative models to to pick out the uner or the expected Information Gain about a particular State and I think that's an another way of looking at exactly what you've just outlined that it may be that there is a great that one action gives you a lot of potential Information Gain about a particular State um but you have to then encounter The Information Gain that other states um or about other states in your model about other things and so that's a situation where maybe it would be the wrong thing to do to focus in on a particular margin and actually what you want to know is the the um Information Gain about all of the things you don't know about awesome um so so here you might say do I want to know about the effects of all the confounding variables or do I just want to know or do I just want to estimate the effect of the intervention so is it relevant for me to characterize the precise shape of the um of the function temporal trajectory with those basis sets or is it sufficient for me to to just focus on resolving Myer about the size of the effect of treatment how different these two plots are and that that problem you know we we were speculating before the issue that I I have in my mind is well how you decide between those two uh levels let's say of information expected information gain resolvable do you have another meta expected Information Gain between the two say the lower level you know which basis functions should I have versus the you know which approach should I even take at all that's that's a question that I I find particularly interesting scaling all the way up to the previous example that that Daniel mentioned you know well should I should I even do the intervention at all um I know that does that that that comes quite a far field from the subject of the paper but um that's very much gets into the question of of well exactly what level is relevant what what Information Gain is relevant and how do we score which one is relevant when when we're doing a clinical trial it's quite obvious relatively obvious let's say for sure and perhaps part of that comes back to the original discussion we were having about the relevance of different sorts of um States and distributions and obviously this is a very subjective thing exactly as you were talking about Rel realization the idea that it's not it's it's both about myself and my model and the environment that I'm dealing can't take one away from the other um and probably a large part of that does come down to the Precision ascribed to different sorts of of mappings where those mappings are going to be conditional probability distributions um and the perhaps voluntary attentional waiting um deployment of different Precision values to different parts of of your model and you could argue that that if you were to do this at a higher level you might be able to use it from empirical prior over what might happen at a lower level of model as well or even to contextualize the preferences so there's no reason why your preferences or cost function can't be um context sensitive and in fact the the the really interesting question comes when you invert that and you say well locate if I'm predicting my cost function based upon the higher La then what I'm doing at the lower La should be able to tell me something about the context at the higher level so if I believe that in this circumstance I like doing this whereas in this circumstance I like doing that then seeing what I do might then give me evidence for being in one of those two different contexts so it's a really interesting question is how you might hierarchically decompose these things and allow layers and layers of context sensitivity that then allow me to select my preferences and also potentially conditioning my precisions in such a way that that the balance between um these exploitive and explorative drives will vary yes there's there's a um there's a relatively canonical example that John B gives on on precisely this issue um you know imagine you're in an election and you need to take good not your initial state is well I don't have good notes you know what are the possible actions uh well I could write stuff down I could type things I could use finger paint the the affordances and the prediction errors the Precision of the prediction errors and the you know the expected Information Gain at afforded as a consequence of any particular action is is very uh undefined it's unspe not unspecified but it's underspecified and so the the exact you know low level routines that you should engage in the the expected Information Gain is a consequence of you know any particular um lowlevel action uh is is relatively similar to any other one so again that there is that question of well of presumably there's going to be something from a higher order um you know preference whereby I have in the past let's say I have built up a model that ah my laptop is an excellent thing for me to use to to write down things and and so forth so that's going to kind of solve the problem in that case case so yeah there does appear to be some model of uh you know hierarchical nesting of these things in some fashion I know that's delightfully um nebulous but uh that's the only that's the only really thing that that came to mind I was just wondering if in the inversion of that particular example if you found yourself having not taken very good notes you might then say well if it were a good lecture I would have wanted to take good notes so the fact that I haven't wasn't a very good lecture that has uh crossed my mind from time to time something in there about like if I had more time I would have written a shorter letter but I didn't so I must have had more time um or the other thing it made me think of was the back to the streetlight example so we talked about how the street light is is both Justified but it's also this kind of like limitation on one hand that's where we can resolve our uncertainty but also that's not the whole story but now we zoom out a layer and there's a policy on the electrical grid deciding which street lights to turn on or how to dim different street lights and then you pull back even another layer there's a construction policy on the street lights over the decades and then and then at the nightly scale it's the energy grid policy so then that agents looking around information foraging is happening within slower scales such that they're not in a stationary single street light World they might be looking around and then spiraling out just like you described and then that moves them into a new attractor a new regime of attention where they're they're sampling differently from there um so it's kind of when we read a paper like this and we see a motif get built up so methodically and then always there's this point in the dot two where even that Motif is just one puzzle piece swirling around with the broader question of of how we make these generative models when even the motif which looks awesome and sounds very cool it's very educational to learn about but then it is also just another element in these broader models yes and I I think clearly it's a it's a very I me there are two two big issues when you're or three big issues when you're trying to trying to design um creatures that behave in an active inference way so one one of those issues is is um obviously drawing inferences about the world another one is changing the world to comply with your predictions and then the third is um given the type of evalua first two in relation to the fit between my model and the data I currently have the third question is always how do I deal with data that I don't yet have and that's where that's where this sort of generic issue of selecting um things so that or selecting courses of action that lead to informative um but also preferred data becomes so important but you're absolutely right all of these things are then conditional upon the model that I that I have in the first place and that model um will condition these various other things that model may say I have very very precise preferences or very precise prior beliefs of the sort of outcomes I'm going to seek out or it might not and that may be conditionally dependent upon other things at other levels for mod which may be subject to exactly the same generic um objective functions but because the form of the model at that level may lead to different sorts of behavior than you might anticipate other ones and so I think you're absolutely right to to highlight that although there are these generic motifs the the optimization of my model fits both by action and perception and the optimization of future data by choosing informative preferred data points um are all relevant only in the context of the models under which they they act they are of course also ways of building which is another interesting point but some of that will be dependent upon the data that's presented back by the world and um and and we sort of get back to some of the discussion we were having last week about things like natural selection and the selection between alternative models alternative individuals being Alternative forms of models that that that are selected um with each generation so there's a history dependent El which is dependent upon the data I've had before for which just comes down to that question of if I'm comparing to the data that I've observed previously and and back to just the problem of comparing models finding the most evidence or finding the models that have the in the in the conclusion you pointed towards uh using sophisticated inference to approach some of of these uh situations where you might want to plan over future observations so where are you hoping to develop what is presented in this paper well I think so the point about the sophisticated inference scheme and for those who haven't come across this the idea is that um that although I have my separable objectives to seek out things I like and things that will inform me about my my model and my world um each of those things may also be dependent upon what I've observed at earlier points in time so it might be that having performed a particular action made an observation and updated my beliefs um in relation to the observation I've got that that will then change what what might be most informative at the next step in time or what might be most rewarding at The Next Step in Time so by rolling out my beliefs about uh what I might do next and conditioning those upon what I might do after that and conditioning those upon what I might do after and more than that conditioning those on the beliefs I might have at each of those points um you you can you can really start to develop much deeper policies have that recursive aspect that that um is probably quite familiar to a lot of people who worked with things like B and optimality problems um and one of the things I find quite interesting about that is that in in principle you might now do things that will help me seek out more um information in the future um as well as doing things that will gain the information might help me um achieve more rewarding observations in the future um so again they are still separable but actually it will look like I'm what what what a lot of people in um in probably reinforcement learning typ Fields would be more familiar with the idea that I might seek out information to gain reward um if I have a recursive scheme then it will look like I'm doing that even if I additionally see information is having its own unique value um in and of itself regardless of whether or not it leads to reward so I think that's what that's one of the key reasons for bringing that in here that that um that I might want to find out how far someone survived up until this point so that I can then contextualize the shape of the function when I know when they've survived later on or I might have the option to now put in multiple follow-up points and actually if I would to do that independently of one another um I might put them both in the same place because that's where I'm going to getting the most information however if I would to use a recursive sophisticated scheme I might say if I put in this follow-up point then I'll have resolved all the uncertain need to about that point so i' better put this at the other point and so you can now start to think about multiple followup points multiple interventions taking account of of how one of those might influence the information you might gain from another one um so that that was probably the key point of of putting in that idea anything you wants to sort of raise or discuss in in depth on that yes I think that's where some of these computational costs start to expand however if it can be if if a if a given situation can even be brought to the table of sophisticated inference then it's well set up to do a lot of interesting analyses and then the other directions that you specified empirical evaluation of active versus alternative sampling methods and identifying appropriate cost functions so what about these yeah uh so I think the empirical evaluation I think if you were to if you were to convince probably a broader Community this is a useful thing to do then one of the things you'd have to do would be to show that it outperforms in a in a very clear way other schemes that you might want to use I think there are good principal theoretical reasons to see how this um offers some benefits um however it may be that if you're dealing with a very nonlinear uh problem that the cost of even doing all the computations is to work out what I should do next might exceed the um process of actually just doing it or sing it random one of the things I found quite interesting is that that actually when for the for the first couple of simulations in the paper the random sampling is actually not much worse than uh choosing the data very carefully and one of the reasons for that is that random sampling will tend to give you a fairly uniform distribution over over the points you sampled and assuming that says uniform uncertainty initially that's actually a perfectly sensible thing to do so part of this is not just about evaluating it for the sake of it or to to um prove that the theoretical results translate into something empirical it's not just about benchmarking but it's also about finding where are the places where it can be most useful clearly we have to have some sort of addressable way of generating the data we have to be able to say I'm going to sample over here or over here with a set of uniform unlabeled data points that that that I there's no way of selecting between that have no spatial or other metric in involved um that's going to be a much harder thing to do in fact it's going to be impossible thing to do if there's no sensible way of defining your policy so I suppose the key thing here is thinking about when is this approach useful when will it actually help to resolve uncertainty um and in many cases it it it might not if there is no um if there is no difference in the Information Gain between different options I might take or if that difference is more or less the same as what I might get using another strategy it may be more computationally efficient to use another sort of strategy that's that's very um interesting and the paper set up accordingly to this development from the random uniform to the max ENT to the full epistemic gain and so each of those are actually sampling policies that can be compared and I guess to um but they're not just samping policies they're also sampling situations that I might be in so if I'm in the sort of situation where ambiguity varies then it's no longer sensible to use a maxim mentary type approach so ultimately You could argue that this formulation automatically accounts for these different situations that if I'm if my model is good enough as an explanation for the world and how do I make sure it's good enough I make sure it's good enough by sing appropriately drawing those inferences uh but if it's good enough that I I now have a sense of how the variance changes as a function of where I might sample uh if I know where I'm uncertain where I'm not then each of these things automatically becomes a contributory Factor whereas if I don't know these things or I think the situation is one in which Things Are completely uniform then this will now reduce back to one of the earlier approaches we were talking about and if there's no benefit anywhere in terms of cost no benefit in terms of of the entropy I might be able to resolve in terms of objective entropy and if the ambiguity is the same everywhere then ultimately this is a random sampling approach and we'll reduce back to that so in a sense all of these things are versions of the same general problem but the situations in which I might benefit um from employing different parts of this are those that that in which there is difference in ambiguity in which there is difference in predictive entropy in which there is difference in in cost and so it all comes back to the model and whether I've got a good model in my world and my world complies with these different sorts of features yes it shifts the focus from summary performance on a previously acquired batch to more granular outcomes in a sampling driven regime like out of sample prediction versus looking at in Sample just how well can you do on what you already have versus how surprised are you going to be about your prediction about what you haven't seen yet and then this even goes a little bit further which is how would you decide which things that you haven't seen to get data on and then how would you assess the cost benefits preferences and the epistemic value associated with that so that moves it from not just out of sample sense making [Music] [Music] however if I take a sophisticated inference approach then I would say okay if I put the first follow-up time here that would resolve my uncertainty my beliefs would be much more precise about that time point so the second one I should put somewhere else and and and that means you can start to think about this and plan this before you even start doing the experiment um it also I mean you can see them serially like that but also it matters in terms of way youve relative to one another so you might not need to put first follow-up point right in the middle if it's better to have it slightly earlier to characterize that bit of the function so that you can put the other one slightly later so it is just having a sense of how each of these things would change my beliefs in such a way that I can then take account of that when when dealing with the other choice and you could roll that out for a whole series of potential future follow-up points and sampling decisions right right so that I mean that clearly does give us a sense of maybe higher considerations than excellent stuff yeah my my only other question was with respect to the issue of uh you know affording computational tractability and and and affordability and so on has had you seen any uh you know potential ins or Avenues to uh maybe instead of things like sophisticated inference to use Federated inference and sort of belief sharing approaches where perhaps we have you know several agents communicating amongst themselves in a joint sort of free energy Minima minimization scheme with respect to this um approach I'm very interested on you know in in whether that would be applicable here to what extent perhaps it would be um yeah just very interested on that that issue no that's a very interesting point and I you know at a very simplistic level I I suppose being able to share beliefs when different agents have different Advantage points is is one of the most obvious examples of that so if I'm if I know what over here and you know what's over there then there's no point both of us looking in both locations if we're able to share our beliefs directly about what's happening in each of those locations um so you can sample with much fewer data points many fewer data points if someone else is sampling some of the other ones um and by optimizing a shared generative model or passing messages that allow you to communicate uh then then that can be massively beneficial then if you were to put a a clinical trial analogy on that you might imagine that being equivalent to Multi Center trial something where different groups across different centers or countries are jointly contributing to different parts of that sample space um so they can jointly optimize a model of how effective a treatment is yes as well I I had the thought as well that you could and we touched on this the issue of you know well how to sample or you know where my where my prize should be for where I sample and so on um we could see how people have done it before and do that you could have some sort of you know imitation scheme where you say okay well I'm GNA have certain number of Agents yeah exactly so yeah that that's just an interesting Avenue that I thought was worthwhile to to think about yeah and and that idea is having um habits passed down from others um May feed into that as well because you know as we were saying it may be that that sometimes the more computationally efficient thing to do is to adopt a policy that will always lead to the same sort of samping rather than have to compute that policy in you each time so form sort of armatized um policy selection which is effectively prior habits or biases or empirical prior over what I should do um that potentially resolve these problems without me having to to even start to think about what I might see yeah that really cuts down on doesn't doesn't eliminate it but very much delimits the problem of you know where your prize come from for these certain things so very good stuff well Thomas do you have any last comments or thoughts or or how do you see the active data sampling going from here um that's a it's a good question isn't it um where's it going to go from here I mean I I suppose in a way this is the same sort of themes that have come up in a lot of active influence research um it I think it's going to be interesting over the next few years seeing how clinical trial methodology develops I think there's been a lot more focus in recent years on things like Bas adaptive clinical trials possibly some of these relatively old ideas about how to optimize experimental design might be coming back in those sorts of settings you know particularly in settings where where the there's quite a rapid change in evidence and understanding of of evolving situations pandemics and or epidemics and the like uh these things become very very relevant so it'll be interesting to see how things develop along those lines and whether they end up adopting approaches like that we sort of outl here um but I think it's also as a lot of what we've discussed has been the sort of generic issues around we sample data as well um one of the difficult issues I think in a lot of machine learning um approaches is the the approach of of dealing with very very large data sets um which are computationally costly to analyze costly to collect and and not necessarily the there may be in some circumstances but but in general may not be the most efficient way of dealing with the under lying inference problem um certainly not the most energetically efficient um so I think there'll be some interesting approaches thinking about how best to optimize that process and whether part of the process is not just optimizing the algorithms that do the um inference based upon those data but actually optimizing the way in which those data are selected in the first place clearly that's a lot of what we as as living organms do we behave awesome Fraser I I only want to say thank you very very much um Thomas my uh this this carefully crafted you know um facade of my relative um you know I'm extremely grateful to be here and it's been just amazing so um although it is early for me but thank you very much it's been most of like and hope to do it again well thank you I I enjoyed learning about um relevance realization I may so B to to link something awesome thank you again Thomas thank you faser and Chris and see you all next time bye for