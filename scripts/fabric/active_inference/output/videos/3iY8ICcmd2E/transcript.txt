all right hello and welcome this is active inference math stream number 10.1 March 28th 2024 or 29th not exactly sure and we're here with Thomas Farley discussing generalized decomposition of multivariate information there will be a presentation followed by a discussion so Thomas thank you very much for joining looking forward to this and everyone's questions yeah thank you for having me I'm really excited to get to talk about this um with uh people who are also interested and I think it's the 29th because I compiled this latch last night was the last time I compiled it so I think it's a one day out of sync all right and so yeah so I'll be talking today about generalized decomposition of multivari information this is sort of walking through a paper that I recently published in um plus one and I'll have a link to that at the end of the talk if you you know want to read more um sort of interested in what I've covered here and so um we'll start with a a little bit of a background sort of the intuitions around information Theory and then introducing these two ideas of the partial information decomposition and a partial entropy decomposition and I can't see who's in the audience but you know if you are an expert in multivariate information Theory you can just go watch YouTube videos for five minutes or so um while we get everybody else up to stream and then um once we've got sort of all the necessary mathematical Machinery built um then I'll talk about how I can how I've taken the PID and the ped and sort of generalize them to this thing I'm calling the G the generalized information decomposition which is based on the um the cach Leer Divergence and once we've kind of built that um we'll talk a little bit about how uh the G can be used to get insight into other information theoretic measures you know um well-known things like the total correlation or the ton sporns adelement complexity and then finally um to show that it is you know truly a generalize generalization of the PID um I'll actually walk through the derivation of the classic Williams and beer byari partial information decomposition from the generalized information decomposition and there are actually some kind of interesting um sort of mathematical questions that kind of that that you discover as you do that derivation that you know I'll talk a a little bit about then I have a brief section at the end sort of talking about sort of future work what um we could do with this and since this is the active inference stream you know I'll end with a little bit of discussion of sort of predictive coding in neuroscience and then I would be really interested in talking um in some way to people in the audience who might be more expert in active inference or free energy than I am you know because there you know maybe things that could be done with this that are not uh super obvious to me just because I'm sort of coming at this from a slightly different angle so um with that in mind uh let's get started background so um you know this is the active inference Stream So I sort of assume that we're all familiar with uh sort of information Theory and complex systems you know it's really I think become the case that information theory is uh sort of emerging as a lingua franka for complex systems right um it's non-parametric it's model free uh which makes it very useful for complex or you know nonlinear systems that are not well modeled just by you know linear regressions um it has some really deep and interesting connections to thermodynamics that I won't talk about here but you know that's something I think is really interesting and there's some very cool work pushing that forward and then what makes it most relevant for uh complex systems is that it really elegantly handles multivariate interactions right you know it's hard to sort of imagine what a what a five way peon correlation might look like besides just a a covariance matrix of of pawise correlations but information Theory can really handle multivar interactions sort of on their own terms okay and then so I'm sure again we're all familiar that the basic object of study is this thing called the entropy this is Shannon's classic entropy function negative sum of P log P I introduce a little bit of notation here so Random variables uh I will be denoting with um italic uppercase italics the support set so that is to say all of the states that you know tala size X can take will be indicated with the um math Cal caligraphic font and then the specific state that you know X is all the elements of the support set I denote with um lowercase italics all right and so you know as we as we you know continue to leverage this notation this distinction between sort of average General random variables and their specific local instances is going to be quite important right so classic Shannon information we're just iterating over all of the possible states that X can take and Computing the probability of that state times the log of the probability of that state okay and so this quantifies sort of our average uncertainty about the state of X right you know if you were to um take X you know it was a coin say you're a coin that you were flipping you know it quantifies how uncertain are you about the state of X you know um and from this we build you know the classic Mutual information Shannon Mutual information is a pairwise measure of correlation and it is um arguably I think the most fundamental one of the most fundamental ideas in modern information Theory and so you know we would read this as you know the information that X discloses about y or ultimately the information that y discloses about X is the difference between our initial uncertainty about X so this is you know the entropy of X and then we subtract off the uncertainty about X that remains after we have learned y right so this is the the conditional entropy here and um when I when I teach this in class you know I like to think you know we start with some big pile of uncertainty we scoop some uncertainty out when we learn why and so we have a slightly smaller pile of uncertainty left the difference between you know the big pile and the small pile is the amount of uncertainty that we scooped out right that's the the uncertainty that is resolved by learning why okay and so you know since we're we're all big fans of sort of basian thinking here you know um I like to think of this you know our initial uncertainty about X this is our prior right um this is the uncertainty about X that sort of we come into without having learned anything okay then we observe Y and we compute a new uncertainty about X and that is our posterior uncertainty uh about X after learning why and thinking about this in terms of priors and pro posteriors is really helpful because this is just a particular case of a prior posterior relationship right you could um sort of heuristically propose a more General uh definition of information it's just the difference between a prior uncertainty and a posterior uncertainty and how you sort of formally specify the prior and the posterior is uh sort of largely up to you okay and so mutual information is just the special case of this broader definition where the prior and posterior are related by this by these sort of joint marginal relationships okay but again it's just a special case of this much larger sort of definition and we're going to come back to this come back to this in a moment okay but continuing on sort of our information theoretic background you can do the multivariant mutual information if you want so here now we have two sources X1 and X2 that are together disclosing information about why right and again you have our prior which is just our uncertainty about Y and then we're going to subtract off the uncertainty about y that remains after learning X1 and X2 okay so far so good any questions Dan in the chat people hanging on for dear life good all right um and so when you start looking at like multivariant Mutual information um things can get really interesting really fast right and so like the the first thing is that you know this Mutual information the information that X1 and X2 disclose about Y is not trivially reducible to the sum of the mutual informations right the mutual information that X1 and X2 disclose about Y is not equal to not generally let's say equal to the information that X1 discloses about y plus the information that X2 discloses about y right the whole in this case X1 and X2 is not trivially reducible to the sum of the parts okay and you can have both cases right if the joint Mutual information is less than the sum of the marginal Mutual informations then what that tells us is that there is information about y that is duplicated over X1 and X2 and so when you sum the two together independently you are double counting that information right and so this is what we call redundancy right it's the information about why that is copied over both of the inputs and gets you know double counted when you add them together arguably the more interesting case is the opposite right the case where the whole the information that X1 and X2 disclos about y jointly is greater than the sum of the two marginal m ual informations okay and if you're familiar with uh uh that should be y not Z I apologize that's a typo um and so if you're familiar with sort of like integrated information Theory some of the stuff that Julio ton has been doing you know you s of might recognize this is as something like integrated information all right it's information that is in the whole as the joint state of X1 and X2 that is not present in the sum of the parts okay and so you know people call that like I said integrated information we're going to call it here Synergy all right and so we have these two sort of interesting things that are happening we got a three-way interaction between X1 X2 and Y and it has like two different it can have two different flavors this redundancy which is duplicated information and then Synergy which is information that is only accessible in the whole and not any of the parts okay um and so you know if we if we sort of take these two ideas um we can kind of make them a little bit more formal and a little bit more rigorous by noticing that um we can talk about them in terms of logical connectives okay so redundancy I like to think of as that information that could be learned by observing X1 or X2 or X3 or you know as many X's as you have in the in your data set right and so for instance if um X1 and X2 are just you know linked by a copy gate you know X2 is just a copy of X1 then you could look at either one on its own and get all of the information right because they are just copies of each other in contrast um Synergy is information that can only be learned by observing X1 and X2 and X3 and yada yada yada okay um and you know this link between logical connectives and higher order information uh lets us do like really interesting things like we can construct very exotic combinations of information and this will come up more when we talk about the information decomposition but you could ask for instance okay what information could only be learned by observing X1 and X2 or X3 and X4 right and so you know we're starting to see like what the structure of you know multivariate information might look like it's going to be these um sort of chains of um Atomic it's going to be these chains of sort of atomic subsets of the collection of inputs joined by logical connectives ANS and ores okay um any questions about this because get this this link between redundancy and Synergy and ores and ANS is very helpful for thinking about what's to come so far so good Okay cool so um this brings us to the partial information decomposition all right and so the idea is that we would like to take um this joint Mutual information uh the information that X1 and X2 disclose about why and these Atomic components that resolves this uh ambiguity about the relationship between the parts and the holes right remember we said that the sum of the two marginal Mutual informations can be greater than or less than the joint Mutual information right so you know how can we um extract a relationship that sort of brings all of these into harmony okay and the way we're going to do this is with um this sort of branch of modern information Theory called the P ID partial information de composition what it does is it takes the mutual information that that two you know that X1 and X2 just close at Y and it breaks it down into the redundancy so this would be the information about y that could be learned by observing X1 alone or X2 alone plus the Synergy so this would be the information about why that can only be learned when X1 and X2 are known together and then these two unique terms right which is the information about why that can only be learned uh when observing X1 or only learned when observing X2 and then to force um Harmony between the joint and the marginal Mutual informations we will also say that the marginal Mutual information should be decomposed in the same way so even though you know the information that X1 discloses about y makes no obvious reference to X2 you know there is still that redund information about why that could be learned by observing X1 or X2 plus the unique information from X1 and likewise for X2 okay and I'm sure many of you have seen these um this kind of classic vent diagram this goes back to the original Williams and beer paper but I find that it's really helpful to sort of build the intuition here right so the big oval is the joint Mutual information uh the two circles are the marginal mut Mutual informations and then so we have the redundancy is the overlap between the two marginal Mutual informations the unique information is the difference between the marginal Mutual informations and the redundancy and then this purple Synergy is the sort of extra special sauce that you get uh in the whole Mutual information that is not you know uh present in either of the two uh the two marginal Mutual informations all right and so um you know this is a a very restricted case you know we just have two inputs and one target y but I find it's really helpful for sort of getting a handle on the the underlying logic of this thing okay but of course we typically are not looking at us at systems that just have two inputs in one target uh we often have many many systems and so you know there is a general case uh for the PID and you can take for an arbitrary number of inputs you know X1 to XK all just exposing information about why it can always be decomposed into a finite set of atoms that are structured into a what we call a partial information lattice this is also an anti-chain an anti-chain lattice for those of you who are into order Theory but again you know over here we have the the two the two Element Case so this is X1 and X2 predicting information about Y and here you know we can see this has the same structure as this V diagram we have the redundancy down here at the middle which is subsumed by the unique uh informations and then we have the Synergy up at the top right and as the number of as the number of sources of information grows the lattice grows you know super exponentially and you start to get you know more complicated uh information theoretic relationships right so like this little guy that I'm circling right here is the information about why that could be learned by observing X2 or the joint state of X1 and X three okay you know I'm not going to you know spend too much time dwelling on these more complicated partial information atoms but you know the idea here is that for an arbitrary number of sources you can decompose the information uh using this very elegant lattice structure okay and so form you know uh if we were going to uh try to do this all out in notation what we would say is that we want a de we have a decomposition that takes the mutual information that X1 all the way up to XK dis closes about Y and decomposes it into a sum of all of these partial information atoms right and so math Cal L here is our our calligraphic L here is the lattice uh each of these Alpha sub eyes is a vertex on the lattice and then you know we're Computing the partial information that that uh vertex for that atom discloses about y okay and so again you know you have a partial information atom like this this is the information about why that could be learned by observing X1 and X2 and X3 or X4 and X5 or X6 okay there's a certain amount of sort of detail that I'm kind of elighting here like how you actually compute the value of these partial information atoms I can talk about that at the end but for our purposes um you don't really need to know that it's just sort of sufficient to know that this decomposition exists and has this form that is connected by logical ANS and ores okay so um the p is very powerful it's very cool I'm a big fan of it uh but it has a pretty severe limitation that it requires distinguishing between Source elements that would be all of these guys and a single Target element right and complex systems aren't typically that nice organized right you know there are many cases where it doesn't make sense to say okay what are our sources and what are our targets we would like to be able to sort of decompose the structure of a system qua itself okay and we can do that um by playing a really fun little mathematical trick which is um for a given multivariate system which I'll denote as bold X which is just you know X1 through xn what we're going to do is we're going to decompose the mutual information that all of the parts the individual you know XIs disclose about the whole all right so here you know our sources our sources of information are the parts all the individual variables and then the target is not some other variable that's exogenous to them it's actually just their own joint State and so we know you know from this basic identity that the mutual information that all of the parts disclose about the whole is just the entropy of the whole and so when we do the p on this particular Mutual information we know that all of the atoms have to sum to the entropy and so this becomes the partial entropy decomposition okay this is the information that all of the parts disclose about the whole you know of which they are apart essentially okay and I spent a lot of time working on working on this partialy decomposition um shout out to Robin Inc and Conor Finn and jier who were working on this a little bit before me as well and laid down a lot of the mathematical sort of fundamentals about this um and for a long time I was sort of satisfied with the partial entropy decomposition because you know it seems you know to provide this decomposition of the system qua itself but it still has now a new limitation it gets rid of the source Target distinction but the problem is is that entropy is no longer really a measure of information right in the way that we uh introduced it before right it's more this measure of uncertainty about the state of the whole it's not really a reduction in uncertainty and so for instance you can see that you know entropy is maximal if all of the elements are independent of each other which doesn't really fit our information intuitions about information right if entropy is maximal we have minimal information so it seems kind of odd that you know our partial entropy decomposition uh it's not odd I shouldn't say it makes perfect sense that the partial entropy decomposition is you know maximized in the case of total Independence but that's not really information you know as we typically would like it to be all right uh and so to try to resolve this problem and really get a a general decomposition of multivaried information um I turned here to the kbach Leer Divergence okay and so the kach Leer Divergence is a nice Target free definition of um information and it's actually sort of a generalization of the classic Shannon Mutual information in its own right you know um the uh the Divergence of p p of x from Q ofx is the amount of information that you gain when you update your beliefs about you know the system X from some prior distribution Q ofx to a posterior distribution P of X right and so now we're starting to think about priors and posteriors again coming back to this initial definition of information that um I introduced earlier right you know in the particular case where Q ofx is you know the product of the marginals and P of X is the joint States you know the C block Lio Divergence just reduces again back to the classic Shannon Mutual information but again we can you know plug in any prior and any posterior and we still have a meaningful definition of information okay so you know my goal then was to say okay can I take the partial entropy decomposition which almost gets us to where I want it to be and can I somehow remix it so that it instead of decomposing the entropy decomposes the cach Leer Divergence instead and spoilers uh yes we actually can do that it's not that hard and so um the the the basic idea comes down to this uh very simple sort of algebraic manipulation of the C Le Divergence right so you know up here we have it written in terms of you know something that looks a lot like Shannon's entropy right you know you have the sum over all of the uh States and the support set you know times the probability of that state then we have this log ratio P of X over Q ofx okay this is an expected value um computed with respect to P of X so I'm just going to take the summation and the P of X and I'm just going to shift it out into the expected value operator and not think about it again so that leaves us with the expected value of this log ratio um by the rules of logs you can split it apart into a difference of two log logs and then these two things look a lot like the uh Shannon information content right the local entropy and so we can take these two things and we can actually rewrite them in terms of um two different local uh local entropies right so we ultimately have the difference between the Shannon information or surprise of seeing you know this particular State Little X computed with respect to the probability distribution Q minus the uh surprise at seeing this little state of X computed with respect to the probability distribution P okay and so if we go back to thinking about our priors and our posteriors this looks very very similar to theistic definition of information that I gave earlier right we have the difference between a prior uncertainty although in this case it's a local uncertainty or a local surprise and then this posterior surprise um attributable to each local uh local configuration X as well all right so again this is you know matches all of our definitions about our intuitions I should say about information and you know we can see that it falls out of the the clock Leo Divergence very nicely okay and this is really this is sort of this is the the most the the Crux of the whole sort of derivation that I'm doing here right is that you can recognize that um the C block Lio Divergence is the expected value of the difference between two local entropies which is you know I've never seen it written out this way although this is I don't think this should be surprising to anybody who's familiar with this um you know it's not groundbreaking discovery or anything but um now we can actually bring in the partial entropy decomposition that I introduced earlier right because uh this thing this you know uh local entropy well we can write this out as a local Mutual information you know but now we're just looking at specific States as opposed to you know average States but the logic is exactly the same you know we decompose the sort of the surprise that all the parts just close about the whole and we end up with a localized partial entropy decomposition that we can apply to every realization that our system uh X can adopt and so this gets us to the um kach leeler Divergence decomposition that I wanted so you know we start with the definition it's the expected value of this difference between two local uh two local entropies and then we can just use our local partial entropy decomposition to decompose each one of these into its component um Atomic bits essentially and so we end up for a given uh Atomic information or information atom the partial Divergence as we go from to P from Q is just equal to the expected value of the partial entropy atoms the local partial entropy atoms um from the prior and the posterior all right and you know because uh this inherits a lot of the nice properties of the partial uh partial entropy decomposition we can then just uh get the original C block ler Divergence back by summing all of these partial kach leer divergences over all of the atoms in the lattice okay and so I realized that there's been a lot of notation here a lot of partials and superscripts and subscripts but you know really what we're doing is we're just you know we're computing two different partial entropy decomposition lates um so this is the prior lattice and the posterior lattice and then we're just subtracting them element wise that's really what this works out to be um and you just do this for every possible state that X can adopt and then average over um average over all of the states essentially okay but you know I I I like to think of it literally just in terms of subtracting one of these lates from another I find that it's much uh much more sort of visually intuitive than um all of the the symbology and the the mathematical notation everything and so that is the generalized information decomposition right it's really just the difference between two uh localized partial entropy decompositions and so before we sort of jump into the fun applications are there any questions about you know what I've worked through everybody again hanging on for dear life yeah that's awesome I definitely will have questions and I'm sure people in the chat will too but let's hear about the generalized information decomposition then we can get to it thank you on plugin okay cool um and so the really nice thing about this generalized information decomposition is that any information theoretic measure that can be written in terms of a cold block legal Divergence um can now be decomposed right you know beforehand we were kind of stuck with like very special cases right the P works for multiple sources disclosing information about one target the partial entropy decomposition work for the entropy but now with the G you know any measure that can be written as a cach webler Divergence is now fair game so for instance you know I just picked the total correlation as kind of an example it's one of the multivariant generalizations of the mutual information and it just generalizes this idea that we're looking at the Divergence of the uh the true joint uh statistics from the product of all the marginals okay and this is very nice it's you know zero if all of the elements are independent and uh in contrast it's maximal if every x uh they're all all the elements are copies of each other essentially um and so that makes it a very nice um generalization of the mutual information but it doesn't really distinguish between lower order and higher order deviations from Independence right it doesn't see any kind of distinction between redundancy and Synergy that I introduced earlier but by taking the total correlation and plugging it into the generalized information decomposition we can start to tease out the lower order in the higher order interactions so for instance you know um just as an example I use the logical exclusive or gauge this sort of a classic example of synergy in discrete systems the information that any uh any XI discloses about Y is just zero bit but then the information about why that's disclosed by X1 and X2 is one bit right so this is pure Synergy the all of the information about Y is in the ho and not in any of the parts okay and so if we take this and we plug it into the generalized information decomposition uh you'll get um a lot of zeros but um I just want to you know bring your attention to this last column over here so this is the total correlation and all of the information here is in this you know the very tippy top of the lattice you know the highest the highest order Synergy term and not anywhere lower okay and so you know a big table full of zeros is probably not that exciting but it um does a really good job I think of illustrating that you know this G is sort of is doing what we want it to you know this is a very good sanity check that you know yes the Sy The Logical exor gate is purely synergistic and we get that back from our generalized information decomposition and I should note that I'm using the hmin redundancy function from um Conor Finn and joier if that doesn't mean anything to you that's fine but it's you know helps describe values to to all of these okay um similarly um if we have some measure that is built on multiple C block leer divergences um you can also decompose that as well so um here I looked at the the pretty wellknown ton sporns Adelman complexity and you know I won't go into all of the details but the idea is that it's this measure of complexity that was designed to be low both in the case where is just random so every XI is independent of every other XJ you know that's kind of like an ideal gas there's no structure there right you know so tsse should be low but also when every XI is just a copy of you know XJ well then the system is also sort of not complex but it's crystallized you know it's it's sort of Highly synchronized highly redundant very boring and so the tsse complexity is sort of high in this interstitial Zone where integration segregation kind of coexist right and that sort of matches a lot of our intuitions about complexity and then if we but and if so if we take you know the G and apply it to each of these total correlations and then um add and subtract sort of the sums and differences between these two uh what we end up with is this really nice uh decomposition where we can see that the redundancy so these are all the these are um total correlation atoms but I've just you know removed the the total correlation notation just to make this visually more accessible you know we can see that it really penalizes redundancy right and sort of the more redundant you are the stronger the the penalty for being redundant is and then as you climb up the lattice so you know here the redundancies at the bottom of the lattice as you start to climb up eventually you hit a point of um increasing Synergy and then suddenly it starts to reward that Synergy okay and so we have this very nice transition as you go from low on the lattice to high on the lattice you know going from um penalty to reward and so I think that this shows us something really interesting about how the um ton sporns adalan complexity relates this idea of you know complexity and integration segregation balance to uh this idea of synergy right you know the tsse complexity was developed like two decades before we had a really rigorous understanding of synergy it was not designed to be a measure of synergy it was designed to be a measure of complexity and then it's you know only now much later that we learn that you know there seems to be something very deep linking this idea of balanced integration segregation to Synergy okay and so again if you're not you know super up on the tsse complexity that's not necessarily like the the main takeaway here what I'm really trying to demonstrate is that the G can be used to give us insights into other measures right that it can help help us understand you know what are these measures telling us in information theoretic terms okay and there are a ton of other measures that we could be using here um and that we could also decompose in the same way and get sort of similar insights that's something that I would be really interested in doing um sort of in the future but finally the last thing that I I wanted to show was that we could recover the single Target partial information decomposition from the G right if the G is a true generalization of the P we should be able to rec the p as a special case right we started with the p we turned it into the partial entropy decomposition by doing this weird sort of thing where we made the Target The Joint state of all the parts and then from that we built the uh the G can we close the loop and go all the way back to the PID okay and so just to remind you the PID takes the information that X1 and X2 just close about Y and breaks it down into redundant unique and synergistic component and then does the same thing for the two marginal Mutual informations okay and we recover this from the G and it turns out that yes you can right um we can write this uh joint Mutual information in terms of an expected value of colbach lier divergences right and so our prior is just the uh statistics of X1 and X2 together and then our posterior is the statistics of X1 and X2 after conditioning on uh y being in some particular state right and then so we compute the expected value of this thing over all possible uh states that y can adopt right and so this just works out to Computing you know you know a bunch of a bunch of lates essentially um Two element lates because we have you know two two variables X1 and X2 and then we just average you know so if we were to take the expected value of all of the top latest Synergy terms we would get the the P Synergy back you know if we were to take the average or the expected value over all of the uh redundancy the redundancies down here at the bottom we would get the P redundancy back okay and uh this does Recapture the partial information decomposition as we would expect if you use the H Min redundancy function for your generalized information decomposition you get the P ID back that uses the imen redundant function for the partial information decomposition so you know we can see very clearly how the the entropy terms turn into the uh information terms okay and that all sort of looks well and good and I was you know pretty happy to be putting a bow on this project until I realized that there is another way that you can write the uh joint Mutual information out as a CB mular Divergence and that's this way right so you know we can also write the same thing out as the uh cach leer Divergence from a prior which is the product of you know the probability of X1 and X2 times the product times the probability of Y and then the uh the posterior is our joint States okay but this requires decomposing a three-dimensional probability distribution PX probility of X1 X2 and Y whereas before we only ever were composing two variable probability distributions okay so this is why you know in this case we had an nice Four Element lce here we're actually decomposing a threedimensional probability distribution and so the resulting lattice will have 18 uh partial entropy at or partial information atoms rather than four right so we're going to end up with this uh decomposition of the joint Mutual information as opposed to the expected Four Element composition okay and I I I spent a long time trying to you know find some way that I could squish this uh 18 element lattice back down into the Four Element lates that I sort of you know expected to get and I was not successful um the people who peer-reviewed the paper were also um you know didn't have any suggestions either so I won't say that it can't be done but if there is a way to do it it is currently Beyond me um and so this sort of puts us in a little bit of a pickle right like we would expect the decomposition we would expect a unique decom I want to maybe not say expect we would hope that there would be a unique decomposition for a single um Mutual information right uh it's kind of odd that you can take one mutual information and depending on how you like choose to denote it you know how you choose to write out the C Divergence you could end up with two sort of non-identical uh non interconvertible decompositions so what's happening here like this was very odd to me um and so my working Theory and this is just a theory if any other mathematicians are in the audience and want to want to take a stab at it you're more than welcome to I think what's actually happening is that you know these two ways of writing out the joint Mutual information are actually sort of fundamentally different right in the first case we're looking at a three-way interaction right we're looking at the case of the interaction between X1 and X2 and Y okay whereas in the second case um we are sort of abstracting Y out or sort of removing it from the Divergence and um sort of wrapping it all in this expectation value of y okay and so what you're doing here is you're actually like these are two different kinds of dependencies right they're mathem ially interconvertible and they'll always resolve to the same value when you plug in numbers but they are in some fundamental way different kinds of structure in the system right and so uh the classic Shannon information Theory sort of can't see this difference right it just says oh you know these two things can be you know algebraically turned into each other and therefore they must be the same but actually kind of under the hood um they are you know two different ways of looking at this interaction between X1 X2 and Y and so again classic Shannon information Theory can't see this difference but the information decomposition can and I sort of should note that this is not the first time this is sort of um Turned Up there are a couple of other cases where classic Shannon information theory has been unable to see a distinction between two you know categories of object but you know when you start looking at the information decomposition suddenly you can okay I'm sure there's a lot more to say about this um and I'd be interested in talking to people about it after the fact but you know I'll just sort of leave you with this question now of sort of non-identical decompositions of the same value and let's see I think I'm coming to the end of my my time here so I want to talk just a little bit about um sort of possible applications and some future work that I would like to do and I'd be happy to collaborate with u with other people uh with as well and so um I think that this uh sort of is a big step towards um what I call like a grand unified theory of multivaried information right you know we have this sort of interesting case where you have you know the we started with the PID right and then from the PID we can construct you know the partial entropy decomposition right the peed is a special case of the p and then from the PED the partial entropy decomposition we can construct the generalized information decomposition right and then we can take the generalized information decomposition and we can re-extract the partial information decomposition from it with sort of these weird caveats right and so you know this kind of you know aoris sort of thing where we have all of these different information decompositions that are kind of fundamentally built out of each other I think is really you know getting it something fundamental with how we can think about sort of these part hole relationships um in multivariate uh multivariate systems um the last thing that I sort of haven't been able to do is incorporate um the integrated information decomposition and so this was proposed by um Ked manano and Fernando roses and you know other people uh at um in England uh I'm not sure where everybody is now um but you know this uh they provided a very very elegant generalization of the P that allows you to have multiple sources and multiple targets um and so you know I would really like to be able to find a way to incorporate that into this um this P ped G framework for sort of a truly brand unified theory of multivariate information decomposition um still working on that open to collaborating with anybody who's also interested in taking that project on um and then finally so let's let's talk about predictive coding because this is an active inference stream and so um I assume everybody is sort of familiar with the basic idea of predictive coding that the that the brain is sort of acting as a kind of basian inference engine right you know it has a world model it has some set of beliefs about the world and it updates those beliefs you know um as it navigates through it and receives sensory stimuli okay U and so you know one of the things that I'm really interested in is you know how might this predictive information about the environment be redundantly or synergistically distributed over different sensory channels right like we're not just learning you know we don't just have Vision right you know we have Vision we have hearing we have touch we have propr reception there are other animals that have senses that are totally alien to us and so when we take in all of that sensory information and build a world model you know we can't just treat every one of these incoming information streams as independent of everyone else right we are uh have to learn you know these complex higher order interactions between different incoming streams of sensory information and we use that to build a really rich World model okay and so a great example that I first heard from Andrea lupy uh who is um you know a friend and sort of collaborator of mine you know he was talking to me about stereoscopic depth perception right for this is sort of an example of synergy between two incoming sensory channels right if you cover one eye you lose the ability to perceive you know depth right so there's you know redundant information you know that you know both eyes get simultaneously there's unique information that you know sort of at the corners of your visual field and then finally you have Synergy which is the this sort of emergent perception of depth this qualia of you know receding distance that you only get when you're getting information from the right eye and the left eye simultaneously right so from sort of a cognitive modeling standpoint our ability to extract sort of higher order information from multip multiple incoming sensory channels is clearly very relevant to our perception and our behavior in the world and so you know I'm I'm sort of tempted to propose you know a hypothesis of Maximum Synergy right so you know if there are two different channels that are totally redundant right you know an agent that only has you know some minimal number of calories that it can burn you know keeping itself alive isn't going to want to spend calories you know perceiving both uh both senses independently right like all the information you get get from one you can get from the other so you know why spend money on both right but in contrast if there's you know synergistic information in in X1 and X2 that you can only get when both are present well then modeling or having channels to you know sense all of them becomes essential right and if it's truly synergistic then you know having just X1 on its own or just X2 on its own may not be you know giving you any information you know it's you know if there's Synergy in the environment then you need to you know spend calories maintaining both pass both channels and so you know my guess is that there's probably some kind of evolutionary pressure that says you know agents with limited resources and complex environments probably want to maximize the number of synergies that they are sensitive to when building their world model while simultaneously minimizing the redundancies right so the redundancies are basically just waste of calories while the synergies are you know potentially very in ative you know higher order interactions that are well worth the calories and so this is about as far as I've gotten on this hypothesis but I think it would be something really interesting to explore uh down the line you know maybe either in very simple animal models or in some kind of in silico minimally conscious or not minimally conscious minimally cognitive agent kind of approach and again that's something that I would love to talk um to really anybody else about and then so you know that's sort of the end of my shiel here this is the paper was published in plus one um couple of months ago you know here is the link and I'll I'll send around the slides um afterwards if anybody wants them I can send them to Dan uh hopefully yeah um and yeah so so that's it this is work that I sort of largely did on my own so I don't have the usual sort of acknowledgement slides but I'll just um say Let's uh jump right to questions and I'd love to get feedback from anybody else on the work what you might think about it or what your own thoughts might be awesome thank you for the very very clear great presentation lot of places to jump in could you speak a little bit about redundancy and Synergy with respect to fragility and other system properties because having redundancy although like as you brought up in those last slides it might cost more energy and so in the short term it might appear like well why do we need to have redundant information when there are like component failures or other kinds of perturbations to the system what's redundant in one moment might come to be not redundant so how do you think about these kind of informational properties of systems or networks with respect to other systems properties so that's a great question and I'd be curious who asked it because I actually just put up a preprint about exactly that exactly that topic so I I don't know if they're aware of it so yeah that's a really good question you know um redundancy and Synergy how do they relate to things like fragility and robustness um I don't I don't have slides for this but I can give you just sort of the verbal um tldr uh I I just did this project where we took um very simple Boolean networks and uh I evolved them either to be uh very redundant or very synergistic and then since Boolean networks you know there's a lot of ways to characterize their Dynamics I ask sort of what are the Dynamics that kind of come along with Evolution for redundancy or Evolution for Synergy and what I found was that the the Redundant Boolean networks were extremely stable right you know you could perturb them and they would almost always fall back to you know one of a very small number of attractors you know they had very restricted State spaces they were kind of crystallized okay um in contrast the synergistic networks were um basically chaotic it was very hard to find ways in which they did not just appear to be you know chaotic systems you know using chaos in the sort of the technical sense here of sort of sensitive dependence on initial conditions you know very large State spaces lots of you know attractors you know small perturbations sent them off onto very different you know possible futures um and the you know the the punchline then was that you know if we took these two different networks then asked you know about their capacity to um integrate information and I Ed this measure of integrated information from integrated information Theory you know what I found was that the synergistic networks could integrate lots of information whereas the Redundant networks were very stable but could not integrate information at all right so there was sort of this this you know when you were at the extremes you could you know be very stable and totally unable to integrate information or you could be hilariously unstable with lots of integrated information right um and so the last thing that I tried then was I actually then evolved networks that had you know this this the the TSE complexity that I mentioned before you know this this um balance of integration and segregation and what I found was actually that the complex networks were able to sort of split this difference right you know they were sort of they were more stable than the purely synergistic networks you know they weren't as chaotic but they also had you know more capacity to integrate information than the crystalized networks right so you know we proposed this kind of um sort of multi-way tradeoff where redundancy brings stability but restricts your ability to integrate information whereas Synergy you know brings integrative capacity but is destabilizing or fragilized and then you can kind of balance those two things with this idea of complexity that you know brings together integration and segregation in a kind of you know sort of modular a modular structure and so that's been sitting under review at um chaos for like the last six months they have no idea what they're doing over there um but hopefully uh you know we will you know that will be impressed before um the end of my postto hopefully and I would you know there's a lot of work that I want to do um going on sort of trying to build on that as well so great question that's awesome I mean you've approached from very informational first oh sorry you've approached it from very informational first principles and recovered a lot of these topological and dynamical features of complex systems and how they have to trade off against these like multiple properties of systemness that sometimes might be like directly contradictory um a question in the live chat Celeste wrote How might G be related with network controlability Ah that's a really good question and um I'm G I'll be honest I have no idea um uh Network control theory is something that i' you know I'm I'm a consumer of network control theory I'm not a producer you know so I'll see these papers you know like Parker Singleton had a great one looking at um like Network control theory and you know LSD and siloc cybin I was like oh that's really cool but I don't I don't know enough about the theory to really get at it um I my guess just sort of just off the cuff would be that redundancy would make the network perhaps less controllable because you know it always wants to fall back into you know like its main attractor whereas Synergy you know probably lowers the energy needed to um you know push you onto a different you know part of the configuration space but you know it's maybe less stable maybe more fragile so so I I I think that this is a great case where um you know some some simple toy models maybe some analysis of um fmri data could go a long way to you know answering a really interesting question question um but I you know I can't say for certain other than just sort of those very sort of handwavy predictions but I'd love to see it I'd love to see it done cool yeah one thing that you brought at the ends with the two eyes looking at the object and getting depth it really made me think about the multiple scales of redundant and synergistic information like you have two photo receptors that are right next to each other so just from a first past correlational value it would seem like they're going to be highly correlated sensors I mean they're in a sensor array like on the retina and yet also the differences between retinal receptors are used to improve like signal to noise characteristics at multiple um steps in the relay of visual processing then you have the two eyes and depth perception and then there's also cross modal synergistic information like maybe if you just saw the video of somebody or only heard what they had to say it might convey certain information and yet putting them together that is very important for understanding like well how do different kinds of multi-modal experiences convey information about real world things and for cognitive modeling like of biological systems or design of cognitive systems these kinds of redundancies and synergy would basically be ignored at one's Peril because you can always describe kind of the syntactic flow of information and say like this is how much data at each moment we're pushing through this connectivity but that might be misleading or fragile or overdesigned or underes with respect to relatively obvious intuitive ways in which we fuse [Music] [Music] path of a given cognitive entity because while you're able to represent all the possible partitions and like you as a mathematician can can pick up that and handle it we might um from like an attentional networks in the brain perspective we might ask like well which node on this lattice should we be looking at like should how should we blend the indicators from person one and two to the um exclusion of three or two and three but not one those are like different attentional modes you can have and you could have a uniform prior across that lattice and just say well we're going to blur across all them but then once you start saying oh but I like this one and this one's irrelevant and these two are the same then you're getting into the business of reshaping the portfolio across the lattice and then that how do we deal with that when outside of dealing with these systems purely symbolically we actually want to be using certain partitions and and identifying useful um decomposed components like how do you think about that well so I mean first thing is you know you mentioned time again I again want to shout out um Pedro and Fernando and Andreas work on integrated information decomposition because they really you know I introduced it as this like multiple sources multiple targets but they have this incredibly cool um application of that where they say okay well all the sources [Music] nobody has ever like computed it right um so finding ways to kind of you know figure out you know how how do we get sort of the information how do we make this information accessible to us as modelers you know is like sort of sort of an outstanding problem as well um which is kind I think kind of getting what you're saying and then the other thing is that like as the lattice gets bigger the the particular atoms become like hilariously Arcane right it's like okay what information could be learned by observing X1 and X2 and X9 and X10 or X1 and X2 and X3 and X9 or X1 and X2 and X7 you know like you end up with these incredibly long chains of logical dependencies that you know my guesses almost certainly don't mean anything right and so again figuring out some way to extract or just decide what are the meaningful dependencies right not just like what are all of the dependencies you know as a mathematician I like completeness right I like having the whole the whole pie but you know again outside of that you know the question of how do we figure out what information is sort of relevant to us um that's that I think is a standing problem you know I think there's a lot of space there for Creative you know attacks um on the question because there isn't you know i' I've taken my own swing at it other people have as as well I think you know again there's a lot of sort of work still to be done in that space and it's very exciting to see what people will come up with in the coming you know next five 10 years yeah few thoughts on that first I think what you said there about even with 10 retinal receptors or like an insect eye with multiple iddia like once you get to 10 enumerating the lattice is is not even finitely accomplishable and I think that in a way must speak to the relevance of coar graining and nesting of models because you couldn't you you couldn't have 10 people in a room and all those par wise combinations happen so like there has to be some clustering and and nesting um and then also that um what you said about the specific atoms being like hilariously Arcane reminded me of random Forest modeling and you also had the kind of logical framework so then it's sort of like tell me either your favorite cereal and what color of this car you would want or this and that and like the concept is yeah those are drawn from a massive State space of possible thresholds or or choices yet through statistics and iteration some of those thresholds May identify kind of critical decision points with within an empirical State space which is probably going to be existing on like manifolds or subspaces that don't require the full unpacking of the lattice but there might be whole like territories of the lattice that you can just average over but the question is how nicely are those distributed on the whole lattice if those are distributed randomly then there may not be many ways to work with it but if those are all on one side then a random for with a simple first question might like bring one into a useful area yeah that's a really interesting idea I never thought about the link to random Forest before but I'm going to write that down and um you know take a stab at I like that a lot cool yeah um I guess one of the interesting questions too is information for whom and about what like in the yeah in the math that's kind of generalized over appropriately so but then when we're constructing active inference models and we're actually using the K Divergence like in the variational free energy where the K Divergence is used like in the complexity minus accuracy way to talk about it or when we're using K Divergence in the expected free energy prospective setting thinking about like the Divergence between what we prefer for observations and for how we think different kinds of courses of action are going to play out looking at those divergences it does get very specific what we're talking about the reduction with respect to so how how do you bring something that's kind of generalized across observers and types of variables and bring that from being kind of an analytical result into being something like the air conditioner is reducing the K Divergence about preferred temperatures with respect to courses of air conditioning what happens between having this math and being able to use it in those settings so so that's that's a really good question and you know like again coming from a math perspective like I'm always like gunning for full generality right like the less useful this is like the happier I am but you know like it like the G really is just you know it is a a decomposition of the KL Divergence right like all of the the general stuff is kind of you know it's sort of an added bonus so you know you could have a KL Divergence where you know your prior and your posterior are very well defined right you're like I know exactly what my prior is I know exactly what my posterior is I know exactly how to interpret it and then you can just go ahead and you know crank the G handle and you know you'll get the decomposition back out so I think you know the you know the again I approach it from sort of the general perspective but if you want to sort of take it and make it specific you know that's I there's no I think fundamental mathematical problem with that it's really just a question of you know how to what extent can you specify exactly sort of what your priors and posteriors are and how you then interpret the resulting numbers right because the G itself doesn't care about the interpretation it just says like we have one distribution we have another distribution and like they have this structure that relates them but you know if you you know have your interpretation and your you know sort of let's say maybe domain knowledge that sort of specifies everything then yeah I think that that's you know that the generality is not necessarily a problem you know how would you connect this to the concept of like known unknowns and unknown unknowns oh boy um so the problem with information theory is that it it has it has a very hard time with unknown unknowns right like it kind of assumes that you have the distributions you know that you have all of the the distribute like how do I how do I say this this is a little a little bit um getting a little Tongue Tied here so you know the from the perspective of the K Divergence like all it sees is what's in the distribution right you know and you know so you plug the distributions in you turn the the math crank and you get numbers out there's not an obvious or real way I think to account for the possibility that there is sort of you know meta uncertainty right like you can be uncertain about you know what's probability of X1 what's the probability of X2 right but there's you know what is the pro like how are like how certain are you about these certainties that's something that as far as I know you know the sort of vanilla information theory that I'm familiar with really actually really quite struggles with you know and I I'm really interested in in climate science and climate change kind of stuff and you know I keep running into this idea of like deep uncertainty right like how you know what's the probability that your probability distrib tion is actually the right one you know and that's like there's I think some very cool work happening in that space But it's you know a step or two Beyond you know what what I what I think can be tackled with what I've presented here so I guess I I don't know um I think that that's something that we've got to work work on yeah that's that's super interesting it reminds me even back in learning about like the mean and the variance of a distribution it's like Okay so we've parameterized our uncertainty about the mean and we called that the variance but then how certain are we or how do we get a P value on the uncertainty and then in the hierarchical basian modeling approach you can just keep on going but the Buck has to stop somewhere and then you can go to kind of another set of methods and pick different prior distributions for that highest possible prior um or take other approaches but that's like a very kind of composite approach that is not necessarily returning back down to the Simplicity of of the initial question you're just getting into like higher orders like what if there what is the probability that there was another element that we were missing and then that but that could um in increase the complexity of the problem so much that even a simple question would be kind of like unnecessarily exploded because of even a very small probability of something happening that changes the state space of the initial question very greatly and then that would kind of like potentially um forego a lot of lwh hanging fruit to kind of cover the bases against some rare events which still might not even be detected because you would have just basically turned some kind of unknown unknown into a Known Unknown but at expensive cost and making the problem quite different so it's kind of like is that something that can be resolved in an airtight way or is that kind of like the openness that just requires iterated engagement yeah I mean my my my sort of my intuition is always you know sort of keep things as simple as possible you know but not too simple like that the quote the quote says you know I I I in in the paper I write a lot about like all of the contexts in which you shouldn't use the G right that was like something that I spent a lot of time on and so you know the K Lio Divergence does have sort of these odd limitations or for instance you know anywhere that you know Q of X is zero you know where you know you have a you know something happens in the posterior that you didn't think could happen the prior like the whole thing blows up right and so I do think that if you wanted to use this in an analytical context you know or in a practical context not just a theoretical one you know would require a lot of thoughts about like is this actually the right tool you know for the question that I want to answer you know and it's entirely possible that no it's not the G the p is not the right tool for you know a system where or you have you know changing support sets you know or unknown unknowns and and that's fine you know there's you know plenty of mathematical um toys in the Box for us to play with and so I guess like my response to that would be like if you find yourself asking those questions like maybe just don't use the G or the P ID maybe there's something else that would be a more appropriate uh appropriate tool for your question H that Al Al makes me think about like the concept of I guess different ways to approach it but like information or or stimuli that have an informational impact information cannot be negative per se yet there are ways to move distributions up and down and then there are ways in which the movement of that distribution up or down would have like an adaptivity benefit or detriment to an organism so information is just kind of at this level this is um coming in lower in the processing that it it is not necessarily a complete answer to questions about complex systems however it helps ground and anchor some subsequent questions about their higher order Dynamics in a way that skipping [Music] [Music] just we'll wait a minute if anyone in the chat has any last questions but I mean where and how are you going to take it forward so I'm really interested you know I've spent most of my PhD I kind of spent working on like the mathematics of these things you know I wrote about the peed I wrote about this you know I've worked on some other stuff I'm really curious about like where can this be applied to real data right and so know I'm working currently I'm at the University of Vermont I'm working with Josh bongard and Mike 11 on um some sort of interesting projects in like evolutionary Computing and evolutionary biology to see like you know where are these you know are are these synergies in nature and are they telling us anything about the the sort of behavior or structure of organisms you know I'm still interested in Neuroscience you know um I sort of a long-standing interest in like psychedelic neuroscience and so you know whether there are changes to redundancies and synergies in the brain you know when you're you know on DMT or whatever uh could that help explain why phenomenal logical Consciousness changes that's something I've worked on um before as well and so really trying to find ways to get out of like sort of math Theory land and see like does this actually tell us something about nature as opposed to just like the structure of information theory is sort of what I'd like to do um next although that's also expensive and requires data whereas pure Theory just needs a whiteboard and a a latte compiler so it's a lower overhead just on that kind of like Altered States Of Consciousness and and um and all of those possibilities it's almost like what what decompositions help one like gain knowledge about thems or about something else and it might be like a decomposition of like this amount of that in this setting or this amount in that setting provide information on a a common Target distribution and that Maps out like an architecture that's not this part of the brain's connected to that one it's not even necessarily the architecture of kind of like the dynamic causal modeling of the neuroanatomy but it really would be toward like architectures of beliefs and how they have different equivalences or or relationships yeah there's um there's a really interesting uh set of papers by Robin carard Harris and Carl friston looking at sort of a free energy or a basian approach to like psychedelic therapy like how do our beliefs change and how does you know tickling these serotonin receptors change our change our beliefs and so I think that would be a really interesting place to try to um apply something like this if you could get like meaningful p's and q's right like you know if you're looking at something like you know post-traumatic stress disorder right you know you're changing your beliefs not just about like the world around you but also like your own interor reception you know is the capacity to you know heal from trauma or something does that require a higher order a synergistic you know change in sort of the joint states of your beliefs about the world and yourself that is sort of not trivially reducible to like just tweaking one or tweaking the other right and so you know getting into sort of more of this um sort of cognitive cognitive kind of stuff I think would be really interesting I also you know one one thing I I didn't mention when we talk about future stuff is one that I've been working on quite recently is you know the the P and the peed you know it's all gamed out currently in terms of entropies and mutual informations but as long as you have a function a general function that satisfies certain axioms you know non- negativity um you know mon picity yada yada yada you can also get a lattice and you can also do like the mobious inversion and get the decomposition so I've been working a lot on you know taking you know what I'm calling sort of like structure decomposition like if you have a network you know you know and you have a measure like the communicability which does satisfy all of the sort of the the desidera to induce a decompos information decomposition you could do a communicability decomposition right looking at like the influence of edges or nodes to this measure the communicability instead of the information you know or you could look at the shortest path efficiency this one also satisfies all of those requirements and so you know can we take these logical mathematical structures that were developed in the context of information and entropy and apply them to other things you know um I'm looking I'm a network guy by training so I'm looking at Network measures now but you know could you how far could you push this right could you start looking at maybe psychological constructs could you start looking at you know dynamical properties like the I don't know the I having a stroke I'm drawing a blank on any good dynamical properties but you you get the sort of the idea of what I'm you know what I'm trying to say like how far can we push this logical structure to look at higher order interactions in other contexts that are information theoretic yes that just makes me feel like networks give a discretized and topological handle on families of continuous phenomena or the phenomena could be discreet at the node level but we could just be talking about a continuous statistical distribution so that at the node level gives us continuity and connection with empirical data and statistics and then the math picks up up with these discretized lates and kind of like studying a tree is like studying a tree and then you pull back and you have a model of the forest and then what could you know by studying two trees well they could be giving redundant information they could be giving synergistic information about what and then it's kind of like off one goes on that inquiry yeah huge potential there I think for a lot of really cool sort of new ways of thinking about complex systems awesome um if you have any last comments feel free to go for it otherwise this has been epic and very informative um you know all I'll say is you know you can find me uh you can find me on Twitter you know you can you know my you can find me on my my email um you know I'm always open I don't know how many people are on the on the YouTube right now but I was I'm always open to like collaboration talking to people you know like I am you know if any of this is interesting to you shoot me an email please and I would be happy to talk you know about any and all of this like my inbox is open so I look forward to hearing from folks thank you for that and thank you again for joining so till 10.2 see you bye e